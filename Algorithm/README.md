# BFS
* 큐를 이용해서 메모리를 힙에 넣고 빼고 크기 조정 없기 때문에 유리
* 어떤 대상을 조건에 맞게 동작하도록 코드 구현

# DFS
* 스택 이용해서 사용; 크기 조정 필요하기 때문에 BFS에 비해 복잡
* 모든 경우를 만들어 보는 경우

# 백준
## 완전 탐색(Brute-force Search)  [bruːt]  
* 비트 마스크, 순열
* 큐, 

## 예제
* 9095, 1107, 1476
* 차이를 최대로: 10819
* 외판원순회: 10971
* 로또: 6603
* 큐(BFS): 1697, 1963(소수경로), 9019(DSLR), 1525(퍼즐), 물통(2251)
* 재귀호출, 비트마스크: 9095, 암호만들기(1759), N-Queen(9663), 스도쿠(2580), 알파벳(1987), 부분집합의 합(1182)
* 수들의 합 2(2003), 소수의 연속합(1644)
* 덱사용 알고스팟(1261), 중간에서 만나기(1208), 합이 0인 네정수(7453)


## DP
* O(높이 제곱) 을 O(n)으로 낮춰줌

# 순서도
## 증감문
* 증감문이 위면 < 아래면 <=

# for문
- for( 식1 ; 조건1 ; 식2)
{
   코드 1
}

## 정답
- 식1 수행 --> 조건1 검사 --> 코드1 수행 --> 식2 수행 --> 조건1 검사 --> 코드1 수행 --> 식2 수행 --> 조건1 검사 …

## 오답
- 식1 수행 --> 조건1 검사 --> 코드1 수행 --> 조건1 검사 --> 식2 수행 --> 코드1 수행 --> 조건1 검사 --> 식2 수행 .



-- 
# 정렬
* 버블(쓰레기), 선택정렬  -> 삽입(best n) -> 셀정렬(보완)
* 분할정복: 병합정렬, 퀵정렬(합병 정렬(merge sort)과 달리 퀵 정렬은 리스트를 비균등하게 분할한다, 배열의 병합정렬과 달리 추가 메모리 공간을 필요로 하지 않는다)

## 버블 정렬  n2 n2 n2
* 서로 인접한 두 원소를 검사하여 정렬하는 알고리즘
* 인접한 2개의 레코드를 비교하여 크기가 순서대로 되어 있지 않으면 서로 교환한다.
* 서로 인접한 두 원소를 검사하여 정렬하는 알고리즘
* 인접한 2개의 레코드를 비교하여 크기가 순서대로 되어 있지 않으면 서로 교환한다.
 * N * (N + 1) / 2  여서 O(N2) 이지만 가운데 스왑을 계속 해주어야 해서 삽입정렬보다도 실질적으로 안좋은 제일 안좋은 정렬
* https://gmlwjd9405.github.io/2018/05/06/algorithm-bubble-sort.html


### 장점
* 구현이 매우 간단하다.

### 단점
* 순서에 맞지 않은 요소를 인접한 요소와 교환한다.
* 하나의 요소가 가장 왼쪽에서 가장 오른쪽으로 이동하기 위해서는 배열에서 모든 다른 요소들과 교환되어야 한다.
* 특히 특정 요소가 최종 정렬 위치에 이미 있는 경우라도 교환되는 일이 일어난다.
* 일반적으로 자료의 교환 작업(SWAP)이 자료의 이동 작업(MOVE)보다 더 복잡하기 때문에 버블 정렬은 단순성에도 불구하고 거의 쓰이지 않는다.


## 삽입 정렬  n n2 n2
 * 자신보다 앞의 원소가 큰지 작은지 비교를 하여서 자신의 위치를 찾아서 '삽입' 하는 정렬입니다.
 * 앞의 원소를 비교해야 하기 때문에 arr[1]~arr[n] 까지 진행합니다. (두번째 원소인 arr[1] 부터 시작.)
 * 삽입을 하면 데이터가 하나씩 밀려야 하기 때문에 배열이 길어질수록 효율이 떨어집니다.

### 장점
* 안정한 정렬 방법
* 레코드의 수가 적을 경우 알고리즘 자체가 매우 간단하므로 다른 복잡한 정렬 방법보다 유리할 수 있다.
* 대부분위 레코드가 이미 정렬되어 있는 경우에 매우 효율적일 수 있다.

### 단점
* 비교적 많은 레코드들의 이동을 포함한다.
* 레코드 수가 많고 레코드 크기가 클 경우에 적합하지 않다.
* https://gmlwjd9405.github.io/2018/05/06/algorithm-insertion-sort.html

## 선택정렬  n2 n2 n2
 * 제자리 정렬(in-place sorting) 알고리즘의 하나
 * 입력 배열(정렬되지 않은 값들) 이외에 다른 추가 메모리를 요구하지 않는 정렬 방법
 * 해당 순서에 원소를 넣을 위치는 이미 정해져 있고, 어떤 원소를 넣을지 선택하는 알고리즘
 * 첫 번째 순서에는 첫 번째 위치에 가장 최솟값을 넣는다.
 * 두 번째 순서에는 두 번째 위치에 남은 값 중에서의 최솟값을 넣는다.
 * 선택 정렬은 첫 번째 자료를 두 번째 자료부터 마지막 자료까지 차례대로 비교하여 가장 작은 값을 찾아 첫 번째에 놓고, 두 번째 자료를 세 번째 자료부터 마지막 자료까지와 차례대로 비교하여 그 중 가장 작은 값을 찾아 두 번째 위치에 놓는 과정을 반복하며 정렬을 수행한다.
* 1회전을 수행하고 나면 가장 작은 값의 자료가 맨 앞에 오게 되므로 그 다음 회전에서는 두 번째 자료를 가지고 비교한다. 마찬가지로 3회전에서는 세 번째 자료를 정렬한다.
 
### 과정 설명
 * 주어진 배열 중에서 최솟값을 찾는다.
 * 그 값을 맨 앞에 위치한 값과 교체한다(패스(pass)).
 * 맨 처음 위치를 뺀 나머지 리스트를 같은 방법으로 교체한다.
 * 하나의 원소만 남을 때까지 위의 1~3 과정을 반복한다.
 * https://gmlwjd9405.github.io/2018/05/06/algorithm-selection-sort.html


### 장점
* 자료 이동 횟수가 미리 결정된다.

### 단점
* 안정성을 만족하지 않는다.
* 즉, 값이 같은 레코드가 있는 경우에 상대적인 위치가 변경될 수 있다.
* https://gmlwjd9405.github.io/2018/05/06/algorithm-selection-sort.html

## 퀵 정렬  nlogn, nlogn n2
* 분할 정복 알고리즘의 하나로, 평균적으로 매우 빠른 수행 속도를 자랑하는 정렬 방법
* 합병 정렬(merge sort)과 달리 퀵 정렬은 리스트를 비균등하게 분할한다.

 - 장점
 * 속도가 빠르다.
 * 시간 복잡도가 O(nlog₂n)를 가지는 다른 정렬 알고리즘과 비교했을 때도 가장 빠르다.
 * 추가 메모리 공간을 필요로 하지 않는다.
 * 퀵 정렬은 O(log n)만큼의 메모리를 필요로 한다.
 - 단점
 * 정렬된 리스트에 대해서는 퀵 정렬의 불균형 분할에 의해 오히려 수행시간이 더 많이 걸린다.
 * 퀵 정렬의 불균형 분할을 방지하기 위하여 피벗을 선택할 때 더욱 리스트를 균등하게 분할할 수 있는 데이터를 선택한다.
 * EX) 리스트 내의 몇 개의 데이터 중에서 크기순으로 중간 값(medium)을 피벗으로 선택한다.


### 퀵정렬 과정
 * 리스트 안에 있는 한 요소를 선택한다. 이렇게 고른 원소를 피벗(pivot) 이라고 한다.
 * 피벗을 기준으로 피벗보다 작은 요소들은 모두 피벗의 왼쪽으로 옮겨지고 피벗보다 큰 요소들은 모두 피벗의 오른쪽으로 옮겨진다. (피벗을 중심으로 왼쪽: 피벗보다 작은 요소들, 오른쪽: 피벗보다 큰 요소들)
 * 피벗을 제외한 왼쪽 리스트와 오른쪽 리스트를 다시 정렬한다.
 * 분할된 부분 리스트에 대하여 순환 호출 을 이용하여 정렬을 반복한다.
 * 부분 리스트에서도 다시 피벗을 정하고 피벗을 기준으로 2개의 부분 리스트로 나누는 과정을 반복한다.
 * 부분 리스트들이 더 이상 분할이 불가능할 때까지 반복한다.
 * 리스트의 크기가 0이나 1이 될 때까지 반복한다.
 * 분할(Divide): 입력 배열을 피벗을 기준으로 비균등하게 2개의 부분 배열(피벗을 중심으로 왼쪽: 피벗보다 작은 요소들, 오른쪽: 피벗보다 큰 요소들)로 분할한다.
 * 정복(Conquer): 부분 배열을 정렬한다. 부분 배열의 크기가 충분히 작지 않으면 순환 호출 을 이용하여 다시 분할 정복 방법을 적용한다.
 * 결합(Combine): 정렬된 부분 배열들을 하나의 배열에 합병한다.
 * 순환 호출이 한번 진행될 때마다 최소한 하나의 원소(피벗)는 최종적으로 위치가 정해지므로, 이 알고리즘은 반드시 끝난다는 것을 보장할 수 있다.
 * https://gmlwjd9405.github.io/2018/05/10/algorithm-quick-sort.html

### 퀵 정렬 단계


### 장점
* 속도가 빠르다.
* 시간 복잡도가 O(nlog₂n)를 가지는 다른 정렬 알고리즘과 비교했을 때도 가장 빠르다.
* 추가 메모리 공간을 필요로 하지 않는다.
* 퀵 정렬은 O(log n)만큼의 메모리를 필요로 한다.

### 단점
* 정렬된 리스트에 대해서는 퀵 정렬의 불균형 분할에 의해 오히려 수행시간이 더 많이 걸린다.
* https://gmlwjd9405.github.io/2018/05/10/algorithm-quick-sort.html

## 힙 정렬  nlogn nlogn nlogn
 * - 사실 선택 정렬과 거의 같은 알고리즘으로. 단지 가장 큰 원소를 뒤로 보내는 데에 단순히 매번 쭉 돌면서 알아내느냐 힙을 사용하여 알아내느냐가 유일한 차이점이다.
 * 힙정렬은 추가적인 메모리를 전혀 필요로 하지 않는다는 점과, 최악의 경우에 O(n2)의 성능을 내는 퀵정렬과 달리 항상 O(nlgn) 정렬의 성능을 발휘하는 장점이 있다. 하지만 실제 코드를 짜서 비교를 해 보면 퀵정렬이 힙정렬보다 일반적인 경우에 빠르게 동작한다.
 * 그러나 아래 퀵정렬의 경우 피벗을 잡는 전략에 어느 정도의 휴리스틱이 들어가야 최악의 경우를 회피할 수 있으나 힙정렬은 휴리스틱이 필요없이 항상 일정한 성능을 보이는 장점이 있다. 즉 알고리즘에 꼼수를 쓰지 않고, 각종 하드웨어 가속도 전혀 고려하지 않고 알고리즘이 정의하는 최소한만 구현할 경우 힙정렬이 가장 안정적인 성능을 보인다.

## 삽입(n, n2, n2), 힙(nlogn), 선택정렬(n2)
* 삽입 정렬은 두 번째 자료부터 시작하여 그 앞(왼쪽)의 자료들과 비교하여 삽입할 위치를 지정한 후 자료를 뒤로 옮기고 지정한 자리에 자료를 삽입하여 정렬하는 알고리즘이다.


## 쉘정렬  n n1.5  n2
* 정렬해야 할 리스트의 각 k번째 요소를 추출해서 부분 리스트를 만든다. 이때, k를 ‘간격(gap)’ 이라고 한다.
* 간격의 초깃값: (정렬할 값의 수)/2
* 생성된 부분 리스트의 개수는 gap과 같다.
* 각 회전마다 간격 k를 절반으로 줄인다. 즉, 각 회전이 반복될 때마다 하나의 부분 리스트에 속한 값들의 개수는 증가한다.
* 간격은 홀수로 하는 것이 좋다.
* 간격을 절반으로 줄일 때 짝수가 나오면 +1을 해서 홀수로 만든다.
* 간격 k가 1이 될 때까지 반복한다.
* https://gmlwjd9405.github.io/2018/05/08/algorithm-shell-sort.html

### 쉘 정렬이 나온 이유
* 삽입 정렬이 어느 정도 정렬된 배열에 대해서는 대단히 빠른 것에 착안
* 삽입 정렬의 최대 문제점: 요소들이 삽입될 때, 이웃한 위치로만 이동
* 즉, 만약 삽입되어야 할 위치가 현재 위치에서 상당히 멀리 떨어진 곳이라면 많은 이동을 해야만 제자리로 갈 수 있다.
* 삽입 정렬과 다르게 셸 정렬은 전체의 리스트를 한 번에 정렬하지 않는다.
* https://gmlwjd9405.github.io/2018/05/08/algorithm-shell-sort.html


### 장점
* 연속적이지 않은 부분 리스트에서 자료의 교환이 일어나면 더 큰 거리를 이동한다. 따라서 교환되는 요소들이 삽입 정렬보다는 최종 위치에 있을 가능성이 높아진다.
* 부분 리스트는 어느 정도 정렬이 된 상태이기 때문에 부분 리스트의 개수가 1이 되게 되면 셸 정렬은 기본적으로 삽입 정렬을 수행하는 것이지만 삽입 정렬보다 더욱 빠르게 수행된다.
* 알고리즘이 간단하여 프로그램으로 쉽게 구현할 수 있다.
* https://gmlwjd9405.github.io/2018/05/08/algorithm-shell-sort.html

## 병합정렬  nlogn, nlogn nlogn
* ‘존 폰 노이만(John von Neumann)’이라는 사람이 제안한 방법
* 일반적인 방법으로 구현했을 때 이 정렬은 안정 정렬 에 속하며, 분할 정복 알고리즘의 하나 이다.
* 분할 정복(divide and conquer) 방법
* 문제를 작은 2개의 문제로 분리하고 각각을 해결한 다음, 결과를 모아서 원래의 문제를 해결하는 전략이다.
* 분할 정복 방법은 대개 순환 호출을 이용하여 구현한다.

### 과정 설명
* 리스트의 길이가 0 또는 1이면 이미 정렬된 것으로 본다. 그렇지 않은 경우에는
* 정렬되지 않은 리스트를 절반으로 잘라 비슷한 크기의 두 부분 리스트로 나눈다.
* 각 부분 리스트를 재귀적으로 합병 정렬을 이용해 정렬한다.
* 두 부분 리스트를 다시 하나의 정렬된 리스트로 합병한다.


### 과정
* 2개의 정렬된 리스트를 합병(merge)하는 과정
* 2개의 리스트의 값들을 처음부터 하나씩 비교하여 두 개의 리스트의 값 중에서 더 작은 값을 새로운 리스트(sorted)로 옮긴다.
* 둘 중에서 하나가 끝날 때까지 이 과정을 되풀이한다.
* 만약 둘 중에서 하나의 리스트가 먼저 끝나게 되면 나머지 리스트의 값들을 전부 새로운 리스트(sorted)로 복사한다.
* 새로운 리스트(sorted)를 원래의 리스트(list)로 옮긴다.
https://gmlwjd9405.github.io/2018/05/08/algorithm-merge-sort.html


### 단점
* 만약 레코드를 배열(Array)로 구성하면, 임시 배열이 필요하다.
* 제자리 정렬(in-place sorting)이 아니다.
* 레크드들의 크기가 큰 경우에는 이동 횟수가 많으므로 매우 큰 시간적 낭비를 초래한다.

### 장점
* 안정적인 정렬 방법
* 데이터의 분포에 영향을 덜 받는다. 즉, 입력 데이터가 무엇이든 간에 정렬되는 시간은 동일하다. (O(nlog₂n)로 동일)
* 만약 레코드를 연결 리스트(Linked List)로 구성하면, 링크 인덱스만 변경되므로 데이터의 이동은 무시할 수 있을 정도로 작아진다.
* 제자리 정렬(in-place sorting)로 구현할 수 있다.
* 따라서 크기가 큰 레코드를 정렬할 경우에 연결 리스트를 사용한다면, 합병 정렬은 퀵 정렬을 포함한 다른 어떤 졍렬 방법보다 효율적이다.
* https://gmlwjd9405.github.io/2018/05/08/algorithm-merge-sort.html


## 힙정렬
* 완전 이진 트리의 일종으로 우선순위 큐를 위하여 만들어진 자료구조
* 최댓값, 최솟값을 쉽게 추출할 수 있는 자료구조
* 최대 힙 트리나 최소 힙 트리를 구성해 정렬을 하는 방법
* 내림차순 정렬을 위해서는 최대 힙을 구성하고 오름차순 정렬을 위해서는 최소 힙을 구성하면 된다.

### 과정 설명
* 정렬해야 할 n개의 요소들로 최대 힙(완전 이진 트리 형태)을 만든다.
* 내림차순을 기준으로 정렬
* 그 다음으로 한 번에 하나씩 요소를 힙에서 꺼내서 배열의 뒤부터 저장하면 된다.
* 삭제되는 요소들(최댓값부터 삭제)은 값이 감소되는 순서로 정렬되게 된다.


1. 내림차순 정렬을 위한 최대 힙(max heap)의 구현
* 힙(heap)은 1차원 배열로 쉽게 구현될 수 있다.
* 정렬해야 할 n개의 요소들을 1차원 배열에 기억한 후 최대 힙 삽입을 통해 차례대로 삽입한다.
* 최대 힙으로 구성된 배열에서 최댓값부터 삭제한다.

2. 최대 힙(max heap)의 삭제
* 최대 힙에서 최댓값은 루트 노드이므로 루트 노드가 삭제된다.
* 최대 힙(max heap)에서 삭제 연산은 최댓값을 가진 요소를 삭제하는 것이다.
* 삭제된 루트 노드에는 힙의 마지막 노드를 가져온다.
* 힙을 재구성한다.
* 아래의 최대 힙(max heap)에서 최댓값을 삭제해보자. 

### 장점
* 시간 복잡도가 좋은편
* 힙 정렬이 가장 유용한 경우는 전체 자료를 정렬하는 것이 아니라 가장 큰 값 몇개만 필요할 때 이다.
 
# 재귀함수
```C
#include <stdio.h>
#include<math.h>
int recursive(int n) {
   int i;
   if (n < 1) { return 2; }
   else
   {
      i = (2 * recursive(n - 1)) + 1;
      printf("%d\n", i);
      return i;
   }
}




void main() {
   int i;
   printf("숫자를 입력하시오");
   scanf_s("%d", &i);
   recursive(i);


}
//5 11 23 47 95
``` 
