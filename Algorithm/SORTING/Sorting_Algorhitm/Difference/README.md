### [Quick Sort와 Merge Sort 두 정렬알고리즘 모두 O(nlogn)의 시간복잡도를 갖는다. 그러나 많은 상용 라이브러리에선 내부적으로 QuickSort구현을 채택하고 있다. 이유가 무엇인가?](https://www.notion.so/Heap-Sort-Hash-Table-333efb4921544a73a27efcdb2a7788d3)

- 답변

    퀵소트는 worst case $O(n^2)$과 $O(nlogn)$의 평균 시간복잡도를 갖는다. 그러나 다른 여러가지 요소들을 고려했을 때, 결론적으로 퀵소트가 선호된다.

    첫번째 이유는 더 낮은 추가메모리가 소요되기 때문이다. merge sort는 추가적으로 O(N)의 메모리공간을 요구한다. 

    두번째 이유는, 퀵소트가 더 좋은 cache locality를 갖는 알고리즘이기 때문이다. 퀵소트는 피벗 주위로 인접해 있는 메모리들만을 참조하며 정렬하기 때문에 알고리즘 진행과정에서 cache hit를 최대한 이용하게되어 merge sort보다 빠르다. 

### Merge Sort와 Quick Sort가 데이터를 정렬하는 과정을 설명해주세요

- 답변

    **[퀵소트 설명]**

    퀵소트는 2 단계로 이루어져 있다.

    첫번째로, 정렬범위에서 피벗을 정해서 피벗 왼쪽엔 피벗보다 작은 숫자들을, 오른쪽엔 큰 숫자들을 배치시킨다. 이때의 총 연산횟수는 N번이다.

    두번째로, 각각의 범위에 재귀적으로 다시 첫번째 단계를 적용한다.

    이때, 동일한 순환호출단계의 모든 데이터범위에 첫번째 단계를 적용할때, 모든 비교연산횟수를 더하더라도 N번이다.

    따라서 피벗을 통해 최대한 정렬범위를 반씩 나눠 순환호출의 깊이를 작게 하는것이 중요하다.

    피벗을 계속해서 정렬범위의 중앙데이터로 정한다면, logN번만에 모든 정렬범위를 1로 만들 수 있고, 각각의 순환호출 단계의 총연산이 N이기 때문에, 정렬성능은 NlogN이다.

    **[머지소트 설명]**

    머지소트는 데이터의 중앙을 기준으로 데이터를 반으로 나눈다.

    범위가 1이 될 때까지 재귀적으로 반복된다.

    그리고 나눠진 각각의 범위를 합치면서 정렬하게 되는데, 이때 동일한 순환호출단계의 모든연산횟수는 O(N)이다.

    머지소트는 데이터를 정확히 반으로 나누기 때문에, 순환호출의 깊이는 logN이 보장되며, 따라서 전체 성능은 NlogN이다.

### Merge Sort와 Quick Sort를 비교해주세요

- 답변

    두 정렬 알고리즘 모두 평균적으로 O(nlogn)의 성능을 보이는 알고리즘 이다.

    그러나, 성능적으로 3가지 측면에서 다른 부분이 있다.

    첫번째로, 정렬을 위해 필요한 추가적인 메모리공간이 다르다. 퀵소트는 정렬에 추가적인 공간을 거의 필요로 하지 않는다. 그러나 머지소트는 데이터범위를 합칠때 임시배열에 해당 데이터를 담아야 하기 때문에 O(N)의 추가데이터가 필요하다.

    두번째로, 캐시 지역성을 활용하는 정도가 다르다. 퀵소트는 피벗값 주변의 메모리를 연속적으로 조회하며 정렬하기 때문에 캐시지역성을 최대한 활용한다고 알려져 있다. merge sort는 이보다는 거리가 먼 인덱스를 번갈아가며 조회하는 연산이 많기 때문에 캐시지역성 활용도가 떨어진다.

    세번째로, 퀵소트는 worst case 시간복잡도가 $O(N^2)$ 가 나올 수 있다는 점이 다르다. pivot 값을 어떻게 정하느냐에 따라 재귀호출의 깊이가 달라진다. 최대 N까지 나올 수 있는데 이 경우 시간복잡도가 O(N^2)이 나오게 된다.
