
# TCP
* 이론상 느릴 수 있다지 속도는 UDP와 큰 차이가 

## [TCP Header](https://evan-moon.github.io/2019/11/10/header-of-tcp/)


# [TCP 구조](https://www.youtube.com/watch?v=cOK_f9_k_O0&list=PL0d8NnikouEWcF1jJueLdjRIC4HsUlULi&index=18)
* 소스 포트(2) + 목적지(2) + Sequence Number(4) + Acnowledgement Number(4)
+ OffSet(4비트) + Reserved(4비트) + TCP Flags(1) + 윈도우(2)
+ CheckSum(2) + Urgent Pointer(2)
+ TCP Options(Variable length, optional, 4)

## Window
* 데이터 얼마만큼 더 보내

## TCP Flag
* C E U A P R S F
* 상대방의 연결 상태를 체크
* U: 긴급 비트
  * 우선순위가 높은 데이터가 포함되어 있다.
* A: 승인 비트
  * 물어본 것에 대한 응답을 해주는 플레그
* P: 밀어넣기 비트
  * 받을 수 있는 공간 상관 없이 밀어 넣겠다
* R: 초기화 비트
  * 상대방과 연결 되어있는 상태에서 우리 둘 사이의 관계를 초기화 하자
* S: Sync 동기화 비트
  * 상대방과 연결을 시작할 때 무조건 사용하는 비트
* F: Fin; 종료 비트
  * 연결을 끊을 때 사용하는 비트

### [Three Way handshake](https://www.youtube.com/watch?v=Ah4-MWISel8&list=PL0d8NnikouEWcF1jJueLdjRIC4HsUlULi&index=19)
* SYN > Syn + ACK > ACK
1. S: 100(처음 S는 랜덤; 와이어 샤크는 이해하기 쉽게 0으로 설정)  A: 0
2. S: 2000 A: 101(받은 S + 1)
3. S: 101(받은 ACK)  A: 2001(받은 S + 1)

### [단순히 TCp 패킷만을 캡슐화하여 통신하는 것이 아닌 페이로드를 포함한 패킷을 주고 받을 때의 일정한 규칙](https://www.youtube.com/watch?v=0vBR666GZ5o&list=PL0d8NnikouEWcF1jJueLdjRIC4HsUlULi&index=20)
* 보낸 쪽에서 또 보낼때는 SEQ번호와 ACK 번호가 그대로다
* 받는 쪽에서 SEQ 번호는 받은 ACK 번호가 된다
* 받는 족에서 ACk 번호는 받은 SEQ 번호 + 데이터의 크기


## Urgent Pointer
* 어디서부터가 긴급 비트인지 알려주는 포인터


# [TCP 상태 전이도](https://www.youtube.com/watch?v=yY0uQf0BTH8&list=PL0d8NnikouEWcF1jJueLdjRIC4HsUlULi&index=21)

## tcp가 만들어 진 이유
* TCP는 방금 이야기 했듯이 1970년 냉전 당시 미 국방성이 개발하던 알파넷 프로젝트의 일부로 개발되었는데, 그 당시 알파넷을 연구할 때 관심을 가진 주제 중에 하나가 바로 핵전쟁이 나도 살아남는 네트워크였다.(핵전쟁의 상대방은 당연히 마더 러씨아…)
* 왜냐하면 1970년대의 네트워크는 회선 교환 방식을 사용하고 있었기 때문에 중계국이 폭격을 맞아서 박살나거나 중간에 연결된 선이 하나가 잘려나가면 그대로 통신이 끊어져 버렸기 때문이다.
* 저 당시 중계국이 하는 일은 그냥 이거다. A가 중계국에 “B랑 연결해주세요!”라고 하면, 위의 사진과 같이 케이블이 마구 꽂혀있는 패치 테이블에서 A 라벨이 붙은 구멍과 B 라벨이 붙은 구멍을 찾아서 케이블로 연결해준다.
* 말 그대로 회선을 교환하는 방식인 것이다. 저러다가 A가 C랑 통신하고 싶으면 B 구멍에서 케이블을 빼서 C 구멍에 꽂으면 된다.
* 이렇게 회선 교환 방식의 경우에는 통신을 하고 싶은 상대방과 물리적으로 회선을 하나 딱 잡아놓고 계속 통신을 하는 것이기 때문에 회선의 효율이 낮을 수 밖에 없다. 우리가 전화를 걸 때 상대방이 통화 중이면 상대방이 통화 중이니... 어쩌고 나오는 것과 같은 원리이다.
* 물론 회선을 독점하기 때문에 대량의 데이터를 빠른 속도로 주르륵 보낼 수 있는 등의 장점도 있긴 하지만, 이때 미국에게 중요한 것은 핵이 터져도 끊기지 않는 연결이었기 때문에 하나의 회선에 전적으로 의존하는 연결이라는 건 큰 단점으로 다가왔을 것이다.
* 그래서 나온 아이디어가 바로 패킷 교환 방식이다. 데이터를 하나의 회선을 사용하여 보내다가 해당 회선이나 중계국이 개박살나면 전송되던 데이터와도 영원히 이별하게 되니, 데이터를 잘게 쪼갠 후 여러 개의 회선을 통해 보내자는 것이다. 일종의 분산투자랄까.
* 최악의 경우 중간에 있는 회선이나 중계국이 박살나서 데이터가 약간 유실될 수는 있겠지만 전체 네트워크를 한 번에 타격하지 않는 이상 모든 데이터가 유실될 가능성은 적다. 또한 하나의 회선을 잡아놓고 계속 통신하는 것이 아니라 패킷에 목적지를 마킹해놓고 그냥 보내기만 하면 되니, 회선의 사용 효율 또한 높아질 수 있다.
* 이런 이유로 미 국방성은 이 아이디어를 채택하여 알파넷에 적용했고, 초기 테스트도 대성공하여 패킷 교환 방식의 실용성을 증명했다.
* 이후 몇 개의 대학과 군에서만 사용되던 알파넷이 대중들에게 공개되고 전 세계적으로 연결되며 인터넷으로 발전하게 되었고, 덩달아 알파넷의 통신 프로토콜이었던 TCP도 함께 떡상하게 된 것이다.

## tcp 역할
* TCP(Transmission Control Protocol)은 원활한 통신을 위해 전송하는 데이터 흐름을 제어하고 네트워크의 혼잡 상태를 파악해서 대처하는 기능을 프로토콜 자체에 포함하고 있다.
* 만약 TCP가 이런 기능들을 제공해주지 않는다면 개발자가 일일히 데이터를 어떤 단위로 보낼 것인지 정의해야하고, 패킷이 유실되면 어떤 예외처리를 해야하는 지까지 신경써야하기 때문에 TCP가 제공해주는 이러한 기능들 덕분에 우리는 온전히 상위 레이어의 동작에만 집중할 수 있는 것이다.
* 보통 TCP의 전송 제어 방법은 전송되는 데이터의 양을 조절하는 흐름 제어, 통신 도중에 데이터가 유실되거나 잘못된 데이터가 수신되었을 경우 대처하는 방법인 오류 제어, 네트워크 혼잡에 대처하는 혼잡 제어로 나누어진다.
* 물론 TCP 같은 전송 계층의 프로토콜을 어플리케이션 레이어에서 활동하는 개발자가 건드릴 일은 많이 없다. 그러나 혹시라도 이 부분에서 뭔가 문제가 발생했을 경우, TCP가 어떤 식으로 작동하는지 모른다면 고치는 건 둘째치고 원인 파악조차 하지 못하는 슬픈 상황이 발생할 수 있으므로 여러모로 알아두는 것이 좋다고 생각한다. (더불어 야근도 따라올 것이다)

## 회선 교환에서 개선된 점
```java
하지만 패킷 교환 방식도 당연히 만능이 아니기에, 몇 가지 문제가 있었다. 우
리가 TCP를 공부할 때 함께 따라오는 ARQ나 SYN, ACK 등의 개념들이 바로 이런 문제들을 해결하기 위해 
과거의 엔지니어들이 머리를 싸맨 결과인 것이다.

Q: 전송 중간에 패킷이 쥐도새도 모르게 사라지거나 훼손되면 어떡해요?
A: 그럼 그 패킷만 다시 보내라고 해!(ARQ)
Q: 송신 측이 패킷을 쪼갠 순서를 알아야 수신 측이 재조립할 수 있겠는데요?
A: 그럼 순서번호를 패킷이랑 같이 보내!(SYN)
Q: 수신 측이 처리할 수 있는 속도보다 송신 측이 패킷을 빠르게 보내버리면 어떡하죠?
A: 그럼 수신 측이 처리할 수 있는 양을 송신 측에 알려주고 그 만큼만 보내라고 해! (슬라이딩 윈도우)
```

# TCP 프로토콜
* 안전한 연결을 지향하는 프로토콜





## 연결지향
* 이게 헷갈리는 이유는 물리적인 연결과 논리적인 연결의 차이 때문이다.
* 우리가 일반적으로 기기와 다른 기기를 연결했다고 할 때 떠올리는 생각은 컴퓨터와 모니터를 연결하거나, USB와 컴퓨터를 연결하는 등의 상황이다. 즉, 기기 간의 물리적인 연결이다.
* 반면, 연결 지향이라는 단어에서 사용하고 있는 연결의 의미는 논리적인 연결(Logical Connection)을 의미한다. 이때 당연히 여러 개의 기기가 서로 통신을 하기위해서는 물리적인 연결 또한 동반되어야한다.
조금 더 쉽게 이야기해보자면, 두 기기가 서로 연결되어 있는 상태를 유지하는 것이다.
* 전화를 예로 들자면, 전화가 전화선에 연결되어있는 것이 물리적인 연결이고 실제로 다른 전화와 통화를 하고 있는 상황이 논리적인 연결, 즉 연결되어 있는 상태인 것이다.
* 그렇다면 왜 TCP는 이런 연결 상태를 유지하는 걸까? 그 이유는 간단하다. 바로 연속적인 데이터 전송의 신뢰성을 위해서이다.
* 기본적으로 TCP는 패킷 전송 방식을 사용하기 때문에 보내려고 하는 데이터를 여러 개의 패킷으로 쪼개서 보낸다. 이때 네트워크를 통해 모든 데이터를 한번에 팍! 보내는 것이 아니라 일정 단위로 묶어서 스트림처럼 상대방에게 흘려보내게 된다.
* 그럼 한번 데이터를 받는 수신자 입장에서 생각해보자. 패킷 전송 방식의 장점 중 하나는 회선을 점유하지 않고 적은 양의 회선으로도 동시에 통신을 할 수 있다는 점이다.
* 그렇다는 것은 각 종단이 동시다발적으로 여러 기기들과 패킷을 주고 받고 있다는 의미인데, 이때 누가 보낸 몇 번째 패킷이라는 정보가 없다면 수신 측은 굉장히 혼란스러울 것이다.
* 위 그림에서 파이프는 물리적인 연결, 각 파이프 끝의 구멍은 포트, 양동이는 패킷을 처리할 프로세스라고 생각해보자. 이때 연결 상태에 대한 구분을 하지 않고 패킷을 구분하고 싶다는 것은 마치 한 양동이에 담긴 물 중에서 어떤 한 파이프 구멍에서 나온 물을 구분해내고 싶다는 말과 비슷하다.
* 그렇기 때문에 TCP는 A와 B의 연결 상태, A와 C의 연결 상태 등 각 기기간의 연결 상태를 따로 구분하고 있는 것이다. 이때 TCP는 상대방과 연결 상태를 만들거나 해제하기 위해 특별한 과정을 거치는데, 이 과정을 핸드쉐이크(Handshake)라고 한다.

# 3-way handshaking
- 클라이언트와 서버가 통신을 하기전 정확한 전송을 보장하기 위해 컴퓨터간 세션을 수립하는 과정으로서 TCP 프로토콜에서 신뢰성을 보장하기 위해 사용됩니다.

## 3-way handshaking이 어떻게 신뢰성을 제공하는가

## 3-wau handshaking 과정
- 초기 클라이언트 상태는 CLOSED 상태이고 서버의 열려있는 포트의 상태는 LISTEN 상태입니다. 먼저 클라이언트가 서버에게 SYN 신호를 보내면 서버에서는 SYN_RCV 상태로 변경됩니다. 다시 서버는 클라이언트에게 SYN 에 대한 응답으로 ACK 를 보내는데 이때 클라이언트의 포트도 열어달라는 요청으로 SYN 를 같이 보냅니다. ACK 와 SYN 를 받은 클라이언트는 ESTABLISHED 로 변경되고 응답신호로서 ACK 를 서버에게 보낸다. 마지막으로 서버가 ACK 신호를 받으면 ESTABLISHED 상태가 되면서 클라이언트와 서버간 연결이 성공합니다.

## 4-way handshaking
- 클라이언트와 서버가 연결하기 위해 3-way handshaking 과정이 필요하듯이 연결을 종료할때에도 데이터 손실없는 전송을 보장하기 위해 handshaking 과정이 필요한데 이것이 4-way handshaking 입니다.

## 4-way handshaking 과정
- 클라이언트가 종료하겠다는 신호인 FIN 을 서버에 보내고 자신은 FIN_WAIT_1 상태로 변경됩니다. FIN 을 받은 서버는 ClOSE_WAIT 상태로 변경되고 응답으로 ACK 를 보냅니다. ACK 를 받은 클라언트는 다시 FIN_WAIT_2 상태로 변경됩니다. 이때 서버는 남은 데이터를 모두 전송하고 전송을 다하면 연결을 종료한다는 신호로 FIN 을 클라이언트에 보며 LAST_ACK 상태로 변경됩니다. FIN 을 받은 클라이언트는 TIME_WAIT 상태로 변경되면서 응답으로 ACK 를 서버에 보내고, 자신은 일정시간이 지난 후 CLOSED 상태로 변경됩니다. 마지막으로 응답신호를 받은 서버는 CLOSED 상태로 변경되면서 포트를 닫게 됩니다.

## 서버가 마지막에 FIN 을 보내는 이유
- 서버가 아직 클라이언트에 보낼 데이터가 남아있을 경우 데이터를 다 전송하지도 못한채 클라이언트에서 포트를 닫아버리게 되므로 서버 또한 종료될 준비가 되었다는 의미로 FIN 을 보내게 됩니다.

## 클라이언트가 마지막에 ACK 를 굳이 보내는 이유
- 서버가 보낸 FIN 신호를 클라언트가 받지 못 할 경우 클라이언트는 FIN_WAIT_2 상태로 종료가 되지 못한채 계속 기다리게 될 것입니다. 허나 서버는 이미 포트를 닫고 더이상 응답을 안하는 상태이기에 클라이언트는 불필요한 자원을 소모하게 됩니다.


# [핸드세이크](https://evan-moon.github.io/2019/11/17/tcp-handshake/)
## 3 way HandHsake
* [3way]('https://evan-moon.github.io/2019/11/17/tcp-handshake/')
```java
1. CLOSED
아직 연결 요청을 시작하지 않았기 때문에 아무런 연결도 없는 상태이다.

2. LISTEN
수신자가 요청자의 연결 요청을 기다리고 있는 상태이다.
이후 요청자가 연결 요청을 보내기 전까지 수신자는 계속 이 상태로 대기하게 된다. 
즉, 적극적으로 상대방에게 대시하지 않는다는 것인데, 그래서 이 상태를 수동 개방(Passive Open)이라 하고, 
수신자를 Passive Opener라고도 한다.
소켓 프로그래밍을 할 때, 소켓 바인딩을 한 후 listen 함수를 호출하게 되면 수신자가 LISTEN 상태로 들어가게 된다.
이후 수신자는 요청자의 연결 요청이 확인되면 accept 함수를 호출하여 다음 단계로 넘어가게 된다.

3. SYN_SENT
요청자가 수신자에게 연결 요청을 하면서 랜덤한 숫자인 시퀀스 번호를 생성해서 SYN 패킷에 담아 보낸 상태이다. 
이제 요청자와 수신자는 이 시퀀스 번호를 사용하여 계속 새로운 값을 만들고 서로 확인하며 연결 상태와 패킷의 순서를 확인하게 된다.

TCP 세그먼트를 캡쳐할 수 있는 tcpdump 유틸리티로 이 과정을 확인해보면 요청자가 패킷의 플래그를 SYN 패킷을
의미하는 S로 설정하고 시퀀스 번호로 3414207244라는 값을 생성해서 수신자에게 보내고 있음을 알 수 있다.

이 경우는 요청자가 수신자에게 연결을 생성하자고 적극적으로 대시하는 상황이므로 이 상태를 
능동 개방(Active Open)이라고 하고, 요청자를 Active Opener라고도 한다.

4. SYN_RECV
SYN_RECV는 요청자가 보낸 SYN 패킷을 수신자가 제대로 받은 상태를 의미한다.

이후 수신자는 제대로 된 시퀀스 번호를 받았다는 확인의 의미인 승인 번호(Acknowledgement) 값을 만들어서
다시 요청자에게 돌려줘야한다. 이때 승인 번호는 처음 요청자가 보낸 시퀀스 번호 + 1이 된다.
이 승인 번호 만드는 과정은 어렵게 생각할 필요가 없는게, 저번 포스팅에서 이야기했듯이 
TCP를 사용하여 실제로 데이터를 주고 받을 때에는 상대방이 보낸 시퀀스 번호 
+ 상대방이 보낸 데이터의 byte를 합쳐서 승인 번호를 만들어낸다. 
즉, 내가 여기까지 받았으니, 다음에는 여기부터 보내달라는 일종의 마킹인 것이다.
그러나 이런 핸드쉐이크 과정에서는 아직 데이터를 주고 받지 않기 때문에 시퀀스 번호에 더할게 없다. 
그렇다고해서 시퀀스 번호를 같은 번호로 주고 받자니 패킷의 순서를 구분할 수 없지 않은가? 그래서 그냥 1을 더하는 것이다.
방금 전과 마찬가지로 tcpdump 유틸리티를 사용하여 이 과정을 확인해볼 수 있다.
수신자가 요청자에게 보내는 패킷을 캡처해보았더니 패킷의 플래그가 S.로 설정되어있다. 
이때 .가 의미하는 것은 헤더의 ACK 플래그 필드가 1이라는 것이므로 이 패킷에는 유효한 승인 번호가 담겨있음을 알 수 있다.
수신자는 이번 통신을 통해 요청자에게 3414207245 이라는 승인 번호를 전달하고 있는데, 
이 값은 방금 전 요청자가 보냈던 시퀀스 번호인 3414207244에 1을 더한 값이다.
또한 랜덤한 수로 자신의 시퀀스 번호인 435597555를 다시 생성하여 함께 요청자에게 보내주고 있는 것을 확인할 수 있다.

5. ESTABLISHED(요청자)
요청자는 자신이 맨 처음에 보냈던 시퀀스 번호와 수신자가 응답으로 보내준 승인 번호, 
즉 내 시퀀스 번호 + 1를 사용하여 연결이 제대로 성립되었는지 확인할 수 있다. 
자신이 보냈던 시퀀스 번호와 이번에 받은 승인 번호의 차가 1이라면 제대로 연결이 되었다고 판단하는 것이다.
이후 요청자는 연결이 성립되었다고 판단하고 ESTABLISHED 상태로 들어가면서, 
이번에는 수신자가 새롭게 만들어서 보내줬던 시퀀스 번호에 1을 더한 값을 다시 승인 번호로 사용하여 다시 수신자에게 보내준다.
즉, 마지막으로 수신자가 보내줬던 시퀀스 번호인 435597555에 1을 더한 값인 435597556이 요청자의 
승인 번호가 될 것이다…만 tcpdump의 동작은 필자의 예상과 달랐다.

6. ESTABLISHED(수신자)
요청자와 마찬가지로 수신자 또한 자신이 보냈던 시퀀스 번호와 이번에 받은 승인 번호의 차가 1이라면 
제대로 연결이 되었다고 판단하고 ESTABLISHED 상태로 들어가게된다. 
여기까지 오면 요청자와 수신자는 안전하고 신뢰성있는 연결이 생성되었다고 판단하고 본격적인 통신을 시작할 수 있다.
```

## 4 way handshake
```java
연결을 생성할 때와 마찬가지로, 연결을 종료할 때도 특정한 과정을 거쳐서 연결을 종료해야한다.
그냥 연결을 끊어버리면 안되냐고 할 수도 있지만, 한 쪽에서 일방적으로 연결을 끊어버리면 
다른 한 쪽은 연결이 끊어졌는지 지속되고 있는지 알 방법이 없다.
또한 연결을 종료하기 전에 아직 다 처리하지 못한 데이터가 있을 수도 있기 때문에 
양 쪽이 다 정상적으로 연결을 종료할 준비가 되었는 지를 확인하는 과정이 필요한 것이다.
이때 요청자와 수신자가 총 4번의 통신 과정을 거치기 때문에, 이 과정을 4 Way Handshake라고 부른다.
이번에도 요청자(Initiator)와 수신자(Receiver)라는 용어를 사용하고 있는데, 
3 Way Handshake와 마찬가지로 클라이언트와 서버, 둘 중에 어느 쪽이든 연결 종료 요청을 시작할 수 있기 
때문에 이런 용어를 사용하는 것이다.
먼저 연결 생성 요청을 했던 쪽이 먼저 연결 종료 요청을 보낼 수도 있고, 
반대로 처음에는 연결 생성 요청을 당했던 쪽이 이번에는 먼저 연결 종료 요청을 보낼 수도 있다.
사실 개발자들은 3 Way Handshake보다 연결을 종료하는 과정인 4 Way Handshake에 더 예민하게 반응할 수 밖에 없는데, 
연결을 생성하는 과정에서 문제가 발생하여 연결이 생성되지 않는다면 다시 시도하면 그만이지만, 
이미 생성된 연결을 종료하는 과정인 4 Way Handshake에서 문제가 발생하면 그대로 연결이 남아있기 때문이다.
게다가 4 Way Handshake는 3 Way Handshake처럼 순차적으로 주고받는 방식이 아니라 
상대방이 응답을 줄 때까지 대기하는 과정이 포함되어있기 때문에 중간에 뭐 하나 엇나가면 
서로 계속 대기만 하고 있는 데드락(Deadlock) 상황이 연출될 수도 있다.
물론 조건에 따라 일정 시간이 지나면 타임아웃이 되며 연결을 강제로 종료하거나 
다음 단계로 넘어갈 수도 있지만 그래도 그 시간 동안 프로세스가 메모리와 포트를 점유하고 있으므로 
트래픽이 많은 서버라면 이로 인해 병목이 발생할 가능성은 늘 있다.

1. FIN_WAIT_1
먼저 연결을 종료하고자 하는 요청자가 FIN 패킷을 상대방에게 보내면서 FIN_WAIT1 상태로 들어서게 된다.
이때 FIN 패킷에도 시퀀스 번호가 포함되어있긴한데, 이번에는 랜덤한 값으로 생성해서 보내는 것이 아니다. 
3 Way Handshake는 시퀀스 번호가 없는 상황에서 새로 만들어야하는 상황이라 랜덤한 값으로 초기화했지만, 
이번에는 시퀀스 번호를 새롭게 생성할 필요가 없으므로 그냥 자신이 이번에 보내야할 순서에 맞는 시퀀스 번호를 사용하면 되는 것이다.

요청자 —SEQ: 1—> 수신자
요청자 <—ACK: 2— 수신자
요청자 —FIN: 2—> 수신자
즉, FIN 플래그만 1로 변경해서 보낸다고 생각하는 게 편하다. 
이 플래그의 의미를 쉽게 얘기해보자면 “나 더 이상 할 말 없음” 정도이다.

이때 요청자가 먼저 적극적으로 연결 종료 요청을 보내는 것이기 때문에 요청자를 Active Closer, 
이 상태를 능동 폐쇄(Active Close)라고 한다

하지만 요청자가 수신자에게 보낸 연결 종료 요청 패킷을 캡처해보니 
F 플래그가 아니라 FIN+ACK를 의미하는 F. 플래그가 설정되어있다. tcpdump를 사용하여 
패킷을 캡처한 다른 블로그를 봐도 대부분 필자와 같은 상황을 겪고 있음을 알 수 있었다.

분명 이론적으로는 FIN 패킷을 보내야하는데 왜 승인 번호를 함께 묶어서 FIN+ACK로 보내고 있는 것일까?

* Half-Close 기법
요청자가 FIN+ACK 패킷을 보내는 이유는 바로 Half-Close라는 기법을 사용하고 있기 때문이다. 
Half-Close 기법은 말 그대로 연결을 종료하려고 할 때 완전히 종료하는 것이 아니라 반만 종료하는 것이다.

Half-Close를 사용하면 요청자가 처음 보내는 FIN 패킷에 승인 번호를 함께 담아서 보내게 되는데, 
이때 이 승인 번호의 의미는 “일단 연결은 종료할 건데 귀는 열어둔다. 이 승인 번호까지 처리했으니까 
마저 보낼 거 있으면 보내”라는 의미가 된다.

즉, 반만 닫겠다는 말의 의미는 연결을 종료할 때 전송 스트림과 수신 스트림 중 하나만 우선 닫겠다는 것을 의미하는 것이다.

이후 수신자는 미처 못 보낸 데이터가 있다면 열심히 보낼 것이고, 이에 요청자는 아직 살아있는 
수신 스트림을 사용하여 데이터를 처리한 후 ACK 패킷을 응답으로 보낼 수 있다. 이후 수신자가 모든 
데이터를 처리하고나면 다시 요청자에게 FIN 패킷을 보냄으로써 모든 데이터가 처리되었다는 신호를 보내준다.

그럼 요청자는 그때 나머지 반을 닫으면서 조금 더 안전하게 연결을 종료할 수 있는 것이다.

소켓 프로그래밍을 할 때 연결 종료 함수로 close()와 shutdown()을 사용할 수 있는데, 
이때 shutdown() 함수를 사용하면 Half-Close를 사용할 수 있다.

만약 요청자가 close() 함수를 사용하면 호출 즉시 OS에게 소켓의 리소스를 반환하며 
모든 스트림이 파기되므로 FIN 패킷을 받은 수신자가 미처 못 보낸 데이터를 뒤늦게 전송하더라도 더 이상 처리할 수 없는 상황이 된다.

위의 예제에서는 SHUT_WR 값을 두 번째 인자로 사용함으로써 전송 스트림만 우선 닫겠다고 선언한 것이다.

이와 관련된 더 자세한 정보는 구글에 Half-Close나 우아한 종료 등의 키워드로 검색하면 많은 자료가 나오니 한번 살펴보도록 하자.

2. CLOSE_WAIT
요청자으로부터 FIN 패킷을 받은 수신자는 요청자가 보낸 시퀀스 번호 + 1로 승인 번호를 만들어서 
다시 요청자에게 응답해주면서 CLOSE_WAIT 상태로 들어간다.

아까 요청자가 FIN 패킷의 시퀀스 번호로 701384376을 보냈으니 이번에 수신자가 응답해줄 승인 번호는 701384377이 되는 것이다.
이후 수신자는 자신이 전송할 데이터가 남아있다면 이어서 계속 전송한 후, 
모든 전송이 끝났다면 명시적으로 close()나 shutdown()과 같은 함수를 호출하여 다음 단계로 넘어갈 것이다.
즉, 요청자는 언제 수신자의 데이터 처리가 끝날지 모르는 상태이기 때문에 
수신자가 작업을 마치고 다시 연결 종료 승인을 의미하는 FIN 패킷을 보내줄 때까지 대기해야한다는 말이 된다.
만약 이 단계에서 수신자의 데이터 처리가 끝나도 연결 종료 함수가 명시적으로 
호출되지 않으면 다음 상태로 넘어갈 수 없기 때문에 데드락이 발생할 가능성이 있다.

이때 수신자는 상대방으로부터 연결 종료 요청을 받은 후에야 수동적으로 연결을 종료할 준비를 하기 때문에 
수신자를 Passive Closer, 이 상태를 수동 폐쇄(Passive Close)라고 한다.


3. FIN_WAIT_2
요청자는 수신자로부터 승인 번호를 받고 자신이 보냈던 시퀀스 번호와 승인 번호의 차가 1이 맞는지 확인한다. 
하지만 아직 수신자의 데이터 전송이 전부 끝나지 않았을 수도 있기에 FIN_WAIT2 상태로 들어가서 수신자가 
연결 종료를 허락하는 FIN 패킷을 보내줄 때까지 기다린다.

방금 CLOSE_WAIT 섹션에서 설명했듯이 여기서부터는 수신자가 다시 FIN 패킷을 보내줄 때까지 요청자는 계속 대기하는 시간이다.

하지만 CLOSE_WAIT와 다르게 무한정 대기만 하는 것은 아니고 커널 파라미터로 타임아웃이 정해져있는 경우, 
일정 시간이 경과하면 자동으로 다음 단계로 넘어갈 수 있다.

4. LAST_ACK
수신자는 자신이 처리할 데이터가 더 이상 없다면 연결을 종료하는 함수를 명시적으로 호출하고, 
아까 요청자가 보냈던 연결 종료 요청에 합의한다는 의미로 요청자에게 다시 FIN 패킷을 보낸다.

이때 수신자가 보내는 FIN 패킷에 담기는 시퀀스 넘버는 자신이 이번에 전송해야 하는 데이터의 
시퀀스 번호를 그대로 사용하며, 승인 번호는 마지막으로 자신이 응답했던 승인 번호를 그대로 사용한다.

이후 수신자는 LAST_ACK 상태로 들어가며 요청자가 다시 승인 번호를 보내줄 때까지 대기한다.

5. TIME_WAIT
수신자가 보낸 FIN 패킷을 받은 요청자는 다시 수신자가 보낸 시퀀스 번호 + 1로 승인 번호를 생성하여 
수신자에게 ACK 패킷으로 응답한다. 이후 요청자는 TIME_WAIT 상태로 들어가며, 실질적인 연결 종료 과정에 들어가게 된다. 
이때 TIME_WAIT의 역할은 의도하지 않은 에러로 인해 연결이 데드락에 빠지는 것을 방지하는 것이다.
TIME_WAIT에서 대기하는 시간은 2 MSL(Maximum Segement Lifetime)으로 정의되어 있으며, 
정확한 MSL의 시간 값은 커널 파라미터로 정의되어있다.

필자의 컴퓨터인 OSX의 MSL은 15초로 설정되어있다. 즉, 필자의 컴퓨터는 TIME_WAIT 상태에서 
30초 정도 대기한다는 것이다. 참고로 이 값은 변경할 수 없기 때문에 TIME_WAIT에서 소비되는 시간은 변경할 수 없다.

보통 TCP 타임아웃 파라미터로 많이 언급되는 net.ipv4.tcp_fin_timeout은 FIN_WAIT2의 타임아웃을 
조절할 수 있는 값이라 TIME_WAIT 상태에는 해당 사항이 없다.

하지만 CLOSE_WAIT와 마찬가지로 여기서도 데드락이 발생할 수 있다. 그런 이유로 많은 네트워크 
엔지니어들이 여기서 소비되는 시간을 줄이거나 운 나쁘게 발생한 데드락을 없애기 위해 tcp_tw_reuse 
커널 파라미터를 변경하는 등 여러가지 방법을 사용하고 있다. (데드락 피하자고 만든 상태인데 데드락이 발생하는 현실)

하지만 역시 그냥 가만 냅두는 게 제일 좋다고들 한다.

6. CLOSED(수신자)
요청자가 보낸 ACK 패킷을 받은 수신자는 CLOSED 상태로 들어가며 연결을 완전히 종료한다.

7. CLOSED(요청자)
TIME_WAIT 상태에서 2 MSL만큼 시간이 지나면 요청자도 CLOSED 상태로 변경된다. 
위에서 설명했듯이 이 시간은 커널 파라미터에 고정되어 있고, 필자가 사용하고 있는 OSX의 경우 30초 정도이다.
```

# [흐름제어와 혼잡제어](https://evan-moon.github.io/2019/11/26/tcp-congestion-control/)
```java
1. Flow control은  (호스트와 호스트 간의 데이터 처리를 효율적으로 하기 위한 기법, End to End)

 송신측과 수신측의 데이터처리 속도 차이를 해결하기 위한 기법이다.

 수신측이 송신측보다 속도가 빠른 것은 아무 문제가 되지 않는다.

 송신측이 수신측보다 속도가 빠르면 문제가 발생한다.

 수신측에서 수신된 데이터를 처리해서 윗 계층으로 서비스 하는 속도보다 송신측에서 보내는 데이터 속도가 더 빠르다면, 
 수신측에서 제한된 저장용량(일반적으로 큐)을 초과하여 이후에 도착하는 데이터의 손실을 가져올 수있다.

 그렇다면 불필요하게 응답과 재전송의 데이터가 다시 송신측과 수신측간에 비번히 이동해야한다.

 따라서, 이러한 위험을 줄이기 위해 강제로 송신측의 데이터 전송을 줄인다.

 

 1-1) Stop and wait 방식

   매번 전송한 패킷에 대해 확인응답을 받아야만 그 다음 패킷을 전송하는 방법

 

 1-2) 슬라이딩 윈도우 기법

   수신 측에서 설정한 윈도우 크기만큼 송신 측에서 확인 응답 없이 세그먼트를 전송할 수 있게 하여 
   데이터 흐름을 동적으로 조절하여 제어하는 기법이다.

   이 처럼 슬라이딩 윈도우 기법을 통하여 송신 버퍼의 범위는 수신 측의 여유 버퍼 공간을 반영하여 
   동적으로 바뀜으로써 흐름제어를 수행한다.

 

 

2. Congestion control은 (호스트와 네트워크 상의 데이터처리를 효율적으로 하기 위한 기법)

 송신측의 데이터 전달과 네트워크의 처리속도  차이를 해결하기 위한 기법이다.

 송신측의 데이터는 지역망이나 인터넷으로 연결된 대형 네트워크를 통해 전달된다.

 하지만 이러한 네트워크 상의 라우터가 항상 한가로운 상황은 아니다.

 만약, 한 라우터에 데이터가 몰릴 경우, 다시 말해 혼잡할 경우 라우터는 자신에게 온 데이터를 모두 처리할 수 없다.

 그렇게 되면 호스트들은 또 다시 재전송을 하게 되고 결국 혼잡을 가중시켜 오버플로우나 데이터 손실을 발생시킨다.

 따라서, 이러한 네트워크의 혼잡을 피하기 위해 송신측에서 보내는 데이터의 전송 속도를 강제로 줄이게 된다.

 

 2-1) Slow start

  윈도우 크기를 2배로 늘린다.

  그러다 혼잡현상이 발생하면 창 크기를 1로 떨어뜨린다.

  그 후 혼잡현상이 발생했던 창 크기의 절반까지는 이전처럼 지수 함수 꼴로(2배로) 
  창 크기를 증가시키고 그 이후부터는 완만하게 1씩 증가시킨다.

 

 2-2) Fast Recovery

   혼잡한 상태가 되면 창 크기를 1로 줄이지 않고 반으로 줄이고 선형 증가시키는 방식이다.



출처: https://jsonsang2.tistory.com/17 [리루]
```

# 흐름제어
* 송신 측과 수신 측이 서로 데이터를 주고 받을 때, 여러가지 요인에 따라 이 두 친구들의 처리 속도가 달라질 수 있다. 이때 데이터를 받는 수신 측의 처리 속도가 송신 측보다 빠른 경우는 사실 별 문제가 없다.
* 주는 족족 빠르게 처리해주니 딱히 문제될 것이 없는 것이다. 그러나 수신 측의 처리 속도보다 송신 측이 더 빠른 경우 문제가 생긴다.
* 송신 측과 수신 측은 모두 데이터를 저장할 수 있는 버퍼를 가지고 있다. 이때 수신 측이 자신의 버퍼 안에 있는 데이터를 처리하는 속도보다 송신 측이 데이터를 전송하는 속도가 더 빠르다면, 당연히 수신 측의 버퍼는 언젠가 꽉 차버릴 것이기 때문이다.
* [goodgid](https://goodgid.github.io/Error-Flow-Control/)
* [evan]['https://evan-moon.github.io/2019/11/22/tcp-flow-control-error-control/']
```java
TCP의 가장 큰 특징은 신뢰성이다.
이러한 신뢰성을 구성해 주는 방법인 흐름제어, 혼잡제어, 오류제어에 대해 알아보자.

송신(호스트) <> 수신(호스트)

흐름제어는 수신측과 송신측의 데이터처리 속도차이를 해결하기 위한 기법이다.

만약 송신측의 전송량 > 수신측의 처리량 일 경우, 전송된 패킷은 수신측의 큐를 넘어서
손실될 수 있기 때문에 송신측의 패킷 전송량을 제어하게 된다.

* 흐름제어 방법
1. 정지-대기(Stop-and-wait)
구조가 간단한 대신, 하나를 주고 응답을 받기 때문에 비효율적이다.

Stop and Wait로 흐름 제어를 할 경우의 대원칙은 단순히 상대방이 응답을 하면 데이터를 보낸다이기 때문에 
구현 자체도 간단하고 프로그래머가 어플리케이션의 작동 원리를 파악하기도 쉬운 편이다.

기본적인 ARQ(Automatic Repeat Request)를 구현한다고 생각해보면, 수신 측의 윈도우 크기를 
1 byte로 설정하고 처리 가능 = 1, 처리 불가능 = 0과 같은 식으로 대충 구현해도 돌아가기는 하기 때문이다.

하지만 서로 처리 가능, 처리 불가능 정도의 의미만 주고받는 방식은 간단한만큼 비효율적이라고 할 수도 있다. 
왜냐하면 송신 측은 자신이 직접 데이터를 보내봐야 이 데이터를 수신 측이 처리할 수 있는지 알 수 있기 때문이다. 
쉽게 말해서 이런 기초적인 Stop and Wait 방식은 그냥 될 때까지 주구장창 보내는 방식이라고 봐도 무방하다.

그런 이유로 Stop and Wait 방식을 사용하여 흐름 제어를 할 경우에는, 이런 비효율성을 커버하기 위해 
이런 단순한 구현이 아닌 여러가지 오류 제어 방식을 함께 도입해서 사용한다.



2. 슬라이딩 윈도우(Sliding Window)
윈도우는 전송,수신 스테이션 양쪽에서 만들어진 버퍼(Buffer)의 크기다.
윈도우의 크기 = (가장 최근 ACK로 응답한 프레임의 수) - (이전에 ACK 프레임을 보낸 프레임의 수)

슬라이딩 윈도우 기법은 앞의 정지-대기 기법의 비효율성을 개선한 기법이다.

ACK프레임을 수신하지 않더라도, 여러 개의 프레임을 연속적으로 전송할 수 있다.

전송측 윈도우 n-1 개의 프레임을 포함한다.



방금 알아본 바와 같이 Stop and Wait를 사용하여 흐름 제어를 하게 되면 비효율적인 부분이 있기 때문에, 
오늘날의 TCP는 특별한 경우가 아닌 이상 대부분 슬라이딩 윈도우(Sliding Window) 방식을 사용한다.

슬라이딩 윈도우는 수신 측이 한 번에 처리할 수 있는 데이터를 정해놓고 그때그때 수신 측의 
데이터 처리 상황을 송신 측에 알려줘서 데이터의 흐름을 제어하는 방식이다.

Stop and Wait과 여러 가지 차이점이 있겠지만, 사실 가장 큰 차이점은 송신 측이 수신 측이 처리할 수 있는 
데이터의 양을 알고 있다는 점이다. 이 정보를 알고 있기 때문에 굳이 수신 측이 처리 가능이라는 
대답을 일일히 해주지 않아도 데이터를 보내기 전에 이게 처리될 지 어떨지 어느 정도 예측이 가능하다는 말이다.

송신 측과 수신 측은 각각 데이터를 담을 수 있는 버퍼를 가지고 있고, 별도로 윈도우라는 
일종의 마스킹 도구를 가지고 있다. 이때 송신 측은 이 윈도우에 들어있는 데이터를 수신 측의 응답이 없어도 연속적으로 보낼 수 있다.

송신 측의 윈도우 크기는 맨 처음 TCP의 연결을 생성하는 과정인 3 Way Handshake 때 결정된다. 
이때 송신 측과 수신 측은 자신의 현재 버퍼 크기를 서로에게 알려주게 되고, 송신 측은 수신 측이 보내준
버퍼 크기를 사용하여 음, 대충 이 정도 처리 가능하겠군이라는 과정을 통해 자신의 윈도우 크기를 정하게 된다.

tcpdump를 통해 3 Way Handshake를 관찰해보면 처음의 SYN과 SYN+ACK 패킷에는 각자 자신의 버퍼를 알려준 후 
마지막 ACK 패킷 때 송신 측이 자신이 정한 윈도우 사이즈를 상대방에게 통보하는 것을 볼 수 있다.

이때 송신 측과 수신 측 모두 자신의 버퍼 크기라 65535라고 이야기했지만 최종적으로 송신 측이 정한 자신의 윈도우 크기는 6379이다. 
왜 송신 측은 수신 측 버퍼 크기의 10분의 1로 자신의 윈도우 크기를 정한 것일까?

사실 송신 측의 윈도우 크기는 수신 측의 버퍼 크기로만 정하는 것이 아니라 다른 여러가지 
요인들을 함께 고려해서 결정된다. 상대방이 보낸 버퍼 크기만 믿고 자신의 윈도우 크기를 정하기에는 
네트워크는 너무나도 험난한 환경이기 때문이다. 이때 사용하는 대표적인 값이 바로 패킷의 왕복 시간을 의미하는 RTT(Round Trip Time)이다.

송신 측은 자신이 처음 SYN 패킷을 보내고, 다시 수신 측이 SYN+ACK 패킷으로 응답하는 시간을 재고, 
이 값을 통해 현재 네트워크 상황을 유추한다. 이때 이 값이 너무 크다면 왕복 시간이 느리다는 것이므로 
네트워크 상태가 좋지 않다고 생각하고 윈도우 크기를 조금 더 줄이게 되는 것이다.

그리고 이때 정해진 윈도우 크기는 고정이 아니라 통신을 하는 과정 중간에도 계속 네트워크의 
혼잡 환경과 수신 측이 보내주는 윈도우 크기를 통해 동적으로 변경될 수 있다. 윈도우의 크기, 
즉 연속적으로 보낼 데이터의 양을 변경해가면서 유연하게 흐름 제어를 할 수 있다는 말이다.

윈도우에 대해 대략적으로 이해를 했다면 이제 이 기법을 왜 슬라이딩 윈도우라고 하는 지 한번 살펴보도록 하자.

먼저, 송신 측이 0 ~ 6번의 시퀀스 번호를 가진 데이터를 상대방에게 전송하고 싶어하는 상황을 상상해보자. 
이때 송신 측의 버퍼에는 전송해야할 데이터들이 이렇게 담겨져 있을 것이다.

이때 송신 측은 수신 측에게 받은 윈도우 크기와 현재 네트워크 상황을 고려하여 윈도우 크기를 3으로 잡았고, 
윈도우 안에 있는 데이터를 우선 주르륵 전송한다.
이때 윈도우 안에 들어있는 데이터는 어떤 상태일까? 일단 데이터를 전송하기는 했지만 아직 수신 측으로부터 
잘 받았다는 응답을 받지 못한 상태일 것이다.

즉, 윈도우에 들어있는 데이터들은 항상 전송은 했지만, 상대방이 처리했는지는 모르는 상태라고 할 수 있다. 
물론 데이터를 윈도우에 넣고 나서 블록킹이 걸려 데이터를 처리하지 못하는 상태도 존재할 수 있지만, 
그런 것까지 다 고려하면 너무 복잡하니까 간단하게 생각하도록 하자.

이후 수신 측은 자신의 처리 속도에 맞게 데이터를 처리한 후 응답으로 현재 자신의 버퍼에 남아있는 
공간의 크기를 알려준다. 만약 수신 측이 응답으로 Window Size: 1을 보냈다면 “내 버퍼 공간이 
1 byte만큼 남았으니까 그 만큼만 더 보내봐”라는 의미가 된다.

이제 송신 측은 자신이 데이터 한 개를 더 보낼 수 있다는 사실을 알았으니, 자신의 윈도우를 한 칸 옆으로 밀고 
새롭게 윈도우에 들어온 3번 데이터를 수신 측에게 전송한다.

이때 윈도우를 옆으로 이동시키며 새로 들어온 데이터를 전송하기 때문에 슬라이딩 윈도우라고 하는 것이다. 
만약 수신 측이 윈도우 크기를 1이 아니라 더 큰 수를 보냈다면, 송신 측은 그 만큼 윈도우를 옆으로 밀고 
더 많은 데이터를 연속적으로 전송할 수 있을 것이다.

단, 이 경우 송신 측의 윈도우 크기가 3이기 때문에 수신 측이 4를 보냈다고 해서 4칸을 밀지는 않고, 
자신의 윈도우 크기인 3만큼만 밀 수 있다. 그러나 이 경우에는 송신 측이 수신 측의 퍼포먼스가 
더 좋아졌다는 것을 알았으니 자신의 윈도우 크기를 늘리는 방법으로 대처할 수 있을 것이다.

이렇게 데이터를 전송하는 송신 측의 버퍼는 대략 3가지 상태로 나눠질 수 있다.

즉 슬라이딩 윈도우 방식은 보내고 -> 응답받고 -> 윈도우 밀고를 반복하면서, 
현재 자신이 보낼 수 있는 데이터를 최대한 연속적으로 보내는 방법이라고 할 수 있다.

이게 지금 0 ~ 6 밖에 안되는 단순화된 그림으로 봐서 잘 와닿지 않을 수도 있지만, 
아무런 옵션도 적용하지 않은 TCP의 최대 윈도우 크기는 65,535 bytes이고, WSCALE 옵션을 최대로 적용하면 1GB로 설정하는 것도 가능하다.

게다가 연속적으로 한번에 보내는 데이터도 이렇게 한 개, 두 개 정도가 아니라 몇 백 바이트 단위로 보내는 경우가 
많기 때문에 실제 환경에서는 Stop and Wait로 흐름 제어를 하는 것과 비교해봤을때 상당히 좋은 효율을 뽑아낼 수 있다. 
즉, 이론적으로는 수신 측의 ACK 응답 없이도 최대 1GB를 연속적으로 전송할 수 있다는 말이다.

이렇게 슬라이딩 윈도우 방식은 일일히 하나 보내고, 응답 받고 하는 Stop and Wait보다 확실히 전송 속도 측면에서 빠르기도 하고, 
송신 측과 수신 측의 지속적인 커뮤니케이션을 통해 윈도우 크기 또한 유연하게 조절할 수 있기 때문에 
최근의 TCP에서는 기본적으로 슬라이딩 윈도우를 사용하여 흐름 제어를 하고 있다.
```


## 혼잡제어
```java
송신(호스트) <> 라우터(네트워크)

혼잡 제어는 송신측과 네트워크의 데이터처리 속도 차이를 해결하기 위한 기법이다.

송신된 패킷이 네트워크 상의 라우터가 처리할 수 있는 양을 넘어서 혼잡하게 되면
데이터가 손실될 수 있기 때문에 송신측의 전송량을 제어하게 된다.

1. 합 증가/곱 감소
이 방식은 AIMD(Additive Increase/Multiplicative Decrease)라고 불리는 방식이다.

처음에 패킷을 하나씩 보내고 이것이 문제없이 도착하면 창 크기(단위 시간 내에 보내는 패킷의 수)를 1씩 증가시켜가면서 전송하는 방법이다.
만일 패킷 전송을 실패하거나 일정한 시간을 넘으면 패킷을 보내는 속도를 절반으로 줄이게 된다.

이 방식은 공평한 방식이다.

이 방식을 사용하는 여러 호스트가 한 네트워크를 공유하고 있으면 나중에 진입하는 쪽이 처음에는 불리하지만 
시간이 흐르면 평형 상태로 수렴하게 되는 특징이 있다.

문제점은 초기에 네트워크의 높은 대역폭을 사용하지 못하여 오랜 시간이 걸리게 되고,
네트워크가 혼잡해지는 상황을 미리 감지하지는 못한다.

즉, 네트워크가 혼잡해지고 나서야 대역폭을 줄이는 방식이다.



2. 슬로우 스타트(Slow Start)
합 증가/곱 감소 방식이 네트워크의 수용량 주변에서는 효율적으로 작동하지만
처음에 전송 속도를 올리는 데 걸리는 시간이 너무 길다는 단점이 있다.

느린 시작(Slow Start) 방식은 합 증가/곱 감소 방식과 마찬가지로 패킷을 하나씩 보내는 것부터 시작하고,
이 방식은 패킷이 문제없이 도착하면 각각의 ACK 패킷마다 Window size를 1씩 늘린다.
즉, 한 주기가 지나면 Window size가 2배로 된다.

따라서 전송 속도는 합 증가/곱 감소와는 다르게 지수 함수 꼴로 증가하게 된다.

대신에 혼잡 현상이 발생하면 Window size를 1로 떨어뜨리게 된다.

처음에는 네트워크의 수용량을 예상할 수 있는 정보가 없지만
한번 혼잡 현상이 발생하고 나면 네트워크의 수용량을 어느 정도 예상할 수 있으므로
혼잡 현상이 발생하였던 Window size의 절반까지는 이전처럼 지수 함수 꼴로 창 크기를 증가시키고 그 이후부터는 완만하게 1씩 증가시키는 방식이다.
미리 정해진 임계 값에 도달할 때까지 윈도우의 크기를 2배씩 증가시킨다.

Slow start란 이름을 사용하지만, 매 전송마다 두 배씩 증가하기 때문에 전송되어지는 데이터의 크기는 지수 함수적으로 증가한다.

전송되어지는 데이터의 크기가 임계 값에 도달하면 혼잡 회피 단계로 넘어간다

3. 혼잡 회피(Congestion Avoidance)
윈도우의 크기가 임계 값에 도달한 이후에 데이터의 손실이 발생할 확률이 높아지게된다.

데이터를 전송함에 있어서 조심하는 단계이다.
전송한 데이터에 대한 Ack를 받으면 윈도우의 크기를 1씩 증가시킨다.
전송하는 데이터의 증가를 왕복시간 동안에 하나씩만 증가시킨다.
신 호스트로부터 일정 시간 동안까지 Ack를 수신하지 못하는 경우
타임아웃의 발생 : 네트워크에 혼잡이 발생하였다고 인식
혼잡상태로 인식된 경우
윈도우의 크기를, 즉 세그먼트의 수를 1로 줄임
동시에 임계 값을 패킷 손실이 발생하였을 때의 윈도우 크기의 반으로 줄임

4. 빠른 회복(Fast Recovery)
빠른 회복 정책은 혼잡한 상태가 되면 Window size를 1로 줄이지 않고 반으로 줄이고 선형 증가시키는 방법이다.

빠른 회복 정책까지 적용하면 혼잡 상황을 한번 겪고 나서부터는 순수한 합 증가/곱 감소 방식으로 동작하게 된다.
```

## [오류 제어](https://evan-moon.github.io/2019/11/22/tcp-flow-control-error-control/)
```java
오류 제어 기법은 오류검출(error detection)과 재전송(retransmisstion)을 포함한다.

TCP는 기본적으로 ARQ(Automatic Repeat Request), 재전송 기반 오류 제어를 사용한다. 
말 그대로 통신 중에 뭔가 오류가 발생하면 송신 측이 수신 측에게 해당 데이터를 다시 전송해야한다는 말이다.

하지만 이 재전송이라는 작업 자체가 했던 일을 또 해야하는 비효율적인 작업이기 때문에, 
이 재전송 과정을 최대한 줄일 수 있는 여러가지 방법을 사용하게 된다.

TCP를 사용하는 송수신 측이 오류를 파악하는 방법은 크게 두 가지로 나누어진다.

수신 측이 송신 측에게 명시적으로 NACK(부정응답)을 보내는 방법, 그리고 송신 측에게 ACK(긍정응답)가 오지 않거나, 
중복된 ACK가 계속 해서 오면 오류가 발생했다고 추정하는 방법이다.

간단히 생각해보면 왠지 NACK를 사용하는 방법이 더 명확하고 간단할 것 같지만,
NACK를 사용하게되면 수신 측이 상대방에게 ACK를 보낼 지 NACK를 보낼 지 선택해야하는 로직이 추가적으로 필요하기 때문에, 
일반적으로는 ACK만을 사용해서 오류를 추정하는 방법이 주로 사용되고 있다.

이때 타임아웃은 말 그대로 송신 측이 보낸 데이터가 중간에 유실되어, 
수신 측이 아예 데이터를 받지 못해 ACK를 보내지도 않았거나, 수신 측은 제대로 응답했지만 해당 ACK 패킷이 유실되는 경우에 발생하게 된다.

어쨌든 두 경우 모두 송신 측은 데이터를 전송했는데 수신 측이 응답하지 않고 일정 시간이 경과한 경우라고 생각하면된다.

그리고 두 번째 방법인 송신 측이 중복된 ACK를 받는 경우 오류라고 판별하는 방법은 대략 이런 느낌이다.

이 상황을 조금 더 쉽게 풀어보자면, 송신 측은 이미 SEQ 2 데이터를 보낸 상황인데 수신 측이 계속 
야, 이번에 2번 보내줄 차례야라고 말하는 상황인 것이다. 그럼 송신 측은 자신이 보낸 2번 데이터에 뭔가 문제가 발생했음을 알 수 있다.

단, 패킷 기반 전송을 하는 TCP의 특성 상 각 패킷의 도착 순서가 무조건 보장되는 것이 아니기 때문에 
위 예시처럼 중복된 ACK를 한 두번 받았다고 해서 바로 에러라고 판별하지는 않고, 보통 3회 정도 받았을 때 에러라고 판별하게 된다.


ARQ(Automatic Repeat Request)기법을 사용하여 프레임이 손상되었거나 손실되었을 경우 재전송을 통해 오류를 복구한다.

ARQ기법은 흐름제어 기법과 관련되어있는데,
“정지-대기”는 정지-대기-ARQ로,
“슬라이딩 윈도우”는 GBn(Go-Back-n) ARQ 또는 SR(Selective-Reject) ARQ 형태로 구현한다.

오류 제어 종류
ARQ(Automatic Repeat Request) : 신뢰성 있는 데이터 전달을 위해 재전송을 기반으로 한 에러 제어 방식

1. 정지-대기 ARQ
Stop and Wait는 흐름 제어 때 한번 살펴보았던, 한번 데이터를 보내면 제대로 받았다라는 응답이 올 때까지 
대기하고 있다가 다음 데이터를 보내는 방식이다.

이 친구가 오류 제어에서 다시 나오는 이유는 그냥 이렇게만 해도 기본적인 오류 제어가 가능하기 때문이다. 
일석이조랄까. 애초에 제대로 받았다는 응답이 오지 않는다면 제대로 받을 때까지 계속 데이터를 재전송하는 방법이니까 
흐름 제어도 되지만 오류 제어도 가능하다.
그러나 위에서 살펴본 슬라이딩 윈도우를 사용하여 흐름 제어를 하는 경우에는 윈도우 안에 있는 데이터를 연속적으로 보내야 하기 때문에, 
오류 제어에 Stop and Wait를 사용해버리면 슬라이딩 윈도우를 쓰는 이점을 잃어버린다.

그런 이유로 일반적으로는 이런 단순한 방법보다 조금 더 효율적이고 똑똑한 ARQ를 사용하게 된다.

전송스테이션은 수신측에서 보내준 ACK를 받을 때 까지, 프레임의 복사본을 유지한다.

식별을 위해 데이터 프레임과 ACK프레임은 각각 0, 1번호를 부여한다.

수신측이 데이터를 받지 못했을 경우, NAK를 보내고, NAK를 받은 송신측은 데이터를 재전송한다.

만약 데이터나 ACK가 분실되었을 경우 일정간격의 시간을 두고 타임아웃이 되면, 송신측은 데이터를 재전송한다.


2. Go-Back-n ARQ (GBn ARQ)
위에서 이야기했듯이 오류를 판별하는 방법에는 ACK의 이상 징후를 파악하는 방법을 더 많이 사용하기는 하지만, 
NACK를 사용하고 있다고 가정하는 것이 다이어그램을 이해하기가 편하므로 오류 제어 기법을 설명할 때는 
수신 측이 NACK를 사용하고 있다고 가정할 것이다.

이 섹션에서는 오류 제어 기법을 설명하는 것이 목적이니, 오류를 어떻게 판별하는지보다는 
오류를 어떻게 제어하는지에 대해서만 집중해보도록 하자.

Go Back N 방식을 사용하면 데이터를 연속적으로 보낸 후 한 개의 ACK나 NACK만을 사용하여 수신 측의 처리 상황을 파악할 수 있으므로, 
연속적으로 데이터를 보낼 수 있는 흐름 제어 방식인 슬라이딩 윈도우와 아주 잘 들어맞는다고 할 수 있다.

즉, 송신 측은 수신 측으로 NACK를 받고나면 오류가 발생한 4번 데이터와 그 이후 전송했던 모든 데이터를 다시 전송해줘야 한다는 
말이 된다. 이때 송신 측은 비록 5번까지 전송했지만 오류가 발생하면, 오류가 발생한 4번 데이터로 되돌아가서 다시 전송해야하므로 
Go Back N이라고 부르는 것이다

전송된 프레임이 손상되거나 분실될 경우, 확인된 마지막 프레임 이후로 모두 재전송 하는 기법이다.

슬라이딩 윈도우는 연속적인 프레임 전송 기법이므로,
전송 스테이션은 전송된 모든 프레임의 복사본을 가지고 있어야 하며, ACK와 NAK 모두 각각 구별을 해야한다.

ACK : 다음 프레임을 전송
NAK : 손상된 프레임 자체 번호를 반환

재전송 되는 경우는 다음과 같다.

[1] NAK 프레임을 받았을 경우
만약, 수신측으로 0부터 5까지의 데이터를 보내었다고 가정한다.
수신측에서 데이터를 받았음을 확인하는 ACK 프레임을 중간 중간 받게 되며, ACK 프레임을 확인한 전송측은 계속해서 데이터를 전송한다.
그러나 만약 수신측에서 데이터 오류 프레임 2를 발견하고 NAK2를 전송 측에 보낸다.
NAK2를 받은 전송측은 데이터 프레임2가 잘못 되었다는 것을 알고 데이터를 재전송한다.
GBn ARQ의 특징은 바로 이 데이터를 재전송하는 부분이다.
GBn ARQ는 NAK(n)을 받아 데이터를 재전송하게 되면, n데이터만을 재전송하는 것이 아닌, n데이터 이후 데이터를 모두 재전송한다.
[2] 전송 데이터 프레임의 분실
GBn ARQ의 특징은 확인된 데이터 이후의 모든 데이터 재전송과 수신측의 폐기이다.
수신측에서 데이터 1을 받았는데 갑자기 다음 데이터 3을 받게 된다면
수신측에서는 데이터 2를 못받았으므로 데이터 3을 폐기하고 NAK2를 전송측에 보낸다.
NAK를 받은 전송측은 위의 [1] 경우에서와 같이 NAK(n) 데이터부터 모두 재전송을 실시하며
수신측은 기존 받았던 데이터 중 NAK(n)으로 보내었던 대상 데이터 이후의 데이터를 모두 폐기하고 재전송 받는다.
[3] 지정된 타임아웃내의 ACK 프레임 분실(Lost ACK)
전송스테이션은 분실된 ACK를 다루기 위해, 타이머를 가지고 있다.
전송측에서는 이 타이머의 타임아웃동안 ACK 데이터를 받지 못했을 경우, 마지막 ACK된 데이터부터 재전송한다.

전송측은 NAK 프레임을 받았을 경우, NAK 프레임 번호부터 다시 재전송을 시작한다.

수신측은 원하는 프레임이 아닐 경우 모두 폐기 처리한다.

타임아웃(ACK의 분실)일 경우, 마지막 ACK된 데이터부터 재전송한다.


3. Selective-Reject(SR) ARQ
GBn ARQ의 재전송되는 프레임 이후의 모든 프레임을 재전송하는 단점을 개선한 방법이다.

SR ARQ는 손상된 분실된 프레임만 재전송한다.

그렇기 때문에 별도의 데이터 재정렬을 수행해야하며, 별도의 버퍼를 필요로 한다.

elective Repeat은 말 그대로 선택적인 재전송을 의미한다. Go Back N 방법도 Stop and Wait에 비하면 많이 효율적인 방법이지만, 
에러가 발생하면 그 이후에 정상적으로 전송되었던 데이터까지 모두 폐기 처분되어 다시 전송해야한다는 비효율이 아직 존재한다.

그래서 나온 방식이 에러난 데이터만 재전송해줘 방식인 것이다.

얼핏 보면 이 방식이 굉장히 효율적이고 좋기만 한 것 같지만 Stop and Wait와 Go Back N 방식과 다르게, 
이 방식을 사용하는 수신 측의 버퍼에 쌓인 데이터가 연속적이지 않다는 단점이 존재한다.

위 예시만 봐도 수신 측의 버퍼에는 0, 1, 2, 3, 4, 5가 순차적으로 들어있는 것이 아니라, 중간에 폐기 처분된 4를 제외한 
0, 1, 2, 3, 5만 버퍼에 존재할 것이기 때문이다. 이때 송신 측이 4를 재전송하게되면 수신 측은 이 데이터를 
버퍼 중간 어딘가에 끼워넣어서 데이터를 정렬해야한다.

이때 같은 버퍼 안에서 데이터를 정렬할 수는 없으니, 별도의 버퍼가 필요하게 된다.

결국 재전송이라는 과정이 빠진 대신 재정렬이라는 과정이 추가된 것인데, 
이 둘 중에 재전송이 좀 더 이득인 상황에서는 Go Bank N 방식을, 재정렬이 좀 더 이득인 상황에서는 Selective Repeat 방식을 사용하면된다.

만약 TCP 통신에서 Selective Repeat 방식을 사용하고 싶다면, 
TCP의 옵션 중 SACK 옵션을 1로 설정하면 된다…만 사실 기본적으로 켜져 있는 경우가 많다.

1
2
$ sysctl net.inet.tcp | grep sack:
net.inet.tcp.sack: 1
OSX 같은 경우, sysctl 명령어를 사용하여 TCP와 관련된 커널 변수들을 확인해보면 그 중 net.inet.tcp.sack 값이 1로 잡혀있는 것을 확인할 수 있다.

아무래도 대부분의 경우에는 정글이나 다름 없는 네트워크를 다시 사용하는 쪽보다는 그냥 수신 측이 재정렬을 하는 것이 이득인 경우가 많다보니 기본적으로 Selective Repeat을 사용하는 것이 아닌가싶다.
```

### GBN ARQ와 SR ARQ의 차이
```java
GBN ARG : SR ARQ
1. 손상/불실된 프레임 이후의 프레임을 모두 재전송 <> 손상/분실된 프레임만을 재전송
2. 구조가 비교적 간단하고 구현이 단순 <> 구조가 복잡(프레임 재배열 등의 추가 로직 필요)
3. 데이터 폐기 방식을 사용하여 추가적 버퍼가 필요 없음 <> 폐기 방식을 사용하지 않으므로 순차적이지 않은 프레임을 재배열하기 위한 버퍼가 필요
4. 비용이 비교적 저렴 <> 

```


## TCP IP 4계층
* [TCP 4계층이란](https://medium.com/@chrisjune_13837/web-http-tcp-ip-%EB%A9%94%EC%8B%9C%EC%A7%80%EB%9E%80-4b2721fe296f)
```JAVA
클라이언트 -> HTTP -> TCP -> IP -> 이더넷 -> 이더넷 -> IP -> TCP -> HTTP -> HTTP -> 서버
클라이언트로부터 특정 주소로 요청이 들어오면 DNS 상에서 IP주소를 받아옵니다 
→ HTTP 계층에서 HTTP 메시지를 작성합니다 
→ TCP 계층에서 HTTP 메시지를 패킷으로 분해합니다. 
→ IP계층에서 전송위치를 확인하고 
→ 네트워크를 통하여 전송합니다. 
그 이후는 위의 과정의 역순으로 진행하여 처리합니다.


HTTP 메시지
HTTP메시지는 시작줄, 헤더, 본문으로 구성되어있습니다

1. 시작줄
1-1 요청 메시지
메서드, 요청 URL, HTTP 버전
GET /document/item/1 1.1

1-2 응답 메시지
사용자에게 일어난 내용을 응답합니다. 상태코드와 사유내용은 일대일 구조로 대응됩니다.
버전, 상태코드, 사유구절
1.1 200 OK

2. 헤더
메시지 본문에 대한 부가정보를 표현합니다. 헤더의 종류는 일반, 요청, 응답, 엔터티, 확장 등이 있습니다.
자주 볼 수 있는 헤더예시를 보도록 하겠습니다.

2-1 Connection
일반적으로 클라이언트와 서버간의 통신은 한번 맺고 끝납니다. 그러나 컨넥션 비용이 많이 소비되기 때문에 이를 개선하기 위하여 keep-alive옵션을 통하여 컨넥션을 재활용합니다.

2-2 Content-type
응답하는 컨텐츠의 유형을 의미합니다.

2-3 Cache-control
캐쉬 사용을 막을 것인지, 허용할 것인지 제어합니다.

2-4 Access-Control-Allow-Origin
클라이언트에서 현재와 다른 도메인에서 정보를 가져올 수 있는 도메인의 정보를 담고 있습니다. 
이를 CORS(Cross Origin Resource Sharing)이라고 부릅니다



HTTP 응답코드
웹 서비스를 개발하면서 자주 접하게 되는 응답 코드입니다.

100대 코드: 정보전달
200대 코드: 성공응답
200: OK, 정상
204: No Content, 보통 특정내용을 삭제시 해당 응답코드를 응답합니다.
206: Range, 헤더를 지정한 요청을 응답할 때 사용합니다.
300대 코드: Redirection, request완료를 위해 추가 동작이 필요합니다
301: Moved Permanently, 영구적으로 URI 변경을 의미
302: Found, 일시적인 URI 이동을 의미
304: Not Modified, 변경 없음
307: Temporary Redirect, 임시적인 redirect
400대 코드: 클라이언트의 에러
400: Bad Request, 잘못된 요청
403: Forbidden, 접근권한없음
404: Not Found, 요청 내용이 없거나 찾을 수 없음
408: Request Timeout, 요청 타임아웃
500번대 코드: 서버의 에러
500: Internal Server Error, 서버에러, 로직에러 발생시 자주 등장합니다.
503: Service Unavailable, 서버 한계 초과등 오류


TCP/IP(Transmission Control Protocol/Internet Protocol)
TCP/IP란 TCP규약과 IP규약을 합친 웹 상에서만 사용하는 규칙을 의미합니다.
TCP는 데이터 전달을 관리하는 규칙입니다. 즉, 데이터를 작게 나누어서 한쪽에서 다른쪽으로 옮기고, 
이를 다시 조립하여 원래의 데이터로 만드는 규칙입니다. 여기서 잘게 나눈 데이터 단위를 패킷이라고 합니다. 
인터넷에서는 정보를 전달하는 단위를 뜻합니다. TCP는 패킷을 조립하고, 손실된 패킷을 확인하고, 재전송하도록 요청하는 기능을 합니다.
IP는 인터넷상의 주소 규칙입니다. 집의 주소를 부여하는 규칙이 존재하듯이, 
인터넷상에 연결된 모든 컴퓨터의 위치에도 규칙이 필요합니다. 
이전에는 2⁸*4자리의 주소인 IPv4를 사용하였지만 주소가 고갈이 되고 있어서 16⁴*8자리인 IPv6로 전환하고 되고 있습니다.

TCP/IP 4계층
OSI(Open Systems Interconnections)7계층은 시스템들의 연결을 위한 모델입니다. 
TCP/IP 4계층은 이를 웹 서비스에 맞게 단순화시킨 모델입니다.

응용계층: HTTP, FTP, Telnet, SMTP 등 네트워크를 사용하는 응용프로그램으로 이뤄집니다.
전송계층: TCP, UDP 등 시스템을 연결하고 데이터를 전송하는 역할을 합니다.
인터넷계층: ICMP, IGMP, IP등 데이터를 정의하고 데이터의 경로를 라우팅합니다.
물리계층: Ethernet, ATM등 네트워크 하드웨어를 의미합니다


통신
프로토콜을 이용하여 source와 target간의 데이터를 주고 받는 방법을 뜻합니다. 크게 동기식과 비동기식으로 구분됩니다.
동기식 통신은 대표적으로 HTTP, 클라이언트의 요청을 서버에서 응답할 때 까지 기다리는 방식입니다.
(HTTP 1.1의 Pipe Lining으로 클라이언트에서 응답메시지를 받기 전에 요청메시지를 전달할 수 있습니다. 
하지만 본질적으로 비동기통신은 아닙니다)

비동기식 통신은 대표적으로 AMQP(Advanced Message Queue Protocol, 개선된 메시지 큐 프로토콜), 
메시지 브로커를 통하여 요청 메시지를 전달하는 방식입니다. 클라이언트에서는 브로커에게 메시지를 전달하기만 하고, 
기다리지 않기 때문에 비동기 식이라고 불립니다. 요청하는 측에서는 메시지를 
Publish하고 처리하는 쪽에서는 메시지를 Subscribe하기 때문에 pub/sub구조라고도 부릅니다.
```
