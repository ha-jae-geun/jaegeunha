## [정아마추어](https://jeong-pro.tistory.com/89?category=793347)

# HTTP
* www에서 쓰이는 핵심 프로토콜로 문서의 전송을 위해 쓰이며, 오늘날 거의 모든 웹 애플리케이션에서 사용되고 있다.
      * 음성, 화상 등 여러 종류의 데이터를 MIME로 정의하여 전송 가능
* Request/Response 동작에 기반하여 서비스 제공

## 통신과정
1. 3Way HandSHake
2. Http 요청
3. Http 응답

# HTTP(TCP) 소프트웨어 개발 시 고려사항
1. TCP handshake 설정
2. 인터넷 혼잡을 제어하기 위한 TCP Slow Start
3. 데이터를 한데 모아 한번에 전송하기 위한 네이글 알고리즘
4. TCp 전송 확인 응답을 위한 확인 응답 지연 알고리즘
5 Time_WAIT 지연과 포트 고갈

# TCP SLOW START
* 급작스러운 부하와 혼잡을 막기 위한 목적
* TCP의 전송할 수 있는 패킷 수는 TCP 커넥션이 만들어진지 얼마나 지났는지에 영향을 받는다
* 데이터가 성공적으로 전송됨에 따라 패킷 수 늘려감

# TIME_WAIT
* CLOSE 한 쪽에서 TIME_WAIT이 발생한다
* IP 주소와 포트 번호를 메모리에 저장한다
    * 같은 IP주소와 포트 번호를 사용하는 TCP Connection을 일정 시간동안 생성하지 않기 위해서 잘못된 패킷을 받아 오동작을 할 수 있음

# http와 https
```java
통신 상대를 확인하지 않기 때문에 위장이 가능하다.
HTTP 에 의한 통신에는 상대가 누구인지 확인하는 처리는 없기 때문에 누구든지 리퀘스트를 보낼 수 있다. IP 주소나 포트 등에서 그 웹 서버에 액세스 제한이 없는 경우 리퀘스트가 오면 상대가 누구든지 무언가의 리스폰스를 반환한다. 이러한 특징은 여러 문제점을 유발한다.

리퀘스트를 보낸 곳의 웹 서버가 원래 의도한 리스폰스를 보내야 하는 웹 서버인지를 확인할 수 없다.
리스폰스를 반환한 곳의 클라이언트가 원래 의도한 리퀘스트를 보낸 클라이언트인지를 확인할 수 없다.
통신하고 있는 상대가 접근이 허가된 상대인지를 확인할 수 없다.
어디의에서 누가 리퀘스트 했는지 확인할 수 없다.
의미없는 리퀘스트도 수신한다. —> DoS 공격을 방지할 수 없다.
보완 방법
위 암호화 방법으로 언급된 SSL로 상대를 확인할 수 있다. SSL 은 상대를 확인하는 수단으로 증명서 를 제공하고 있다. 증명서는 신뢰할 수 있는 제 3 자 기관에 의해 발행되는 것이기 때문에 서버나 클라이언트가 실재하는 사실을 증명한다. 이 증명서를 이용함으로써 통신 상대가 내가 통신하고자 하는 서버임을 나타내고 이용자는 개인 정보 누설 등의 위험성이 줄어들게 된다. 한 가지 이점을 더 꼽자면 클라이언트는 이 증명서로 본인 확인을 하고 웹 사이트 인증에서도 이용할 수 있다.


완전성을 증명할 수 없기 때문에 변조가 가능하다
여기서 완전성이란 정보의 정확성 을 의미한다. 서버 또는 클라이언트에서 수신한 내용이 송신측에서 
보낸 내용과 일치한다라는 것을 보장할 수 없는 것이다. 리퀘스트나 리스폰스가 발신된 후에 상대가 수신하는 사이에 
누군가에 의해 변조되더라도 이 사실을 알 수 없다. 이와 같이 공격자가 도중에 리퀘스트나 리스폰스를 빼앗아 변조하는 
공격을 중간자 공격(Man-in-the-Middle)이라고 부른다.

보완 방법
MD5, SHA-1 등의 해시 값을 확인하는 방법과 파일의 디지털 서명을 확인하는 방법이 존재하지만 확실히 확인할 수 있는 
것은 아니다. 확실히 방지하기에는 HTTPS를 사용해야 한다. SSL 에는 인증이나 암호화, 그리고 다이제스트 기능을 제공하고 있다.


HTTPS
HTTP 에 암호화와 인증, 그리고 완전성 보호를 더한 HTTPS

HTTPS는 SSL 의 껍질을 덮어쓴 HTTP 라고 할 수 있다. 즉, HTTPS 는 새로운 애플리케이션 계층의 프로토콜이 
아니라는 것이다. HTTP 통신하는 소켓 부분을 SSL(Secure Socket Layer) or TLS(Transport Layer Security)라는 
프로토콜로 대체하는 것 뿐이다. HTTP 는 원래 TCP 와 직접 통신했지만, HTTPS 에서 HTTP 는 SSL 과 통신하고 SSL
이 TCP 와 통신 하게 된다. SSL 을 사용한 HTTPS 는 암호화와 증명서, 안전성 보호를 이용할 수 있게 된다.

HTTPS 의 SSL 에서는 공통키 암호화 방식과 공개키 암호화 방식을 혼합한 하이브리드 암호 시스템을 사용한다. 
공통키를 공개키 암호화 방식으로 교환한 다음에 다음부터의 통신은 공통키 암호를 사용하는 방식이다.

모든 웹 페이지에서 HTTPS 를 사용하지 않는 이유
평문 통신에 비해서 암호화 통신은 CPU 나 메모리 등 리소스가 많이 필요하다. 통신할 때마다 암호화를 하면 많은 
리소스를 소비하기 때문에 서버 한 대당 처리할 수 있는 리퀘스트의 수가 줄어들게 된다. 그렇기 때문에 민감한 정보를 
다룰 때만 HTTPS 에 의한 암호화 통신을 사용한다.

cf) HTTP 2.0 이 발전되면서 HTTPS 가 HTTP 보다 빠르다는 사실이 나왔는데요, 다음 링크를 통해 보다 자세한 내용을 
확인하실 수 있습니다. 관련 링크 : HTTPS 가 HTTP 보다 빠르다.
```

## HTTP 1.1 에서 추가된 기능
- 1.0에서의 모호함과 성능을 개선하기 위해 1.1이 나왔습니다. 1.0의 경우 구조는 단순하지만 연결의 설정과 해체 반복으로 인해 네트워크 혼잡에 대한 정보를 확보할 수가 없었고, 대역폭이 낮은 링크에서는 성능저하를 발생시킵니다. 또한 캐시 모델이 미흡하여 동작상의 오버헤드와 캐시 데이터 관리에 문제가 많았습니다. 대표적으로 keepalive를 추가하여 연결의 설정과 해제의 반복을 줄이고, 캐시 제어 메커니즘이 도입되었으며, 파이프라이닝을 추가하여 동시에 여러 클라이언트와 연결을 할 수 있었으며, 요청메소드가 확장되어 PUT, DELETE 등이 추가되었습니다.

# holb
* 처음 요청한 request 문제 발생 -> 다음 도착한 요청에 대한 처리가 늦어짐 -> 병목현상 발생 -> Latency 증가

## http1.1문제
* 도메인마다 커넥션을 맺고 끊음
* 상당한 시간과 대역폭 소모
* 연결할 수 있는 커넥션 수의 제한
* TCP 성능 면에서 근본적인 문제가 해결되지 않음

## HTTP 2.0 에서 추가된 기능
* 기본 목표는 멀티플렉싱을 통해 Latency를 줄이고 헤더 압축을 통해 Overhead를 최소화하며 서버푸시기능을 지원하는 것
- 1.1보다 웹 속도를 개선하기 위해 2.0이 등장하였습니다. 추가된 기능으로 SSL 환경에서만 사용가능하기 때문에 보안성이 높으며 Header의 압축을 통한 성능향상이 되었고, Server Push를 통해 클라이언트의 요청없이도 필요 데이터를 보낼 수 있게 되었습니다. 또한 하나의 TCP 커넥션 내에서 병렬 처리를 지원하여 동시 처리가 가능하게 되었습니다. 메세지 전송 포맷도 바뀌었습니다. 1.1에서는 플레인텍스트로 형태로 header와 body를 보냈다면 2.0에서는 바이너리로 인코딩하여 header와 body를 전송합니다. 바이너리로 인코딩된 데이터를 프레임 단위로 전송하며 프레임이 모여 하나의 메세지를 보냅니다. 여러 메세지는 스트림 구조로 전송되기에 다수의 메세지를 동시에 처리함으로써 빠른 응답속도를 보장하게 되었습니다.

## 멀티플렉싱
* Frame: Http/2에서 통신의 최소 단위, 최소 하나의 프레임 헤더, 바이너리로 인코딩
* 메세지: 다수의 프레임, 요청 응답의 단위
* 프레임이 여러개가 모여 메시지, 메시지가 여러개가 모여 스트림
* Stream: 양방향 통신을 통해 전달되는 한 개 이상의 메시지

## 헤더 압축
* HPACK 압축방식
  1. 헤더 인덱싱
  2. 인코딩

## 서버푸시
### 과거
1. html 요청
2. html 태그 파싱
3. 필요한 리소스(css, jss, png) 재요청
4. 웹페이지 완성

### 현재
1. html 요청
2. 웹페이지 완성

## http 2.0 문제
* http request over tcp + TLS 기반

## holb 문제
* 그 외에도 TCP를 사용하는 기존의 HTTP에는 한 가지 문제가 더 있는데, 바로 HOLB(Head of Line Blocking)이라고 하는 문제이다. 사실 HTTP 레벨에서의 HOLB와 TCP 레벨에서의 HOLB는 다른 의미이기는 하나 결국 어떤 요청에 병목이 생겨서 전체적인 레이턴시가 늘어난다는 맥락으로 본다면 동일하다고 할 수 있다.
* TCP를 사용한 통신에서 패킷은 무조건 정확한 순서대로 처리되어야 한다. 수신 측은 송신 측과 주고받은 시퀀스 번호를 참고하여 패킷을 재조립해야하기 때문이다.
* 그래서 통신 중간에 패킷이 손실되면 완전한 데이터로 다시 조립할 수 없기 때문에 절대로 그냥 넘어가지 않는다. 무조건 송신 측은 수신 측이 패킷을 제대로 다 받았다는 것을 확인한 후, 만약 수신 측이 제대로 패킷을 받지 못했으면 해당 패킷을 다시 보내야 한다.
* 또한 패킷이 처리되는 순서 또한 정해져있으므로 이전에 받은 패킷을 파싱하기 전까지는 다음 패킷을 처리할 수도 없다. 이렇게 패킷이 중간에 유실되거나 수신 측의 패킷 파싱 속도가 느리다면 통신에 병목이 발생하게 되는 현상을 HOLB라고 부르는 것이다. 이건 TCP 자체의 문제이므로 HTTP/1 뿐만 아니라 HTTP/2도 가지고 있는 문제이다.
* 이런 문제들을 해결하기 위해 HTTP/3는 UDP를 기반으로 만들어진 프로토콜인 QUIC 위에서 작동하는 것을 선택한 것이다. 그럼 이제 QUIC가 정확히 어떤 프로토콜인지, UDP를 사용한다는 것이 TCP에 비해서 어떤 장점이 있다는 것인지를 알아보자.

## TCP 헤더 문제
* TCP의 경우 워낙 오래 전에 설계되기도 했고, 이런 저런 기능이 워낙 많이 포함된 프로토콜이다보니 이미 헤더가 거의 풀방이다. TCP에 기본적으로 정의되어 있는 기능 외에 다른 추가 기능을 구현하고 싶다면 가장 하단에 있는 옵션(Options) 필드를 사용해야 하는데, 옵션 필드도 무한정 배당 해줄 수는 없으니 최대 크기를 320 bits로 정해놓았다.
* 그러나 TCP의 단점을 보완하기 위해 나중에 정의된 MSS(Maximum Segment Size), WSCALE(Window Scale factor), SACK(Selective ACK) 등 많은 옵션들이 이미 옵션 필드를 차지하고 있기 때문에 실질적으로 사용자가 커스텀 기능을 구현할 수 있는 자리는 거의 남지도 않았다.
* 반면 UDP는 데이터 전송 자체에만 초점을 맞추고 설계되었기 때문에 헤더에 진짜 아무 것도 없다.
* UDP의 헤더에는 출발지와 도착지, 패킷의 길이, 체크섬 밖에 없다. 이때 체크섬은 패킷의 무결성을 확인하기 위해 사용되는데, TCP의 체크섬과는 다르게 UDP의 체크섬은 사용해도 되고 안해도 되는 옵션이다.
* 물론 TCP가 신뢰성을 확보하기위해 이런 저런 기능을 제공해주는 것이 개발자 입장에서는 편하고 좋지만, 한가지 슬픈 점은 이 기능들이 프로토콜 자체에 정의된 필수 과정이라서 개발자가 맘대로 커스터마이징 할 수 없다는 것이다. 결국 여기서 발생하는 레이턴시들을 어떻게 더 줄여볼 시도조차 하기 힘들다.


# TLS



## http3
* UDP는 User Datagram Protocol이라는 이름에서도 알 수 있듯이 데이터그램 방식을 사용하는 프로토콜이기 때문에 애초에 각각의 패킷 간의 순서가 존재하지 않는 독립적인 패킷을 사용한다. 또한 데이터그램 방식은 패킷의 목적지만 정해져있다면 중간 경로는 어딜 타든 신경쓰지 않기 때문에 종단 간의 연결 설정 또한 하지 않는다. 즉, 핸드쉐이크 과정이 필요없다는 것이다.
* HTTP/3는 HTTP(Hypertext Transfer Protocol)의 세 번째 메이저 버전으로, 기존의 HTTP/1, HTTP/2와는 다르게 UDP 기반의 프로토콜인 QUIC을 사용하여 통신하는 프로토콜이다. HTTP/3와 기존 HTTP 들과 가장 큰 차이점이라면 TCP가 아닌 UDP 기반의 통신을 한다는 것이다.
* 사실 HTTP/3는 처음에는 HTTP-over-QUIC이라는 이름을 가지고 있었는데, IETF(Internet Engineering Task Force) 내 HTTP 작업 그룹과 QUIC 작업 그룹의 의장인 마크 노팅엄이 이 프로토콜의 이름을 HTTP/3로 변경할 것을 제안했고, 2018년 11월에 이 제안이 통과되어 HTTP-over-QUIC이라는 이름에서 HTTP/3으로 변경되게 되었다.
* 즉, HTTP/3는 QUIC이라는 프로토콜 위에서 돌아가는 HTTP인 것이다. QUIC은 Quick UDP Internet Connection의 약자로, 말 그대로 UDP를 사용하여 인터넷 연결을 하는 프로토콜이다.(참고로 발음은 그냥 퀵이라고 한다)
* HTTP/3는 QUIC을 사용하고, QUIC은 UDP를 사용하기 때문에 결과적으로 HTTP/3는 UDP를 사용한다 라고 이야기 할 수 있는 것이다.*&
* QUIC은 TCP를 사용하지 않기 때문에 통신을 시작할 때 번거로운 3 Way Handshake 과정을 거치지 않아도 된다. 클라이언트가 보낸 요청을 서버가 처리한 후 다시 클라이언트로 응답해주는 사이클을 RTT(Round Trip Time)이라고 하는데, TCP는 연결을 생성하기 위해 기본적으로 1 RTT가 필요하고, 여기에 TLS를 사용한 암호화까지 하려고 한다면 TLS의 자체 핸드쉐이크까지 더해져 총 3 RTT가 필요하다.
* 반면 QUIC은 첫 연결 설정에 1 RTT만 소요된다. 클라이언트가 서버에 어떤 신호를 한번 주고, 서버도 거기에 응답하기만 하면 바로 본 통신을 시작할 수 있다는 것이다. 즉, 연결 설정에 소요되는 시간이 반 정도 밖에 안된다.
* . 첫번째 핸드쉐이크를 거칠 때, 연결 설정에 필요한 정보와 함께 데이터도 보내버리는 것이다. TCP+TLS는 데이터를 보내기 전에 신뢰성있는 연결과 암호화에 필요한 모든 정보를 교환하고 유효성을 검사한 뒤에 데이터를 교환하지만, QUIC은 묻지도 따지지도 않고 그냥 바로 데이터부터 꽂아버리고 시작한다.

## QUIC 과정
* 결국 이 영상에서 말하고자 하는 것은 TCP+TLS는 서로 자신의 세션 키를 주고 받아 암호화된 연결을 성립하는 과정을 거치고 나서야 세션 키와 함께 데이터를 교환할 수 있지만, QUIC은 서로의 세션 키를 교환하기도 전에 데이터를 교환할 수 있기 때문에 연결 설정이 더 빠르다는 것이다.
* 단, 클라이언트가 서버로 첫 요청을 보낼 때는 서버의 세션 키를 모르는 상태이기 때문에 목적지인 서버의 Connection ID를 사용하여 생성한 특별한 키인 초기화 키(Initial Key)를 사용하여 통신을 암호화 한다. 이 과정에 대한 자세한 설명은 QUIC 작업 그룹의 Using TLS to Secure QUIC 문서에서 확인 해볼 수 있다.
* 그리고 한번 연결에 성공했다면 서버는 그 설정을 캐싱해놓고 있다가, 다음 연결 때는 캐싱해놓은 설정을 사용하여 바로 연결을 성립시키기 때문에 0 RTT만으로 바로 통신을 시작할 수도 있다. 이런 점들 때문에 QUIC은 기존의 TCP+TLS 방식에 비해 레이턴시를 더 줄일 수 있었던 것이다.
* 참고로 이 세션이 발표될 당시에는 TLS 1.3이 나오기 전이라 따로 언급이 되지 않았지만, 지금은 TCP Fast Open과 TLS 1.3을 사용하여 QUIC와 비슷한 과정을 통해 연결을 설정함으로써 TCP를 사용하더라도 동일한 이점을 가져갈 수도 있긴하다.
* 그러나 TCP SYN 패킷은 한 패킷당 약 1460 Byte만 전송할 수 있도록 제한하지만 QUIC은 데이터 전체를 첫 번째 라운드 트립에 포함해서 전송할 수 있기 때문에 주고 받아야할 데이터가 큰 경우에는 여전히 QUIC가 유리하다고 할 수 있다.

## QUIC 흐름제어
* 패킷 손실 감지에 걸리는 시간 단축
* QUIC도 TCP와 마찬가지로 전송하는 패킷에 대한 흐름 제어를 해야한다. 왜냐면 QUIC든 TCP든 결국 본질적으로는 ARQ 방식을 사용하는 프로토콜이기 때문이다. 통신과정에서 발생한 에러를 어떻게 처리할 것인지를 이야기하는 것인데, ARQ 방식은 에러가 발생하면 재전송을 통해 에러를 복구하는 방식을 말하는 것이다.
* TCP는 여러 ARQ 방식 중에서 Stop and Wait ARQ 방식을 사용하고 있다. 이 방식은 송신 측이 패킷을 보낸 후 타이머를 사용하여 시간을 재고, 일정 시간이 경과해도 수신 측이 적절한 답변을 주지 않는다면 패킷이 손실된 것으로 판단하고 해당 패킷을 다시 보내는 방식이다.
* 우선 2017년 구글에서 발표한 QUIC Loss Detection and Congestion Control에 따르면, QUIC은 기본적으로 TCP와 유사한 방법으로 패킷 손실을 탐지하나, 몇 가지 개선 사항을 추가한 것으로 보인다.
* TCP에서 패킷 손실 감지에 대한 대표적인 문제는 송신 측이 패킷을 수신측으로 보내고 난 후 얼마나 기다려줄 것인가, 즉 타임 아웃을 언제 낼 것인가를 동적으로 계산해야한다는 것이다. 이때 이 시간을 RTO(Retransmission Time Out)라고 하는데, 이때 필요한 데이터가 바로 RTT(Round Trip Time)들의 샘플들이다.
* 한번 패킷을 보낸 후 잘 받았다는 응답을 받을 때 걸렸던 시간들을 측정해서 동적으로 타임 아웃을 정하는 것이다. 즉, RTT 샘플을 측정하기 위해서는 반드시 송신 측으로 부터 ACK를 받아야하는데, 정상적인 상황에서는 딱히 문제가 없으나 타임 아웃이 발생해서 패킷 손실이 발생하게 되면 RTT 계산이 애매해진다.
* 이때 이 ACK가 어느 패킷에 대한 응답인지 알기 위해서는 타임스탬프를 패킷에 찍어주는 등 별도의 방법을 또 사용해야하고, 또 이를 위한 패킷 검사도 따로 해줘야 한다. 이를 재전송 모호성(Retransmission Ambiguity)이라고 한다.
* 이 문제를 해결하기 위해 QUIC는 헤더에 별도의 패킷 번호 공간을 부여했다. 이 패킷 번호는 패킷의 전송 순서 자체만을 나타내며, 재전송시 동일한 번호가 전송되는 시퀀스 번호와는 다르게 매 전송마다 모노토닉하게 패킷 번호가 증가하기 때문에, 패킷의 전송 순서를 명확하게 파악할 수 있다.
* TCP의 경우 타임스탬프를 사용할 수 있는 상황이라면 타임스탬프를 통해 패킷의 전송 순서를 파악할 수 있지만, 만약 사용할 수 없는 경우 시퀀스 번호에 기반하여 암묵적으로 전송 순서를 추론할 수 밖에 없지만, QUIC는 이런 불필요한 과정을 패킷마다 고유한 패킷 번호를 통해 타파함으로써 패킷 손실 감지에 걸리는 시간을 단축할 수 있었다.
* 이 외에도 QUIC는 대략 5가지 정도의 기법을 사용하여 이 패킷 손실 감지에 걸리는 시간을 단축시켰는데, 자세한 내용은 QUIC Loss Detection and Congestion Control의 3.1 Relevant Differences Between QUIC and TCP 챕터를 한번 읽어보는 것을 추천한다.

## 멀티플렉싱
* 멀티플렉싱(Multiplexing)은 위에서 TCP의 단점으로 언급했던 HOLB(Head of Line Blocking)을 방지하기 때문에 매우 중요하다. 여러 개의 스트림을 사용하면, 그 중 특정 스트림의 패킷이 손실되었다고 하더라도 해당 스트림에만 영향을 미치고 나머지 스트림은 멀쩡하게 굴릴 수 있기 때문이다.
* 참고로 멀티플렉싱은 여러 개의 TCP 연결을 만든다는 의미가 아니라, 단일 연결 안에서 몇 가지 얌생이를 사용하여 여러 개의 데이터를 섞이지 않게 보내는 기법이다. 이때 각각의 데이터의 흐름을 스트림이라고 하는 것이다.
* HTTP/1의 경우는 하나의 TCP 연결에 하나의 스트림만 사용하기 때문에 HOLB 문제에서 벗어날 수 없었다. 또한 한번의 전송이 끝나게 되면 연결이 끊어지기 때문에 다시 연결을 만들기 위해서는 번거로운 핸드쉐이크 과정을 또 겪어야 했다.
* 비록 keep-alive 옵션을 통해 어느 정도의 시간 동안 연결을 유지할 수는 있지만 결국 일정 시간 안에 액세스가 없다면 연결이 끊어지게 되는 것은 똑같다.
* 그리고 HTTP/2는 하나의 TCP 연결 안에서 여러 개의 스트림을 처리하는 멀티플렉싱 기법을 도입하여 성능을 끌어올린 케이스이다. 이 경우 한번의 TCP 연결로 여러 개의 데이터를 전송할 수 있기 때문에 핸드쉐이크 횟수도 줄어들게 되어 효율적인 데이터 전송을 할 수 있게 된다.


## Connection ID
* 클라이언트의 IP가 바뀌어도 연결이 유지됨
* TCP의 경우 소스의 IP 주소와 포트, 연결 대상의 IP 주소와 포트로 연결을 식별하기 때문에 클라이언트의 IP가 바뀌는 상황이 발생하면 연결이 끊어져 버린다. 연결이 끊어졌으니 다시 연결을 생성하기 위해 결국 눈물나는 3 Way Handshake 과정을 다시 거쳐야한다는 것이고, 이 과정에서 다시 레이턴시가 발생한다.
* 게다가 요즘에는 모바일로 인터넷을 사용하는 경우가 많기 때문에 Wi-fi에서 셀룰러로 전환되거나 그 반대의 경우, 혹은 다른 Wi-fi로 연결되는 경우와 같이 클라이언트의 IP가 변경되는 일이 굉장히 잦아서 이 문제가 더 눈에 띈다.
* 반면 QUIC은 Connection ID를 사용하여 서버와 연결을 생성한다. Connection ID는 랜덤한 값일 뿐, 클라이언트의 IP와는 전혀 무관한 데이터이기 때문에 클라이언트의 IP가 변경되더라도 기존의 연결을 계속 유지할 수 있다. 이는 새로 연결을 생성할 때 거쳐야하는 핸드쉐이크 과정을 생략할 수 있다는 의미이다.

# Keepalive
- 두 호스트간 통신이 일정시간 패킷교환이 없을 때 자동으로 연결이 해제되는데 이것을 막기 위해 주기적으로 패킷을 보내는 것을 말합니다. keepalive는 tcp와 http 프로토콜 모두에서 일어날 수 있습니다.

# TCP에서 Keepalive
- HTTP/1.1부터 지원하는 기능으로 TCP 연결을 재사용하는 기능이다.
- 즉 Handshake 과정이 생략되므로 성능 향상을 기대 할 수 있다.
- 일정 시간동안 서로의 패킷 교환이 없을 경우 두 지점간 상대방의 안부를 묻기위해 payload 가 없는 패킷을 주기적으로 보내는 것입니다. 종단 시스템 중의 하나가 다운될 때 다른쪽 시스템만 열린 연결 상태를 정리하기 위해 사용됩니다.
- 단 모든 TCP 세션을 무한정 유지할 수는 없으므로 Timeout 및 Max 설정을 통해 관리되어야 한다.
- 최근에는 N/W 환경이 개선되면서 Keep Alive Timeout이 점점 줄어드는 추세이다.
- Event-driven 구조여서 non-blocking을 사용하는 Nginx 등은 Keep Alive를 하면서도 Thread를 점유하지 않기 때문에 동시 처리에 유리하다.

## Q. Keep Alive Timeout 설정은 왜 필요한가?
- 서버 자원은 무한정이 아니기에 이러한 접속을 계속 유지하는 것은 Server에 손실을 발생시킨다.
- 즉 서버와의 연결을 맺을 수 있는 Socket은 한정되어 있고 연결이 오래 지속되면 다른 사람들이 연결을 못하게되는 상황이 닥친다.
- 하지만 사람들이 적게 접속한다면 소수의 사람이 빠르게 인터넷을 사용 할 수 있다는 장점이 있다.
- Why? Request 요청을 하기 위한 작업이 생략되므로 속도는 빨라진다.
- 정적 자원(HTML, 이미지 파일 등)으로만 구성된 웹 서버에 Keep Alive을 사용할 경우 약 50%의 성능 향상을 보인다고 한다.
- 단 이와 같은 성능 향상을 보이려면 서버가 바쁘지 않아야 하는데 바쁜 서버 환경에서 Keep Alive 기능을 사용할 경우 모든 요청 마다 연결을 유지해야 하기 때문에 프로세스 수가 기하급수적으로 늘어나 MaxClient값을 초과하게 된다.
- 따라서 메모리를 많이 사용하게 되며 이는 곧 성능 저하의 원인이 된다. -즉 대량 접속 시 효율이 떨어지게 된다.

## HTTP에서의 Keepalive
- http 는 비연결형 통신이기에 커넥션을 유지하지 않습니다. 따라서 재요청시 커넥션을 다시 설정해야되는 비용이 큽니다. 이것을 해결하기 위해 Keepalive timeout내에 재요청을하면 열려있는 커넥션을 통해 전송하는 구조가 Keepalive입니다. Keepalive Timeout 을 너무 오래 설정하면 다른 사용자가 연결을 못하게 됨으로 사용자가 많은 서버보다는 소수의 사람이 빠르게 인터넷을 사용하자 하는 환경에서 사용하는 것이 좋습니다.
- HTTP는 Connectionless 방식이라 매번 Socket(port)를 열어야 하고 이는 비용적인 측면에서 비효율적인 구조이다.
- 그래서 Keep Alive Timeout내에 Client에서 Request를 재요청하면 새로운 세션을 생성하는 게 아닌 기존에 세션을 사용해 전송하는 구조이다.

## ThreadPool 과 Keep Alive
- 웹 서버만 놓고 볼 때 웹 서버 역시 ThreadPool을 사용하는 방식으로 설정 할 수 있다. 이때 ThreadPool은 사용자 수와 관련이 있는데,
- 동시 사용자가 500명이라면 최소한 500개 이상으로 ThreadPool을 설정해야 한다.
- 하나의 웹 페이지 호출 시 사용자는 동시에 여러 Connection을 생성할 수 있다.
- 만약 특정 웹 페이지 하나를 구성하는데 많은 자원이 필요하다면 ThreadPool은 그에 비례하여 증가시켜야 한다.
- 이때 Keep Alive까지 적용되어 있다면 Idle Thread까지 고려하여 ThreadPool 설정을 해야 한다

## Connection Timeout
## Socket Timeout
```java
웹 브라우저가 네이버 서버에 접속하기 위해 서버와 연결된 상태가 되어야 한다.

연결을 구성하기 위해서 보통 TCP Connection과 동일하게 3-way Handshake 방식으로 수행하게 된다.

3-way Handshake를 정상적으로 수행하게 되면 웹 브라우저와 네이버 서버는 연결된 상태가 된다.

이 때까지 소요된 시간을 Connection에 소요된 시간이라고 할 수 있다.

즉 Connection Timeout은 Connection을 구성하는데 소요되는 시간의 임계치를 의미한다.
```

```java
Socket Timeout

보통 서버는 클라이언트와 Established 후 데이터를 클라이언트에게 전송한다.

이 때 하나의 패킷이 아니라 여러 개의 패킷으로 나눠서 전송한다.

각 패킷이 전송될 때 시간 Gap이 생길 수 있는데 이 시간의 임계치를 Socket Timeout이라고 한다.

즉 Socket Timeout은 개별 패킷을 기다리는 Timeout이다.

주의할 점은 Socket Timeout이 전체 응답을 수신하는 Timeout이라고 생각하는 것이다.

다시말해 전체 응답이 아닌 개별 응답에 대한 시간 제한이다.

따라서 Timeout 시간 제한이 1초이고 응답 패킷이 3개일 경우 (각 패킷 도착 시간이 0.9초 )
총 응답 시간이 2.7초가 걸리지만 Timeout이 발생하지 않는다.

결론적으로 URL을 호출할 때에는 Connection Timeout과 Socket Timeout 설정이 모두 필요하다.
Q. 만약 두 가지 Timeout을 설정하지 않으면 어떤 일이 벌어질까?

URL 접속시 무한 대기가 발생할 수 있다.
```

### Connection vs Socket
```java
A는 최대 10분까지 맛집을 가기위해 기다릴 생각이 있다.

10분을 넘게 기다렸지만 A(=클라이언트)는 맛집(=서버)을 들어가지 못해 떠났다.

이처럼 서버에 클라이언트가 접근을 시래했을 시 적용되는 것이 Connection Timeout이다.

즉 접근을 시도하는 시간 제한(=10분)이 Connection Timeout이 되는 것이다.

만약 A가 10분 안에 맛집에 들어갔다고 가정해보자.

그리고 A는 음식을 기다리는데 최대 5분을 소요할 생각이 있다.

5분이 지난 A는 그냥 가게를 나왔다.

즉 클라이어트가 서버에 접속은 성공했으나 클라이언트가 원하는 요청에 대해
서버가 너무 오랫동안 응답을 못해 클라이언트가 연결을 해제하는 것이 Read Timeout이다.

이런 경우 클라이언트는 현 상황을 오류로 인지하고(=음식이 안나옴)
서버는 계속 요청(=요리중)을 수행하고 있기 때문에 요청 성공으로 인지를 한다.

이로인해 클라이언트와 서버간 싱크가 맞지 않아 문제가 발생할 확률이 높다
```



## Server - Client Model
* 서비스 제공자, 서비스 요청자로 구분되는 네트워크 모델이다.
* 제공자역할을 서버, 요청자 역할을 클라이언트라고 한다.
* 서버/클라이언트 모델에서 모든 자원은 서버에 집중된다.
  * 다수의 클라이언트 요청을 처리하기 위해서 고성능 컴퓨터를 사용
* 클라이언트는 데이터 presentation을 위해 최소한의 자원을 가지는게 일반적이다.
* 장점
  * 서버/클라이언트 역할이 분리된다
    * 프리젠테이션 영역과 데이터 처리 영역이 분리됨을 의미
  * 데이터가 서버에 집중되므로 보안 유지 상대적으로 쉽다.
* 단점
  * 서버에 네트워크 트래픽과 데이터가 집중된다.
  * 클라이언트 접속수가 ㅁ낳아지면 처리 비용이 증가한다.


## HTTPS
* [정아마추어]('https://jeong-pro.tistory.com/m/89?category=793347')
- 표현계층의 SSL 프로토콜 위에서 응용계층의 HTTP 프로토콜이 실행되는 것을 말하며, HTTP Over SSL 이란 의미입니다.
* SSL 프로토콜은 테리사(Terrsa)가 개발해 Netscape사가 NetSite의 암호화 중심 프로토콜로 정착시킨 기술로 정보 암호화시 공개키(Pubilc Key)와 개인키(Private Key)라는 두가지 키를 이용하는 방법

## http와 https 차이
* http : HyperText Transfer Protocol -> 동작순서 : TCP -> HTTP
* https : Hypertext Transfer Protocol over Secure Socket Layer -> 동작순서 : TCP -> SSL -> HTTP

```JAVA
HTTPS에 대해 알아보기 전에 HTTP를 간단하게 설명할 수 있으면 좋다.

HTTP는 HyperText Tranfer Protocol로 WWW상에서 정보를 주고 받는 프로토콜이다.

클라이언트인 웹브라우저가 서버에 HTTP를 통해 웹페이지나 이미지 정보를 요청하면 서버는 이 요청에 응답하여 
요구하는 정보를 제공하게 된다.

결국, HTTP 는 웹브라우저(Client)와 서버(Server)간의 웹페이지같은 자원을 주고 받을 때 쓰는 통신 규약이다.

http는 텍스트 교환이다. html페이지도 텍스트다. 바이너리 데이터로 되어있는 것도 아니고 단순 텍스트를 주고 받기 때문에 
누군가 네트워크에서 신호를 가로채어 본다면 내용이 노출된다.

이런 보안상의 문제를 해결해주는 프로토콜이 HTTPS다.

HTTPS는 인터넷 상에서 정보를 암호화하는 SSL(Secure Socket Layer)프로토콜을 이용하여 웹브라우저(클라이언트)와 
서버가 데이터를 주고 받는 통신 규약이다.

HTTPS는 http 메세지(text)를 암호화하는 것이다.

HTTPS의 S가 Secure Socket, 보안 통신망을 말한다.

HTTPS의 암호화 원리를 간단히 알아보면 핵심은 공개키 암호화 방식이다.


암호학을 공부하는게 아니니 공개키 알고리즘을 간단하게만 소개하겠다.

암호화, 복호화시킬 수 있는 서로 다른 키 2개가 존재하는데 이 두 개의 키는 서로 1번 키로 암호화하면 
반드시 2번키로만 복호화할 수 있고 2번 키로 암호화하면 반드시 1번키로만 복호화할 수 있는 룰이 있는 것이다.

그 중에서 하나 키는 모두에게 공개하는 공개키(1번 키)로 만들어서 공개키 저장소에 등록해놓는다.

서버는 서버만 알 수 있는 개인키(2번 키)를 소유하고 있으면 된다.

그러면 1번키로 암호화된 http 요청, 즉 HTTPS 프로토콜을 사용한 요청이 온다면 서버는 개인키(2번 키)를 
이용하여 1번키로 암호화된 문장을 해독하게 된다.

서버는 요청이 무엇인지 알게되고 요청에 맞는 응답을 다시 개인키(2번 키)로 암호화해서 요청한 클라이언트에게 보내주게 된다.

그리고 응답을 받은 클라이언트는 공개키(1번 키)를 이용해서 개인키(2번 키) 암호화된 HTTPS 응답을 해독하고 
사용하는 시나리오다. (* 공개키 암호화 방식에 대한 이해를 위한 설명일 뿐 더 정확한 HTTPS 연결 과정은 아래에 따로 정리 했습니다.)

HTTPS를 지원하는 서버에 요청(Request)을 하려면 공개키가 필요하다는 것을 알 수 있다.

그러면 그 공개키는 공개키 저장소에 있다는 것은 알겠는데 어떻게 공개키 저장소에서 가져올까?

추가적으로 공개키는 누구나 얻을 수 있고 공개키를 알면 서버가 주는 데이터(Response)는 알 수 있는데 보안상에 의미가 있을까?

보안상의 의미는 없다.

대신 얻을 수 있는 이점은 해당 서버로부터 온 응답임을 확신할 수 있다. 
왜? 공개키로 해독이 가능했으니까 반드시 해당 서버의 개인키로 암호화했다는 것을 보장하기 때문이다.

조금 더 자세한 HTTPS 통신 흐름

아까 의문을 가졌던 것을 다시 생각해보자.

공개키가 공개키 저장소에 있는데 어떻게 가져올 수 있을까?

HTTPS 통신 흐름에 대해서 자세히 들여다보면 알 수 있다.

일단 공개키 저장소라고 부르던 곳이 원래 명칭은 CA(Certificate Authority)다.

CA는 민간기업이지만 아무나 운영할 수 없고 신뢰성이 검증된 기업만 CA를 운영할 수 있다.

1. 먼저 애플리케이션 서버(A)를 만드는 기업은 HTTPS를 적용하기 위해서 공개키와 개인키를 만듭니다.

2. 그 다음에 신뢰할 수 있는 CA 기업을 선택하고 그 기업에 내 공개키를 관리해달라고 계약하고 돈을 지불합니다.

3. 계약을 완료한 CA 기업은 또 CA 기업만의 공개키와 개인키가 있습니다.

CA 기업은 CA기업의 이름과 A서버의 공개키, 공개키의 암호화 방법 등의 정보를 담은 인증서를 만들고, 
해당 인증서를 CA 기업의 개인키로 암호화해서 A서버에게 제공합니다.

4. A서버는 암호화된 인증서를 갖게 되었습니다. 이제 A서버는 A서버의 공개키로 암호화된 HTTPS 요청이 아닌 
요청(Request)이 오면 이 암호화된 인증서를 클라이언트에게 줍니다.

5. 이제 클라이언트 입장에서, 예를 들어 A서버로 index.html 파일을 달라고 요청했습니다. 
그러면 HTTPS 요청이 아니기 때문에 CA기업이 A서버의 정보를 CA 기업의 개인키로 암호화한 인증서를 받게되겠지요.

6. 여기서 중요합니다. 세계적으로 신뢰할 수 있는 CA 기업의 공개키는 브라우저가 이미 알고 있습니다!

7. 브라우저가 CA 기업 리스트를 쭉 탐색하면서 인증서에 적혀있는 CA기업 이름이 같으면 
해당 CA기업의 공개키를 이미 알고 있는 브라우저는 해독할 수 있겠죠? 그러면 해독해서 A서버의 공개키를 얻었습니다.

8. 그러면 A서버와 통신할 때는 A서버의 공개키로 암호화해서 Request를 날리게 되겠죠.


HTTPS를 지원한다고 해서 무조건 안전한 것은 아닙니다.

왜냐하면 신뢰할 수 있는 CA 기업이 아니라 자체적으로 인증서를 발급할 수도 있고, 신
뢰할 수 없는 CA 기업을 통해서 인증서를 발급받을 수도 있기 때문입니다.

그렇게 되면 브라우저에서는 https지만 "주의 요함", "안전하지 않은 사이트"등의 알림을 주게됩니다.
```
 

## HTTPS 동작 방식
- 응용계층에서 HTTP 프로토콜에 따라 메세지에 데이터를 담아 표현계층으로 보냅니다. 표현계층의 SSL에 따라 메세지를 클라이언트와 주고받은 대칭키로 암호화하여 전송 계층에 보냅니다. 전송계층에서는 TCP 프로토콜에 따라 세그먼트에 메세지을 담아 클라이언트에게 보냅니다. 클라이언트는 서버에서 가공한 과정의 역순으로 진행되며 표현계층에서는 서버와 주고받은 대칭키로 복화를 하여 데이터를 열어볼 수 있게 됩니다.

### SSL에 대해 설명해보아라.
- OSI 7계층에서 표현계층에 속하는 보안 프로토콜로서 스니핑과 같은 악의적인 행위를 방지하기위해 만들어진 프로그램 계층이다. SSL은 디지털 증명의 사용에도 포함되는 RSA의 비대칭키 암호화 시스템을 사용한다.
- (HTTPS와 SSL를 같은 의미로 이해하고 있는 경우가 많다. 이것은 맞기도 틀리기도 하다. 그것은 마치 인터넷과 웹을 같은 의미로 이해하는 것과 같다. 결론적으로 말하면 웹이 인터넷 위에서 돌아가는 서비스 중의 하나인 것처럼 HTTPS도 SSL 프로토콜 위에서 돌아가는 프로토콜이다.)

### SSL 디지털 인증서
- SSL 인증서는 클라이언트와 서버간의 통신을 제3자가 보증해주는 전자화된 문서다. 클라이언트가 서버에 접속한 직후에 서버는 클라이언트에게 이 인증서 정보를 전달한다. 클라이언트는 이 인증서 정보가 신뢰할 수 있는 것인지를 검증 한 후에 다음 절차를 수행하게 된다.
- SSL 인증서에는 서비스의 정보 (인증서를 발급한 기관), 서버 측 공개키가 포함되어 있다.

### SSL 동작방법
```java
SSL 동작방법
공개키 암호 방식은 알고리즘 계산방식이 느린 경향이 있다.
따라서 SSL은 암호화된 데이터를 전송하기 위해서 공개키와 대칭키 암호화 방식을 혼합하여 사용한다.
안전한 의사소통 채널을 수립할 때는 공개키 암호를 사용하고, 
이렇게 만들어진 안전한 채널을 통해서 임시의 무작위 대칭키를 생성 및 교환한다. 해당 대칭키는 나머지 데이터 암호화에 활용한다.

실제 데이터 암호화 방식 : 대칭키
상기 대칭키를 서로 공유하기 위한 암호화 방식 : 공개키


* SSL 통신과정
컴퓨터와 컴퓨터가 네트워크를 통해서 통신을 할때 핸드쉐이크 -> 세션 -> 세션종료 의 과정을 거친다.
암호화된 HTTP 메시지를 교환하기 전에 클라이언트와 서버는 SSL 핸드쉐이크를 진행한다.
핸드쉐이크의 목적은 아래와 같다.
프로토콜 버전번호 교환
양쪽이 알고 있는 pre master secret 키 생성 및 교환
양쪽의 신원 인증
채널을 암호화 하기 위한 임시 세션 키 생성
SSL 통신과정을 간단하게 도식화 하면 아래와 같다.
생활코딩 SSL의 동작방법에 아주 쉽게 설명되어 있어서 함께 참고하면 좋다.
```
[개발자몽키](https://wayhome25.github.io/cs/2018/03/11/ssl-https/)

# 대칭키 기법
- https://soul0.tistory.com/372 
- 하나의 비밀키를 양쪽(client - server)가 모두 같이 사용하는 것이 문제
-     (암호화와 복호화에 같은 암호 키를 쓰는 알고리즘)
- 해커로부터 안전할 수 없다
- 알고리즘 방식으로 DES, 3-DES, AES, SEED, ARIA, MASK 등이 있다.

# 비대칭키
- 비대칭키 는 암/복호화 할때의 Key 값이 다르다 대표적으로 RSA 라는 암호화가 있으며
 암호화 할때의 키를 공개키(Public Key) 복호화 할때의 키를 ​개인키(Private Key) 라고 한다.
- 즉,  암호화 할때의 Key 와 복호화 할때의 Key 값이 같으면 “대칭키”  ​암호화 할때의 Key 와 복호화 할때의 Key 값이 다르면 “비대칭키” 라고 한다.
 




# 공개키 기법 (≒비대칭키 기법, ≒비밀키 암호화, ≒비대칭형 암호 알고리즘)
- 보내야 하는 데이터를 송신자가 수신자의 공개키로 암호화를 걸어 놓고 데이터를 받은 수신자가 자신의 개인키(=비밀키)로 복호화를 하는 방법
- 개인 키는 한쪽에만 속해 있기 때문에 개인 키가 사용된 것으로 나타난 모든 경우 해당 키의 소유자만이 그것을 사용했다고 결론지을 수 있다.
- 한 쌍(공개키 + 개인키)의 키 조합이 필요.
- 암호화에 사용된 키와 복호화에 사 용된는 키가 다름에도 수학적 원리에 의해 해독이 가능하도록 한 방식
- 알고리즘 방식으로 RSA, DSA 등이 있다.
- 공개키 기법은 시간이 오래 걸리는 단점을 극복하고자 공개키 암호화는 대칭키를 보내는 용도로만 사용
- 개인키만 잘 보관하면 완벽한 암호화 기법

## 공개키 과정
- 공개키로 암호화하면 개이키로만 풀 수 있다.
- 각 키는 매우 큰 숫자이므로 한 개의 키로 다른 키를 알아내기 어렵다.
상대방에게 내 공개키를 알려준다.
2. 상대방은 나에게 자신의 공개키를 알려준다.
3. 상대방은 나의 공개키를 이용해 암호화된 문서를 나에게 보낸다.
4. 나는 내 개인키로 이 암호문을 해독한다.
5. 내 대답은 상대방의 공개키로 암호화해서 보낸다.
6. 상대방은 자신의 개인키로 내 글을 해독한다. 

# 공개키 기법으로 암호화한 대칭키 기법 내용
- 표준 보안 방식 SSL 이라고 부름.
- Secure Socket Layer
- 접속한 사이트가 신뢰할 수 있는 지 확인하기 위한 인증서가 출현
- 대칭키 기법 + 공개키 기법 = 장점만을 살린 방법
- 여기서 사용되는 대칭키는 매번 랜덤으로 선택되는데, 이렇게되면 만약 대칭키가 누출되어도 다음번에는 다른 키가 사용되기 때문에 안전

# 인증서란? ( 사이트와 인증기관의 구분을 명확히 생각하도록 하자. )
- 모든 개인키는 오직 자기 자신만 소유한다. 즉, 통신을 위한 공개키를 대충에게 공개해야 한다.
- 공인 인증 기관 출현
- 공인 인증 기관은 인증서를 발행해 주지만, 주 목적은 요청한 사이트에게 해당하는 인증기관 개인키와 인증기관 공개키 쌍을 만든다. 사이트에는 인증기관 개인키로 암호화한 인증서(사이트 공개키 + 사이트정보)를 발행 / 웹 브라우저에는 인증기관 공개키를 발행하여 암복호화 할 수 있도록 구성
- 사이트 개인키(Private Key) 를 보증(SSL 통신)하기 위해서 그 쌍이 되는 사이트 공개키(Public Key)가 바로 인증서에 들어있음.
- 또한 '공인 인증 기관의 전자 서명'이 바로 인증서에 들어 있음.
- 즉, 인증서는 사이트 공개키 + 공인 인증 기관의 전자 서명
- 인증서는 공개된 위치에 저장해서 요청하는 사람에게 내려보내 줄 수 있는 시스템이 갖춰져 있다. (보통 공인 인증 기관의 LDAP 에 저장)
- 이를 PKI(Public key infrastructure) 라고 한다.

## 인증서의 Root CA
- SSL의 기본 구조는 당신이 인증서를 서명한 사람을 신뢰한다면, 서명된 인증서도 신뢰할 수 있다는 것
- 이것은 마치 트리(Tree)와 같은 구조를 이루면서 인증서끼리 서명하게 된다.
- 인증서를 발행한 기관을 Root Certification Authority(Root CA)라고 부르며, 널리 알려진 인증 기관(Verisign, Thawte, Entrust 등)의 Root CA 인증서는 웹브라우저에 기본적으로 설치되어 있다.
- Root CA의 인증서는 누가 서명을 했을까? 모든 Root CA 인증서는 자체 서명(Self Signed)되어 있다.
- 여기서 서명이란 신뢰할 수 있다고 서명하는 것을 뜻함.

## 정리
 * Q: SSL 이란?
 * A: 데이터를 암호화 해서 주고 받는 것
 * 
 * Q: SSL은 어떤 키를 사용?
 * A: 실제 암호문을 주고받는 것은 양쪽이 같은 대칭키를 사용 (대칭키를 전송하기 위한 공개키를 사용과 햇갈리지 말자)
 * 
 * Q: 대칭키를 전달할 때 위험을 피하는 방법은?
 * A: 사이트의 공개키로 암호화해서 데이터를 전송
 * 
 * Q: 인증기관의 역할은?
 * A: 사이트의 공개키가 신뢰할 수 있는지 보증하는 역할
 * A: 인증기관의 개인키로 사이트의 공개키를 전자서명과 함께 암호화 = 인증서 (이는 인증기관의 공개키로만 풀 수 있기 때문에 인증기관에서 발급한 인증서가 신뢰할 수 있다고 판단할 수 있다.)
 * 
 * Q: 인증서란?
 * A: 사이트의 공개키와 사이트 정보(전자서명 등)을 인증기관 개인키로 암호화한 파일에 불과하다.
 

### 대칭키
- 암호를 만드는 행위인 암호화를 할 때 사용하는 일종의 비밀번호를 키(key)라고 한다. 이 키에 따라서 암호화된 결과가 달라지기 때문에 키를 모르면 암호를 푸는 행위인 복호화를 할 수 없다. 대칭키는 동일한 키로 암호화와 복호화를 같이 할 수 있는 방식의 암호화 기법을 의미한다. 대칭키 방식은 단점이 있다. 암호를 주고 받는 사람들 사이에 대칭키를 전달하는 것이 어렵다는 점이다. 대칭키가 유출되면 키를 획득한 공격자는 암호의 내용을 복호화 할 수 있기 때문에 암호가 무용지물이 되기 때문이다. 이런 배경에서 나온 암호화 방식이 공개키방식이다.

### 공개키
- 공개키 방식은 두개의 키를 갖게 되는데 A키로 암호화를 하면 B키로 복호화 할 수 있고, B키로 암호화하면 A키로 복호화 할 수 있는 방식이다. 이 방식에 착안해서 두개의 키 중 하나를 비공개키(private key, 개인키, 비밀키라고도 부른다)로하고, 나머지를 공개키(public key)로 지정한다. 비공개키는 자신만이 가지고 있고, 공개키를 타인에게 제공한다. 공개키를 제공 받은 타인은 공개키를 이용해서 정보를 암호화한다. 암호화한 정보를 비공개키를 가지고 있는 사람에게 전송한다. 비공개키의 소유자는 이 키를 이용해서 암호화된 정보를 복호화 한다. 이 과정에서 공개키가 유출된다고해도 비공개키를 모르면 정보를 복호화 할 수 없기 때문에 안전하다. 공개키로는 암호화는 할 수 있지만 복호화는 할 수 없기 때문이다.
- SSL은 공개키와 대칭키의 장점을 혼합한 방법을 사용한다. (클라이언트에서 생성한 대칭키를 서버의 공개키를 이용해 암호화해 보낸다. 그 후 데이터를 주고받는(세션) 과정에서는 대칭키를 사용한다.)

### SSL의 동작 방법
- SSL 역시 TCP 프로토콜 기반이라서 Handshake 과정을 거친다.
1. Client는 Server에게 hello 메시지를 보냅니다. Server는 Client에게 Hello 메시지로 응답을 보냅니다. 서로간의 통신을 준비하는 단계로 보면 됩니다.
2. Server는 Client에게 인증서, 사용할 서버키를 교환하며, 인증요청을 보냅니다.
3. Client는 Server에게 인증서, 사용할 클라이언트키를 교환하며, 인증서 확인요청을 합니다.
4. Server, Client 모두 Change Cipher Spec Protocol을 교환하며 위 단계에서 교환한 서버/클라이언트 키, 인증서 등을 토대로 이후의 통신을 지속하겠다는 메시지를 교환하며 서로의 인증을 마칩니다.

### SSL의 사용 예
기본적인 통신외에 무언가 덧붙여진다는 것은 정보를 보호하는데 도움이 될지언정 속도에는 도움이 되지 않는것이 사실이다. 보안을 강화하면 편의성이 떨어진다는 것은 어쩔 수 없는 것이다. 암호화를 하기 위해 크고작은 사전절차를 거쳐야하고, 데이터를 암호화, 복호화 하는 것도 컴퓨터에게는 모두 ‘일’이기 때문이다.
따라서 모든 웹페이지를 암호화해서 HTTPS로 만들면 좋겠지만 그렇게 되면 간단한 페이지를 열어보는 것도 시간이 많이 걸릴 수 있다. 이러한 속도 문제로 인해 단순한 웹 서핑때에는 HTTPS를 사용하지 않고, 로그인이나 결제와 같은 페이지에서 주로 사용한다. 참고로 일반적인 웹 페이지 HTTP는 TCP 80 포트를 사용하고, SSL이 적용된 HTTPS 페이지는 TCP 443 포트를 사용한다.

# TCP와 UDP
- 전송계층에서 사용되는 통신규약으로서 사용되는 환경에 따라 TCP와 UDP로 나뉘게 됩니다.

## UDP
- UDP 데이터 중심 프로토콜로서 주고받는 통신보다 데이터를 일방적으로 보내는 것을 중요시 합니다. 따라서 데이터 전송의 신뢰성이 보장되지 않지만 그만큼 가볍고 단순한 구조이고 속도가 빨라 실시간으로 통신할 수 있는 장점이 있습니다. 보통 p2p나 스트리밍, 전화 같은 경우에 사용됩니다.

## TCP
- 이에 반해 TCP 흐름 중심 프로토콜로서 서로가 통신을 주고 받는 것을 중요시합니다. 따라서 데이터 전송의 안전을 신경쓰기 때문에 중간에 패킷이 손실되는 경우 재전송을 통해(SYN-ACK handshaking) 신뢰성을 보장할 수 있습니다. 하지만 그만큼 전송속도가 느리다는 단점이 있습니다. TCP 프로토콜은 거의 대부분의 통신에서 사용되고 있으며, 특히 파일이나 데이터 전송시에 사용됩니다.

### TCP 의 신뢰성 보장이 어떻게 이루어지는가
- 3-way-handshaking 과 혼잡제어, 흐름제어를 통해 신뢰성을 보장합니다.
# 흐름 제어 (control flow)
- TCP가 신뢰성 보장을 위해 사용하는 메커니즘 중 하나로서 송신측과 수신측의 속도 차이를 해결하기 위해 사용하는 메커니즘입니다. 대표적으로 Stop and Wait ARQ, Sliding Window 기법이 있습니다.

## Stop and Wait ARQ
- 매번 패킷을 보내고 난 후 확인 응답을 받아야만 패킷을 전송하는 방식입니다.

## Sliding Window
- 수신측에서 설정한 윈도우 크기만큼 확인 없이 세그먼트를 전송할도록 하여 데이터 흐름을 동적으로 조절하는 방식입니다.

## Window
- 데이터를 보내기 전 3-way-handshaking 을 통해 수신측이 데이터를 받을 수 있는 버퍼양과 송신측이 데이터를 보낼 양을 맞추게 되는데 이 데이터 양을 window size라고 합니다.

## Go-Back-N ARQ
- 누적 응답을 사용한 방식으로 응답신호가 손실되더라도 이후 순서의 응답신호를 받으면 window가 shift 됩니다. timer가 하나이기에 순서가 낮은 프레임이 손실되면 이후의 모든 프레임을 재전송합니다. 수신측의 window 사이즈가 1로 설정되어 있어 프레임을 순차적으로만 수신할 수 있습니다.

## Selective Repeat ARQ
- 선택 응답을 사용한 방식으로 window의 가장 처음 프레임의 응답신호를 받아야 window가 shift 됩니다. 각 프레임당 timer가 동작하고 순서가 낮은 프레임이 손실되더라도 해당 프레임만 재전송합니다. 송신측과 수신측의 window size가 같기에 수신측에서 프레임 순서와 상관없이 수신이 가능합니다.

## 혼잡제어 (congestion control)
- TCP가 신뢰성 보장을 위해 사용하는 메커니즘 중 하나로서 네트워크의 혼잡을 피하기 위해 송신자의 전송속도를 줄이기 위해 사용하는 메커니즘입니다. 대표적으로 AIMD, Slow Start, Fast Retransmit, Fast Recovery 기법이 있습니다.

## AIME (Additive Increase/Multiplicative Decrease)
- window size를 1부터 시작하여 하나씩 증가시킵니다. 혼잡상태가 감지되면 window size를 절반으로 감소시킵니다.

## Slow Start
- window size를 1부터 시작해서 매회 2배씩 증가시킵니다. 혼잡이 발생하면 window size를 1로 감소시킨 후 지수적으로 증가시킵니다. 혼잡이 발생했던 window size의 절반부터는 선형적으로 증가시켜 나갑니다.

## Fast Retransmit
- 수신자가 프레임을 순서대로 받지 못햇을 경우 순서대로 받은 프레임 중 가장 최근의 프레임에 대한 ACK 신호를 보내게 됩니다. 이때 송신자는 3개 이상의 중복된 ACK를 받을 경우 timeout까지 기다리지 않고 바로 패킷을 재전송함으로서 시간을 절약합니다. 이런 현상이 반복되면 혼잡 상태로 인지하여 window size를 감소시킵니다

## Fast Recovery
- Slow Start 처럼 window size를 증가시키다가 혼잡상태를 만나면 window size를 1이 아닌 절반으로 감소시킨 후 선형적으로 증가시키는 방법입니다.

# Java에서 TCP와 UDP 소켓 생성 방법
- TCP와 UDP 모두 소켓 프로그래밍이라는 관점에서 같지만, 서버와 클라이언트간 연결과정에서 차이를 보입니다. 일단 socket() 함수를 통해 socket을 생성하고 ip 와 port 를 socket에 bind 하는 작업을 거칩니다. 이후에 TCP에서 서버는 listen() 함수를 호출하여 클라이언트에서

## TCP 소켓 생성방법
 1. 클라이언트
 * 1. socket() 함수를 통해 socket 을 생성합니다. 반환값으로 소켓 지정 번호가 부여됩니다.
 * socket(domain, type, protocol)
 * domain - 소켓 사용영역 (AF_INET, AF_UNIX)
 * type - 소켓 유형 (SOCKET_STREAM - IPPROTO_TCP, SOCKET_DGRAM - IPPROTO_UDP)
 * protocol - 사용할 프로토콜 (IPPROTO_TCP, IPPROTO_UDP)
 
 2. connect() 함수를 통해 연결할 ip 와 port 번호를 지정합니다. 클라이언트에서 connect() 가 ip주소와 port번호를 binding 하는 역할을 하며 커널에 소켓을 등록함으로서 커널이 외부와 통신할 귀를 열어놓게 됩니다.
 * connect(sockfd, serv_addr, addrlen
 * sockfd - 소켓 지정 번호
 * serv_addr - 연결할 서버에 대한 소켓 주소 구조체
 * addrlen - 구조체 크기
 
 3. read(), write() 함수를 를 통해서 데이터를 주고 받습니다.
 * read(fd, buf, count), write(fd, buf, count)
 * fd - 소켓 지정 번호
 * buf - 데이터를 담거나 담을 버퍼
 * count - 버퍼의 크기
 
 4. 작업이 끝나면 close() 함수를 통해서 연결을 종료합니다.
 * close(sockfd)
 * sockfd - 소켓 지정 번호
 
 2. 서버
 1. socket() 함수를 통해 socket 을 생성합니다. 반환값으로 소켓 지정 번호가 부여됩니다.
 2. socket 에 지정할 ip 와 port 번호를 bind() 함수를 통해 binding 합니다.
 * bind(sockfd, addr, addrlen)
 * socked - 소켓 지정 번호
 * addr - 소켓 주소 구조체 (소켓 유형, 연결할 대상의 ip 주소와 port 번호를 가진다.)
 * addrlen - 구조체의 크기
 
 3. listen() 함수를 통해 수신 대기열을 설정하여 여러 클라이언트 요청 저장합니다.
 * listen(queue_size)
 * queue_size - 수신 대기열 크기
 
 4. accept() 함수를 통해 수신 대기열에 있는 요청을 가져와 연결합니다. 연결이 성공하면 새로운 소켓인 연결 소켓을 생성합니다. 연결 소켓과 듣기 소켓을 따로 구분하는 이유는 동시에 여러 클라이언트의 요청을 처리하기 위함입니다. 만약 소켓이 하나라면 하나의 클라이언트의 요청만 처리할 수 있을 것이기 때문입니다.
 * accept(sockfd, addr, addrlen)
 * sockfd - 듣기 소켓 지정 번호 (socket()을 통해 처음 생성했던 소켓의 지정번호)
 * addr - 새로운 소켓에 바인드할 소켓 주소 구조체
 * addrlen - 구조체의 크기
 
 5. read(), write() 함수를 통해서 데이터를 주고 받습니다.
 
 6. 작업이 끝나면 close() 함수를 통하여 연결을 종료합니다.
 
 ## UDP 소켓 생성방법
 1. 송신자
 1. socket() 함수를 통하여 연결에 사용할 소켓을 생성합니다.
 * socket(AF_INET, SOCK_DGRAM, 0);
 2. bind() 함수를 통하여 통신할 서버의 ip 주소와 port 번호를 소켓에 binding 합니다.
 3. sendto(), recvfrom() 함수를 통하여 데이터를 주고 받습니다. UDP에서는 read() 나 write() 함수를 쓸 수가 없습니다. TCP처럼 연결을 맺지 않기 때문에 데이터를 읽을때마다 누가 보냈는지 확인해야하기 때문입니다.
 * sendto(s, message, msglen, flags, addr, addrlen)
 
 s - 소켓 지정 번호
 * message - 보낼 데이터
 * msgflen - 데이터 크기
 * flags - 전송을 위한 옵션 (대부분 0)
 * addr - 소켓 주소 구조체 (소켓 유형, 연결할 대상의 ip 주소와 port 번호를 가진다.)
 * addrlen - 소케 주소 구조체 크기
 * recvfrom(s, buf, buflen, flags, fromaddr, fromlen)
 * s - 소켓 지정 번호
 * buf - 데이터를 담을 버퍼
 * buflen - 버퍼의 크기
 * flags - 수신을 위한 옵션
 * fromaddr - 소켓 주소 구조체 (소켓 유형, 연결할 대상의 ip 주소와 port 번호를 가진다.)
 * fromlen - 소켓 주소 구조체의 크기
 
 4. 작업이 끝나면 close() 함수를 통하여 작업을 종료합니다.
 
 2. 수신자
 * 1. socket() 함수를 통하여 연결에 사용할 소켓을 생성합니다.
 * 2. bind() 함수를 통하여 통신할 서버의 ip 주소와 port 번호를 소켓에 binding 합니다.
 * 3. sendto(), recvfrom() 함수를 통하여 데이터를 주고 받습니다.
 * 4. 작업이 끝나면 close() 함수를 통하여 작업을 종료합니다.
 
## TCP 패킷구조
- 먼저 source / destination port number 를 가지고 있습니다. 패킷의 순서를 매기기 위한 Sequence number 와 마지막에 수신한 패킷을 알려주기 위한 Acknowledgement number 를 가지고 있습니다. 헤더크기와 잡음 및 변조를 확인하기 위한 checksum 이 있고, 데이터 관리 제어를 하는 6개의 flag 가 있습니다. 마지막으로 송수신 버퍼를 맞추기 위한 window size 를 가지고 있는 구조입니다.

## UDP 패킷구조
- TCP 헤더에 비해 훨씬 간단합니다. source, destination port 와 헤더 길이, 잡음과 변조를 확인하기 위한 checksum이 있습니다.

## 애플리케이션에서 사용하는 프로토콜의 종류 3가지
 * HTTP, SMTP, FTP, DHCP



# TCP, UDP 차이
## TCP
[TCP]('https://www.youtube.com/watch?v=8Ql1l048MD8&list=PLVsNizTWUw7GZy4UA9pntGRC9IIXIYiHm&index=3')
*  TCP is on IP
* physical -> internet -> transport -> application
* Ethernet Protocol <> IP Protocol <> TCp Protocol <> HTTP Protocol
* 소켓은 전송 레이어에 있음  
  ^Socket is on the transport  
  - Kernel - driver - network card - network card - kernel
  - BSD socket 
  - 소프트웨어 연결
  - Create socket -> give port > connect ip/port
  - Socket server: socket() > bind > listen > accept > send > recv
  - Socket client: socket() >                connect > recv > send > close
* ethernet ->     ip   ->    TCP    ->    Web server
* 프로세스 사이에서 소통을 도와줌  
    ^It provides communication function between processes
* 3웨이 핸드쉐이크 사용  
  ^Threeway handshake, based on flow
* 장점: 신뢰성
* 단점: 낮은 성능, 데이터 연속성 유지 힘듬  
    ^cons: low performance, hard to stay data continuity -> reliability is more important
* segment


## UDP
* 연속성이 신뢰성보다 중요함; 스타크래프트 UDP 서버  
  ^continuity is more important than reliability -> fast(ex: starcraft)
  - 손실에 신경쓰지 않는다.  
    ^don't care about loss
* 높은 성능  
    ^High performance
* socket() -> connect() -> sentto()/recvfrom () -> close()

