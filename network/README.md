# 네트워크
*   네트워크는 미리 정의된 규약인 프로토콜로 정보를 주고받는 하드웨어와 소프트웨어 기반의 시스템을 의미한다.

# 핑
* Packet Internet Groper;  
   * Groper: 물곡, 잠수함, 더듬더듬 알아간다.
* tracert로 경로 확인 가능

## 핑을 줄이는 방법
1. 네이글 알고리즘 해제
  * 데이터를 모아 보내지 말고 사소한 것들도 바로 보내기
2. 응답 대기 시간 삭제
   * 하나의 패킷이 오면 바로 응답해주기



# 프로토콜
* 네트워크 통신에서 OSI 참조 모델의 계층을 넘어설 때마다 데이터를 캡슐화 한다.
* 2계층: 프레임, 3계층: 패킷, 4계층: 세그먼트

## 프로토콜 종류
```java
각 계층은 서로 영향을 받지 않는다.

실제 네트워크에서 사용하는 프로토콜은 극히 일부

1,2계층 : 이더넷
3계층 : IP, ICMP, ARP
4계층 : TCP, UDP
5~7계층 : 애플리케이션 프로토콜
```

## 서버
* 서버는 상위 -> 하위 계층으로 캡슐화 처리를 하여 전송용 데이터를 만든다.

```java
먼저 서버 애플리케이션은 만든 애플리케이션 데이터를 그 상태로 전송 계층에 전달

전송 계층은 받은 애플리케이션 데이터를 TCP/UDP 캡슐(세그먼트)에 넣어 네트워크 계층으로 전달

네트워크 계층은 받은 세그먼트를 IP 캡슐(패킷)에 넣어 데이터링크 계층으로 전달

데이터링크 계층은 받은 패킷을 이더넷 캡슐(프레임)에 넣어 물리 계층으로 전달

물리 계층은 받은 프레임을 신호로 보내기 좋은 비트로 변환 후 전기 신호 or 광 신호로 만들어 전송
```

## 클라이언트
```java
물리 계층은 전기 신호 or 광 신호를 받으면 비트로 변환 후 프레임으로 만들어 데이터링크 계층으로 전달

데이터링크 계층은 받은 프레임에서 패킷을 꺼내 네트워크 계층으로 전달

네트워크 계층은 받은 패킷에서 세그먼트를 꺼낸 전송 계층으로 전달

전송 계층은 받은 세그먼트에서 데이터를 꺼내 원래의 애플리케이션 데이터를 클라이언트 애플리케이션에게 전달
```

## ICMP
*  ICMP[Internet Control Message Protocol] : 인터넷 제어 메시지 프로토콜  오류 메세지를 전송받는 데 주로 쓰입니다.

```java
ICMP의 용도는 뭘까요? 
- 인터넷/통신 상에서 발생한 일반적인 상황에 대한 보고(report)
- 인터넷/통신 상에서 발생한 오류에 대한 보고
- 위험한 상황에 대한 경보

ICMP의 기능을 정리해볼까요?
- IP 프로토콜을 이용하여 ICMP 메세지 전달 
- 네트워크 계층에 속하여 네트워크 관리 프로토콜의 역할 수행 
   (여기서 포인트는 종단간 데이터 수송 역할 X)
   
ICMP 사용(활용) 명령어 
1. Ping 명령어 : 상대방 호스트의 작동 여부 및 응답시간 측정하는데 사용
 - Echo Request (ICMP 질의메세지 요청
 - Echo Reply (ICMP 응답메세지 요청)

2. Tracert명령어 : 목적지까지의 라우팅 경로 추적을 하기 위해 사용 
 - Time Exceeded 확인 가능  (이 내용은 추후에 다루도록 할게요 ~)
```

# 소켓과 웹프로그래밍
* 직접 포트(TCP/IP)를 이용하여 통신하면 소켓 프로그래밍, 브라우저를 이용하면 웹프로그래밍

# OSI 7계층
- 국제표준화 기구(ISO)에서 개발한 모델로서 네트워크 프로토콜 통신을 계층으로 나눔으로서 표준화와 모듈화를 통해 프로그래머가 하위 수준의 단계에 크게 신경 쓰지 않고 개발을 할 수 있으며, 계층별 독립성과 단계적 계층 때문에 오류 처리가 수월하다는 장점이 있습니다. 1층은 물리계층, 2층은 데이터링크 계층, 3층은 네트워크 계층, 4층은 전송 계층, 5층은 세션 계층, 6층은 표현 계층, 7층은 응용계층이로 나누어져 있다.

## 그림
* 각 계층은 -을 정의한다
  * 물리적인 표준을 정의 - MAC 지정 - IP, 라우팅 정의 - 상대편에 도달하기 전에 다시 합치는 과정(Segment)
    - 동기화와 대화 기능 - 전송하는 데이터의 Format(구성 방식)을 결정 - 인터페이스 역할 / 사용자와 가장 가까운 프로토콜을 정의한다.

## 물리계층
- 통신케이블을 통해 데이터를 전송하는 계층입니다. 통신 단위는 bit 이며 데이터를 전송하기만 할뿐 무슨 데이터인지는 신경을 쓰지 않습니다.
```java
네트워크 통신을 위한 물리적인 표준을 정의하는 계층이다.

두 컴퓨터 간의 전기적, 기계적, 절차적인 연결을 정의하는 계층이다.

케이블 종류, 데이터 송수신 속도, 신호의 전기 전압 등
```


## 데이터링크계층
- 송수신하는 정보가 안전하게 전달하도록 서비스하는 계층입니다. 
  이 계층에서는 MAC address 를 가지고 통신을 하며 전송 단위가 프레임이며 오류 검출과 흐름 제어를 통해 안전하게 도달하도록 합니다.

```java
@ 신뢰성
물리적 계층을 통한 데이터 전송에 신뢰성을 제공한다.

이러한 서비스를 위해 물리적 주소(MAC) 지정, 네트워크 토폴로지, 오류통지, 프레임의 순차적 전송, 흐름제어 등의 기능을 가진다.

직접 연결되어 있지 않은 네트워크에 대해서는 상위 계층에서 오류 제어를 담담한다.

두가지 하위 게층이 존재한다.
Logical Link Contorl - 통신 장치간의 연결을 설정하고 관리하는 책임
Media Access Control - 다중 장치가 같은 미디어 채널을 공유, 제어(Block ID + Device ID)
2계층 장비 : Switch, Bridge
```

### 이더넷
```java
이더넷에서 프레임을 만든다.
1,2계층에서 필수불가결한 규격이 이더넷이다.

유선 네트워크의 경우 거의 대부분이 이더넷을 사용하고 있다 생각해도 좋다.

컴퓨터가 데이터를 송신할 때는
자신의 MAC 주소를 출발지 MAC 주소
데이터를 보낼 상대방의 MAC 주소를 목적 MAC 주소로 하여
헤더에 넣어 프레임을 만든다.

이더넷은 3계층으로부터 받은 데이터(패킷)에
프레임의 처음을 나타내는 프리앰블(Preamble과
목적지(수신자)와 출발지(송신자)를 나타내는 헤더,
비트 오류 체크에 사용하는 FCS(Frame Check Sequence)를 추가하여 프레임을 만든다.
```

#### MAC 주소로 컴퓨터를 식별한다.
```java
이더넷은 48비트로 된 MAC 주소라는 식별자를 사용하여 컴퓨터를 식별
a8:66:7f:04:00:80 / 00-50-56-c0-00-01

위와 같이 8비트마다 하이픈 or 콜론으로구분하여 16진수로 표기

상위 24비트 : 제조업체별로 할당한 제조업체 코드 = OUI(Organizationally Unique Identifier)

OUI를 통해 기기의 제조업체를 알 수 있다.

하위 24비트 : 제조업체 내부에서 기기별로 고유한 값으로 할당한 코드
```

## 네트워크 계층
- 시스템간 연결성과 경로 선택을 제공하는 역할을 하는 계층입니다. IP address 를 이용하여 라우팅 프로토콜이 연결된 네트워크를 통한 최적경로를 선택합니다.

```java
Logical Address(IP, IPX)를 담당한다.

패킷의 이동경로를 결정하는 계층이다.

3계층의 단위 : Packet

경로선택, 라우팅, 논리적인주소(IP)를 정의하는 계층이다.

Routing Protocol을 이용하여 최적경로를 선택한다.

대표적인 프로토콜로는 VPN을 구성하는데 사용되는 IPSec가 있다.

3계층 장비 : Router
```

### IP
* IP주소 알면 도시, 동까지는 알 수 있다.

```java
3계층에서 가장 중요한 프로토콜은 IP

IP는 전송 계층(4계층)으로부터 받은 데이터(세그먼트)에 IP 헤더를 붙여 패킷으로 만든다.

IP 헤더는 패킷의 목적지를 나타내는 택배 전표와 같다

IP는 IP 주소라는 32비트로 된 식별번호를 사용하여 컴퓨터를 식별한다.

192.168.1.1
8비트마다 .으로 구분하여 10진수로 표기, 점으로 구분된 그룹을 옥텟이라 하며 맨 처음부터 1옥텟, 2옥텟이라 부른다.

IP 주소는 단독으로 사용하는 것이 아니라 서브넷 마스크라는 32비트로 된 값과 세트로 사용

IP 주소는 서브넷 마스크로 분할된 네트워크부와 호스트부로 구성

네트워크부는 네트워크 자체 호스트부는 해당 네트워크에 연결되어 있는 단말을 나타냄

서브넷 마스크는 이 둘을 구분하는 표식과 같은 것으로,
1 : 네트워크부 / 0 : 호스트부

서브넷 마스크에는 10진수 표기와 CIDR 표기라는 2종류 표기 방법이 존재

10진수 표기는 IP 주소와 마찬가지로 32비트를 8비트씩 4개 그룹으로 나눈 후 각각을 10진수로 변환하여 점으로 구분

CIDR 표기는 IP 주소 다음에 슬래시와 ‘1’의 개수를 추가하여 표기
```

## 여러 가지 IP 주소
```java
사용 용도나 사용 장소에 따라 어디까지 어떻게 사용해야 하는지가 정해져 있다.

A ~ E 클래스까지 5개의 주소 클래스로 나눌 수 있다.

주소 클래스는 IP 주소의 32비트 중 처음 1~4비트로 분류
즉 맨 처음 비트에 따라 사용할 수 있는 IP 주소의 범위가 정해짐

일반적으로 A ~ C 클래스 사용
차이점은 네트워크 규격의 차이이다.

A -> B -> C 순서로 규격이 작아진다.

D와 E는 특수한 용도로 사용하므로 일반적으로는 사용 X

IP 주소에는 호스트부가 모두 0인 네트워크 주소
혹은 모두 1인 브로드캐스트 주소등 컴퓨터에 설정할 수 없는 것도 존재한다.

사용 장소에 따른 분류
IP 주소는 사용 장소에 따라
글로벌 IP 주소 / 프라이빗 IP 주소로 분류

글로벌 IP 주소는 인터넷에서 고유한 IP 주소

프라이빗 IP 주소는 조직이나 가정 등의 LAN에서 자유롭게 할당해도 좋은 IP 주소

Class A --> 10.0.0.0 ~ 10.255.255.255

Class B --> 172.168.0.0 ~ 172.31.255.255

Class C --> 192.168.0.0 ~ 192.168.255.255

```

### ARP
* ip주소 -> mAC주소; <> MAC 주소 -> IP 주소: RARP
```java
MAC 주소는 컴퓨터의 NIC(Network Interface Card)에 새겨져 있는 물리적 주소

NIC란 컴퓨터를 네트워크에 연결하기 위해 꼭 필요한 확장 보드이다.

NIC에는 LAN 케이블을 연결하기 위한 잭이 마련되어 있으며,
컴퓨터의 데이터를 전기적인 신호로 변환하여 이 잭으로 송출한다.
받는 수신도 여기서 일어나며, 그 경에우는 수신한 전자 신호를 원래 데이터로 복원하여 컴퓨터에게 전달한다.

IP 주소는 OS에서 설정하는 논리적 주소

두 주소는 서로 협조하면서 사용

이 두 주소를 협조하면서 이용할 수 있도록
물리와 논리의 다리 역할을 하고 있는 것이 ARP(Address Resolution Protocol)

실질적으로 IP 주소와 MAC 주소를 대응시키는 일을 한다.
```

### ARP의 처리 흐름
```java
데이터를 송신하는 컴퓨터가 제 3계층으로부터 패킷을 받으면 패킷의 목적지 IP 주소를 본다.

그것이 동일한 네트워크에 있는 컴퓨터의 것이라면
그 IP 주소를 ARP에서 조회하여 응답 결과를 ARP 테이블이라는 메모리상의 테이블에 등록 후
그 정보를 바탕으로 프레임을 만든다.

만약 다른 네트워크에 있는 컴퓨터의 것이라면
기본 게이트웨이의 MAC 주소를 ARP에서 조회하여 똑같은 처리를 수행한다.

기본 게이트웨이란 자신 이외의 네트워크로 갈 때 사용하는 출구가 되는 IP주소로,
방화벽이나 라우터의 IP 주소가 기본 게이트웨이가 되는 경우가 많다.

자신이 모르는 네트워크의 목적지 IP 주소로 가는 패킷인 경우는 일단 기본 게이트 웨이의 MAC 주소로 송신한다.
```

## 전송 계층
- 데이터의 전송을 위한 논리적인 연결을 하는 대문같은 역할을 합니다. 신뢰성 있는 전송을 보장하기 위해 오류 검출 및 복구와 흐름 제어를 제공합니다.

```java
정보를 분할하고, 상대편에 도달하기 전에 다시 합치는 과정을 담당하는 계층이다.

4계층의 단위 : Segment

목적지 컴퓨터에서 발신지 컴퓨터 간의 통신에 있어 흐름제어, 혼잡 제어, 오류제어를 담당한다.

전송 방식을 결정한다.
EX) 포트번호나 TCP/UDP 등

4계층 프로토콜 : TCP, UDP

TCP - 신뢰성, 비 연결지향성 프로토콜, Connection-ful(연결을 유지하며 전송하는 방식)
UDP - 비 신뢰성, 비 연결지향성 프로토콜, Connection-less(연결을 유지하지 않고 전송하는 방식, Data 손실을 신경쓰지 않음)
```

## 세션 계층
- 앞의 4개의 계층은 데이터 전송과 관련된 계층이라하면 앞으로의 3개 계층은 어플리케이션과 관련있는 서비스를 제공합니다. 이 계층은 어플리케이션간 세션을 구축하고 관리하며 종료하는 역할을 합니다.

```java
네트워크 상에서 통신을 할 경우 양쪽 host간 최초 연결이 되게 하고
통신 중 연결이 지속되도록 시켜주는 역할을 하는 계층이다.

통신을 하는 두 host사이에 세션을 열고, 닫고, 관리하는 기능을 담당한다.

중요한 기능에는 동기화와 대화 기능이 있다.


* 
동기란 통신 양단에서 서로 동의하는 논리적인 공통처리 지점으로써, 동기점을 설정하기위해 사용된다.

동기점은 오류 복구를 위하여 필수적으로 사용되는데
동기점이 설정된다는 의미는 그 이전까지의 통신은 서로 완벽하게 처리했다는것을 뜻한다.

동기점 이전 과정은 복구가 필요 없고 동기점 이후 처리 과정에 대한 복구 절차가 진행된다.

* 대화
대화는 데이터 전송 과정을 의미한다.

시간 경과에 따라 순차적으로 동기점을 부여하여 신뢰성 보장 기능을 단계적으로 구현할 수 있게 된다.

의도적으로 일시 정지하여 나중에 이어서 작업을 하는 것이 가능하다.

데이터 송수신 방식(Duplex), 반 이중 방식(Half Duplex), 전 이중 방식(Full Duplex)의 통신과 함께, 체크 포인팅과 유휴, 종료, 다시 시작 과정을 수행한다.

대표적인 프로토콜로는 SSL/TLS가 있다.

TCP, IP, IPX 등 전송계층 프로토콜을 연결해주는 역할을 한다. 연결을 도와주는 거다.
```

## 표현계층이란
- 데이터 표현이 상이한 응용 프로세스의 독립성을 제공하고 암호화 하는 역할을 합니다. 다루고 있는 데이터가 text인지 image 인지 등을 구분합니다.
```java
전송하는 데이터의 Format(구성 방식)을 결정하는 계층이다.

다양한 데이터 Format을 일관되게 상호 변환, 압축 및 암-복호화 기능을 수행한다.
EX) ASCII, EBCDIC, CIF, JPEG, AVI, MPEG 등
```
* - 표현계층의 SSL 프로토콜 위에서 응용계층의 HTTP 프로토콜이 실행되는 것을 말하며, HTTP Over SSL 이란 의미입니다.


## 어플리케이션 계층
- OSI 모델에서 가장 유저와 가까운 층으로서 상대방이 보낸 데이터의 최종 목적지가 됩니다. HTTP, FTP, SMTP 등이 이 계층에 속한 프로토콜이다.

```java
사용자 인터페이스의 역할을 담당하는 계층이다.

즉, 사용자가 이용하는 네트워크 응용프로그램이다.
EX) Internet Explorer

사용자와 가장 가까운 프로토콜을 정의한다.
EX) HTTP(80), FTP(20,21), Telnet(23), SMTP(25), DNS(53), TFTP(69) 등
```

# Big endian, Little endian
- 엔디언이란 컴퓨터 메모리에 연속된 바이트를 배열하는 방법을 말하는데 이 순서에 있어서 최상위 바이트가 앞에 오면 빅엔디언, 최하위 바이트가 앞에 오면 리틀엔디언이라고 합니다.

## Big endian. Little endian 장단점
- 빅엔디안의 경우 사람이 읽고 쓰는 방법과 같기에 디버깅이 쉬우나, 수가 커질 경우 메모리에 저장된 데이터를 오른쪽으로 옮겨야하는 단점이 있습니다. 반대로 리틀엔디안의 경우 디버깅은 어려울수 있으나 수가 커지더라도 오버헤드가 발생하지 않는다는 장점이 있습니다.

# 3-way handshaking
- 클라이언트와 서버가 통신을 하기전 정확한 전송을 보장하기 위해 컴퓨터간 세션을 수립하는 과정으로서 TCP 프로토콜에서 신뢰성을 보장하기 위해 사용됩니다.

## 3-way handshaking이 어떻게 신뢰성을 제공하는가

## 3-wau handshaking 과정
- 초기 클라이언트 상태는 CLOSED 상태이고 서버의 열려있는 포트의 상태는 LISTEN 상태입니다. 먼저 클라이언트가 서버에게 SYN 신호를 보내면 서버에서는 SYN_RCV 상태로 변경됩니다. 다시 서버는 클라이언트에게 SYN 에 대한 응답으로 ACK 를 보내는데 이때 클라이언트의 포트도 열어달라는 요청으로 SYN 를 같이 보냅니다. ACK 와 SYN 를 받은 클라이언트는 ESTABLISHED 로 변경되고 응답신호로서 ACK 를 서버에게 보낸다. 마지막으로 서버가 ACK 신호를 받으면 ESTABLISHED 상태가 되면서 클라이언트와 서버간 연결이 성공합니다.

## 4-way handshaking
- 클라이언트와 서버가 연결하기 위해 3-way handshaking 과정이 필요하듯이 연결을 종료할때에도 데이터 손실없는 전송을 보장하기 위해 handshaking 과정이 필요한데 이것이 4-way handshaking 입니다.

## 4-way handshaking 과정
- 클라이언트가 종료하겠다는 신호인 FIN 을 서버에 보내고 자신은 FIN_WAIT_1 상태로 변경됩니다. FIN 을 받은 서버는 ClOSE_WAIT 상태로 변경되고 응답으로 ACK 를 보냅니다. ACK 를 받은 클라언트는 다시 FIN_WAIT_2 상태로 변경됩니다. 이때 서버는 남은 데이터를 모두 전송하고 전송을 다하면 연결을 종료한다는 신호로 FIN 을 클라이언트에 보며 LAST_ACK 상태로 변경됩니다. FIN 을 받은 클라이언트는 TIME_WAIT 상태로 변경되면서 응답으로 ACK 를 서버에 보내고, 자신은 일정시간이 지난 후 CLOSED 상태로 변경됩니다. 마지막으로 응답신호를 받은 서버는 CLOSED 상태로 변경되면서 포트를 닫게 됩니다.

## 서버가 마지막에 FIN 을 보내는 이유
- 서버가 아직 클라이언트에 보낼 데이터가 남아있을 경우 데이터를 다 전송하지도 못한채 클라이언트에서 포트를 닫아버리게 되므로 서버 또한 종료될 준비가 되었다는 의미로 FIN 을 보내게 됩니다.

## 클라이언트가 마지막에 ACK 를 굳이 보내는 이유
- 서버가 보낸 FIN 신호를 클라언트가 받지 못 할 경우 클라이언트는 FIN_WAIT_2 상태로 종료가 되지 못한채 계속 기다리게 될 것입니다. 허나 서버는 이미 포트를 닫고 더이상 응답을 안하는 상태이기에 클라이언트는 불필요한 자원을 소모하게 됩니다.

# 로드밸런싱(Load balancing)
- 가상 ip를 통하여 하나의 서비스를 여러대의 서버가 분산 처리하는 메커니즘을 말합니다. 대표적으로 하나의 서버에 발생하는 트래픽이 많을 경우 서버의 부하량과 속도저하를 해소하거나 하나의 서버에서 장애가 발생하더라도 서비스가 중단되지 않고 지속하기 위해 사용됩니다.

## 분산처리를 어떻게 하는가
- 먼저 서버의 대표 ip를 virtual ip로 설정합니다. virtual ip로 통해 들어오는 패킷들을 L4 또는 L7 스위치를 통해 분석합니다. L4 스위치의 경우 포트를 분석하여 알맞는 서버를 찾아 보내고, L7 스위치의 경우 포트 뿐만 아니라 이메일 또는 파일 제목, url까지 분석하여 패킷을 분산처리합니다. 이때 각각의 서버에 트래픽을 균등하게 보내기 위해 Round Robin, Least Connection, Response Time, Hash 등의 기법으로 분산시킵니다.

## Round Robin
- 각 서버에 session을 순차적으로 맺어주는 방식입니다. 모든 클라이언트를 동일하게 취급하고, 각 서버별 처리량을 기억하고 있어야 합니다.

## Least Connextion
- 클라이언트와 서버별 연결된 connection 수를 고려하여 가장 적은 서버에 connection 을 맺는 방식입니다.

## Weighted Least Connections
- Least Connection 방식에서 서버에 가중치를 추가한 것으로 open 된 connection 수가 같을 경우 가중치가 높은 서버에게 우선 분배하는 방식입니다.

## Response Time
- 서버의 응답시간에 대한 학습을 통하여 응답시간이 빠른 서버에 conneciton을 우선 분배하고 응답이 느린 서버에는 connection을 적게 분배하는 방식입니다.

## Hash
- Hash 알고리즘을 적용하여 특정 서버에 connection을 연결한 클라이언트는 다음 연결에도 같은 서버에 connection을 맺는 방식입니다. 한번 성립된 session을 유지할 수 있는 장점이 있습니다.

# 도메인(domain)
- 컴퓨터간 통신을 하기위해 고유숫자인 ip 를 통해 통신을 하게 되는데 숫자로만 이루어진 ip 는 사람들이 이해하거나 외우기가 어렵기에 편하게 쓰기위해 ip 별로 고유이름을 부여한 것이 도메인입니다.

## IP Address와 MAC Address
- IP address 는 인터넷 네트워크 상의 고유 주소이고 라우팅시에 필요합니다. MAC address 는 장치의 고유 번호로서 통신시 상대방 컴퓨터를 찾아내기 위해 필요한 주소입니다. 따라서 인터넷에 접속하여 네트워크 통신을 할때 상대방이 접속한 인터넷 망까지 IP address 를 통해 찾아가고, MAC address 를 통해 망에 접속된 장치 중 알맞는 장치에 도착할 수 있습니다.

## ARP (Address Resolution Protocol) 와 RARP에 대해 설명
- ARP 는 OSI 7계층의 네트워크 계층에서 사용되는 주소 결정 프로토콜로서 IP 주소에서 MAC 주소를 알아내기 위한 프로토콜이고, RARP 은 반대로 MAC 주소에서 IP 주소를 알아내기 위한 프로토콜입니다. 상대방 MAC 주소를 모를 경우 IP와 브로드 캐스팅 네트워크 주소 FFFFFFFFFFFF를 가지는 ARP 패킷을 네트워크 상에 전송하여 이를 수신한 호스트가 자신의 MAC 주소를 반송하는 메커니즘입니다. 이때 ARP 캐시라 불리는 메모리에 테이블 형태로 저장하여, 패킷을 전송할 때에 다시 사용됩니다.

# 리피터, 허브, 브릿지, 라우터와 L2, L3, L4, L7 스위치 차이점
## 리피터
- 리피터는 물리계층에서 단순히 전기적인 신호만 증폭시키는 장치입니다. 네트워크 신호가 연결된 모든 PC에 전달되기 때문에 연결된 장치가 많을수록 부하가 심해집니다.

## 허브
- 허브는 리피터처럼 물리계층에서 전기적인 신호를 증폭시켜 전송거리를 연장시켜주는 장치입니다. 플러딩으로 인해 네트워크 장치가 많을수록 부하가 심해지고, 잡음 신호고 증폭된다는 단점이 있습니다.

### 플러딩
- 네트워크 장치에서 신호를 보내면 연결되어 있는 모든 장치들에서 신호를 전송하는 방식을 말합니다. 따라서 보안성이 약하고, 네트워크 충돌 문제가 발생할 수 있습니다.

## 허브와 리피터의 차이
- 허브는 리피터에 몇가지 기능이 추가된 것으로 패킷 모니터링과 멀티 포트를 지원하여 문제가 생긴곳을 고립시킬 수 있습니다.
*  허브는 패킷모니터링이 가능하다.
  - 멀티 포트를 지원하며 문제가 생긴 곳을 고립(Fault isolation)시킬 수 있다.

## 브릿지
- 브릿지는 데이터링크계층에서 전송거리를 연장시켜주는 장치입니다. 단순 전기적 신호를 증폭시키는 것이 아닌 프레임을 다시 만들어 전송합니다.

### 허브, 리피터, 브릿지 차이
* 브릿지부터 무제한 길이확장이 가능하다.
* 브릿지는  이건 특별히 Datalink Layer(제 2 레이어)에서 동작한다. (맥 어드레스를 해석해서 처리하기 때문임.)
* 브릿지는 속도가 다른 두 네트워크 간도 연결할 수 있다.
* 브릿지는 망에서 생긴 잡음이 유지되지 않는다 (생기면 곧 사라짐. 잡음은 패킷 프레임이 아니기 때문에 브릿지에서 제거해 버린다.)

## 스위치
- 스위치는 브릿지와 마찬가지로 데이터링크계층에서 전송거리를 연장시켜주는 장치입니다. 스위치는 성능에 따라 L2와 L3 L4 L7스위치로 구분되는데 단순히 MAC 주소만 참조하여 처리하는 장치를 L2 스위치라고 합니다. MAC 주소와 포트번호가 기록된 MAC 주소 테이블을 가지고 있어, 목적지 MAC 주소를 가진 장비가 연결된 포트로만 프레임을 전송하기 때문에 충돌이 일어나지 않지만 MAC 주소가 브로드캐스트일 때 모든장비로 프레임을 전송하기에 성능저하가 일어납니다.

### 브릿지와 스위치의 차이
- 스위치는 Bridge 와 같은 레이어에서 동작하는 L2 스위치도 있지만, IP주소를 해석하여 동작하는 L3 스위치, 패킷정보를 해석하여 동작하는 L4 스위치도 있다.
- 데이터링크 계층에서 프레임을 전송하는 역할은 같으나, 브릿지에 비해 속도와 기능이 업그레드 된 것이 스위치입니다. 따라서 대부분 스위치를 사용하고 있습니다.
* 우리가 집에서 쓰는 것은 한 공인IP를 여러 사설아이피로 쓸 수 있게 해주는 “공유기“이고,
* 학교나 회사에서 여러 PC 를 연결하기 위해서, 같은 레벨(단계)에서 선을 분할 할 때 사용하는 것은 “허브” 이고, (벽에서 랜선 하나 연결해서 6포트 허브에 연결하면, 총 5대의 PC에 연결할 수 있게된다.)
* 패킷이 대량으로 통신하는 서버들을 연결하는 것은 “스위치“이다.
* 스위치가 가장 좋은 기기이긴한데, 서버 사용하는 경우 아니면 구매하지 않길 바란다.
* 비유하자면, 집앞 마트를 가는데, 공유기는 “자전거를 타고 가는 것”이고, 허브는 “킥보드를 타고 가는 것”이고, 스위치는 “람보르기니를 타고 가는 것”이다.


### 공유기
* 요즘 출시되는 공유기는 웹서버, 토렌트 다운로드, vpn 서버 등 다양한 기능을 제공하고 있습니다.
* Application Layer(L7) 기능을 제공하고 있기 때문에, 포트가 여러개 달린 컴퓨터라고 보는게 맞는 것 같습니다.
* 다만 공유기 기능 중 하나인 허브모드 기능을 사용하여 허브처럼(!) 사용할 수도 있습니다.

### 스위치가 속도가 더 빠른 이유
- 데이터 처리 방식에 있어서 브릿지는 소프트웨어적으로만 처리하는 반면 스위치는 하드웨어적으로 처리가 가능하여 속도가 월등히 빠릅니다.

### L3 스위치
- L2 스위치에서 접속된 장비가 많을수록 브로드캐스트 트래픽이 증가하는 문제를 해결하기 위해 VALN이 도입되었고, 이 기술을 적용한 장치가 L3 스위치입니다. VLAN이 다르면 브로드캐스트 프레임이 차단하여 성능저하를 해결할 수 있습니다. 네트워크 계층에서 사용되는 장치입니다.

### L4, L7 차이점
- L4 스위치는 전송계층에서 작동하는 스위치로서 ip 주소를 통해 호스트종단으로 전송하는 것 뿐만 아니라 포트번호에 맞는 서버로 패킷을 전송하여 분산처리가 가능하다는 장점이 있습니다. L7 스위치는 응용계층에서 작동하는 스위치로서 L4 스위치보다 한단계 더 높이 패킷의 url, 쿠키, payload 일부분을 읽어서 더욱 세밀한 분산 처리를 도울 수 있는 장점이 있습니다.
### 라우터란

- 라우터는 네트워크 계층에서 IP주소를 이용해 목적지 포트로 패킷을 전송하는 장치입니다. 특히 서브넷이 다른 IP주소를 가진 장비간 통신은 이 네트워크 계층 장비를 거쳐야 합니다.

# 게이트웨이(Gateway)란?
- 외부로 연결되는 통로를 의미하며, 로컬망 라우터와 외부 망 라우터간의 통로를 말합니다.

# 프로토콜(Protocol)
- 컴퓨터간 데이터 통신을 원활하게 하기 위해 규정한 규약으로 신호 송신의 순서(handshaking)나 데이표 표현법, 요류 검출법 등을 정한 것을 말한다.

## HTTP 프로토콜
* 하이퍼 텍스트는 하이퍼링크를 통하여 이곳에서 저곳으로 움직일 수 있는 텍스트라고 할 수 있습니다. 일반적으로 앞에서 뒤로 읽어나가는 순차적 흐름이 아니라 중간에서 다른곳으로 오가는 방식을 의미합니다.
- 한 문서에서 다른 문서로 즉시 접근할 수 있는 텍스트를 하이퍼텍스트라고 하는데 이 텍스트를 전송하는 규약을 말한다.
* HTTP 통신의 특징은 Connectionless와 Stateless가 있습니다.

### RestAPI

### 메소드
* Get: 데이털를 read, 조회하는데 사용
* Post: 새로운 정보를 추가하는데 사용
* put, patch를 사용해서 변경, Update
  * put: 정보를 통쨰로 갈아끼울 때
  * patch: 정보 중 일부를 특정 방식으로 변경하거나 update할 때

```JAVA
onnectionless(비 연결지향)
클라이언트에서 서버에 요청을 보내면 서버는 클라이언트에 응답을 하고 접속을 끊는 특성이 있습니다. 
(HTTP1.1에서 Connection 헤더에 keep-alive라고 설정하면 컨넥션을 유지할 수 있습니다)

Stateless(상태정보유지안함)
HTTP 통신은 요청을 응답하고 접속을 끊기 때문에 클라이언트의 상태정보를 알 수 없습니다. 이를 Stateless하다고 합니다.
만약 로그인을 하고 그 상태를 유지한 채로 웹 서비스를 제공하려면 어떻게 해야할까요? 이를 위하여 쿠키와 세션이라는 방법이 존재합니다.

```

## 쿠키와 세션
```JAVA
쿠키
쿠키는 클라이언트 로컬에 저장되는 Key-Value쌍의 작은 데이터 파일입니다.
서버에서 클라이언트에 쿠키를 생성해줍니다. 클라이언트는 서버에 요청메시지를 보낼때
헤더에 쿠키값을 자동으로 추가하여 보내주는데 이는 브라우저에서 처리를 해주는 작업입니다. 
쿠키의 기한이 정해져 있지 않고 명시적으로 지우지 않는다면 반 영구적으로 쿠키가 남아있게 됩니다.
브라우저의 개발자도구 또는 쿠키관리 플러그인을 설치하면 쿠키를 확인하고 수정할 수 있습니다. 
쿠키는 파일로 저장되어 있기 때문에 탈취와 변조가 가능합니다.

세션
쿠키처럼 서버에서 클라이언트에게 unique한 id인 세션아이디를 발급해주고 클라이언트와 서버에 동시에 저장합니다. 
이후 클라이언트는 서버에 요청메시지를 보낼 때 쿠키처럼 세션아이디를 헤더에 추가하여 서버에 전송합니다. 
서버에서는 유효한 값인지 확인 후 요청을 처리합니다.
로그인 이후 발급받은 SESSIONID를 쿠키에 생성해 주고 이후 모든 요청의 헤더마다 SESSIONID가 추가되는 것을 확인할 수 있습니다. 
세션의 내용은 서버에 저장되기 때문에 계속하여 늘어날 경우 서버에 부하가 발생합니다.


쿠키와 세션의 차이점은 총 4가지 입니다
1. 저장위치
쿠키는 로컬에, 세션은 로컬과 서버에 저장됩니다.

2. 보안
쿠키는 탈취와 변조가 가능하지만, 세션은 ID값만 가지고 있고 서버에도 저장이 되어있기 때문에 상대적으로 안전합니다.

3. Lifecycle
쿠키는 브라우저를 종료해도 파일로 남아있지만, 세션은 브라우저 종료시 세션을 삭제합니다

4. 속도
쿠키는 파일에서 읽기 때문에 상대적으로 빠르고, 세션은 요청마다 서버에서 처리를 해야하기 때문에 비교적 느립니다.

```

## tcp가 만들어 진 이유
* TCP는 방금 이야기 했듯이 1970년 냉전 당시 미 국방성이 개발하던 알파넷 프로젝트의 일부로 개발되었는데, 그 당시 알파넷을 연구할 때 관심을 가진 주제 중에 하나가 바로 핵전쟁이 나도 살아남는 네트워크였다.(핵전쟁의 상대방은 당연히 마더 러씨아…)
* 왜냐하면 1970년대의 네트워크는 회선 교환 방식을 사용하고 있었기 때문에 중계국이 폭격을 맞아서 박살나거나 중간에 연결된 선이 하나가 잘려나가면 그대로 통신이 끊어져 버렸기 때문이다.
* 저 당시 중계국이 하는 일은 그냥 이거다. A가 중계국에 “B랑 연결해주세요!”라고 하면, 위의 사진과 같이 케이블이 마구 꽂혀있는 패치 테이블에서 A 라벨이 붙은 구멍과 B 라벨이 붙은 구멍을 찾아서 케이블로 연결해준다.
* 말 그대로 회선을 교환하는 방식인 것이다. 저러다가 A가 C랑 통신하고 싶으면 B 구멍에서 케이블을 빼서 C 구멍에 꽂으면 된다.
* 이렇게 회선 교환 방식의 경우에는 통신을 하고 싶은 상대방과 물리적으로 회선을 하나 딱 잡아놓고 계속 통신을 하는 것이기 때문에 회선의 효율이 낮을 수 밖에 없다. 우리가 전화를 걸 때 상대방이 통화 중이면 상대방이 통화 중이니... 어쩌고 나오는 것과 같은 원리이다.
* 물론 회선을 독점하기 때문에 대량의 데이터를 빠른 속도로 주르륵 보낼 수 있는 등의 장점도 있긴 하지만, 이때 미국에게 중요한 것은 핵이 터져도 끊기지 않는 연결이었기 때문에 하나의 회선에 전적으로 의존하는 연결이라는 건 큰 단점으로 다가왔을 것이다.
* 그래서 나온 아이디어가 바로 패킷 교환 방식이다. 데이터를 하나의 회선을 사용하여 보내다가 해당 회선이나 중계국이 개박살나면 전송되던 데이터와도 영원히 이별하게 되니, 데이터를 잘게 쪼갠 후 여러 개의 회선을 통해 보내자는 것이다. 일종의 분산투자랄까.
* 최악의 경우 중간에 있는 회선이나 중계국이 박살나서 데이터가 약간 유실될 수는 있겠지만 전체 네트워크를 한 번에 타격하지 않는 이상 모든 데이터가 유실될 가능성은 적다. 또한 하나의 회선을 잡아놓고 계속 통신하는 것이 아니라 패킷에 목적지를 마킹해놓고 그냥 보내기만 하면 되니, 회선의 사용 효율 또한 높아질 수 있다.
* 이런 이유로 미 국방성은 이 아이디어를 채택하여 알파넷에 적용했고, 초기 테스트도 대성공하여 패킷 교환 방식의 실용성을 증명했다.
* 이후 몇 개의 대학과 군에서만 사용되던 알파넷이 대중들에게 공개되고 전 세계적으로 연결되며 인터넷으로 발전하게 되었고, 덩달아 알파넷의 통신 프로토콜이었던 TCP도 함께 떡상하게 된 것이다.

## tcp 역할
* TCP(Transmission Control Protocol)은 원활한 통신을 위해 전송하는 데이터 흐름을 제어하고 네트워크의 혼잡 상태를 파악해서 대처하는 기능을 프로토콜 자체에 포함하고 있다.
* 만약 TCP가 이런 기능들을 제공해주지 않는다면 개발자가 일일히 데이터를 어떤 단위로 보낼 것인지 정의해야하고, 패킷이 유실되면 어떤 예외처리를 해야하는 지까지 신경써야하기 때문에 TCP가 제공해주는 이러한 기능들 덕분에 우리는 온전히 상위 레이어의 동작에만 집중할 수 있는 것이다.
* 보통 TCP의 전송 제어 방법은 전송되는 데이터의 양을 조절하는 흐름 제어, 통신 도중에 데이터가 유실되거나 잘못된 데이터가 수신되었을 경우 대처하는 방법인 오류 제어, 네트워크 혼잡에 대처하는 혼잡 제어로 나누어진다.
* 물론 TCP 같은 전송 계층의 프로토콜을 어플리케이션 레이어에서 활동하는 개발자가 건드릴 일은 많이 없다. 그러나 혹시라도 이 부분에서 뭔가 문제가 발생했을 경우, TCP가 어떤 식으로 작동하는지 모른다면 고치는 건 둘째치고 원인 파악조차 하지 못하는 슬픈 상황이 발생할 수 있으므로 여러모로 알아두는 것이 좋다고 생각한다. (더불어 야근도 따라올 것이다)

## 회선 교환에서 개선된 점
```java
하지만 패킷 교환 방식도 당연히 만능이 아니기에, 몇 가지 문제가 있었다. 우
리가 TCP를 공부할 때 함께 따라오는 ARQ나 SYN, ACK 등의 개념들이 바로 이런 문제들을 해결하기 위해 
과거의 엔지니어들이 머리를 싸맨 결과인 것이다.

Q: 전송 중간에 패킷이 쥐도새도 모르게 사라지거나 훼손되면 어떡해요?
A: 그럼 그 패킷만 다시 보내라고 해!(ARQ)
Q: 송신 측이 패킷을 쪼갠 순서를 알아야 수신 측이 재조립할 수 있겠는데요?
A: 그럼 순서번호를 패킷이랑 같이 보내!(SYN)
Q: 수신 측이 처리할 수 있는 속도보다 송신 측이 패킷을 빠르게 보내버리면 어떡하죠?
A: 그럼 수신 측이 처리할 수 있는 양을 송신 측에 알려주고 그 만큼만 보내라고 해! (슬라이딩 윈도우)
```

## 연결지향
* 이게 헷갈리는 이유는 물리적인 연결과 논리적인 연결의 차이 때문이다.
* 우리가 일반적으로 기기와 다른 기기를 연결했다고 할 때 떠올리는 생각은 컴퓨터와 모니터를 연결하거나, USB와 컴퓨터를 연결하는 등의 상황이다. 즉, 기기 간의 물리적인 연결이다.
* 반면, 연결 지향이라는 단어에서 사용하고 있는 연결의 의미는 논리적인 연결(Logical Connection)을 의미한다. 이때 당연히 여러 개의 기기가 서로 통신을 하기위해서는 물리적인 연결 또한 동반되어야한다.
조금 더 쉽게 이야기해보자면, 두 기기가 서로 연결되어 있는 상태를 유지하는 것이다.
* 전화를 예로 들자면, 전화가 전화선에 연결되어있는 것이 물리적인 연결이고 실제로 다른 전화와 통화를 하고 있는 상황이 논리적인 연결, 즉 연결되어 있는 상태인 것이다.
* 그렇다면 왜 TCP는 이런 연결 상태를 유지하는 걸까? 그 이유는 간단하다. 바로 연속적인 데이터 전송의 신뢰성을 위해서이다.
* 기본적으로 TCP는 패킷 전송 방식을 사용하기 때문에 보내려고 하는 데이터를 여러 개의 패킷으로 쪼개서 보낸다. 이때 네트워크를 통해 모든 데이터를 한번에 팍! 보내는 것이 아니라 일정 단위로 묶어서 스트림처럼 상대방에게 흘려보내게 된다.
* 그럼 한번 데이터를 받는 수신자 입장에서 생각해보자. 패킷 전송 방식의 장점 중 하나는 회선을 점유하지 않고 적은 양의 회선으로도 동시에 통신을 할 수 있다는 점이다.
* 그렇다는 것은 각 종단이 동시다발적으로 여러 기기들과 패킷을 주고 받고 있다는 의미인데, 이때 누가 보낸 몇 번째 패킷이라는 정보가 없다면 수신 측은 굉장히 혼란스러울 것이다.
* 위 그림에서 파이프는 물리적인 연결, 각 파이프 끝의 구멍은 포트, 양동이는 패킷을 처리할 프로세스라고 생각해보자. 이때 연결 상태에 대한 구분을 하지 않고 패킷을 구분하고 싶다는 것은 마치 한 양동이에 담긴 물 중에서 어떤 한 파이프 구멍에서 나온 물을 구분해내고 싶다는 말과 비슷하다.
* 그렇기 때문에 TCP는 A와 B의 연결 상태, A와 C의 연결 상태 등 각 기기간의 연결 상태를 따로 구분하고 있는 것이다. 이때 TCP는 상대방과 연결 상태를 만들거나 해제하기 위해 특별한 과정을 거치는데, 이 과정을 핸드쉐이크(Handshake)라고 한다.

## 3 way HandHsake
* [3way]('https://evan-moon.github.io/2019/11/17/tcp-handshake/')
```java
1. CLOSED
아직 연결 요청을 시작하지 않았기 때문에 아무런 연결도 없는 상태이다.

2. LISTEN
수신자가 요청자의 연결 요청을 기다리고 있는 상태이다.
이후 요청자가 연결 요청을 보내기 전까지 수신자는 계속 이 상태로 대기하게 된다. 
즉, 적극적으로 상대방에게 대시하지 않는다는 것인데, 그래서 이 상태를 수동 개방(Passive Open)이라 하고, 
수신자를 Passive Opener라고도 한다.
소켓 프로그래밍을 할 때, 소켓 바인딩을 한 후 listen 함수를 호출하게 되면 수신자가 LISTEN 상태로 들어가게 된다.
이후 수신자는 요청자의 연결 요청이 확인되면 accept 함수를 호출하여 다음 단계로 넘어가게 된다.

3. SYN_SENT
요청자가 수신자에게 연결 요청을 하면서 랜덤한 숫자인 시퀀스 번호를 생성해서 SYN 패킷에 담아 보낸 상태이다. 
이제 요청자와 수신자는 이 시퀀스 번호를 사용하여 계속 새로운 값을 만들고 서로 확인하며 연결 상태와 패킷의 순서를 확인하게 된다.

TCP 세그먼트를 캡쳐할 수 있는 tcpdump 유틸리티로 이 과정을 확인해보면 요청자가 패킷의 플래그를 SYN 패킷을
의미하는 S로 설정하고 시퀀스 번호로 3414207244라는 값을 생성해서 수신자에게 보내고 있음을 알 수 있다.

이 경우는 요청자가 수신자에게 연결을 생성하자고 적극적으로 대시하는 상황이므로 이 상태를 
능동 개방(Active Open)이라고 하고, 요청자를 Active Opener라고도 한다.

4. SYN_RECV
SYN_RECV는 요청자가 보낸 SYN 패킷을 수신자가 제대로 받은 상태를 의미한다.

이후 수신자는 제대로 된 시퀀스 번호를 받았다는 확인의 의미인 승인 번호(Acknowledgement) 값을 만들어서
다시 요청자에게 돌려줘야한다. 이때 승인 번호는 처음 요청자가 보낸 시퀀스 번호 + 1이 된다.
이 승인 번호 만드는 과정은 어렵게 생각할 필요가 없는게, 저번 포스팅에서 이야기했듯이 
TCP를 사용하여 실제로 데이터를 주고 받을 때에는 상대방이 보낸 시퀀스 번호 
+ 상대방이 보낸 데이터의 byte를 합쳐서 승인 번호를 만들어낸다. 
즉, 내가 여기까지 받았으니, 다음에는 여기부터 보내달라는 일종의 마킹인 것이다.
그러나 이런 핸드쉐이크 과정에서는 아직 데이터를 주고 받지 않기 때문에 시퀀스 번호에 더할게 없다. 
그렇다고해서 시퀀스 번호를 같은 번호로 주고 받자니 패킷의 순서를 구분할 수 없지 않은가? 그래서 그냥 1을 더하는 것이다.
방금 전과 마찬가지로 tcpdump 유틸리티를 사용하여 이 과정을 확인해볼 수 있다.
수신자가 요청자에게 보내는 패킷을 캡처해보았더니 패킷의 플래그가 S.로 설정되어있다. 
이때 .가 의미하는 것은 헤더의 ACK 플래그 필드가 1이라는 것이므로 이 패킷에는 유효한 승인 번호가 담겨있음을 알 수 있다.
수신자는 이번 통신을 통해 요청자에게 3414207245 이라는 승인 번호를 전달하고 있는데, 
이 값은 방금 전 요청자가 보냈던 시퀀스 번호인 3414207244에 1을 더한 값이다.
또한 랜덤한 수로 자신의 시퀀스 번호인 435597555를 다시 생성하여 함께 요청자에게 보내주고 있는 것을 확인할 수 있다.

5. ESTABLISHED(요청자)
요청자는 자신이 맨 처음에 보냈던 시퀀스 번호와 수신자가 응답으로 보내준 승인 번호, 
즉 내 시퀀스 번호 + 1를 사용하여 연결이 제대로 성립되었는지 확인할 수 있다. 
자신이 보냈던 시퀀스 번호와 이번에 받은 승인 번호의 차가 1이라면 제대로 연결이 되었다고 판단하는 것이다.
이후 요청자는 연결이 성립되었다고 판단하고 ESTABLISHED 상태로 들어가면서, 
이번에는 수신자가 새롭게 만들어서 보내줬던 시퀀스 번호에 1을 더한 값을 다시 승인 번호로 사용하여 다시 수신자에게 보내준다.
즉, 마지막으로 수신자가 보내줬던 시퀀스 번호인 435597555에 1을 더한 값인 435597556이 요청자의 
승인 번호가 될 것이다…만 tcpdump의 동작은 필자의 예상과 달랐다.

6. ESTABLISHED(수신자)
요청자와 마찬가지로 수신자 또한 자신이 보냈던 시퀀스 번호와 이번에 받은 승인 번호의 차가 1이라면 
제대로 연결이 되었다고 판단하고 ESTABLISHED 상태로 들어가게된다. 
여기까지 오면 요청자와 수신자는 안전하고 신뢰성있는 연결이 생성되었다고 판단하고 본격적인 통신을 시작할 수 있다.
```

## 4 way handshake
```java
연결을 생성할 때와 마찬가지로, 연결을 종료할 때도 특정한 과정을 거쳐서 연결을 종료해야한다.
그냥 연결을 끊어버리면 안되냐고 할 수도 있지만, 한 쪽에서 일방적으로 연결을 끊어버리면 
다른 한 쪽은 연결이 끊어졌는지 지속되고 있는지 알 방법이 없다.
또한 연결을 종료하기 전에 아직 다 처리하지 못한 데이터가 있을 수도 있기 때문에 
양 쪽이 다 정상적으로 연결을 종료할 준비가 되었는 지를 확인하는 과정이 필요한 것이다.
이때 요청자와 수신자가 총 4번의 통신 과정을 거치기 때문에, 이 과정을 4 Way Handshake라고 부른다.
이번에도 요청자(Initiator)와 수신자(Receiver)라는 용어를 사용하고 있는데, 
3 Way Handshake와 마찬가지로 클라이언트와 서버, 둘 중에 어느 쪽이든 연결 종료 요청을 시작할 수 있기 
때문에 이런 용어를 사용하는 것이다.
먼저 연결 생성 요청을 했던 쪽이 먼저 연결 종료 요청을 보낼 수도 있고, 
반대로 처음에는 연결 생성 요청을 당했던 쪽이 이번에는 먼저 연결 종료 요청을 보낼 수도 있다.
사실 개발자들은 3 Way Handshake보다 연결을 종료하는 과정인 4 Way Handshake에 더 예민하게 반응할 수 밖에 없는데, 
연결을 생성하는 과정에서 문제가 발생하여 연결이 생성되지 않는다면 다시 시도하면 그만이지만, 
이미 생성된 연결을 종료하는 과정인 4 Way Handshake에서 문제가 발생하면 그대로 연결이 남아있기 때문이다.
게다가 4 Way Handshake는 3 Way Handshake처럼 순차적으로 주고받는 방식이 아니라 
상대방이 응답을 줄 때까지 대기하는 과정이 포함되어있기 때문에 중간에 뭐 하나 엇나가면 
서로 계속 대기만 하고 있는 데드락(Deadlock) 상황이 연출될 수도 있다.
물론 조건에 따라 일정 시간이 지나면 타임아웃이 되며 연결을 강제로 종료하거나 
다음 단계로 넘어갈 수도 있지만 그래도 그 시간 동안 프로세스가 메모리와 포트를 점유하고 있으므로 
트래픽이 많은 서버라면 이로 인해 병목이 발생할 가능성은 늘 있다.

1. FIN_WAIT_1
먼저 연결을 종료하고자 하는 요청자가 FIN 패킷을 상대방에게 보내면서 FIN_WAIT1 상태로 들어서게 된다.
이때 FIN 패킷에도 시퀀스 번호가 포함되어있긴한데, 이번에는 랜덤한 값으로 생성해서 보내는 것이 아니다. 
3 Way Handshake는 시퀀스 번호가 없는 상황에서 새로 만들어야하는 상황이라 랜덤한 값으로 초기화했지만, 
이번에는 시퀀스 번호를 새롭게 생성할 필요가 없으므로 그냥 자신이 이번에 보내야할 순서에 맞는 시퀀스 번호를 사용하면 되는 것이다.

요청자 —SEQ: 1—> 수신자
요청자 <—ACK: 2— 수신자
요청자 —FIN: 2—> 수신자
즉, FIN 플래그만 1로 변경해서 보낸다고 생각하는 게 편하다. 
이 플래그의 의미를 쉽게 얘기해보자면 “나 더 이상 할 말 없음” 정도이다.

이때 요청자가 먼저 적극적으로 연결 종료 요청을 보내는 것이기 때문에 요청자를 Active Closer, 
이 상태를 능동 폐쇄(Active Close)라고 한다

하지만 요청자가 수신자에게 보낸 연결 종료 요청 패킷을 캡처해보니 
F 플래그가 아니라 FIN+ACK를 의미하는 F. 플래그가 설정되어있다. tcpdump를 사용하여 
패킷을 캡처한 다른 블로그를 봐도 대부분 필자와 같은 상황을 겪고 있음을 알 수 있었다.

분명 이론적으로는 FIN 패킷을 보내야하는데 왜 승인 번호를 함께 묶어서 FIN+ACK로 보내고 있는 것일까?

* Half-Close 기법
요청자가 FIN+ACK 패킷을 보내는 이유는 바로 Half-Close라는 기법을 사용하고 있기 때문이다. 
Half-Close 기법은 말 그대로 연결을 종료하려고 할 때 완전히 종료하는 것이 아니라 반만 종료하는 것이다.

Half-Close를 사용하면 요청자가 처음 보내는 FIN 패킷에 승인 번호를 함께 담아서 보내게 되는데, 
이때 이 승인 번호의 의미는 “일단 연결은 종료할 건데 귀는 열어둔다. 이 승인 번호까지 처리했으니까 
마저 보낼 거 있으면 보내”라는 의미가 된다.

즉, 반만 닫겠다는 말의 의미는 연결을 종료할 때 전송 스트림과 수신 스트림 중 하나만 우선 닫겠다는 것을 의미하는 것이다.

이후 수신자는 미처 못 보낸 데이터가 있다면 열심히 보낼 것이고, 이에 요청자는 아직 살아있는 
수신 스트림을 사용하여 데이터를 처리한 후 ACK 패킷을 응답으로 보낼 수 있다. 이후 수신자가 모든 
데이터를 처리하고나면 다시 요청자에게 FIN 패킷을 보냄으로써 모든 데이터가 처리되었다는 신호를 보내준다.

그럼 요청자는 그때 나머지 반을 닫으면서 조금 더 안전하게 연결을 종료할 수 있는 것이다.

소켓 프로그래밍을 할 때 연결 종료 함수로 close()와 shutdown()을 사용할 수 있는데, 
이때 shutdown() 함수를 사용하면 Half-Close를 사용할 수 있다.

만약 요청자가 close() 함수를 사용하면 호출 즉시 OS에게 소켓의 리소스를 반환하며 
모든 스트림이 파기되므로 FIN 패킷을 받은 수신자가 미처 못 보낸 데이터를 뒤늦게 전송하더라도 더 이상 처리할 수 없는 상황이 된다.

위의 예제에서는 SHUT_WR 값을 두 번째 인자로 사용함으로써 전송 스트림만 우선 닫겠다고 선언한 것이다.

이와 관련된 더 자세한 정보는 구글에 Half-Close나 우아한 종료 등의 키워드로 검색하면 많은 자료가 나오니 한번 살펴보도록 하자.

2. CLOSE_WAIT
요청자으로부터 FIN 패킷을 받은 수신자는 요청자가 보낸 시퀀스 번호 + 1로 승인 번호를 만들어서 
다시 요청자에게 응답해주면서 CLOSE_WAIT 상태로 들어간다.

아까 요청자가 FIN 패킷의 시퀀스 번호로 701384376을 보냈으니 이번에 수신자가 응답해줄 승인 번호는 701384377이 되는 것이다.
이후 수신자는 자신이 전송할 데이터가 남아있다면 이어서 계속 전송한 후, 
모든 전송이 끝났다면 명시적으로 close()나 shutdown()과 같은 함수를 호출하여 다음 단계로 넘어갈 것이다.
즉, 요청자는 언제 수신자의 데이터 처리가 끝날지 모르는 상태이기 때문에 
수신자가 작업을 마치고 다시 연결 종료 승인을 의미하는 FIN 패킷을 보내줄 때까지 대기해야한다는 말이 된다.
만약 이 단계에서 수신자의 데이터 처리가 끝나도 연결 종료 함수가 명시적으로 
호출되지 않으면 다음 상태로 넘어갈 수 없기 때문에 데드락이 발생할 가능성이 있다.

이때 수신자는 상대방으로부터 연결 종료 요청을 받은 후에야 수동적으로 연결을 종료할 준비를 하기 때문에 
수신자를 Passive Closer, 이 상태를 수동 폐쇄(Passive Close)라고 한다.


3. FIN_WAIT_2
요청자는 수신자로부터 승인 번호를 받고 자신이 보냈던 시퀀스 번호와 승인 번호의 차가 1이 맞는지 확인한다. 
하지만 아직 수신자의 데이터 전송이 전부 끝나지 않았을 수도 있기에 FIN_WAIT2 상태로 들어가서 수신자가 
연결 종료를 허락하는 FIN 패킷을 보내줄 때까지 기다린다.

방금 CLOSE_WAIT 섹션에서 설명했듯이 여기서부터는 수신자가 다시 FIN 패킷을 보내줄 때까지 요청자는 계속 대기하는 시간이다.

하지만 CLOSE_WAIT와 다르게 무한정 대기만 하는 것은 아니고 커널 파라미터로 타임아웃이 정해져있는 경우, 
일정 시간이 경과하면 자동으로 다음 단계로 넘어갈 수 있다.

4. LAST_ACK
수신자는 자신이 처리할 데이터가 더 이상 없다면 연결을 종료하는 함수를 명시적으로 호출하고, 
아까 요청자가 보냈던 연결 종료 요청에 합의한다는 의미로 요청자에게 다시 FIN 패킷을 보낸다.

이때 수신자가 보내는 FIN 패킷에 담기는 시퀀스 넘버는 자신이 이번에 전송해야 하는 데이터의 
시퀀스 번호를 그대로 사용하며, 승인 번호는 마지막으로 자신이 응답했던 승인 번호를 그대로 사용한다.

이후 수신자는 LAST_ACK 상태로 들어가며 요청자가 다시 승인 번호를 보내줄 때까지 대기한다.

5. TIME_WAIT
수신자가 보낸 FIN 패킷을 받은 요청자는 다시 수신자가 보낸 시퀀스 번호 + 1로 승인 번호를 생성하여 
수신자에게 ACK 패킷으로 응답한다. 이후 요청자는 TIME_WAIT 상태로 들어가며, 실질적인 연결 종료 과정에 들어가게 된다. 
이때 TIME_WAIT의 역할은 의도하지 않은 에러로 인해 연결이 데드락에 빠지는 것을 방지하는 것이다.
TIME_WAIT에서 대기하는 시간은 2 MSL(Maximum Segement Lifetime)으로 정의되어 있으며, 
정확한 MSL의 시간 값은 커널 파라미터로 정의되어있다.

필자의 컴퓨터인 OSX의 MSL은 15초로 설정되어있다. 즉, 필자의 컴퓨터는 TIME_WAIT 상태에서 
30초 정도 대기한다는 것이다. 참고로 이 값은 변경할 수 없기 때문에 TIME_WAIT에서 소비되는 시간은 변경할 수 없다.

보통 TCP 타임아웃 파라미터로 많이 언급되는 net.ipv4.tcp_fin_timeout은 FIN_WAIT2의 타임아웃을 
조절할 수 있는 값이라 TIME_WAIT 상태에는 해당 사항이 없다.

하지만 CLOSE_WAIT와 마찬가지로 여기서도 데드락이 발생할 수 있다. 그런 이유로 많은 네트워크 
엔지니어들이 여기서 소비되는 시간을 줄이거나 운 나쁘게 발생한 데드락을 없애기 위해 tcp_tw_reuse 
커널 파라미터를 변경하는 등 여러가지 방법을 사용하고 있다. (데드락 피하자고 만든 상태인데 데드락이 발생하는 현실)

하지만 역시 그냥 가만 냅두는 게 제일 좋다고들 한다.

6. CLOSED(수신자)
요청자가 보낸 ACK 패킷을 받은 수신자는 CLOSED 상태로 들어가며 연결을 완전히 종료한다.

7. CLOSED(요청자)
TIME_WAIT 상태에서 2 MSL만큼 시간이 지나면 요청자도 CLOSED 상태로 변경된다. 
위에서 설명했듯이 이 시간은 커널 파라미터에 고정되어 있고, 필자가 사용하고 있는 OSX의 경우 30초 정도이다.
```

# 흐름제어
* 송신 측과 수신 측이 서로 데이터를 주고 받을 때, 여러가지 요인에 따라 이 두 친구들의 처리 속도가 달라질 수 있다. 이때 데이터를 받는 수신 측의 처리 속도가 송신 측보다 빠른 경우는 사실 별 문제가 없다.
* 주는 족족 빠르게 처리해주니 딱히 문제될 것이 없는 것이다. 그러나 수신 측의 처리 속도보다 송신 측이 더 빠른 경우 문제가 생긴다.
* 송신 측과 수신 측은 모두 데이터를 저장할 수 있는 버퍼를 가지고 있다. 이때 수신 측이 자신의 버퍼 안에 있는 데이터를 처리하는 속도보다 송신 측이 데이터를 전송하는 속도가 더 빠르다면, 당연히 수신 측의 버퍼는 언젠가 꽉 차버릴 것이기 때문이다.
* [goodgid](https://goodgid.github.io/Error-Flow-Control/)
* [evan]['https://evan-moon.github.io/2019/11/22/tcp-flow-control-error-control/']
```java
TCP의 가장 큰 특징은 신뢰성이다.
이러한 신뢰성을 구성해 주는 방법인 흐름제어, 혼잡제어, 오류제어에 대해 알아보자.

송신(호스트) <> 수신(호스트)

흐름제어는 수신측과 송신측의 데이터처리 속도차이를 해결하기 위한 기법이다.

만약 송신측의 전송량 > 수신측의 처리량 일 경우, 전송된 패킷은 수신측의 큐를 넘어서
손실될 수 있기 때문에 송신측의 패킷 전송량을 제어하게 된다.

* 흐름제어 방법
1. 정지-대기(Stop-and-wait)
구조가 간단한 대신, 하나를 주고 응답을 받기 때문에 비효율적이다.

Stop and Wait로 흐름 제어를 할 경우의 대원칙은 단순히 상대방이 응답을 하면 데이터를 보낸다이기 때문에 
구현 자체도 간단하고 프로그래머가 어플리케이션의 작동 원리를 파악하기도 쉬운 편이다.

기본적인 ARQ(Automatic Repeat Request)를 구현한다고 생각해보면, 수신 측의 윈도우 크기를 
1 byte로 설정하고 처리 가능 = 1, 처리 불가능 = 0과 같은 식으로 대충 구현해도 돌아가기는 하기 때문이다.

하지만 서로 처리 가능, 처리 불가능 정도의 의미만 주고받는 방식은 간단한만큼 비효율적이라고 할 수도 있다. 
왜냐하면 송신 측은 자신이 직접 데이터를 보내봐야 이 데이터를 수신 측이 처리할 수 있는지 알 수 있기 때문이다. 
쉽게 말해서 이런 기초적인 Stop and Wait 방식은 그냥 될 때까지 주구장창 보내는 방식이라고 봐도 무방하다.

그런 이유로 Stop and Wait 방식을 사용하여 흐름 제어를 할 경우에는, 이런 비효율성을 커버하기 위해 
이런 단순한 구현이 아닌 여러가지 오류 제어 방식을 함께 도입해서 사용한다.



2. 슬라이딩 윈도우(Sliding Window)
윈도우는 전송,수신 스테이션 양쪽에서 만들어진 버퍼(Buffer)의 크기다.
윈도우의 크기 = (가장 최근 ACK로 응답한 프레임의 수) - (이전에 ACK 프레임을 보낸 프레임의 수)

슬라이딩 윈도우 기법은 앞의 정지-대기 기법의 비효율성을 개선한 기법이다.

ACK프레임을 수신하지 않더라도, 여러 개의 프레임을 연속적으로 전송할 수 있다.

전송측 윈도우 n-1 개의 프레임을 포함한다.



방금 알아본 바와 같이 Stop and Wait를 사용하여 흐름 제어를 하게 되면 비효율적인 부분이 있기 때문에, 
오늘날의 TCP는 특별한 경우가 아닌 이상 대부분 슬라이딩 윈도우(Sliding Window) 방식을 사용한다.

슬라이딩 윈도우는 수신 측이 한 번에 처리할 수 있는 데이터를 정해놓고 그때그때 수신 측의 
데이터 처리 상황을 송신 측에 알려줘서 데이터의 흐름을 제어하는 방식이다.

Stop and Wait과 여러 가지 차이점이 있겠지만, 사실 가장 큰 차이점은 송신 측이 수신 측이 처리할 수 있는 
데이터의 양을 알고 있다는 점이다. 이 정보를 알고 있기 때문에 굳이 수신 측이 처리 가능이라는 
대답을 일일히 해주지 않아도 데이터를 보내기 전에 이게 처리될 지 어떨지 어느 정도 예측이 가능하다는 말이다.

송신 측과 수신 측은 각각 데이터를 담을 수 있는 버퍼를 가지고 있고, 별도로 윈도우라는 
일종의 마스킹 도구를 가지고 있다. 이때 송신 측은 이 윈도우에 들어있는 데이터를 수신 측의 응답이 없어도 연속적으로 보낼 수 있다.

송신 측의 윈도우 크기는 맨 처음 TCP의 연결을 생성하는 과정인 3 Way Handshake 때 결정된다. 
이때 송신 측과 수신 측은 자신의 현재 버퍼 크기를 서로에게 알려주게 되고, 송신 측은 수신 측이 보내준
버퍼 크기를 사용하여 음, 대충 이 정도 처리 가능하겠군이라는 과정을 통해 자신의 윈도우 크기를 정하게 된다.

tcpdump를 통해 3 Way Handshake를 관찰해보면 처음의 SYN과 SYN+ACK 패킷에는 각자 자신의 버퍼를 알려준 후 
마지막 ACK 패킷 때 송신 측이 자신이 정한 윈도우 사이즈를 상대방에게 통보하는 것을 볼 수 있다.

이때 송신 측과 수신 측 모두 자신의 버퍼 크기라 65535라고 이야기했지만 최종적으로 송신 측이 정한 자신의 윈도우 크기는 6379이다. 
왜 송신 측은 수신 측 버퍼 크기의 10분의 1로 자신의 윈도우 크기를 정한 것일까?

사실 송신 측의 윈도우 크기는 수신 측의 버퍼 크기로만 정하는 것이 아니라 다른 여러가지 
요인들을 함께 고려해서 결정된다. 상대방이 보낸 버퍼 크기만 믿고 자신의 윈도우 크기를 정하기에는 
네트워크는 너무나도 험난한 환경이기 때문이다. 이때 사용하는 대표적인 값이 바로 패킷의 왕복 시간을 의미하는 RTT(Round Trip Time)이다.

송신 측은 자신이 처음 SYN 패킷을 보내고, 다시 수신 측이 SYN+ACK 패킷으로 응답하는 시간을 재고, 
이 값을 통해 현재 네트워크 상황을 유추한다. 이때 이 값이 너무 크다면 왕복 시간이 느리다는 것이므로 
네트워크 상태가 좋지 않다고 생각하고 윈도우 크기를 조금 더 줄이게 되는 것이다.

그리고 이때 정해진 윈도우 크기는 고정이 아니라 통신을 하는 과정 중간에도 계속 네트워크의 
혼잡 환경과 수신 측이 보내주는 윈도우 크기를 통해 동적으로 변경될 수 있다. 윈도우의 크기, 
즉 연속적으로 보낼 데이터의 양을 변경해가면서 유연하게 흐름 제어를 할 수 있다는 말이다.

윈도우에 대해 대략적으로 이해를 했다면 이제 이 기법을 왜 슬라이딩 윈도우라고 하는 지 한번 살펴보도록 하자.

먼저, 송신 측이 0 ~ 6번의 시퀀스 번호를 가진 데이터를 상대방에게 전송하고 싶어하는 상황을 상상해보자. 
이때 송신 측의 버퍼에는 전송해야할 데이터들이 이렇게 담겨져 있을 것이다.

이때 송신 측은 수신 측에게 받은 윈도우 크기와 현재 네트워크 상황을 고려하여 윈도우 크기를 3으로 잡았고, 
윈도우 안에 있는 데이터를 우선 주르륵 전송한다.
이때 윈도우 안에 들어있는 데이터는 어떤 상태일까? 일단 데이터를 전송하기는 했지만 아직 수신 측으로부터 
잘 받았다는 응답을 받지 못한 상태일 것이다.

즉, 윈도우에 들어있는 데이터들은 항상 전송은 했지만, 상대방이 처리했는지는 모르는 상태라고 할 수 있다. 
물론 데이터를 윈도우에 넣고 나서 블록킹이 걸려 데이터를 처리하지 못하는 상태도 존재할 수 있지만, 
그런 것까지 다 고려하면 너무 복잡하니까 간단하게 생각하도록 하자.

이후 수신 측은 자신의 처리 속도에 맞게 데이터를 처리한 후 응답으로 현재 자신의 버퍼에 남아있는 
공간의 크기를 알려준다. 만약 수신 측이 응답으로 Window Size: 1을 보냈다면 “내 버퍼 공간이 
1 byte만큼 남았으니까 그 만큼만 더 보내봐”라는 의미가 된다.

이제 송신 측은 자신이 데이터 한 개를 더 보낼 수 있다는 사실을 알았으니, 자신의 윈도우를 한 칸 옆으로 밀고 
새롭게 윈도우에 들어온 3번 데이터를 수신 측에게 전송한다.

이때 윈도우를 옆으로 이동시키며 새로 들어온 데이터를 전송하기 때문에 슬라이딩 윈도우라고 하는 것이다. 
만약 수신 측이 윈도우 크기를 1이 아니라 더 큰 수를 보냈다면, 송신 측은 그 만큼 윈도우를 옆으로 밀고 
더 많은 데이터를 연속적으로 전송할 수 있을 것이다.

단, 이 경우 송신 측의 윈도우 크기가 3이기 때문에 수신 측이 4를 보냈다고 해서 4칸을 밀지는 않고, 
자신의 윈도우 크기인 3만큼만 밀 수 있다. 그러나 이 경우에는 송신 측이 수신 측의 퍼포먼스가 
더 좋아졌다는 것을 알았으니 자신의 윈도우 크기를 늘리는 방법으로 대처할 수 있을 것이다.

이렇게 데이터를 전송하는 송신 측의 버퍼는 대략 3가지 상태로 나눠질 수 있다.

즉 슬라이딩 윈도우 방식은 보내고 -> 응답받고 -> 윈도우 밀고를 반복하면서, 
현재 자신이 보낼 수 있는 데이터를 최대한 연속적으로 보내는 방법이라고 할 수 있다.

이게 지금 0 ~ 6 밖에 안되는 단순화된 그림으로 봐서 잘 와닿지 않을 수도 있지만, 
아무런 옵션도 적용하지 않은 TCP의 최대 윈도우 크기는 65,535 bytes이고, WSCALE 옵션을 최대로 적용하면 1GB로 설정하는 것도 가능하다.

게다가 연속적으로 한번에 보내는 데이터도 이렇게 한 개, 두 개 정도가 아니라 몇 백 바이트 단위로 보내는 경우가 
많기 때문에 실제 환경에서는 Stop and Wait로 흐름 제어를 하는 것과 비교해봤을때 상당히 좋은 효율을 뽑아낼 수 있다. 
즉, 이론적으로는 수신 측의 ACK 응답 없이도 최대 1GB를 연속적으로 전송할 수 있다는 말이다.

이렇게 슬라이딩 윈도우 방식은 일일히 하나 보내고, 응답 받고 하는 Stop and Wait보다 확실히 전송 속도 측면에서 빠르기도 하고, 
송신 측과 수신 측의 지속적인 커뮤니케이션을 통해 윈도우 크기 또한 유연하게 조절할 수 있기 때문에 
최근의 TCP에서는 기본적으로 슬라이딩 윈도우를 사용하여 흐름 제어를 하고 있다.
```


## 혼잡제어
```java
송신(호스트) <> 라우터(네트워크)

혼잡 제어는 송신측과 네트워크의 데이터처리 속도 차이를 해결하기 위한 기법이다.

송신된 패킷이 네트워크 상의 라우터가 처리할 수 있는 양을 넘어서 혼잡하게 되면
데이터가 손실될 수 있기 때문에 송신측의 전송량을 제어하게 된다.

1. 합 증가/곱 감소
이 방식은 AIMD(Additive Increase/Multiplicative Decrease)라고 불리는 방식이다.

처음에 패킷을 하나씩 보내고 이것이 문제없이 도착하면 창 크기(단위 시간 내에 보내는 패킷의 수)를 1씩 증가시켜가면서 전송하는 방법이다.
만일 패킷 전송을 실패하거나 일정한 시간을 넘으면 패킷을 보내는 속도를 절반으로 줄이게 된다.

이 방식은 공평한 방식이다.

이 방식을 사용하는 여러 호스트가 한 네트워크를 공유하고 있으면 나중에 진입하는 쪽이 처음에는 불리하지만 시간이 흐르면 평형 상태로 수렴하게 되는 특징이 있다.

문제점은 초기에 네트워크의 높은 대역폭을 사용하지 못하여 오랜 시간이 걸리게 되고,
네트워크가 혼잡해지는 상황을 미리 감지하지는 못한다.

즉, 네트워크가 혼잡해지고 나서야 대역폭을 줄이는 방식이다.



2. 슬로우 스타트(Slow Start)
합 증가/곱 감소 방식이 네트워크의 수용량 주변에서는 효율적으로 작동하지만
처음에 전송 속도를 올리는 데 걸리는 시간이 너무 길다는 단점이 있다.

느린 시작(Slow Start) 방식은 합 증가/곱 감소 방식과 마찬가지로 패킷을 하나씩 보내는 것부터 시작하고,
이 방식은 패킷이 문제없이 도착하면 각각의 ACK 패킷마다 Window size를 1씩 늘린다.
즉, 한 주기가 지나면 Window size가 2배로 된다.

따라서 전송 속도는 합 증가/곱 감소와는 다르게 지수 함수 꼴로 증가하게 된다.

대신에 혼잡 현상이 발생하면 Window size를 1로 떨어뜨리게 된다.

처음에는 네트워크의 수용량을 예상할 수 있는 정보가 없지만
한번 혼잡 현상이 발생하고 나면 네트워크의 수용량을 어느 정도 예상할 수 있으므로
혼잡 현상이 발생하였던 Window size의 절반까지는 이전처럼 지수 함수 꼴로 창 크기를 증가시키고 그 이후부터는 완만하게 1씩 증가시키는 방식이다.
미리 정해진 임계 값에 도달할 때까지 윈도우의 크기를 2배씩 증가시킨다.

Slow start란 이름을 사용하지만, 매 전송마다 두 배씩 증가하기 때문에 전송되어지는 데이터의 크기는 지수 함수적으로 증가한다.

전송되어지는 데이터의 크기가 임계 값에 도달하면 혼잡 회피 단계로 넘어간다

3. 혼잡 회피(Congestion Avoidance)
윈도우의 크기가 임계 값에 도달한 이후에 데이터의 손실이 발생할 확률이 높아지게된다.

데이터를 전송함에 있어서 조심하는 단계이다.
전송한 데이터에 대한 Ack를 받으면 윈도우의 크기를 1씩 증가시킨다.
전송하는 데이터의 증가를 왕복시간 동안에 하나씩만 증가시킨다.
신 호스트로부터 일정 시간 동안까지 Ack를 수신하지 못하는 경우
타임아웃의 발생 : 네트워크에 혼잡이 발생하였다고 인식
혼잡상태로 인식된 경우
윈도우의 크기를, 즉 세그먼트의 수를 1로 줄임
동시에 임계 값을 패킷 손실이 발생하였을 때의 윈도우 크기의 반으로 줄임

4. 빠른 회복(Fast Recovery)
빠른 회복 정책은 혼잡한 상태가 되면 Window size를 1로 줄이지 않고 반으로 줄이고 선형 증가시키는 방법이다.

빠른 회복 정책까지 적용하면 혼잡 상황을 한번 겪고 나서부터는 순수한 합 증가/곱 감소 방식으로 동작하게 된다.
```

## 오류 제어
```java
오류 제어 기법은 오류검출(error detection)과 재전송(retransmisstion)을 포함한다.

TCP는 기본적으로 ARQ(Automatic Repeat Request), 재전송 기반 오류 제어를 사용한다. 
말 그대로 통신 중에 뭔가 오류가 발생하면 송신 측이 수신 측에게 해당 데이터를 다시 전송해야한다는 말이다.

하지만 이 재전송이라는 작업 자체가 했던 일을 또 해야하는 비효율적인 작업이기 때문에, 
이 재전송 과정을 최대한 줄일 수 있는 여러가지 방법을 사용하게 된다.

TCP를 사용하는 송수신 측이 오류를 파악하는 방법은 크게 두 가지로 나누어진다.

수신 측이 송신 측에게 명시적으로 NACK(부정응답)을 보내는 방법, 그리고 송신 측에게 ACK(긍정응답)가 오지 않거나, 
중복된 ACK가 계속 해서 오면 오류가 발생했다고 추정하는 방법이다.

간단히 생각해보면 왠지 NACK를 사용하는 방법이 더 명확하고 간단할 것 같지만,
NACK를 사용하게되면 수신 측이 상대방에게 ACK를 보낼 지 NACK를 보낼 지 선택해야하는 로직이 추가적으로 필요하기 때문에, 
일반적으로는 ACK만을 사용해서 오류를 추정하는 방법이 주로 사용되고 있다.

이때 타임아웃은 말 그대로 송신 측이 보낸 데이터가 중간에 유실되어, 
수신 측이 아예 데이터를 받지 못해 ACK를 보내지도 않았거나, 수신 측은 제대로 응답했지만 해당 ACK 패킷이 유실되는 경우에 발생하게 된다.

어쨌든 두 경우 모두 송신 측은 데이터를 전송했는데 수신 측이 응답하지 않고 일정 시간이 경과한 경우라고 생각하면된다.

그리고 두 번째 방법인 송신 측이 중복된 ACK를 받는 경우 오류라고 판별하는 방법은 대략 이런 느낌이다.

이 상황을 조금 더 쉽게 풀어보자면, 송신 측은 이미 SEQ 2 데이터를 보낸 상황인데 수신 측이 계속 
야, 이번에 2번 보내줄 차례야라고 말하는 상황인 것이다. 그럼 송신 측은 자신이 보낸 2번 데이터에 뭔가 문제가 발생했음을 알 수 있다.

단, 패킷 기반 전송을 하는 TCP의 특성 상 각 패킷의 도착 순서가 무조건 보장되는 것이 아니기 때문에 
위 예시처럼 중복된 ACK를 한 두번 받았다고 해서 바로 에러라고 판별하지는 않고, 보통 3회 정도 받았을 때 에러라고 판별하게 된다.


ARQ(Automatic Repeat Request)기법을 사용하여 프레임이 손상되었거나 손실되었을 경우 재전송을 통해 오류를 복구한다.

ARQ기법은 흐름제어 기법과 관련되어있는데,
“정지-대기”는 정지-대기-ARQ로,
“슬라이딩 윈도우”는 GBn(Go-Back-n) ARQ 또는 SR(Selective-Reject) ARQ 형태로 구현한다.

오류 제어 종류
ARQ(Automatic Repeat Request) : 신뢰성 있는 데이터 전달을 위해 재전송을 기반으로 한 에러 제어 방식

1. 정지-대기 ARQ
Stop and Wait는 흐름 제어 때 한번 살펴보았던, 한번 데이터를 보내면 제대로 받았다라는 응답이 올 때까지 
대기하고 있다가 다음 데이터를 보내는 방식이다.

이 친구가 오류 제어에서 다시 나오는 이유는 그냥 이렇게만 해도 기본적인 오류 제어가 가능하기 때문이다. 
일석이조랄까. 애초에 제대로 받았다는 응답이 오지 않는다면 제대로 받을 때까지 계속 데이터를 재전송하는 방법이니까 
흐름 제어도 되지만 오류 제어도 가능하다.
그러나 위에서 살펴본 슬라이딩 윈도우를 사용하여 흐름 제어를 하는 경우에는 윈도우 안에 있는 데이터를 연속적으로 보내야 하기 때문에, 
오류 제어에 Stop and Wait를 사용해버리면 슬라이딩 윈도우를 쓰는 이점을 잃어버린다.

그런 이유로 일반적으로는 이런 단순한 방법보다 조금 더 효율적이고 똑똑한 ARQ를 사용하게 된다.

전송스테이션은 수신측에서 보내준 ACK를 받을 때 까지, 프레임의 복사본을 유지한다.

식별을 위해 데이터 프레임과 ACK프레임은 각각 0, 1번호를 부여한다.

수신측이 데이터를 받지 못했을 경우, NAK를 보내고, NAK를 받은 송신측은 데이터를 재전송한다.

만약 데이터나 ACK가 분실되었을 경우 일정간격의 시간을 두고 타임아웃이 되면, 송신측은 데이터를 재전송한다.


2. Go-Back-n ARQ (GBn ARQ)
위에서 이야기했듯이 오류를 판별하는 방법에는 ACK의 이상 징후를 파악하는 방법을 더 많이 사용하기는 하지만, 
NACK를 사용하고 있다고 가정하는 것이 다이어그램을 이해하기가 편하므로 오류 제어 기법을 설명할 때는 
수신 측이 NACK를 사용하고 있다고 가정할 것이다.

이 섹션에서는 오류 제어 기법을 설명하는 것이 목적이니, 오류를 어떻게 판별하는지보다는 
오류를 어떻게 제어하는지에 대해서만 집중해보도록 하자.

Go Back N 방식을 사용하면 데이터를 연속적으로 보낸 후 한 개의 ACK나 NACK만을 사용하여 수신 측의 처리 상황을 파악할 수 있으므로, 
연속적으로 데이터를 보낼 수 있는 흐름 제어 방식인 슬라이딩 윈도우와 아주 잘 들어맞는다고 할 수 있다.

즉, 송신 측은 수신 측으로 NACK를 받고나면 오류가 발생한 4번 데이터와 그 이후 전송했던 모든 데이터를 다시 전송해줘야 한다는 
말이 된다. 이때 송신 측은 비록 5번까지 전송했지만 오류가 발생하면, 오류가 발생한 4번 데이터로 되돌아가서 다시 전송해야하므로 
Go Back N이라고 부르는 것이다

전송된 프레임이 손상되거나 분실될 경우, 확인된 마지막 프레임 이후로 모두 재전송 하는 기법이다.

슬라이딩 윈도우는 연속적인 프레임 전송 기법이므로,
전송 스테이션은 전송된 모든 프레임의 복사본을 가지고 있어야 하며, ACK와 NAK 모두 각각 구별을 해야한다.

ACK : 다음 프레임을 전송
NAK : 손상된 프레임 자체 번호를 반환

재전송 되는 경우는 다음과 같다.

[1] NAK 프레임을 받았을 경우
만약, 수신측으로 0부터 5까지의 데이터를 보내었다고 가정한다.
수신측에서 데이터를 받았음을 확인하는 ACK 프레임을 중간 중간 받게 되며, ACK 프레임을 확인한 전송측은 계속해서 데이터를 전송한다.
그러나 만약 수신측에서 데이터 오류 프레임 2를 발견하고 NAK2를 전송 측에 보낸다.
NAK2를 받은 전송측은 데이터 프레임2가 잘못 되었다는 것을 알고 데이터를 재전송한다.
GBn ARQ의 특징은 바로 이 데이터를 재전송하는 부분이다.
GBn ARQ는 NAK(n)을 받아 데이터를 재전송하게 되면, n데이터만을 재전송하는 것이 아닌, n데이터 이후 데이터를 모두 재전송한다.
[2] 전송 데이터 프레임의 분실
GBn ARQ의 특징은 확인된 데이터 이후의 모든 데이터 재전송과 수신측의 폐기이다.
수신측에서 데이터 1을 받았는데 갑자기 다음 데이터 3을 받게 된다면
수신측에서는 데이터 2를 못받았으므로 데이터 3을 폐기하고 NAK2를 전송측에 보낸다.
NAK를 받은 전송측은 위의 [1] 경우에서와 같이 NAK(n) 데이터부터 모두 재전송을 실시하며
수신측은 기존 받았던 데이터 중 NAK(n)으로 보내었던 대상 데이터 이후의 데이터를 모두 폐기하고 재전송 받는다.
[3] 지정된 타임아웃내의 ACK 프레임 분실(Lost ACK)
전송스테이션은 분실된 ACK를 다루기 위해, 타이머를 가지고 있다.
전송측에서는 이 타이머의 타임아웃동안 ACK 데이터를 받지 못했을 경우, 마지막 ACK된 데이터부터 재전송한다.

전송측은 NAK 프레임을 받았을 경우, NAK 프레임 번호부터 다시 재전송을 시작한다.

수신측은 원하는 프레임이 아닐 경우 모두 폐기 처리한다.

타임아웃(ACK의 분실)일 경우, 마지막 ACK된 데이터부터 재전송한다.


3. Selective-Reject(SR) ARQ
GBn ARQ의 재전송되는 프레임 이후의 모든 프레임을 재전송하는 단점을 개선한 방법이다.

SR ARQ는 손상된 분실된 프레임만 재전송한다.

그렇기 때문에 별도의 데이터 재정렬을 수행해야하며, 별도의 버퍼를 필요로 한다.

elective Repeat은 말 그대로 선택적인 재전송을 의미한다. Go Back N 방법도 Stop and Wait에 비하면 많이 효율적인 방법이지만, 
에러가 발생하면 그 이후에 정상적으로 전송되었던 데이터까지 모두 폐기 처분되어 다시 전송해야한다는 비효율이 아직 존재한다.

그래서 나온 방식이 에러난 데이터만 재전송해줘 방식인 것이다.

얼핏 보면 이 방식이 굉장히 효율적이고 좋기만 한 것 같지만 Stop and Wait와 Go Back N 방식과 다르게, 
이 방식을 사용하는 수신 측의 버퍼에 쌓인 데이터가 연속적이지 않다는 단점이 존재한다.

위 예시만 봐도 수신 측의 버퍼에는 0, 1, 2, 3, 4, 5가 순차적으로 들어있는 것이 아니라, 중간에 폐기 처분된 4를 제외한 
0, 1, 2, 3, 5만 버퍼에 존재할 것이기 때문이다. 이때 송신 측이 4를 재전송하게되면 수신 측은 이 데이터를 
버퍼 중간 어딘가에 끼워넣어서 데이터를 정렬해야한다.

이때 같은 버퍼 안에서 데이터를 정렬할 수는 없으니, 별도의 버퍼가 필요하게 된다.

결국 재전송이라는 과정이 빠진 대신 재정렬이라는 과정이 추가된 것인데, 
이 둘 중에 재전송이 좀 더 이득인 상황에서는 Go Bank N 방식을, 재정렬이 좀 더 이득인 상황에서는 Selective Repeat 방식을 사용하면된다.

만약 TCP 통신에서 Selective Repeat 방식을 사용하고 싶다면, 
TCP의 옵션 중 SACK 옵션을 1로 설정하면 된다…만 사실 기본적으로 켜져 있는 경우가 많다.

1
2
$ sysctl net.inet.tcp | grep sack:
net.inet.tcp.sack: 1
OSX 같은 경우, sysctl 명령어를 사용하여 TCP와 관련된 커널 변수들을 확인해보면 그 중 net.inet.tcp.sack 값이 1로 잡혀있는 것을 확인할 수 있다.

아무래도 대부분의 경우에는 정글이나 다름 없는 네트워크를 다시 사용하는 쪽보다는 그냥 수신 측이 재정렬을 하는 것이 이득인 경우가 많다보니 기본적으로 Selective Repeat을 사용하는 것이 아닌가싶다.
```

### GBN ARQ와 SR ARQ의 차이
```java
GBN ARG : SR ARQ
1. 손상/불실된 프레임 이후의 프레임을 모두 재전송 <> 손상/분실된 프레임만을 재전송
2. 구조가 비교적 간단하고 구현이 단순 <> 구조가 복잡(프레임 재배열 등의 추가 로직 필요)
3. 데이터 폐기 방식을 사용하여 추가적 버퍼가 필요 없음 <> 폐기 방식을 사용하지 않으므로 순차적이지 않은 프레임을 재배열하기 위한 버퍼가 필요
4. 비용이 비교적 저렴 <> 

```


## TCP IP 4계층
* [TCP 4계층이란](https://medium.com/@chrisjune_13837/web-http-tcp-ip-%EB%A9%94%EC%8B%9C%EC%A7%80%EB%9E%80-4b2721fe296f)
```JAVA
클라이언트 -> HTTP -> TCP -> IP -> 이더넷 -> 이더넷 -> IP -> TCP -> HTTP -> HTTP -> 서버
클라이언트로부터 특정 주소로 요청이 들어오면 DNS 상에서 IP주소를 받아옵니다 
→ HTTP 계층에서 HTTP 메시지를 작성합니다 
→ TCP 계층에서 HTTP 메시지를 패킷으로 분해합니다. 
→ IP계층에서 전송위치를 확인하고 
→ 네트워크를 통하여 전송합니다. 
그 이후는 위의 과정의 역순으로 진행하여 처리합니다.


HTTP 메시지
HTTP메시지는 시작줄, 헤더, 본문으로 구성되어있습니다

1. 시작줄
1-1 요청 메시지
메서드, 요청 URL, HTTP 버전
GET /document/item/1 1.1

1-2 응답 메시지
사용자에게 일어난 내용을 응답합니다. 상태코드와 사유내용은 일대일 구조로 대응됩니다.
버전, 상태코드, 사유구절
1.1 200 OK

2. 헤더
메시지 본문에 대한 부가정보를 표현합니다. 헤더의 종류는 일반, 요청, 응답, 엔터티, 확장 등이 있습니다.
자주 볼 수 있는 헤더예시를 보도록 하겠습니다.

2-1 Connection
일반적으로 클라이언트와 서버간의 통신은 한번 맺고 끝납니다. 그러나 컨넥션 비용이 많이 소비되기 때문에 이를 개선하기 위하여 keep-alive옵션을 통하여 컨넥션을 재활용합니다.

2-2 Content-type
응답하는 컨텐츠의 유형을 의미합니다.

2-3 Cache-control
캐쉬 사용을 막을 것인지, 허용할 것인지 제어합니다.

2-4 Access-Control-Allow-Origin
클라이언트에서 현재와 다른 도메인에서 정보를 가져올 수 있는 도메인의 정보를 담고 있습니다. 
이를 CORS(Cross Origin Resource Sharing)이라고 부릅니다



HTTP 응답코드
웹 서비스를 개발하면서 자주 접하게 되는 응답 코드입니다.

100대 코드: 정보전달
200대 코드: 성공응답
200: OK, 정상
204: No Content, 보통 특정내용을 삭제시 해당 응답코드를 응답합니다.
206: Range, 헤더를 지정한 요청을 응답할 때 사용합니다.
300대 코드: Redirection, request완료를 위해 추가 동작이 필요합니다
301: Moved Permanently, 영구적으로 URI 변경을 의미
302: Found, 일시적인 URI 이동을 의미
304: Not Modified, 변경 없음
307: Temporary Redirect, 임시적인 redirect
400대 코드: 클라이언트의 에러
400: Bad Request, 잘못된 요청
403: Forbidden, 접근권한없음
404: Not Found, 요청 내용이 없거나 찾을 수 없음
408: Request Timeout, 요청 타임아웃
500번대 코드: 서버의 에러
500: Internal Server Error, 서버에러, 로직에러 발생시 자주 등장합니다.
503: Service Unavailable, 서버 한계 초과등 오류


TCP/IP(Transmission Control Protocol/Internet Protocol)
TCP/IP란 TCP규약과 IP규약을 합친 웹 상에서만 사용하는 규칙을 의미합니다.
TCP는 데이터 전달을 관리하는 규칙입니다. 즉, 데이터를 작게 나누어서 한쪽에서 다른쪽으로 옮기고, 
이를 다시 조립하여 원래의 데이터로 만드는 규칙입니다. 여기서 잘게 나눈 데이터 단위를 패킷이라고 합니다. 
인터넷에서는 정보를 전달하는 단위를 뜻합니다. TCP는 패킷을 조립하고, 손실된 패킷을 확인하고, 재전송하도록 요청하는 기능을 합니다.
IP는 인터넷상의 주소 규칙입니다. 집의 주소를 부여하는 규칙이 존재하듯이, 
인터넷상에 연결된 모든 컴퓨터의 위치에도 규칙이 필요합니다. 
이전에는 2⁸*4자리의 주소인 IPv4를 사용하였지만 주소가 고갈이 되고 있어서 16⁴*8자리인 IPv6로 전환하고 되고 있습니다.

TCP/IP 4계층
OSI(Open Systems Interconnections)7계층은 시스템들의 연결을 위한 모델입니다. 
TCP/IP 4계층은 이를 웹 서비스에 맞게 단순화시킨 모델입니다.

응용계층: HTTP, FTP, Telnet, SMTP 등 네트워크를 사용하는 응용프로그램으로 이뤄집니다.
전송계층: TCP, UDP 등 시스템을 연결하고 데이터를 전송하는 역할을 합니다.
인터넷계층: ICMP, IGMP, IP등 데이터를 정의하고 데이터의 경로를 라우팅합니다.
물리계층: Ethernet, ATM등 네트워크 하드웨어를 의미합니다


통신
프로토콜을 이용하여 source와 target간의 데이터를 주고 받는 방법을 뜻합니다. 크게 동기식과 비동기식으로 구분됩니다.
동기식 통신은 대표적으로 HTTP, 클라이언트의 요청을 서버에서 응답할 때 까지 기다리는 방식입니다.
(HTTP 1.1의 Pipe Lining으로 클라이언트에서 응답메시지를 받기 전에 요청메시지를 전달할 수 있습니다. 
하지만 본질적으로 비동기통신은 아닙니다)

비동기식 통신은 대표적으로 AMQP(Advanced Message Queue Protocol, 개선된 메시지 큐 프로토콜), 
메시지 브로커를 통하여 요청 메시지를 전달하는 방식입니다. 클라이언트에서는 브로커에게 메시지를 전달하기만 하고, 
기다리지 않기 때문에 비동기 식이라고 불립니다. 요청하는 측에서는 메시지를 
Publish하고 처리하는 쪽에서는 메시지를 Subscribe하기 때문에 pub/sub구조라고도 부릅니다.
```

## HTTP 1.1 에서 추가된 기능
- 1.0에서의 모호함과 성능을 개선하기 위해 1.1이 나왔습니다. 1.0의 경우 구조는 단순하지만 연결의 설정과 해체 반복으로 인해 네트워크 혼잡에 대한 정보를 확보할 수가 없었고, 대역폭이 낮은 링크에서는 성능저하를 발생시킵니다. 또한 캐시 모델이 미흡하여 동작상의 오버헤드와 캐시 데이터 관리에 문제가 많았습니다. 대표적으로 keepalive를 추가하여 연결의 설정과 해제의 반복을 줄이고, 캐시 제어 메커니즘이 도입되었으며, 파이프라이닝을 추가하여 동시에 여러 클라이언트와 연결을 할 수 있었으며, 요청메소드가 확장되어 PUT, DELETE 등이 추가되었습니다.

## HTTP 2.0 에서 추가된 기능
- 1.1보다 웹 속도를 개선하기 위해 2.0이 등장하였습니다. 추가된 기능으로 SSL 환경에서만 사용가능하기 때문에 보안성이 높으며 Header의 압축을 통한 성능향상이 되었고, Server Push를 통해 클라이언트의 요청없이도 필요 데이터를 보낼 수 있게 되었습니다. 또한 하나의 TCP 커넥션 내에서 병렬 처리를 지원하여 동시 처리가 가능하게 되었습니다. 메세지 전송 포맷도 바뀌었습니다. 1.1에서는 플레인텍스트로 형태로 header와 body를 보냈다면 2.0에서는 바이너리로 인코딩하여 header와 body를 전송합니다. 바이너리로 인코딩된 데이터를 프레임 단위로 전송하며 프레임이 모여 하나의 메세지를 보냅니다. 여러 메세지는 스트림 구조로 전송되기에 다수의 메세지를 동시에 처리함으로써 빠른 응답속도를 보장하게 되었습니다.

## olb 문제
* 그 외에도 TCP를 사용하는 기존의 HTTP에는 한 가지 문제가 더 있는데, 바로 HOLB(Head of Line Blocking)이라고 하는 문제이다. 사실 HTTP 레벨에서의 HOLB와 TCP 레벨에서의 HOLB는 다른 의미이기는 하나 결국 어떤 요청에 병목이 생겨서 전체적인 레이턴시가 늘어난다는 맥락으로 본다면 동일하다고 할 수 있다.
* TCP를 사용한 통신에서 패킷은 무조건 정확한 순서대로 처리되어야 한다. 수신 측은 송신 측과 주고받은 시퀀스 번호를 참고하여 패킷을 재조립해야하기 때문이다.
* 그래서 통신 중간에 패킷이 손실되면 완전한 데이터로 다시 조립할 수 없기 때문에 절대로 그냥 넘어가지 않는다. 무조건 송신 측은 수신 측이 패킷을 제대로 다 받았다는 것을 확인한 후, 만약 수신 측이 제대로 패킷을 받지 못했으면 해당 패킷을 다시 보내야 한다.
* 또한 패킷이 처리되는 순서 또한 정해져있으므로 이전에 받은 패킷을 파싱하기 전까지는 다음 패킷을 처리할 수도 없다. 이렇게 패킷이 중간에 유실되거나 수신 측의 패킷 파싱 속도가 느리다면 통신에 병목이 발생하게 되는 현상을 HOLB라고 부르는 것이다. 이건 TCP 자체의 문제이므로 HTTP/1 뿐만 아니라 HTTP/2도 가지고 있는 문제이다.
* 이런 문제들을 해결하기 위해 HTTP/3는 UDP를 기반으로 만들어진 프로토콜인 QUIC 위에서 작동하는 것을 선택한 것이다. 그럼 이제 QUIC가 정확히 어떤 프로토콜인지, UDP를 사용한다는 것이 TCP에 비해서 어떤 장점이 있다는 것인지를 알아보자.

## TCP 헤더 문제
* TCP의 경우 워낙 오래 전에 설계되기도 했고, 이런 저런 기능이 워낙 많이 포함된 프로토콜이다보니 이미 헤더가 거의 풀방이다. TCP에 기본적으로 정의되어 있는 기능 외에 다른 추가 기능을 구현하고 싶다면 가장 하단에 있는 옵션(Options) 필드를 사용해야 하는데, 옵션 필드도 무한정 배당 해줄 수는 없으니 최대 크기를 320 bits로 정해놓았다.
* 그러나 TCP의 단점을 보완하기 위해 나중에 정의된 MSS(Maximum Segment Size), WSCALE(Window Scale factor), SACK(Selective ACK) 등 많은 옵션들이 이미 옵션 필드를 차지하고 있기 때문에 실질적으로 사용자가 커스텀 기능을 구현할 수 있는 자리는 거의 남지도 않았다.
* 반면 UDP는 데이터 전송 자체에만 초점을 맞추고 설계되었기 때문에 헤더에 진짜 아무 것도 없다.
* UDP의 헤더에는 출발지와 도착지, 패킷의 길이, 체크섬 밖에 없다. 이때 체크섬은 패킷의 무결성을 확인하기 위해 사용되는데, TCP의 체크섬과는 다르게 UDP의 체크섬은 사용해도 되고 안해도 되는 옵션이다.
* 물론 TCP가 신뢰성을 확보하기위해 이런 저런 기능을 제공해주는 것이 개발자 입장에서는 편하고 좋지만, 한가지 슬픈 점은 이 기능들이 프로토콜 자체에 정의된 필수 과정이라서 개발자가 맘대로 커스터마이징 할 수 없다는 것이다. 결국 여기서 발생하는 레이턴시들을 어떻게 더 줄여볼 시도조차 하기 힘들다.



## http3
* UDP는 User Datagram Protocol이라는 이름에서도 알 수 있듯이 데이터그램 방식을 사용하는 프로토콜이기 때문에 애초에 각각의 패킷 간의 순서가 존재하지 않는 독립적인 패킷을 사용한다. 또한 데이터그램 방식은 패킷의 목적지만 정해져있다면 중간 경로는 어딜 타든 신경쓰지 않기 때문에 종단 간의 연결 설정 또한 하지 않는다. 즉, 핸드쉐이크 과정이 필요없다는 것이다.
* HTTP/3는 HTTP(Hypertext Transfer Protocol)의 세 번째 메이저 버전으로, 기존의 HTTP/1, HTTP/2와는 다르게 UDP 기반의 프로토콜인 QUIC을 사용하여 통신하는 프로토콜이다. HTTP/3와 기존 HTTP 들과 가장 큰 차이점이라면 TCP가 아닌 UDP 기반의 통신을 한다는 것이다.
* 사실 HTTP/3는 처음에는 HTTP-over-QUIC이라는 이름을 가지고 있었는데, IETF(Internet Engineering Task Force) 내 HTTP 작업 그룹과 QUIC 작업 그룹의 의장인 마크 노팅엄이 이 프로토콜의 이름을 HTTP/3로 변경할 것을 제안했고, 2018년 11월에 이 제안이 통과되어 HTTP-over-QUIC이라는 이름에서 HTTP/3으로 변경되게 되었다.
* 즉, HTTP/3는 QUIC이라는 프로토콜 위에서 돌아가는 HTTP인 것이다. QUIC은 Quick UDP Internet Connection의 약자로, 말 그대로 UDP를 사용하여 인터넷 연결을 하는 프로토콜이다.(참고로 발음은 그냥 퀵이라고 한다)
* HTTP/3는 QUIC을 사용하고, QUIC은 UDP를 사용하기 때문에 결과적으로 HTTP/3는 UDP를 사용한다 라고 이야기 할 수 있는 것이다.*&
* QUIC은 TCP를 사용하지 않기 때문에 통신을 시작할 때 번거로운 3 Way Handshake 과정을 거치지 않아도 된다. 클라이언트가 보낸 요청을 서버가 처리한 후 다시 클라이언트로 응답해주는 사이클을 RTT(Round Trip Time)이라고 하는데, TCP는 연결을 생성하기 위해 기본적으로 1 RTT가 필요하고, 여기에 TLS를 사용한 암호화까지 하려고 한다면 TLS의 자체 핸드쉐이크까지 더해져 총 3 RTT가 필요하다.
* 반면 QUIC은 첫 연결 설정에 1 RTT만 소요된다. 클라이언트가 서버에 어떤 신호를 한번 주고, 서버도 거기에 응답하기만 하면 바로 본 통신을 시작할 수 있다는 것이다. 즉, 연결 설정에 소요되는 시간이 반 정도 밖에 안된다.
* . 첫번째 핸드쉐이크를 거칠 때, 연결 설정에 필요한 정보와 함께 데이터도 보내버리는 것이다. TCP+TLS는 데이터를 보내기 전에 신뢰성있는 연결과 암호화에 필요한 모든 정보를 교환하고 유효성을 검사한 뒤에 데이터를 교환하지만, QUIC은 묻지도 따지지도 않고 그냥 바로 데이터부터 꽂아버리고 시작한다.

## QUIC 과정
* 결국 이 영상에서 말하고자 하는 것은 TCP+TLS는 서로 자신의 세션 키를 주고 받아 암호화된 연결을 성립하는 과정을 거치고 나서야 세션 키와 함께 데이터를 교환할 수 있지만, QUIC은 서로의 세션 키를 교환하기도 전에 데이터를 교환할 수 있기 때문에 연결 설정이 더 빠르다는 것이다.
* 단, 클라이언트가 서버로 첫 요청을 보낼 때는 서버의 세션 키를 모르는 상태이기 때문에 목적지인 서버의 Connection ID를 사용하여 생성한 특별한 키인 초기화 키(Initial Key)를 사용하여 통신을 암호화 한다. 이 과정에 대한 자세한 설명은 QUIC 작업 그룹의 Using TLS to Secure QUIC 문서에서 확인 해볼 수 있다.
* 그리고 한번 연결에 성공했다면 서버는 그 설정을 캐싱해놓고 있다가, 다음 연결 때는 캐싱해놓은 설정을 사용하여 바로 연결을 성립시키기 때문에 0 RTT만으로 바로 통신을 시작할 수도 있다. 이런 점들 때문에 QUIC은 기존의 TCP+TLS 방식에 비해 레이턴시를 더 줄일 수 있었던 것이다.
* 참고로 이 세션이 발표될 당시에는 TLS 1.3이 나오기 전이라 따로 언급이 되지 않았지만, 지금은 TCP Fast Open과 TLS 1.3을 사용하여 QUIC와 비슷한 과정을 통해 연결을 설정함으로써 TCP를 사용하더라도 동일한 이점을 가져갈 수도 있긴하다.
* 그러나 TCP SYN 패킷은 한 패킷당 약 1460 Byte만 전송할 수 있도록 제한하지만 QUIC은 데이터 전체를 첫 번째 라운드 트립에 포함해서 전송할 수 있기 때문에 주고 받아야할 데이터가 큰 경우에는 여전히 QUIC가 유리하다고 할 수 있다.

## QUIC 흐름제어
* 패킷 손실 감지에 걸리는 시간 단축
* QUIC도 TCP와 마찬가지로 전송하는 패킷에 대한 흐름 제어를 해야한다. 왜냐면 QUIC든 TCP든 결국 본질적으로는 ARQ 방식을 사용하는 프로토콜이기 때문이다. 통신과정에서 발생한 에러를 어떻게 처리할 것인지를 이야기하는 것인데, ARQ 방식은 에러가 발생하면 재전송을 통해 에러를 복구하는 방식을 말하는 것이다.
* TCP는 여러 ARQ 방식 중에서 Stop and Wait ARQ 방식을 사용하고 있다. 이 방식은 송신 측이 패킷을 보낸 후 타이머를 사용하여 시간을 재고, 일정 시간이 경과해도 수신 측이 적절한 답변을 주지 않는다면 패킷이 손실된 것으로 판단하고 해당 패킷을 다시 보내는 방식이다.
* 우선 2017년 구글에서 발표한 QUIC Loss Detection and Congestion Control에 따르면, QUIC은 기본적으로 TCP와 유사한 방법으로 패킷 손실을 탐지하나, 몇 가지 개선 사항을 추가한 것으로 보인다.
* TCP에서 패킷 손실 감지에 대한 대표적인 문제는 송신 측이 패킷을 수신측으로 보내고 난 후 얼마나 기다려줄 것인가, 즉 타임 아웃을 언제 낼 것인가를 동적으로 계산해야한다는 것이다. 이때 이 시간을 RTO(Retransmission Time Out)라고 하는데, 이때 필요한 데이터가 바로 RTT(Round Trip Time)들의 샘플들이다.
* 한번 패킷을 보낸 후 잘 받았다는 응답을 받을 때 걸렸던 시간들을 측정해서 동적으로 타임 아웃을 정하는 것이다. 즉, RTT 샘플을 측정하기 위해서는 반드시 송신 측으로 부터 ACK를 받아야하는데, 정상적인 상황에서는 딱히 문제가 없으나 타임 아웃이 발생해서 패킷 손실이 발생하게 되면 RTT 계산이 애매해진다.
* 이때 이 ACK가 어느 패킷에 대한 응답인지 알기 위해서는 타임스탬프를 패킷에 찍어주는 등 별도의 방법을 또 사용해야하고, 또 이를 위한 패킷 검사도 따로 해줘야 한다. 이를 재전송 모호성(Retransmission Ambiguity)이라고 한다.
* 이 문제를 해결하기 위해 QUIC는 헤더에 별도의 패킷 번호 공간을 부여했다. 이 패킷 번호는 패킷의 전송 순서 자체만을 나타내며, 재전송시 동일한 번호가 전송되는 시퀀스 번호와는 다르게 매 전송마다 모노토닉하게 패킷 번호가 증가하기 때문에, 패킷의 전송 순서를 명확하게 파악할 수 있다.
* TCP의 경우 타임스탬프를 사용할 수 있는 상황이라면 타임스탬프를 통해 패킷의 전송 순서를 파악할 수 있지만, 만약 사용할 수 없는 경우 시퀀스 번호에 기반하여 암묵적으로 전송 순서를 추론할 수 밖에 없지만, QUIC는 이런 불필요한 과정을 패킷마다 고유한 패킷 번호를 통해 타파함으로써 패킷 손실 감지에 걸리는 시간을 단축할 수 있었다.
* 이 외에도 QUIC는 대략 5가지 정도의 기법을 사용하여 이 패킷 손실 감지에 걸리는 시간을 단축시켰는데, 자세한 내용은 QUIC Loss Detection and Congestion Control의 3.1 Relevant Differences Between QUIC and TCP 챕터를 한번 읽어보는 것을 추천한다.

## 멀티플렉싱
* 멀티플렉싱(Multiplexing)은 위에서 TCP의 단점으로 언급했던 HOLB(Head of Line Blocking)을 방지하기 때문에 매우 중요하다. 여러 개의 스트림을 사용하면, 그 중 특정 스트림의 패킷이 손실되었다고 하더라도 해당 스트림에만 영향을 미치고 나머지 스트림은 멀쩡하게 굴릴 수 있기 때문이다.
* 참고로 멀티플렉싱은 여러 개의 TCP 연결을 만든다는 의미가 아니라, 단일 연결 안에서 몇 가지 얌생이를 사용하여 여러 개의 데이터를 섞이지 않게 보내는 기법이다. 이때 각각의 데이터의 흐름을 스트림이라고 하는 것이다.
* HTTP/1의 경우는 하나의 TCP 연결에 하나의 스트림만 사용하기 때문에 HOLB 문제에서 벗어날 수 없었다. 또한 한번의 전송이 끝나게 되면 연결이 끊어지기 때문에 다시 연결을 만들기 위해서는 번거로운 핸드쉐이크 과정을 또 겪어야 했다.
* 비록 keep-alive 옵션을 통해 어느 정도의 시간 동안 연결을 유지할 수는 있지만 결국 일정 시간 안에 액세스가 없다면 연결이 끊어지게 되는 것은 똑같다.
* 그리고 HTTP/2는 하나의 TCP 연결 안에서 여러 개의 스트림을 처리하는 멀티플렉싱 기법을 도입하여 성능을 끌어올린 케이스이다. 이 경우 한번의 TCP 연결로 여러 개의 데이터를 전송할 수 있기 때문에 핸드쉐이크 횟수도 줄어들게 되어 효율적인 데이터 전송을 할 수 있게 된다.


## Connection ID
* 클라이언트의 IP가 바뀌어도 연결이 유지됨
* TCP의 경우 소스의 IP 주소와 포트, 연결 대상의 IP 주소와 포트로 연결을 식별하기 때문에 클라이언트의 IP가 바뀌는 상황이 발생하면 연결이 끊어져 버린다. 연결이 끊어졌으니 다시 연결을 생성하기 위해 결국 눈물나는 3 Way Handshake 과정을 다시 거쳐야한다는 것이고, 이 과정에서 다시 레이턴시가 발생한다.
* 게다가 요즘에는 모바일로 인터넷을 사용하는 경우가 많기 때문에 Wi-fi에서 셀룰러로 전환되거나 그 반대의 경우, 혹은 다른 Wi-fi로 연결되는 경우와 같이 클라이언트의 IP가 변경되는 일이 굉장히 잦아서 이 문제가 더 눈에 띈다.
* 반면 QUIC은 Connection ID를 사용하여 서버와 연결을 생성한다. Connection ID는 랜덤한 값일 뿐, 클라이언트의 IP와는 전혀 무관한 데이터이기 때문에 클라이언트의 IP가 변경되더라도 기존의 연결을 계속 유지할 수 있다. 이는 새로 연결을 생성할 때 거쳐야하는 핸드쉐이크 과정을 생략할 수 있다는 의미이다.

# Keepalive
- 두 호스트간 통신이 일정시간 패킷교환이 없을 때 자동으로 연결이 해제되는데 이것을 막기 위해 주기적으로 패킷을 보내는 것을 말합니다. keepalive는 tcp와 http 프로토콜 모두에서 일어날 수 있습니다.

# TCP에서 Keepalive
- HTTP/1.1부터 지원하는 기능으로 TCP 연결을 재사용하는 기능이다.
- 즉 Handshake 과정이 생략되므로 성능 향상을 기대 할 수 있다.
- 일정 시간동안 서로의 패킷 교환이 없을 경우 두 지점간 상대방의 안부를 묻기위해 payload 가 없는 패킷을 주기적으로 보내는 것입니다. 종단 시스템 중의 하나가 다운될 때 다른쪽 시스템만 열린 연결 상태를 정리하기 위해 사용됩니다.
- 단 모든 TCP 세션을 무한정 유지할 수는 없으므로 Timeout 및 Max 설정을 통해 관리되어야 한다.
- 최근에는 N/W 환경이 개선되면서 Keep Alive Timeout이 점점 줄어드는 추세이다.
- Event-driven 구조여서 non-blocking을 사용하는 Nginx 등은 Keep Alive를 하면서도 Thread를 점유하지 않기 때문에 동시 처리에 유리하다.

## Q. Keep Alive Timeout 설정은 왜 필요한가?
- 서버 자원은 무한정이 아니기에 이러한 접속을 계속 유지하는 것은 Server에 손실을 발생시킨다.
- 즉 서버와의 연결을 맺을 수 있는 Socket은 한정되어 있고 연결이 오래 지속되면 다른 사람들이 연결을 못하게되는 상황이 닥친다.
- 하지만 사람들이 적게 접속한다면 소수의 사람이 빠르게 인터넷을 사용 할 수 있다는 장점이 있다.
- Why? Request 요청을 하기 위한 작업이 생략되므로 속도는 빨라진다.
- 정적 자원(HTML, 이미지 파일 등)으로만 구성된 웹 서버에 Keep Alive을 사용할 경우 약 50%의 성능 향상을 보인다고 한다.
- 단 이와 같은 성능 향상을 보이려면 서버가 바쁘지 않아야 하는데 바쁜 서버 환경에서 Keep Alive 기능을 사용할 경우 모든 요청 마다 연결을 유지해야 하기 때문에 프로세스 수가 기하급수적으로 늘어나 MaxClient값을 초과하게 된다.
- 따라서 메모리를 많이 사용하게 되며 이는 곧 성능 저하의 원인이 된다. -즉 대량 접속 시 효율이 떨어지게 된다.

## HTTP에서의 Keepalive
- http 는 비연결형 통신이기에 커넥션을 유지하지 않습니다. 따라서 재요청시 커넥션을 다시 설정해야되는 비용이 큽니다. 이것을 해결하기 위해 Keepalive timeout내에 재요청을하면 열려있는 커넥션을 통해 전송하는 구조가 Keepalive입니다. Keepalive Timeout 을 너무 오래 설정하면 다른 사용자가 연결을 못하게 됨으로 사용자가 많은 서버보다는 소수의 사람이 빠르게 인터넷을 사용하자 하는 환경에서 사용하는 것이 좋습니다.
- HTTP는 Connectionless 방식이라 매번 Socket(port)를 열어야 하고 이는 비용적인 측면에서 비효율적인 구조이다.
- 그래서 Keep Alive Timeout내에 Client에서 Request를 재요청하면 새로운 세션을 생성하는 게 아닌 기존에 세션을 사용해 전송하는 구조이다.

## ThreadPool 과 Keep Alive
- 웹 서버만 놓고 볼 때 웹 서버 역시 ThreadPool을 사용하는 방식으로 설정 할 수 있다. 이때 ThreadPool은 사용자 수와 관련이 있는데,
- 동시 사용자가 500명이라면 최소한 500개 이상으로 ThreadPool을 설정해야 한다.
- 하나의 웹 페이지 호출 시 사용자는 동시에 여러 Connection을 생성할 수 있다.
- 만약 특정 웹 페이지 하나를 구성하는데 많은 자원이 필요하다면 ThreadPool은 그에 비례하여 증가시켜야 한다.
- 이때 Keep Alive까지 적용되어 있다면 Idle Thread까지 고려하여 ThreadPool 설정을 해야 한다

## Connection Timeout
## Socket Timeout
```java
웹 브라우저가 네이버 서버에 접속하기 위해 서버와 연결된 상태가 되어야 한다.

연결을 구성하기 위해서 보통 TCP Connection과 동일하게 3-way Handshake 방식으로 수행하게 된다.

3-way Handshake를 정상적으로 수행하게 되면 웹 브라우저와 네이버 서버는 연결된 상태가 된다.

이 때까지 소요된 시간을 Connection에 소요된 시간이라고 할 수 있다.

즉 Connection Timeout은 Connection을 구성하는데 소요되는 시간의 임계치를 의미한다.
```

```java
Socket Timeout

보통 서버는 클라이언트와 Established 후 데이터를 클라이언트에게 전송한다.

이 때 하나의 패킷이 아니라 여러 개의 패킷으로 나눠서 전송한다.

각 패킷이 전송될 때 시간 Gap이 생길 수 있는데 이 시간의 임계치를 Socket Timeout이라고 한다.

즉 Socket Timeout은 개별 패킷을 기다리는 Timeout이다.

주의할 점은 Socket Timeout이 전체 응답을 수신하는 Timeout이라고 생각하는 것이다.

다시말해 전체 응답이 아닌 개별 응답에 대한 시간 제한이다.

따라서 Timeout 시간 제한이 1초이고 응답 패킷이 3개일 경우 (각 패킷 도착 시간이 0.9초 )
총 응답 시간이 2.7초가 걸리지만 Timeout이 발생하지 않는다.

결론적으로 URL을 호출할 때에는 Connection Timeout과 Socket Timeout 설정이 모두 필요하다.
Q. 만약 두 가지 Timeout을 설정하지 않으면 어떤 일이 벌어질까?

URL 접속시 무한 대기가 발생할 수 있다.
```

### Connection vs Socket
```java
A는 최대 10분까지 맛집을 가기위해 기다릴 생각이 있다.

10분을 넘게 기다렸지만 A(=클라이언트)는 맛집(=서버)을 들어가지 못해 떠났다.

이처럼 서버에 클라이언트가 접근을 시래했을 시 적용되는 것이 Connection Timeout이다.

즉 접근을 시도하는 시간 제한(=10분)이 Connection Timeout이 되는 것이다.

만약 A가 10분 안에 맛집에 들어갔다고 가정해보자.

그리고 A는 음식을 기다리는데 최대 5분을 소요할 생각이 있다.

5분이 지난 A는 그냥 가게를 나왔다.

즉 클라이어트가 서버에 접속은 성공했으나 클라이언트가 원하는 요청에 대해
서버가 너무 오랫동안 응답을 못해 클라이언트가 연결을 해제하는 것이 Read Timeout이다.

이런 경우 클라이언트는 현 상황을 오류로 인지하고(=음식이 안나옴)
서버는 계속 요청(=요리중)을 수행하고 있기 때문에 요청 성공으로 인지를 한다.

이로인해 클라이언트와 서버간 싱크가 맞지 않아 문제가 발생할 확률이 높다
```

# POST 방식과 GET 방식
- HTTP 프로토콜을 이용하여 서버에 요청방법 중 하나로서 요청방법에 따라 GET과 POST로 나뉩니다. 이때 필요에 따라 데이터를 보낼수 있는데 이때 데이터는 url 뒤에 쿼리스트링으로 입력하여 보내기에 외부에 쉽게 노출된다는 단점이 있습니다.

## GET method
- GET 방식은 서버에 데이터를 요청하는 방식으로서 특정 웹페이지 등을 요청할 때 쓰입니다.

## POST medthod
- POST 방식은 서버에 데이터를 전송을 요청하는 방식으로서 웹 페이지의 폼에 입력한 데이터를 서버에 보낼 때 쓰입니다. 데이터는 HTTP의 body에 담아 보이기에 GET처럼 대놓고 보이지 않아 안정적이라 말할 수 있으나, 암호화 되어 있지 않아 쉽게 발견될 수 있습니다.

## get보다 post 방식 사용하는 이유
1. 데이터 생성, 변경 등 원본 파일의 수정이 발생하는 경우
2. 중요한 정보를 전달할 때
  * body에 담기 떄문에 기본적인 보안; 하지만 post로 전달되는 데이터도 URL에 노출만 안될뿐 똑같이 쉽게 확인할 수 있따.
  * 그렇기 때문에 Postㄹ 전달할 때 많은 데이터들이 암호화된 상태로 전송된다.
  * 이렇게 암호화된 데이터는 클라이언트 사이드에서 decrypt 해준다. 반대로 서버로 전달핼 때도 클라이언트 사이드에서 encrypt한 후 보내면 Post 로그를 통해 데이터가 누출되는 일을 막을 수 있다.
3 전송 데이터의 양이 많을 때
  * 전송 길이에 제한이 없다

## Restfult API에서의 URL과 일반적인 HTTP 에서의 URL의 차이
- 일반적인 HTTP의 URL은 기능에 중점을 두어 설계를하기 때문에 회원정보를 가져온다면 ‘/getUser’ 와 같이 설계를 하지만 Restful API에서는 자원에 중점을 두고 설계를 합니다. 따라서 ‘/user’로 설계를 하되 기능에 대한 구분은 POST, GET, DELETE, PUT 등의 HTTP 메서드를 통하여 설계하는 차이가 있습니다.

## Restful API
- ROA(Resource Oriented Architecture) 구조를 지향하여 이미지, 텍스트, DB 등 모든 자원에 대하여 고유한 URL을 부여하도록 설계하는 방식을 말합니다.
## Get 방식(그 어떤 방식이든간에)의 URL을 통해서 데이터를 전달시 보안성 취약 해결방법
- SSL을 이용한 HTTPS 프로토콜로 데이터 전송을 암호화하여 보냅니다. 그러면 URL 뒤에 붙는 쿼리스트링 내용 모두 암호화되어 전송되기 때문에 보안성을 강화할 수 있습니다.

## HTTPS
- 표현계층의 SSL 프로토콜 위에서 응용계층의 HTTP 프로토콜이 실행되는 것을 말하며, HTTP Over SSL 이란 의미입니다.

## HTTPS 동작 방식
- 응용계층에서 HTTP 프로토콜에 따라 메세지에 데이터를 담아 표현계층으로 보냅니다. 표현계층의 SSL에 따라 메세지를 클라이언트와 주고받은 대칭키로 암호화하여 전송 계층에 보냅니다. 전송계층에서는 TCP 프로토콜에 따라 세그먼트에 메세지을 담아 클라이언트에게 보냅니다. 클라이언트는 서버에서 가공한 과정의 역순으로 진행되며 표현계층에서는 서버와 주고받은 대칭키로 복화를 하여 데이터를 열어볼 수 있게 됩니다.

### SSL에 대해 설명해보아라.
- OSI 7계층에서 표현계층에 속하는 보안 프로토콜로서 스니핑과 같은 악의적인 행위를 방지하기위해 만들어진 프로그램 계층이다. SSL은 디지털 증명의 사용에도 포함되는 RSA의 비대칭키 암호화 시스템을 사용한다.
- (HTTPS와 SSL를 같은 의미로 이해하고 있는 경우가 많다. 이것은 맞기도 틀리기도 하다. 그것은 마치 인터넷과 웹을 같은 의미로 이해하는 것과 같다. 결론적으로 말하면 웹이 인터넷 위에서 돌아가는 서비스 중의 하나인 것처럼 HTTPS도 SSL 프로토콜 위에서 돌아가는 프로토콜이다.)

### SSL 디지털 인증서
- SSL 인증서는 클라이언트와 서버간의 통신을 제3자가 보증해주는 전자화된 문서다. 클라이언트가 서버에 접속한 직후에 서버는 클라이언트에게 이 인증서 정보를 전달한다. 클라이언트는 이 인증서 정보가 신뢰할 수 있는 것인지를 검증 한 후에 다음 절차를 수행하게 된다.
- SSL 인증서에는 서비스의 정보 (인증서를 발급한 기관), 서버 측 공개키가 포함되어 있다.

### SSL 동작방법
```java
SSL 동작방법
공개키 암호 방식은 알고리즘 계산방식이 느린 경향이 있다.
따라서 SSL은 암호화된 데이터를 전송하기 위해서 공개키와 대칭키 암호화 방식을 혼합하여 사용한다.
안전한 의사소통 채널을 수립할 때는 공개키 암호를 사용하고, 
이렇게 만들어진 안전한 채널을 통해서 임시의 무작위 대칭키를 생성 및 교환한다. 해당 대칭키는 나머지 데이터 암호화에 활용한다.

실제 데이터 암호화 방식 : 대칭키
상기 대칭키를 서로 공유하기 위한 암호화 방식 : 공개키


* SSL 통신과정
컴퓨터와 컴퓨터가 네트워크를 통해서 통신을 할때 핸드쉐이크 -> 세션 -> 세션종료 의 과정을 거친다.
암호화된 HTTP 메시지를 교환하기 전에 클라이언트와 서버는 SSL 핸드쉐이크를 진행한다.
핸드쉐이크의 목적은 아래와 같다.
프로토콜 버전번호 교환
양쪽이 알고 있는 pre master secret 키 생성 및 교환
양쪽의 신원 인증
채널을 암호화 하기 위한 임시 세션 키 생성
SSL 통신과정을 간단하게 도식화 하면 아래와 같다.
생활코딩 SSL의 동작방법에 아주 쉽게 설명되어 있어서 함께 참고하면 좋다.
```
[개발자몽키](https://wayhome25.github.io/cs/2018/03/11/ssl-https/)

### 대칭키
- 암호를 만드는 행위인 암호화를 할 때 사용하는 일종의 비밀번호를 키(key)라고 한다. 이 키에 따라서 암호화된 결과가 달라지기 때문에 키를 모르면 암호를 푸는 행위인 복호화를 할 수 없다. 대칭키는 동일한 키로 암호화와 복호화를 같이 할 수 있는 방식의 암호화 기법을 의미한다. 대칭키 방식은 단점이 있다. 암호를 주고 받는 사람들 사이에 대칭키를 전달하는 것이 어렵다는 점이다. 대칭키가 유출되면 키를 획득한 공격자는 암호의 내용을 복호화 할 수 있기 때문에 암호가 무용지물이 되기 때문이다. 이런 배경에서 나온 암호화 방식이 공개키방식이다.

### 공개키
- 공개키 방식은 두개의 키를 갖게 되는데 A키로 암호화를 하면 B키로 복호화 할 수 있고, B키로 암호화하면 A키로 복호화 할 수 있는 방식이다. 이 방식에 착안해서 두개의 키 중 하나를 비공개키(private key, 개인키, 비밀키라고도 부른다)로하고, 나머지를 공개키(public key)로 지정한다. 비공개키는 자신만이 가지고 있고, 공개키를 타인에게 제공한다. 공개키를 제공 받은 타인은 공개키를 이용해서 정보를 암호화한다. 암호화한 정보를 비공개키를 가지고 있는 사람에게 전송한다. 비공개키의 소유자는 이 키를 이용해서 암호화된 정보를 복호화 한다. 이 과정에서 공개키가 유출된다고해도 비공개키를 모르면 정보를 복호화 할 수 없기 때문에 안전하다. 공개키로는 암호화는 할 수 있지만 복호화는 할 수 없기 때문이다.
- SSL은 공개키와 대칭키의 장점을 혼합한 방법을 사용한다. (클라이언트에서 생성한 대칭키를 서버의 공개키를 이용해 암호화해 보낸다. 그 후 데이터를 주고받는(세션) 과정에서는 대칭키를 사용한다.)

### SSL의 동작 방법
- SSL 역시 TCP 프로토콜 기반이라서 Handshake 과정을 거친다.
1. Client는 Server에게 hello 메시지를 보냅니다. Server는 Client에게 Hello 메시지로 응답을 보냅니다. 서로간의 통신을 준비하는 단계로 보면 됩니다.
2. Server는 Client에게 인증서, 사용할 서버키를 교환하며, 인증요청을 보냅니다.
3. Client는 Server에게 인증서, 사용할 클라이언트키를 교환하며, 인증서 확인요청을 합니다.
4. Server, Client 모두 Change Cipher Spec Protocol을 교환하며 위 단계에서 교환한 서버/클라이언트 키, 인증서 등을 토대로 이후의 통신을 지속하겠다는 메시지를 교환하며 서로의 인증을 마칩니다.

### SSL의 사용 예
기본적인 통신외에 무언가 덧붙여진다는 것은 정보를 보호하는데 도움이 될지언정 속도에는 도움이 되지 않는것이 사실이다. 보안을 강화하면 편의성이 떨어진다는 것은 어쩔 수 없는 것이다. 암호화를 하기 위해 크고작은 사전절차를 거쳐야하고, 데이터를 암호화, 복호화 하는 것도 컴퓨터에게는 모두 ‘일’이기 때문이다.
따라서 모든 웹페이지를 암호화해서 HTTPS로 만들면 좋겠지만 그렇게 되면 간단한 페이지를 열어보는 것도 시간이 많이 걸릴 수 있다. 이러한 속도 문제로 인해 단순한 웹 서핑때에는 HTTPS를 사용하지 않고, 로그인이나 결제와 같은 페이지에서 주로 사용한다. 참고로 일반적인 웹 페이지 HTTP는 TCP 80 포트를 사용하고, SSL이 적용된 HTTPS 페이지는 TCP 443 포트를 사용한다.

# TCP와 UDP
- 전송계층에서 사용되는 통신규약으로서 사용되는 환경에 따라 TCP와 UDP로 나뉘게 됩니다.

## UDP
- UDP 데이터 중심 프로토콜로서 주고받는 통신보다 데이터를 일방적으로 보내는 것을 중요시 합니다. 따라서 데이터 전송의 신뢰성이 보장되지 않지만 그만큼 가볍고 단순한 구조이고 속도가 빨라 실시간으로 통신할 수 있는 장점이 있습니다. 보통 p2p나 스트리밍, 전화 같은 경우에 사용됩니다.

## TCP
- 이에 반해 TCP 흐름 중심 프로토콜로서 서로가 통신을 주고 받는 것을 중요시합니다. 따라서 데이터 전송의 안전을 신경쓰기 때문에 중간에 패킷이 손실되는 경우 재전송을 통해(SYN-ACK handshaking) 신뢰성을 보장할 수 있습니다. 하지만 그만큼 전송속도가 느리다는 단점이 있습니다. TCP 프로토콜은 거의 대부분의 통신에서 사용되고 있으며, 특히 파일이나 데이터 전송시에 사용됩니다.

### TCP 의 신뢰성 보장이 어떻게 이루어지는가
- 3-way-handshaking 과 혼잡제어, 흐름제어를 통해 신뢰성을 보장합니다.
# 흐름 제어 (control flow)
- TCP가 신뢰성 보장을 위해 사용하는 메커니즘 중 하나로서 송신측과 수신측의 속도 차이를 해결하기 위해 사용하는 메커니즘입니다. 대표적으로 Stop and Wait ARQ, Sliding Window 기법이 있습니다.

## Stop and Wait ARQ
- 매번 패킷을 보내고 난 후 확인 응답을 받아야만 패킷을 전송하는 방식입니다.

## Sliding Window
- 수신측에서 설정한 윈도우 크기만큼 확인 없이 세그먼트를 전송할도록 하여 데이터 흐름을 동적으로 조절하는 방식입니다.

## Window
- 데이터를 보내기 전 3-way-handshaking 을 통해 수신측이 데이터를 받을 수 있는 버퍼양과 송신측이 데이터를 보낼 양을 맞추게 되는데 이 데이터 양을 window size라고 합니다.

## Go-Back-N ARQ
- 누적 응답을 사용한 방식으로 응답신호가 손실되더라도 이후 순서의 응답신호를 받으면 window가 shift 됩니다. timer가 하나이기에 순서가 낮은 프레임이 손실되면 이후의 모든 프레임을 재전송합니다. 수신측의 window 사이즈가 1로 설정되어 있어 프레임을 순차적으로만 수신할 수 있습니다.

## Selective Repeat ARQ
- 선택 응답을 사용한 방식으로 window의 가장 처음 프레임의 응답신호를 받아야 window가 shift 됩니다. 각 프레임당 timer가 동작하고 순서가 낮은 프레임이 손실되더라도 해당 프레임만 재전송합니다. 송신측과 수신측의 window size가 같기에 수신측에서 프레임 순서와 상관없이 수신이 가능합니다.

## 혼잡제어 (congestion control)
- TCP가 신뢰성 보장을 위해 사용하는 메커니즘 중 하나로서 네트워크의 혼잡을 피하기 위해 송신자의 전송속도를 줄이기 위해 사용하는 메커니즘입니다. 대표적으로 AIMD, Slow Start, Fast Retransmit, Fast Recovery 기법이 있습니다.

## AIME (Additive Increase/Multiplicative Decrease)
- window size를 1부터 시작하여 하나씩 증가시킵니다. 혼잡상태가 감지되면 window size를 절반으로 감소시킵니다.

## Slow Start
- window size를 1부터 시작해서 매회 2배씩 증가시킵니다. 혼잡이 발생하면 window size를 1로 감소시킨 후 지수적으로 증가시킵니다. 혼잡이 발생했던 window size의 절반부터는 선형적으로 증가시켜 나갑니다.

## Fast Retransmit
- 수신자가 프레임을 순서대로 받지 못햇을 경우 순서대로 받은 프레임 중 가장 최근의 프레임에 대한 ACK 신호를 보내게 됩니다. 이때 송신자는 3개 이상의 중복된 ACK를 받을 경우 timeout까지 기다리지 않고 바로 패킷을 재전송함으로서 시간을 절약합니다. 이런 현상이 반복되면 혼잡 상태로 인지하여 window size를 감소시킵니다

## Fast Recovery
- Slow Start 처럼 window size를 증가시키다가 혼잡상태를 만나면 window size를 1이 아닌 절반으로 감소시킨 후 선형적으로 증가시키는 방법입니다.

# Java에서 TCP와 UDP 소켓 생성 방법
- TCP와 UDP 모두 소켓 프로그래밍이라는 관점에서 같지만, 서버와 클라이언트간 연결과정에서 차이를 보입니다. 일단 socket() 함수를 통해 socket을 생성하고 ip 와 port 를 socket에 bind 하는 작업을 거칩니다. 이후에 TCP에서 서버는 listen() 함수를 호출하여 클라이언트에서

## TCP 소켓 생성방법
 1. 클라이언트
 * 1. socket() 함수를 통해 socket 을 생성합니다. 반환값으로 소켓 지정 번호가 부여됩니다.
 * socket(domain, type, protocol)
 * domain - 소켓 사용영역 (AF_INET, AF_UNIX)
 * type - 소켓 유형 (SOCKET_STREAM - IPPROTO_TCP, SOCKET_DGRAM - IPPROTO_UDP)
 * protocol - 사용할 프로토콜 (IPPROTO_TCP, IPPROTO_UDP)
 
 2. connect() 함수를 통해 연결할 ip 와 port 번호를 지정합니다. 클라이언트에서 connect() 가 ip주소와 port번호를 binding 하는 역할을 하며 커널에 소켓을 등록함으로서 커널이 외부와 통신할 귀를 열어놓게 됩니다.
 * connect(sockfd, serv_addr, addrlen
 * sockfd - 소켓 지정 번호
 * serv_addr - 연결할 서버에 대한 소켓 주소 구조체
 * addrlen - 구조체 크기
 
 3. read(), write() 함수를 를 통해서 데이터를 주고 받습니다.
 * read(fd, buf, count), write(fd, buf, count)
 * fd - 소켓 지정 번호
 * buf - 데이터를 담거나 담을 버퍼
 * count - 버퍼의 크기
 
 4. 작업이 끝나면 close() 함수를 통해서 연결을 종료합니다.
 * close(sockfd)
 * sockfd - 소켓 지정 번호
 
 2. 서버
 1. socket() 함수를 통해 socket 을 생성합니다. 반환값으로 소켓 지정 번호가 부여됩니다.
 2. socket 에 지정할 ip 와 port 번호를 bind() 함수를 통해 binding 합니다.
 * bind(sockfd, addr, addrlen)
 * socked - 소켓 지정 번호
 * addr - 소켓 주소 구조체 (소켓 유형, 연결할 대상의 ip 주소와 port 번호를 가진다.)
 * addrlen - 구조체의 크기
 
 3. listen() 함수를 통해 수신 대기열을 설정하여 여러 클라이언트 요청 저장합니다.
 * listen(queue_size)
 * queue_size - 수신 대기열 크기
 
 4. accept() 함수를 통해 수신 대기열에 있는 요청을 가져와 연결합니다. 연결이 성공하면 새로운 소켓인 연결 소켓을 생성합니다. 연결 소켓과 듣기 소켓을 따로 구분하는 이유는 동시에 여러 클라이언트의 요청을 처리하기 위함입니다. 만약 소켓이 하나라면 하나의 클라이언트의 요청만 처리할 수 있을 것이기 때문입니다.
 * accept(sockfd, addr, addrlen)
 * sockfd - 듣기 소켓 지정 번호 (socket()을 통해 처음 생성했던 소켓의 지정번호)
 * addr - 새로운 소켓에 바인드할 소켓 주소 구조체
 * addrlen - 구조체의 크기
 
 5. read(), write() 함수를 통해서 데이터를 주고 받습니다.
 
 6. 작업이 끝나면 close() 함수를 통하여 연결을 종료합니다.
 
 ## UDP 소켓 생성방법
 1. 송신자
 1. socket() 함수를 통하여 연결에 사용할 소켓을 생성합니다.
 * socket(AF_INET, SOCK_DGRAM, 0);
 2. bind() 함수를 통하여 통신할 서버의 ip 주소와 port 번호를 소켓에 binding 합니다.
 3. sendto(), recvfrom() 함수를 통하여 데이터를 주고 받습니다. UDP에서는 read() 나 write() 함수를 쓸 수가 없습니다. TCP처럼 연결을 맺지 않기 때문에 데이터를 읽을때마다 누가 보냈는지 확인해야하기 때문입니다.
 * sendto(s, message, msglen, flags, addr, addrlen)
 
 s - 소켓 지정 번호
 * message - 보낼 데이터
 * msgflen - 데이터 크기
 * flags - 전송을 위한 옵션 (대부분 0)
 * addr - 소켓 주소 구조체 (소켓 유형, 연결할 대상의 ip 주소와 port 번호를 가진다.)
 * addrlen - 소케 주소 구조체 크기
 * recvfrom(s, buf, buflen, flags, fromaddr, fromlen)
 * s - 소켓 지정 번호
 * buf - 데이터를 담을 버퍼
 * buflen - 버퍼의 크기
 * flags - 수신을 위한 옵션
 * fromaddr - 소켓 주소 구조체 (소켓 유형, 연결할 대상의 ip 주소와 port 번호를 가진다.)
 * fromlen - 소켓 주소 구조체의 크기
 
 4. 작업이 끝나면 close() 함수를 통하여 작업을 종료합니다.
 
 2. 수신자
 * 1. socket() 함수를 통하여 연결에 사용할 소켓을 생성합니다.
 * 2. bind() 함수를 통하여 통신할 서버의 ip 주소와 port 번호를 소켓에 binding 합니다.
 * 3. sendto(), recvfrom() 함수를 통하여 데이터를 주고 받습니다.
 * 4. 작업이 끝나면 close() 함수를 통하여 작업을 종료합니다.
 
## TCP 패킷구조
- 먼저 source / destination port number 를 가지고 있습니다. 패킷의 순서를 매기기 위한 Sequence number 와 마지막에 수신한 패킷을 알려주기 위한 Acknowledgement number 를 가지고 있습니다. 헤더크기와 잡음 및 변조를 확인하기 위한 checksum 이 있고, 데이터 관리 제어를 하는 6개의 flag 가 있습니다. 마지막으로 송수신 버퍼를 맞추기 위한 window size 를 가지고 있는 구조입니다.

## UDP 패킷구조
- TCP 헤더에 비해 훨씬 간단합니다. source, destination port 와 헤더 길이, 잡음과 변조를 확인하기 위한 checksum이 있습니다.

## 애플리케이션에서 사용하는 프로토콜의 종류 3가지
 * HTTP, SMTP, FTP, DHCP



# TCP, UDP 차이
## TCP
[TCP]('https://www.youtube.com/watch?v=8Ql1l048MD8&list=PLVsNizTWUw7GZy4UA9pntGRC9IIXIYiHm&index=3')
*  TCP is on IP
* physical -> internet -> transport -> application
* Ethernet Protocol <> IP Protocol <> TCp Protocol <> HTTP Protocol
* 소켓은 전송 레이어에 있음  
  ^Socket is on the transport  
  - Kernel - driver - network card - network card - kernel
  - BSD socket 
  - 소프트웨어 연결
  - Create socket -> give port > connect ip/port
  - Socket server: socket() > bind > listen > accept > send > recv
  - Socket client: socket() >                connect > recv > send > close
* ethernet ->     ip   ->    TCP    ->    Web server
* 프로세스 사이에서 소통을 도와줌  
    ^It provides communication function between processes
* 3웨이 핸드쉐이크 사용  
  ^Threeway handshake, based on flow
* 장점: 신뢰성
* 단점: 낮은 성능, 데이터 연속성 유지 힘듬  
    ^cons: low performance, hard to stay data continuity -> reliability is more important
* segment


## UDP
* 연속성이 신뢰성보다 중요함; 스타크래프트 UDP 서버  
  ^continuity is more important than reliability -> fast(ex: starcraft)
  - 손실에 신경쓰지 않는다.  
    ^don't care about loss
* 높은 성능  
    ^High performance
* socket() -> connect() -> sentto()/recvfrom () -> close()



# DNS
## DNS 서버의 역할
```java
인터넷에서는 컴퓨터를 식별하기 위해 IP 주소를 사용

하지만 이 숫자만으로는 무엇에 사용되고 있는지 알 수 없다.

그래서 인터넷에서는 IP 주소에 도메인명이라는 이름을 붙혀 알기 쉽게 한다.

IP 주소와 도메인명을 서로 교환하는 장치를 DNS(Domain Name System)이라 한다.

도메인명은 트리 구조로 되어 있다.
도메인명은 ‘www.examaple.co.kr’과 같이 점으로 구분된 문자열로 구성되어 있다.

이 하나하나의 문자열을 라벨이라고 하며,
오른쪽부터 순서대로 ‘탑레벨 도메인’, ‘제 2레벨 도메인’, ‘제 3레벨 도메인’과 같이 부른다.

즉 트리 모양의 계층 구조로 되어 있다.
```

## DNS 종류
```java
DNS 서버는 2종류
DNS 서버는 캐시 서버와 콘텐츠 서버로 크게 나눈다.

캐시 서버는 LAN 안에 있는 클라이언트로부터 조회를 받아 클라이언트를 대신하여 인터넷에 조회해 주는 DNS 서버
클라이언트가 인터넷에 Access할 때 사용
콘텐츠 서버는 외부 호스트로부터 자신이 관리하는 도메인에 관한 조회를 받는 DNS 서버
자신의 도메인 내의 호스트명은 zone 파일이라는 DB에서 관리

 
클라이언트로부터 조회를 받은 캐시 서버는 받은 도메인명을
오른쪽부터 순서대로 검색하여 해당 도메인명을 관리하는 콘텐츠 서버를 찾는다.
거기까지 도달하면 해당 콘텐츠 서버에 대해 호스트명+도메인명에 대응하는 IP주소를 가르쳐 준다.
이러한 동작을 이름 해결이라 한다.
```

## DNS 서버의 이중화
* DNS 서버는 인터넷을 보이지 않는 곳에서 지지해 주는 중요한 서버이다.
* DNS 서버에서 도메인명을 이름 해결할 수 없으면 목적하는 웹 서버에 Access할 수 없다.
* 그래서 DNS 서버는 단독 구성이 아니라 프라이머리 DNS 서버와 세컨더리 DNS 서버와 같이 이중 구성으로 구축하는 것이 기본이다.

## 캐시 서버의 이중화
* LAN에 배치하는 캐시 서버는 클라이언트가 조회한 이름 해결 정보를 캐시할 뿐이다.
* 따라서 프라이머리 DNS 서버와 세컨더리 DNS 서버에서 특별한 이중화 설정을 할 필요가 없다.
* 프라이머리 DNS 서버로부터 Response가 오지 않으면 세컨더리 DNS에게 다시 조회한다.

## 콘텐츠 서버의 이중화
* 콘텐츠 서버는 도메인명에 관한(zone 파일)을 저장하는 중요한 서버이다.
* 만일 프라이머리 DNS 서버가 다운되어도 세컨더리 DNS 서버가 동일한 정보를 반환할 수 있도록
* 동일한 zone 파일을 저장해 둘 필요가 있다.
* 이것은 프라이머리 DNS 서버에서 세컨더리 DNS 서버로 zone 전송을 하여 zone 파일을 동기화한다.
* 정기적 or 임의의 타이밍에 zone 파일을 동기화한다.

# 토렌트
* 장점
  1. 인기많은 파일도 안정적인 성능 보장
  2. 먹튀 현상 방지 알고리즘

* 일반 서버-클라이언트 방식과 달리 P2P 방식은 중앙 서버가 없고 트래커, 시드자가 서버 역할
* 시드(트래커; 최초 유포자) - 시드 - 리치(leech; 두번째 뜻: 거머리; 다운로드 하고 시드 안하고 도망)
  * 트래커는 리치에게 다른 시드자의 주소도 줌; 주소가 가까우면 다운로드 속도가 빠르니 
* 먹튀 스코어 계산: Choke Algorithm; 한 시드자는 4명의 리치에게 다운로드하게 할 수 있는데 업로드 비율이 낮은 사용자에게는 우선순위에서 제한이 될 확률이 높다.
* 단점
  * SSD는 P/E Cycle(쓰기 횟수 제한)이 있는데 장기적으로 저장장치에 무리를 줄 수 있다.
* 불법 콘텐츠에 대해 업로드/다운로드 모두 처벌


# 외부에서 내부 라우터로 접근
* 1. 포트 포워드 - VPN으로 테스트(프록시 자동)
* 2. TeamViewer




# NAT
* 자신의 네트워크를 만듭니다. Nat는 내부 및 외부와 통신하는 도구입니다.  
    ^it makes it own network. Nat is a tool to make communicate with inside and outside 

# Bridge
* 개인 IP 주소를 제공합니다. 그래서 많은 IP 주소가 필요하다.  
    ^it gives personal IP address. So i need a lot of ip addresses



## UNC Route
* UNC 경로는 네트워크상의 공유자원에 연결할 때 사용하는 규칙이다. UNC 경로는 항상 \\Server_name\Share_name 형태로  \\는 데이터가 네트워크에 있다는 것을 의미한다.
* Server_name에는 연결할 서버의 컴퓨터 이름을 입력해야 하며 Windows Server 2003에서 컴퓨터 이름은 NetBIOS, DNS, IP 형식 등으로 입력할 수 있다.
* Share_name에는 서버에서 공유하고 있는 공유 폴더의 이름을 입력해야 한다.
* UNC 경로는 브라우징 기능을 사용할 수 없는 경우나 네트워크 드라이브 연결을 설정할 때 자주 사용된다.


# Netbios
* 컴퓨터 속성 -> 이름 변경 -> 자세히에서 확인 가능  
    ^Computer properties -> change name -> detail
* 윈도우에서만 해당  
    ^Only in Window OS
-  OSI 모형의 세션 계층에 관련된 서비스들을 제공하여 개개의 컴퓨터의 애플리케이션들이 근거리 통신망을 통해 통신할 수 있게 한다. "세션 지향" 의 통신 서비스를 제공한다. 세션 지향은 먼저 두 컴퓨터 사이에서 통신을 확립하고 서로 통신이 가능한 방식.전화처럼 먼저 전화 해 상대에 연결하고 통신하는 형태의 서비스. 일대일 통신이 가능하다.
- 일반적으로 TCP / IP 네트워크에서 사용하는 기기에 고유한 "IP 주소"를 부여하면 서로 문제없이 통신을 할 수 있습니다. TCP / IP 네트워크에서는 IP 주소만 있으면 이름이 부여되지 않아도 서로 통신을 할 수 있기 때문입니다. 하지만 Windows OS의 경우는 차이점이 있습니다. Windows 네트워크에서는 "NetBIOS (Network BIOS)"라는 기술이 사용되고 있으며, IP 주소보다 "컴퓨터 이름 (정확하게는 NetBIOS 이름)"이 중요한 역할을 하고 있습니다.
* 컴퓨터 속성 -> 이름 변경 -> 자세히에서 확인 가능  
    ^Computer properties -> change name -> detail
* 윈도우에서만 해당  
    ^Only in Window OS

## 과정
- 1. 시스템 시작 시 NetBIOS 이름 등록 기능을 사용하여 네트워크에 참여합니다.
2. NetBIOS 이름을 사용하여 통신 상대를 식별하고 통신 패킷을 보내는 작업을 반복합니다.
3. 시스템 종료 시 NetBIOS 이름 등록을 삭제하고 네트워크에서 이탈합니다.


# 가상 네트워크
## Host-Only
* 외부와 단절된 내부 네트워크 구축하는 것으로 구성된 가상머신들끼리만 통신이 가능합니다.

## NAT(Network Address Translation)
* 호스트PC로부터 IP를 할당 받아 가상머신 프로그램이 자체 DHCP서버를 띄워 내부 네트워크 대역 할당 및 통신을 합니다. 호스트PC를 통해 외부 네트워크와 통신이 가능합니다.
- 즉, 사설 IP 주소로는 원칙적으로 외부와 통신할 수 없기 때문에 이를 공인 IP 주소로 중간에 변환해 주어 외부와 통신(인터넷 연결) 할 수 잇게 해주는 것입니다. 한가지 NAT는 장비가 아니라 기능 즉, 프로그램을 의미합니다. 그래서 라우터 등에 NAT 기능이 포함되어 있습니다. 흔히 NAT 기능이 포함된 라우터를 NAT 라우터라고 부릅니다.
- 우리가 주변에서 흔히 볼 수 있는 NAT 라우터로는 바로 인터넷 공유기가 있습니다. 공유기는 허브/스위치의 역할도 하면서 동시에 NAT 기능을 탑재하여 우리가 하나의 인터넷 회선으로(공인IP) 다수의 컴퓨터에서(내부 사설 IP) 동시에 인터넷을 사용할 수 있게 해주는 것 입니다. NAT 를 가장 쉽게 이해하시는 방법은
* NAT = 인터넷 공유기 라는 공식을 대입시키시면 됩니다.

## Bridge
* 공유기로부터 IP를 할당 받아, 호스트PC와 동일한 네트워크 대역의 IP를 갖게 됩니다. 공유기를 통해 외부 네트워크와 통신이 가능합니다.
* Host-only로 구성된 내부 네트워크 내의 가상머신4에 NAT연결선을 추가한 후 가상머신4를 게이트웨이로 사용하면, 가상머신1,2,3에서도 외부 네트워크로 접속할 수 있습니다. <포트 포워딩 필요>




# IP
* ㆍIP 는 에 대한 주소를 가진다 IP  주소는 네트워크에서 장치들이 서로를 인식하고 통신을 하기 위해서 사용하는 특수한 번호이다 IP . 네트워크에 연결된 장치는 모든 기계는 를 가지고 있어야 한다 
* 네트워크 구조를 유지시키는 역할  
    ^to stay the network structure
* IP 부여 -> 내가 원하는 곳으로 루트 선정  
    * Give ip address > set route to node that i want
    * 1988년 IANA; Internet Assigned Numbers Authority; 현재 ICANN(미국 LA)이 요청에 따라 APNIC에게 나눠줌 ->  한국의 국가기관(KRNIC)에서 발급 -> SK/KT/LG -> 가정집에 1개 부여 -> 공유기에 따라 분배(외부에서 안보이는 나만 보이는; 192.168.0. 가상 IP; 밖에서 봤을 땐 하나의 IP)
      * 대륙마다 기관이 다름: APNIC(호주에 위치; 한국 포함), RIPE(NCC), AFRINIC(아프리카), LACNIC(남미), ARIN(북미)
      * 홈페이지: KRNIC 홈페이지에서 확인 가능

## IP 형태
* 고정 IP: 고정 는 컴퓨터에 고정적으로 부여된 로 한번 부여되면 를 반납하기 전까지는 다른 장비에 IP IP IP 부여할 수 없다. 고정 는 일반 전화기라고 생각하면 된다 IP . 
* 유동 IP: 유동 는 장비에 고정적으로 를 부여하지 않고 컴퓨터를 사용할 때 남아 있는 중에서 IP IP IP 돌아가면서 부여한다. 유동 는 공중 전화기라고 생가하면 된다 IP . 
* 사설 IP:  사설 는 사용자가 임의로 부여한다 IP . 사설 는 내부적으로 인터넷 환경처럼 사용할 수 있지만 인터넷 상에서 서로 연결되지 않도록 IP 되어 있다. 사설 는 내부 전화기라고 생각하면 된다 IP .

## 내 IP 확인 방법
* 구글에서 MY IP 검색

## IP Tracker
* 추적 가능: 도시, 동 + 대략적 위치 좌표, 인터넷 가입 회사, 인터넷 속도, 인터넷 브라우저, 시간


## IP 가리기

### 프록시
* 클라이언트가 자신을 통해서 다른 네트워크 서비스에 간접적으로 접속할 수 있는 서버
* 서버와 클라이언트 사이의 중계기 역할을 한다.
* 처음: 속도를 위해 나왔다. 이미 빨라진지금 보안을 위해서 사용. (프록시에 사용자마다의 캐쉬가 등록)
* 사용자 - 프록시(프록시만의 IP; ex)2.2.2.2) - 인터넷

## 순방향 Proxy(Forward Proxy)
* 내부망에서 외부망으로 접근할때, 먼저 Forward Proxy서버를 거쳐서 외부망에 연결되는 방식이다.
* Proxy Server에서 In/Out bound패킷에 대한 보안 정책을 적용할 수 있다.
* Proxy Server는 내부에 Cache를 유지하면 이미 한번 통신한 외부 자원이 있을경우 프록시 서버에서 캐싱처리를 해서 성능향상에 도움이 된다.

# 역방향 Proxy(Reverse Proxy)
* 외부에서 내부 서버가 제공하는 서비스 접근시, Proxy서버를 거쳐서 내부 서버로 접근하는 방식이다.
* 외부 사용자는 내부망의 서버 존재를 모른다. 모든 접속은 Reverse Proxy서버에게 들어오면, Reverse Proxy는 요청에 맵핑되는 내부 서버에게 요청을 넘긴다. (내부서버 정보를 외부로부터 숨긴다)
* Reverse Proxy서버가 내부 서버의 정보를 맵핑한 상태이기 때문에, 로드밸런싱을 통해 부하 분산이 가능하다
정적 컨텐츠 캐싱처리 가능

### 사용하는 이유
```java
프록시 서버 는 클라이언트가 자신을 통해서 다른 네트워크 서비스에 간접적으로 접속할 수 있게 해 주는 컴퓨터나 응용 프로그램을 가리킨다. 
서버와 클라이언트 사이에서 중계기로서 대리로 통신을 수행하는 기능을 가리켜 ‘프록시’, 그 중계 기능을 하는 것을 프록시 서버라고 부른다. 
프록시 서버는 프록시 서버에 요청된 내용들을 캐시를 이용하여 저장해 둔다. 
이렇게 캐시를 해 두고 난 후에, 캐시 안에 있는 정보를 요구하는 요청에 대해서는 원격 서버에 접속하여 데이터를 가져올 필요가 없게 됨으로써 
전송 시간을 절약할 수 있게 됨과 동시에 불필요하게 외부와의 연결을 하지 않아도 된다는 장점을 갖게 된다. 
또한 외부와의 트래픽을 줄이게 됨으로써 네트워크 병목 현상을 방지하는 효과도 얻을 수 있게 된다.

* 정리
프록시 서버의 사용 목적은 잠재적으로 다양하다:
익명으로 컴퓨터를 유지 (주로 보안을 위하여)
캐시를 사용하여 리소스로의 접근을 빠르게 하기 위해. 웹 프록시는 웹 서버로부터 웹 페이지를 캐시로 저장하는 데 흔히 쓰인다.
네트워크 서비스나 콘텐츠로의 접근 정책을 적용하기 위해. (이를테면 원치 않는 사이트를 차단)
사용률을 기록하고 검사하기 위해 (이를테면 회사는 인터넷 이용을 파악)
보안 및 통제를 뚫고 나가기 위해
바이러스 전파, 악성 루머 전파, 다른 정보들을 빼낼 목적으로
역으로 IP추적을 당하지 않을 목적으로
전달에 앞서 악성 코드를 목적으로 전달된 콘텐츠를 검사하기 위해
밖으로 나가는 콘텐츠를 검사하기 위해 (데이터 유출 보호)
지역 제한을 우회하기 위해
```

### VPN
* 사용자 - AES(보안) - VPN - 인터넷
* 암호화 기능 보유; VPN에서 복호화/암호해독 시전
* IPTracker에서 확인하면 다른 지역이 나옴
* 몇몇 나라에서는 불법이지만 아직 한국은 불법이 아니다.
* VPN에 따라 로그를 남기는지 안남기는지에 따라서 완전한 익명성을 보존하는지 아닌지가 다름

#### VPN과 프록시의 공통점
* 유저와 인터넷 사이에 거쳐가면서 내 IP 정보를 숨길 수 있음

#### VPN과 프록시의 차이
* VPN은 데이터를 암호화해서 전달하고 암호화해서 받음
[거니의 VPN](https://www.youtube.com/watch?v=hjRQzHeirw8&list=PLLcbGhhl4sQDOYzzB8eNB7m0IdVffIyLM&index=27)

### 토르 브라우저
* 사용자 - 입구노드 - 중계 노드 - 출구 노드 - 인터넷
   * 노드 마다 계속 데이터를 암호화 시킴 
   * 입구노드와 중계노드는 출발지/목적지를 모르고 인터넷은 데이터가 출구노드에서 온 것으로 인식함
   * 일반 사용자도 토드의 노드가 될 수 있고 법적인 처벌을 받지 않는다.
      * 제재를 당하더라도 입구 노드와 출구 노드만 안되지 브릿지 역할은 가능하다.
* 파이어폭스를 기반으로 한 브라우저
* [거니의 토르 브라우저](https://www.youtube.com/watch?v=A3-moPb-_ls&list=PLLcbGhhl4sQDOYzzB8eNB7m0IdVffIyLM&index=28)
* 수사기관은 토르를 설치한 사용자를 바로 해킹해서 수사하다가 문제 생김
   * Active x나 java가 인터넷으로 바로 통하는 프로그램을 조사해서 조사
   * 경찰이 브릿지의 역할을 하면서 조사

#### 딥웹/다크웹
* 토르 브라우저를 사용해야만 입장 가능

## 프록시 서버의 역할
```java
프록시 서버의 프록시(Proxy)는 영어로 ‘대리’라는 뜻이다.
프록시 서버는 그 이름처럼 클라이언트로부터 인터넷에 대한 통신을 대리로 수행하는 서버이다.
클라이언트의 통신을 일단 받아 클라이언트를 대신하여 인터넷에 액세스한다.
사람에 따라서는 프록시 서버나 캐시 서버라고 부른다.

예전에 프록시 서버는 자주 열람하는 웹 사이트의 데이터를 일시적으로 저장하였다가 클라이언트에게 반환하는 캐시 기능을 메인으로 이용
최근에는 캐시 기능의 효과가 적은 동적 웹 페이지가 많아지고 회선 대역 자체가 넓어졌기 때문에
캐시 목적만으로 프록시 서버를 도입하는 경우는 줄고있다.
```

## 프록시 서버의 보안 기능의 강화
```java
최근의 프록시 서버는 URL 필터링이나 안티 바이러스등과 같이 보안 기능을 강화,발전중이다.
URL 필터링은 액세스할 수 있는 사이트를 한정하는 기능이다.
여러 사이트의 URL을 카테고리별로 분류하여 DB에 저장
예를 들어 ‘위법성, 성인사이트’등과 같은 식으로 분류

프록시 서버는 클라이언트가 액세스하려는 URL을 보고 DB와 대조하여 액세스 허가 또는 거부를 판단
안티 바이러스는 바이러스 대책 기능이다.
프록시 서버는 바이러스 대책 SW의 정의 파일과 같은 것을 시그니처로서 저장한다.
프록시 서버는 클라이언트가 주고받는 파일을 일단 내부에서 열어 시그니처와 대조한다.
```

# IP 주소
-  하나의 IP주소에는 Network ID와 Host ID가 존재하고 있습니다. 먼저 Network ID는 인터넷 상에서 모든 Host들을 전부 관리하기 힘들기에 한 Network의 범위를 지정하여 관리하기 쉽게 만들어 낸 것입니다. 그리고 Host ID는 호스트들을 개별적으로 관리하기 위해 사용하게 된 것입니다. 따라서 우리가 인터넷을 사용할 때 Routing으로 목적지를 알아내고 찾아가는 등의 역할을 할 때에는 NetworkID와 HostID가 합쳐진 IP주소를 보게 됩니다. 서브넷 마스크에 대해 알고자 하실 때에는 이 부분이 매우 중요합니다. Subnet mask를 활용하여 Network ID를 올리거나 낮출 수 있게 됩니다. 반대로 Host ID는 줄어들거나 늘어날 수 있게 됩니다. 라우터끼리의 통신에서는 IP를 사용하기에 Network ID와 Host ID보고 목적지가 어떤 네트워크에 속하는지 알 수 있게 됩니다.
-  쉬운 예를 들어보겠습니다. 홍대리는 집에 장롱이 필요하여 가구회사에 주문을 하였습니다. 장롱을 가져다 주는 배달원은 주소를 보고 홍대리의 집이 '부산광역시 해운대구 우동 792번지'라는걸 확인하고 도착하였습니다. 그런데 배달원은 집까지 가져왔지만 어느 곳에 두어야 할 지 모릅니다. 이 때 홍대리가 작은 방의 한쪽 구석을 가리키며 정확한 위치를 알려주었습니다. 이 예시를 보면 배달원의 역할은 최종 목적지가 속한 지역(집)까지 전달하는 Network ID에 해당합니다. 그리고 홍대리는 자신의 지역(집)에서 최종적으로 장롱을 두어야 하는 위치를 안내하여 주기에 Host ID의 역할로 보시면 되겠습니다. 나름 생각하고 만들었는데 적절한 비유인지는 모르겠으나 이 예시를 통해 이해에 도움이 되었으면 좋겠습니다.

## Mac Address
- 이러한 MAC address는 LAN(Local Area Network) 또는 Ethernet 이라 불리는 망에서 통신을 하기 위하여 사용됩니다. LAN이라는 이름에서 알 수 있듯이 MAC은 자신이 속한 네트워크 안에서만 통신이 됩니다. 이후 네트워크를 빠져나가는 장치인 Router를 지나게 되면 IP를 이용하여 통신하게 됩니다. 

## IP 클래스
-  A Class의 경우 처음 8bit(1byte)가 Network ID이며, 나머지 24bit(3byte)가 Host ID로 사용됩니다. 비트가 0으로 시작하기에 네트워크 할당은 0~127입니다 . 즉, 128 곳에 가능하며, 최대 호스트 수는 16,777,214개입니다. 
-  B Class의 경우 처음 16bit(2byte)가 Network ID이며, 나머지 16bit(2byte)가 Host ID로 사용됩니다. 비트가 10으로 시작하기에 네트워크 할당은 16,384 곳에 가능하며, 최대 호스트 수는 65,534개입니다. 
-  C Class의 경우 처음 24bit(3byte)가 Network ID이며, 나머지 8bit(1byte)가 Host ID로 사용됩니다. 비트가 110으로 시작하기에 네트워크 할당은 2,097,152 곳에 가능하며, 최대 호스트 수는 254개입니다.
### IP 클래스 영역
- 각각의 Class를 구분하는 방법은 의외로 간단하게 제일 첫 번째 옥텟(Octet)으로 구분하실 수 있습니다. Octet은 위에서도 잠깐 언급이 된 내용으로 2진수 8개(8bit)를 묶음으로 표현하는 것을 Octet이라고 합니다. 만약 IP가 164.58.94.125라고 할 때 첫 번째 Octet은 164가 되는 것입니다. 

-  IP 주소에서 쓸  수 있는 숫자의 범위는 0~255로 되어 있기에 첫 번째 Octet에서 0~255까지의 숫자를 5개로 나누어서 A, B, C, D, E Class로 구분 되는 것입니다.
 * A Class : 0 ~ 127 (0.0.0.0 ~ 127.255.255.255)
 * B Class : 128 ~ 191 (128.0.0.0 ~ 191.255.255.255)
 * C Class : 192 ~ 223 (192.0.0.0 ~ 233.255.255.255)
 * D Class : 224 ~ 239 (224.0.0.0 ~ 239.255.255.255)
 * E Class : 240 ~ 255 (240.0.0.0. ~ 255.255.255.255)

-  숫자로 이루어진 클래스 범위를 무작정 외우기에는 쉽지 않습니다. 그래서 쉬운 방법을 생각해 보았는데 의외로 정말 간단한 방법으로 외우게 되었습니다. 먼저 특징을 말씀드리자면 "주소체계 범위의 각 클래스 시작이 짝수이고 끝이 홀수"라는 것과, "범위가 반으로 나누어지게 된다는 것(n / 2)"입니다.
 * IP에 입력하는 범위가 256개가 존재한다 (0 ~ 255)
 * 256부터 2씩 나눈다.
 * 256 / 2 = 128 - 1 = 127 (A Class 범위 : 0 ~ 127)
 * 128 / 2 = 64 + 127 = 191 (B Class 범위 : 128 ~ 191)
 * 64 / 2 = 32 + 191 = 223 (C Class 범위 : 192 ~ 223)
 * 남은 32의 수는 16씩 나누어서 D Class와 E Class가 가진다.


# DHCP
- 필요한 이유: DHCP가 필요한 이유는 무엇보다 네트워크의 IP 주소 관리를 간소화하기 위해서다. 호스트 2개가 같은 IP 주소를 보유할 수 없으므로, IP 주소 수동 설정 시 오류가 발생할 가능성이 높다. 소규모 네트워크라도 수동으로 IP 주소를 할당하면 문제가 발생할 수 있다. 특히, 비정기적으로 IP 주소가 필요한 모바일 디바이스라면 더욱 그렇다. 또한, 일반 사용자 중 문제가 발생했을 때 컴퓨터의 IP 주소 정보를 찾아 바꿀 수 있는 사람도 많지 않다. 따라서 이 과정을 DHCP로 자동화하면 사용자와 네트워크 관리자 모두 업무가 편리해진다.

## DHCP 서버의 역할
```java
DHCP 서버는 네트워크와 관련된 설정 정보를 DHCP 클라이언트에게 배포하는 서버

컴퓨터에 IP 주소를 할당하는 방법으로는 정적 할당과 동적 할당이 존재

정적 할당은 수동으로 IP 주소를 설정하는 방법

서버나 네트워크 기기 등 동일한 IP 주소를 계속 사용해야하는 기기에서 사용


동적 할당은 서버가 클라이언트에 대해 IP주소, 서브넷 마스크, 기본 게이트웨이 등과 같은
네트워크와 관련된 설정 정보를 배포하여 자동으로 설정하는 방법
DHCP(Dynamic Host Configuration Protocol)는 동적 할당으로 IP주소를 배포할 때 사용하는 프로토콜이다.
DHCP를 사용하면 번잡한 IP 주소 관리를 편하게 사용 + 부족한 IP 주소를 활용
```

## 구성요소
DHCP 서버: IP 주소 및 관련 설정 정보를 보유한 DCHP 서버를 작동하는 네트워크 디바이스. 일반적으로 DHCP 서버는 서버 또는 라우터를 의미하지만, 호스트로 작동할 수 있다면 별도의 제한이 없다. SD-WAN 어플라이언스가 대표적이다.
- DHCP 클라이언트: DHCP 서버에서 설정 정보를 전송 받는 엔드포인트. 컴퓨터, 모바일 디바이스, IoT 엔드포인트 및 네트워크 연결 장비 등이 있다. DHCP 클라이언트 대부분은 DHCP 정보를 자동 수신할 수 있도록 지원한다.
- IP 주소 풀: DHCP 클라이언트에서 이용할 수 있는 IP 주소의 범위. 일반적으로, 모든 IP 주소는 순차적으로 배포한다.
- 서브넷: IP 네트워크를 서브넷으로 알려진 세그먼트로 나눌 수 있다. 서브넷으로 네트워크를 관리할 수 있다.
- 대여(Lease): DHCP 클라이언트가 IP 주소 정보를 보유할 수 있는 시간. IP 주소 대여가 만료되면 클라이언트가 갱신해야 한다.
- DHCP 릴레이: 네트워크에서 브로드캐스트 된 클라이언트 메시지를 수신 받은 뒤, 설정된 서버로 전달하는 라우터 또는 호스트. 그 후에 서버는 클라이언트에 반응 값을 전송하는 릴레이 에이전트로 되돌려 보낸다. 이 때문에 각 서브넷에 서버를 보유하지 않고도 DHCP 서버를 중앙 집중할 수 있다.

## 장점
- 정확한 IP 설정: IP 주소 설정 매개변수 값은 정확해야 하지만, '192.168.159.3' 같은 형식이어서 입력시 실수가 발생할 가능성이 높다. 이런 오타는 해결하기 힘든 고질적 문제인데, DHCP 서버를 사용하면 문제를 최소화할 수 있다.
- IP 주소 충돌 감소: 연결된 디바이스라면 IP 주소를 보유해야 한다. 하지만, 각 IP 주소는 한 번만 사용할 수 있으므로 중복 시 충돌이 발생해 중복된 디바이스 일방 또는 양방의 연결이 해제될 수 있다. IP 주소를 수동으로 할당하거나 특히 모바일 디바이스처럼 주기적으로 연결해야 하는 다수의 엔드 포인트가 있을 때 이런 문제가 발생할 가능성이 높다. DHCP를 사용하면 각 IP 주소가 자동으로 한 번만 사용된다.
- IP 주소 관리 자동화: DHCP를 사용하지 않으면 네트워크 관리자가 수동으로 IT 주소를 할당, 철회해야 한다. 디바이스가 언제 네트워크에 접속되고 끊기는지 정확하게 파악하기는 사실상 불가능하므로, 어떤 디바이스가 특정 주소를 보유하고 있는지 일일이 추적하는 것도 불가능하다. 반면 DHCP를 이용하면 네트워크 전문가가 단일 위치에서 모든 기기를 관리할 수 있도록 자동화 및 중앙집중화해 준다.
- 효율적인 변경 관리: DHCP를 사용하면 IP 주소, 범위, 엔드 포인트의 변경이 매우 쉽다. 예를 들어 DHCP를 통해 IP 주소 지정 시스템을 변경한다고 하자. 새로운 IP 주소 정보로 DHCP 서버를 설정한 뒤 해당 정보를 새로운 엔드 포인트에 전파하면 끝이다. 이와 유사하게, 네트워크 디바이스를 업그레이드 또는 교체할 때도 네트워크 설정을 별도로 할 필요가 없다.

## 단점
- DHCP 프로토콜은 인증 과정이 없으므로, 어떤 클라이언트도 빠르게 네트워크에 접속할 수 있다. 그러나 바로 이 점 때문에 다양한 보안 문제를 수반한다. 예를 들어 비인증 서버를 통한 클라이언트 유해 정보 배포, 비인증 클라이언트에 IP 주소 전달, 비인증 또는 유해 클라이언트로 인한 IP 주소 고갈 등이다.
- 이밖에도 클라이언트가 DHCP 서버의 진본성을 입증할 수 있는 수단을 보유하고 있지 않으므로, 부정확한 네트워크 정보를 제공하기 위해 인위적 수단을 써야 한다. 이로 인해, 서비스 거부 공격(DoS) 또는 중간자 공격이 발생할 수 있다. 즉, 가짜 서버가 악의적인 용도로 사용될 수 있는 자료를 중간에서 가로챌 가능성이 있다.
- 또한, DHCP 서버가 클라이언트 증명 시스템을 자체 보유하고 있지 않기 때문에, 요청한 디바이스에게 IP 주소 정보를 배포할 수밖에 없다. 그에 따라, 악의적 이용자가 크리덴셜(credential)을 지속해서 변환하기 위해 클라이언트를 설정할 수 있을 뿐만 아니라, 영역 내에서 이용할 수 있는 모든 IP 주소를 순식간에 고갈시킬 수 있다. 이는 기업의 정상적인 업무용 엔드 포인트가 네트워크에 접속하는 것을 방해할 것이다.
- 이에 따라 보안 위험을 낮추는 방법도 속속 등장하고 있다. 예를 들어 릴레이 에이전트 정보 옵션(Relay Agent Information Option)은 엔지니어가 DHCP 메시지가 네트워크에 도착했을 때 태그화를 지원한다. 태그는 네트워크 접속을 관리하는 용도로 사용할 수 있다. DHCP 메시지를 입증할 수 있는 수단도 있다. 단, 복잡한 키 관리 때문에 채택이 어려워진다는 단점이 있다. 그 외에도 DHCP의 보안을 강화하기 위해 802.1x 인증 방식(망 접근제어, Network Access Control, NAC)을 사용할 수 있다. 주요 네트워크 업체가 NAC 지원을 통해 배치 과정을 크게 간소화하고 있다. ciokr@idg.co.kr



# 랜카드
- 네트워크 연결 및 데이터 전송은 랜카드(LAN card)로부터 시작된다. 랜카드는 ‘네트워크 카드(network card)’ 또는 ‘네트워크 인터페이스 컨트롤러(network interface controller, NIC)’, ‘네트워크 어댑터(network adapter)’ 등으로 부르지만, ‘랜카드’라는 이름이 국내 사용자들 사이에서 통용되고 있다(여기서 랜-LAN은 ‘Local Area Network’, ‘로컬 영역 연결’을 말한다).


- 편하게 말하면 랜카드가 컴퓨터에 설치되어 있어야 바로 랜선이 꽂히는 포트가 생기는데요. 요즘은 대체적으로 메인보드에 내장되어 있습니다.  위 사진의 넷메이트 N-313 랜카드처럼 내장령 랜카드가 아닌 메인보드 PCI Express 슬롯에 장착하는
메인보드형 랜카드가 있으며,  요즘 많이 사용하는 내장형 랜카드가 고장나거나  컴퓨터를 업그레이드 할 때 기존 내장형 랜카드가 새 부품과 맞지 않는 일이 생기거나   인터넷 속도가 느려서 보니 랜선이나 ﻿통신사 라인 문제가 아니라 랜카드 성능이 떨어져서 느릴 경우 메인보드형 랜카드(N-313은 기가비트 속도 지원)로 교체해서 문제를 해결할 수가 있습니다.﻿
- 랜카드는 개방형 시스템 네트워크 통신을 위한 국제 표준인 OSI(Open Systems Interconnection) 7계층 모델 중 가장 하위 단계인 ‘물리적 계층(Physical layer)’에 속하는 기기로, 네트워크를 통한 데이터 전송 및 수신의 역할을 담당한다. 즉 한 컴퓨터에서 처리된 데이터를 전기 신호로 변환해 네트워크 내 다른 컴퓨터로 전송하고, 이 전기 신호를 수신해 다시 컴퓨터가 처리할 수 있는 데이터로 변환하는 역할이다.
-

## 랜카드 종류
- 또한 랜카드는 네트워크 유형 또는 형태에 따라 이더넷(Ethernet/Fast Ethernet)용, 기가비트 이더넷(Gigabit Ethernet)용, 토큰링(Token ring)용 등으로 구분되는데, 여기서는 일반적인 개인용 컴퓨터(PC) 유선 네트워크에 사용되는 이더넷 및 기가비트 이더넷용 랜카드에 대해서만 언급한다.
- 랜카드의 종류는 PC에 랜선을 연결해서 통신을 하는 유선랜카드와 랜선 연결 없이 와이파이로 연결해서 사용하는 무선 랜카드가 있습니다. 무선랜(wireless LAN)은 말 그대로 해당 기기(랜카드)가 있는 곳 주변의 일정 영역에서 랜선(LAN Cable)없이도
- 통신(인터넷)이 가능하도록 하는 기능입니다. 물론 무선랜이 가능한 랜카드를 설치하면 사용할 수 있습니다. 랜카드의 형태는 다양한데, 요즘 많이 사용되는 랜카드는 PC 내장형 이외에 USB형 랜카드가 있습니다. 크롬북 사용기에서도 잠깐 소개했었는데요. USB 포트에 꽂아 랜포트를 만들어주는 기기입니다.


## 랜카드 구조
- 랜카드 전면부에는 랜케이블을 꽂을 수 있는 단자(RJ-45 커넥터)와 네트워크 연결(Link) 및 통신 상태(Act)를 보여주는 LED(발광다이오드)가 달려 있다. 통신 가능한 랜케이블을 꽂으면 연결 상태 LED가 켜지며, 네트워크로 데이터가 전송/수신됨에 따라 통신 상태 LED가 깜박거린다. 따라서 이 LED 상태를 육안으로 확인하고 랜카드와 케이블 연결 상태를 1차적으로 점검할 수 있다.
 - 이러한 이더넷 랜카드는 일반적으로 최대 전송속도에 따라 10Mbps(mega-bit per second), 100Mbps(패스트, fast), 1000Mbps(1Gbps, giga-, 기가비트)로 나뉜다. 이를 MB로 환산하면 각각 초당 약 2.5MB, 12.5MB, 125MB로 전송되는 셈이다. 물론 이는 어디까지나 이론적 최대 수치이며, 여기에 네트워크 상태와 신호감쇠 현상 등이 작용하여 평균적으로 약 30% 정도 전송속도가 저하된다. 최근 출시되는 랜카드나 메인보드 내장 랜카드는 대개 10/100/1000Mbps 속도를 모두 지원하고 있다. 다만 랜카드가 1000Mbps 속도를 지원해도 랜케이블이나 스위치/라우터 등의 네트워크 장비가 이를 지원하지 않으면 기가비트 속도를 만끽할 수 없다.
- 참고로 전송속도 외에 전송매체, 즉 랜케이블의 유형에 따라서도 랜카드가 구분된다. 현재 일반적으로 사용되는 UTP(Unshielded Twisted-Pair) 케이블과 연결되면 BaseT, TV 안테나 케이블처럼 생긴 콕시얼(coxial) 케이블과 연결되면 Base2(씬넷-thin net), 모니터 케이블과 비슷한 케이블에 연결되면 Base5(씩넷-thick net), 광섬유 케이블과 연결되면 BaseF로 각각 나뉜다. 이에 따라 10/100/1000Mbps 속도를 모두 지원하며 일반적인 UTP 랜케이블을 사용하는 랜카드라면 ‘10/100/1000BaseT’ 규격이라 표기한다. 현재 콕시얼 랜케이블은 구형이라 거의 사용되지 않으며, 광섬유 랜케이블은 기업형 전산망에 주로 적용되고 있다.

## 맥주소
- 랜카드의 ‘주민등록번호’ - MAC 주소
전세계 네트워크로 연결된 모든 컴퓨터에는 (카드형이든 메인보드 내장형이든) 랜카드가 하나 이상은 장착돼 있다. 그리고 세상의 모든 랜카드에는 고유의 식별 코드가 들어 있는데, 이를 MAC 주소(MAC-Media Access Control Address)라 한다. 사람으로 치면 주민등록번호에 해당되는 MAC 주소 때문에 네트워크를 통해 데이터가 출발지에서 목적지까지 정확하게 도착할 수 있다.
- 랜카드의 MAC 주소는 두 자리의 영문자+숫자가 여섯 쌍으로 이뤄진다. 예를 들어, ‘E0-68-92-65-BC-61’과 같은 식(12자, 총 48비트)이다. 이 중 왼쪽에서 3쌍, 즉 ‘E0-68-92’는 랜카드(정확히는 랜 칩셋) 제조사를 의미하는 고유 코드다. 랜 칩셋의 주요 제조사로는 인텔(intel), 리얼텍(Realtek) 등이 있다. 한편 오른쪽에서 3쌍, 즉 ’65-BC-61’은 해당 랜카드의 고유 번호가 된다.
- 이러한 랜카드의 MAC 주소는 흔히 인터넷 서비스 제공사에서 가입자마다 인터넷 회선을 고정하는데 사용되곤 한다. 평소 인터넷을 사용하던 PC를 새로 교체한 후 인터넷 연결이 안 된다면 이는 십중팔구 인터넷 서비스 제공사에 처음 등록된 사용자 PC의 MAC 주소가 다르기 때문이라 짐작할 수 있다. 이런 경우 해당 인터넷 서비스 제공사에 전화 문의하여 PC(즉 랜카드의 MAC 주소)가 교체되었음을 고지하면 된다.
- 참고로 랜카드의 MAC 주소는 MS 윈도우 운영체계의 명령 프롬프트에서 ‘ipconfig /all’ 명령을 수행하여 확인할 수 있다. 윈도우 운영체계에서는 ‘물리적 주소’라 표기하고 있다. 앞서 언급한 대로 랜카드는 OSI 7계층 모델의 물리적 계층에 속하기 때문이다.

## 기본적인 랜카드 설정 및 점검법
- PC에 설치된 랜카드에 문제가 발생하면 PC 부팅 및 기본 사용에는 지장이 없으나 인터넷 접속은 불가능해 진다. 이런 경우 인터넷 상태의 문제인지 PC의 랜카드 또는 랜케이블과의 연결 문제인지를 우선 파악하는 것이 중요하다.
- 우선 랜카드의 연결 상태(Link) LED가 점등되어 있는지 확인한다. 꺼져 있다면 랜케이블을 뽑았다 끼워 점등 상태를 다시 확인한다. 그래도 점등되지 않는다면 랜케이블의 단선 또는 인터넷 서비스 제공사 측의 이상으로 판단할 수 있다. 물론 랜카드의 문제일 수도 있다. 윈도우의 명령 프롬프트를 실행해 ‘ping’ 명령어를 통해 ‘ping localhost’ 또는 ‘ping 127.0.0.1’라 입력하여, 아래 그림처럼 정상적인 ping 응답 결과가 나타나는지 확인한다. 정상이라면 적어도 랜카드 설정 및 구성(드라이버 설치 상태 등)에는 문제가 없는 것으로 판단할 수 있다.


# DNS
* DNS 값을 IP로 변환 -> Socket(IP, Port) -> IP가 맥주소로 변환 
- 전화 안내 서비스인 114와 같은 역할
- 윈도우에서 nslookup 으로 도메인과 IP주소 알 수 있음.
- 과정: URL 검색 -> URL 질의 -> 해당 URL의 IP 주소 알려줌


# UNC Route
* [Network](http://miniyo78.tistory.com/entry/UNC-%EA%B2%BD%EB%A1%9C)
- UNC 경로는 네트워크상의 공유자원에 연결할 때 사용하는 규칙이다. UNC 경로는 항상 \\Server_name\Share_name 형태로  \\는 데이터가 네트워크에 있다는 것을 의미한다.
- Server_name에는 연결할 서버의 컴퓨터 이름을 입력해야 하며 Windows Server 2003에서 컴퓨터 이름은 NetBIOS, DNS, IP 형식 등으로 입력할 수 있다

# 공유기
* 공유기는 라우터에 속해있음
## 2.4GHz 5.0GHz 신호의 차이점 비교 
* [거니](https://www.youtube.com/watch?v=KSFTAupElJ8&list=PLLcbGhhl4sQDOYzzB8eNB7m0IdVffIyLM&index=33)

## 2.4GHz
* 물체를 잘 통과, 넓은 범위를 커버
* 방해받지 않는 채널이 별로 없음
   * 블루투스, 와이파이, 전자렌지

## 5.0GHz
* 물체를 잘 통과하지 못함, 좁은 범위를 커버
   * 와이파이 증폭기를 사용하면 해결 가능
* 방해받지 않는 채널이 많음
  

# 라우터
1. Static Routing 
- Static Routing은 말 그대로 정적인, 즉 사람이 일일이 경로를 수동으로 결정해줘야 하는 라우팅 프로토콜을 의미합니다. static의 경우 일일이 사람이 경로를 설정해줘야 하기 때문에 장애가 발생했을 때 능동적으로 대처할 수 없는 단점이 있습니다. 하지만 자신이 원하는 경로를 직접 설정할 수 있고, 외부에 경로 정보를 알릴 필요가 없기 때문에 보안적인 측면에서 장점을 갖습니다. 


- (라우터는 원래 라우터끼리 라우팅 테이블을 주고 받으며 경로 정보를 서로 업데이트 합니다.)


2. Dynamic Routing
- ﻿Dynamic Routing은 말 그대로 그 때 그 때 동적으로 최적의 경로를 결정하는 라우팅 알고리즘을 의미합니다. 잘 알려진 라우팅 프로토콜 대부분이 바로 Dynamic 라우팅에 속합니다. RIP, OSPF, IGRP, EIGRP 등...
- 사람이 일일이 경로를 설정해주지 않아도 되고, 자동으로 경로에 대한 정보를 업데이트 하기 때문에 장애가 발생했을 때 경로 결정에 대해 능동적으로 대처할 수 있습니다. 하지만 시간이 지날 때마다 바뀐 정보는 없는지 확인해야 하고 새로운 경로를 계산해야 하는 등 라우터 자체에 부담을 많이 주는 단점이 있습니다.

## 라우터의 기능
- 경로 설정(Path Determination): 데이터 패킷이 출발지부터 목적지까지 갈 수 있는 경로를 검사하고 어떤 경로로 가는 것이 최선인지 결정
- 스위칭(Switching): 경로 설정이 결정될 경우 데이터 패킷 스위칭 작업을 함


## 포트
- Ethernet: 내부 네트워크 간 접속시에 사용되는 인터페이스
- Serial: WAN(Wide Area Network) 접속을 위해 사용되는 인터페이스
- 같은 종류의 포트가 많아질수록 포트는 보통 0/0, 0/1, 0/2, 0/3... 순으로 증가한다. (예 : f0/0, f0/1, f/2...)
- 인터페이스에 따라 연결가능한 케이블(선)의 종류에 유의해야한다. (예: 라우터와 라우터 연결은 크로스오버 케이블)

## 포트 번호로 서비스를 식별
* 포트 번호를 이용하여 컴퓨터 안의 어떤 서비스에게 데이터를 전달하면 좋은지 식별
* 0 ~ 1023 : 잘 알려진 포트(Well-know-Port)
* 1024 ~ 49151 : 등록된 포트(Registered Port)
* 49152 ~ 65535 : 동적 포트(Dynamic Port)

### 포트 번호
* 21: FTP(컨트롤 커넥션)
* 22: SSH(원격제어, 보안 기능 있음)
* 23: Telnet(원격 제어)
* 25: SMTP(이메일 전송)
* 80: HTTP
* 110: POP3(이멩리 수신)

## AS(Autonomous System)
- 네트워크 관리자에 의해 관리되는 라우터들의 집단을 하나로 생각하는 것
- 예를들어 K사라는 ISP업체의 라우터들을 관리자에 의해 설정되었다면 그 K사의 라우터들은 하나의 AS가 된다.
- AS는 ASBR(Autonomous System Boundary Router)이라는 문지기 라우터를 통해 인터넷으로 나가게 된다.
- ASBR은 자신의 AS와 인접해 있는 다른 AS에 대한 정보를 가지며 밖으로 나가는 AS나 자신의 AS쪽으로 들어오는 ASBR 라우터에게 정보를 제공한다.
- 따라서 AS 내의  라우터들은 인터넷에 접속하기 위해 이 세상의 모든 네트워크 정보를 가지고 있을 필요가 없고 단지 자신의 AS정보만 가지면 된다.

## Interior Gateway Protocol (IGP)
- AS안에서 운영되는 라우팅 프로토콜로서 RIP, IGRP, OSPF, EIGRP 등이 있다.
 
## Exterior Gateway Protocol (EGP)
- AS 간 연결하는 라우팅 프로토콜로서 EGP, BGP 등이 있다.

# router
* DHCP, DNS

## wifi
* DHCP, DNS, switch




# 인터넷
인터넷 여러 가지 프로토콜 중에서 TCP/IP . 

## 프레젠테이션
- 브라우저; 화면에 띄어주기

## 세션
- 스택에서 나온 힙처럼 유지 기능(소멸 시키지 않는 기능)을 가진다.


# 프로토콜
- 프로토콜://인터넷 주소 혹은 도메인:80/파일; 전체 영향 받아라
- https://www.naver.com:443 원래 이것인데 기본포트라 생략 가능 (443은 https 포트번호)
- https://www.naver.com/index.html   // index.html이 파일 이름; 기본 페이지여서 생략 가능
-   하위 디렉토리 모두가 프로토콜에 영향을 준다.


## 기본 파일명
- index.html, index.htm, index.jsp, default.html, default.htm, default.jsp


## 메일
- 데이터를 패킷단위로 전송하는 것을 의미; 
- # MIME;

## MIME
- 데이터를 패킷단위로 전송하는 것을 의미; 
- MIME (영어: Multipurpose Internet Mail Extensions)는 전자 우편을 위한 인터넷 표준 포맷이다. 전자우편은 7비트 ASCII 문자를 사용하여 전송되기 때문에, 8비트 이상의 코드를 사용하는 문자나 이진 파일들은 MIME 포맷으로 변환되어 SMTP로 전송된다. 실질적으로 SMTP로 전송되는 대부분의 전자 우편은 MIME 형식이다. MIME 표준에 정의된 content types은 HTTP와 같은 통신 프로토콜에서 사용되며, 점차 그 중요성이 커지고 있다.
- 기본적으로 인터넷 전자 우편 전송 프로토콜인 SMTP는 7비트 ASCII 문자만을 지원한다. 이것은 7비트 ASCII 문자로 표현할 수 없는 영어 이외의 언어로 쓰인 전자 우편은 제대로 전송될 수 없다는 것을 의미한다. MIME은 ASCII가 아닌 문자 인코딩을 이용해 영어가 아닌 다른 언어로 된 전자 우편을 보낼 수 있는 방식을 정의한다. 또한 그림, 음악, 영화, 컴퓨터 프로그램과 같은 8비트짜리 이진 파일을 전자 우편으로 보낼 수 있도록 한다. MIME은 또한 전자우편과 비슷한 형식의 메시지를 사용하는 HTTP와 같은 통신 프로토콜의 기본 구성 요소이다. 메시지를 MIME 형식으로 변환하는 것은 전자 우편 프로그램이나 서버 상에서 자동으로 이루어진다.
- 전자 우편의 기본적인 형식은 RFC 2821에서 정의하고 있다. 이 문서는 RFC 822를 대체한다. 이 문서는 텍스트 전자 우편의 헤더와 본문의 형식을 명시하고 있으며, 그중에는 우리에게 익숙한 "To:", "Subject:", "From:", "Date:" 등의 헤더가 포함되어 있다. MIME은 메시지의 종류를 나타내는 content-type, 메시지 인코딩 방식을 나타내는 content-transfer-encoding과 같은 추가적인 전자 우편 헤더를 정의하고 있다. MIME은 또한 ASCII가 아닌 문자를 전자 우편 헤더로 사용할 수 있도록 규정하고 있다.
- MIME은 확장 가능하다. MIME 표준은 새로운 content-type과 또 다른 MIME 속성 값을 등록할 수 있는 방법을 정의하고 있다.
- MIME의 명시적인 목표 중 하나는 기존 전자 우편 시스템과의 호환성이다. MIME을 지원하는 클라이언트에서 비 MIME가 제대로 표시될 수 있고, 반대로 MIME을 지원하지 않는 클라이언트에서 간단한 MIME 메시지가 표시될 수 있다.


## //
- 프로토콜://인터넷 주소 혹은 도메인:80/파일; 전체 영향 받아라

## 포트
- 인터넷 프로토콜 스위트에서 포트(port)는 운영 체제 통신의 종단점이다. 이 용어는 하드웨어 장치에도 사용되지만, 소프트웨어에서는 네트워크 서비스나 특정 프로세스를 식별하는 논리 단위이다. 주로 포트를 사용하는 프로토콜은 전송 계층 프로토콜이라 하며, 예를 들어 전송 제어 프로토콜(TCP)와 사용자 데이터그램 프로토콜(UDP)가 있다. 각 포트는 번호로 구별되며 이 번호를 포트 번호라고 한다. 포트 번호는 IP 주소와 함께 쓰여 해당하는 프로토콜에 의해 사용된다.
- 소켓은 포트를 이용하여 통신하기 위한 것.
- 윈도우: 제어판 - 방화벽 - 인바운드 - 포트 등록 가능


# 5g
* 다수의 기기 지원(점점 IOT 되는 기기), (응답) 속도
* 특징: IOT, 센서, 홀로그램
