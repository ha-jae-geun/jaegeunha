


# 바이너리와 문자열 차이
* 바이너리: 길이가 없다.
* 문자열
	* String
	* char*; 문자에 대한 포인터(배열)
	* 'Null Terminated String'이라고 하기도 함.

# 텍스트 파일
-  텍스트 파일이란, 글자들이 씌어 있는 파일입니다. 사람이 눈으로 직접 내용을 읽을 수 있습니다. 텍스트 파일은 아스키 파일이라고도 합니다. 대부분의 텍스트 파일이 아스키 코드 (ASCII Code)로 글자들을 나타내기 때문입니다. Plain Text File 이라고도 합니다. "암호화되지 않은 평범한 텍스트"라는 뜻입니다.
- (우리 키보드에 있는 문자중 한글을 제외한 모든 문자들은 전부 아스키코드로 표현된다. 한글의 표현 방법은 다음에 살표보자)  그럼 텍스트 파일로 저장 한다 하면 아스키코드로 저장된다고 생각하면 된다. 
- 텍스트 파일의 대표적인 확장자는 ".txt" 입니다. 또한 .c .cpp .pl .bat .java .html .xml .css 등의 각종 프로그래밍 소스들과 웹문서도 텍스트 파일입니다.
- 텍스트 모드에서는 "\n"은 "\r\n"으로 변경되어 저장됨; 분명 "\n"로 저장했는데 "\r\n"으로 바뀌었다. 실제로 파일의 바이트 수를 살펴봐도 자신이 저장한 문자열에 "\r"이 추가되어 1byte가 추가됨을 알 수 있다. 그렇다면 결국 개행 하나에 1byte가 추가되는 셈이다.
- \r은 0x0D 로 저장되고 (1byte) 아스키 코드 13, \n은 0x0A 로 저장된다.(1byte) 아스키 코드 10, 그리고 \r\n은 0x0D0x0A 형태가 될 것이다.


- 리눅스에서 만든 문서는 리눅스에서 위와 같이 깨진다. 줄이 바뀌는 부분에 검은색 네모 안에 동그라미 표시 문자가 나타난다. 이 것은 "\n"을 의미하는 문자다. 윈도우는 "\n"을 위와 같은 문자로 표현해 준다. 이를 해결하기 위해서 "\n"을 "\r\n"으로 바꿔주면 된다. 어떻게 바꿔줄 수 있을까? 사실 파이썬으로는 너무 간단하다. 바이너리 모드로 열어서 "\n"을 "\r\n"로 바꿔주기만 하면 된다.



## 텍스트 파일의 장점
 * 단순히 텍스트 편집기만으로 리소스 파일을 생성, 수정 할 수 있다.
 * 쉽게 파일의 내용을 살펴볼 수 있어서 디버깅이 쉽다.

# 바이너리 파일
- * 이진 파일은, 바이너리 파일 Binary File 이라고도 합니다. "0"과 "1"이라는, 2진수 데이터만으로 이루어진 파일입니다. (사실 텍스트 파일 역시 "0"과 "1"이라는, 2진수로 이루어져 있는 것은 마찬가지입니다.) 사람이 직접 읽을 수는 없습니다.
- .exe .dll 등의 프로그램 파일과, .zip .rar 등의 압축파일, .mp3 .mpg .jpg .gif 등의 멀티미디어 파일은 이진파일입니다.
- 도스의 type 명령은 파일의 내용을 화면에 출력하는 명령입니다. type 명령으로, "test.txt"라는 텍스트 파일과, "notepad.exe"라는 이진파일의 내용을 출력한 결과가 아래의 그림입니다.
 
## 바이너리 파일의 장점
 * 데이터를 처리하고 전송하는데 일반적으로 비용이 적게 든다.
 * 보통 텍스트에 비해서 파싱이 쉬워서 데이터 처리 속도가 빠르다.
 * 필요한 데이터 공간도 더 작은 경우가 많다.

## 텍스트 파일과 바이너리 파일의 차이
- 예상대로 바이너리 파일이 더 빠르게 처리 할 수 있을것 같다. 이유는 텍스트 파일의 경우 숫자 하나가 8bit 의 아스키 코드로 이루어져 있어서 정수형 데이터 하나가 몇 bit 로 이루어 졌는지 탐색하는 비용이 클것 같다. 하지만 바이너리 파일의 경우 정수형 데이터 하나는 4bit 으로 고정되어 있어서 offset 값을 옮겨가면서 합을 구하면 더 빠르게 처리가 될것 같다.

## 텍스트, 바이너리 파일 차이
 * 파일을 다루다 보면 텍스트 파일과 바이너리 파일이 있다는 알게 됩니다. 과연 두 파일은 어떤 차이가 있을까요?
 * 텍스트 파일도 바이너리 파일의 일종입니다. 바이너리 파일 중 문장을 읽기 편한 문자 코드만 사용해서 만들어진 파일이
 * 텍스트 파일입니다. 그래서 텍스트 파일을 ASCII 파일이라고도 하는데 한글도 사용할 수 있다는 것을 상기한다면
 * ASCII 파일이라고 말하는 것은 옳지 못 합니다.
 *  
 * 영문이든 한글이든 일본어이든 여러 줄의 문장으로 되어 있다면, 그래서 한 줄씩 읽을 수 있다면 텍스트 파일이라고
 * 생각하시면 되겠습니다. 그렇다면 어떻게 텍스트 파일을 만들어야 할까요?
 *  
 * 문장과 문장 사이는 개행 특수 코드(0x0d)가 있어야겠지요? 행 바꿈 없이 하나의 문장이라서 사용하지 않는 경우도 있습니다.
 * 무엇보다도 문장은 개행 코드 전까지 모두 읽어 들일 수 있도록 NULL 코드가 없어야합니다.
 *  
 * 이에 비해 바이너리 파일은 NULL 코드든, 개행 코드(0x0d), 0x01, 0x02, 등등 모든 코드를 자유롭게 저장할 수 있습니다.
 * 영화나 압축 파일을 생각해 보면 이해가 쉽죠. 영화 내용에 따라, 압축된 데이터 코드 중에는 0x00, 0x0d, 0x11, ...
 * 숫자로 표현할 수 있는 모든 코드를 사용해야 합니다.
 *  
 * C언어에서도 문자열에 0x01, 0x02, 0x07 처럼 다양한 코드를 사용할 수 있습니다.
 * 물론 화면에 출력하거나 파일로 저장하면 이상한 문자로 보이지만, 사용할 수 있죠.
 * 그러나 문장 사이에 NULL을 사용할 수 없습니다. 
 *  
 * 화면에 출력하고 싶어도, 파일로 저장하고 싶어도 바이너리 용 함수가 아닌 텍스트 전용 함수로는
 * NULL 문자를 출력하거나 저장할 수 없습니다.
 *  
 * 즉, NULL 문자를 자유롭게 사용할 수 있느냐 없느냐로 따지는 것이 텍스트 파일과 바이너리 파일을 
 * 구분하기 제일 간편한 방법입니다.
 *  
 * 예로 "falinux.com 입니다." 사이에 NULL 문자가 숨어 있다면 텍스트 관련 함수는 NULL 까지만 처리합니다.
 * 왜냐하면 C 언어에서는 NULL Terminated String을 사용하기 때문이죠. 즉, NULL 코드를 문자의 끝으로 인식합니다.
 * 파스칼 처럼 문자열 변수가 [문자열 길이][문장]처럼 길이 값을 갖지 않습니다. C 언어는 [문장][NULL]을 사용하죠.


# 인코딩
```java
문자열 인코딩 개념
문자열 인코딩이란

2진법을 사용하는 컴퓨터가

인간의 언어를 일정한 규칙에 따라 2진수로 변환하는 방식이다.

컴퓨터는 ‘안녕하세요’와 같은 문장을 그대로 읽고 처리할 수 없기 때문이다.

그래서 컴퓨터는

2진수와 문자를 1:1로 대응하는 규칙을 통해 2진수로 문자를 처리한다.

ex) ( 2진수 : 0100 0001 ) : ( 문자 : A )

Q. 인터넷에서 글자가 깨지거나 보이지 않는 문제는 왜 발생하는 걸까?

컴퓨터가 처음 등장했을 때

모든 프로그램은 영어와 일부 특수 문자만 지원했다.

그러나 시간이 지나 많은 국가가 컴퓨터를 사용하기 시작했고

국가별로 사용하는 언어를 표현하고자

독자적인 규칙을 만들기 시작했다.

참고로 한국에서는 독자적인 인코딩 방식인 EUC-KR을 만들었다.

독자적인 규칙을 만드는 움직임은

모든 언어를 같은 규칙으로 표현할 수 있는 유니코드 방식이 등장하면서 통일되었다.


 
그러나 모든 개발 환경이 유니코드를 동일하게 처리하지 않아

개발자는 서로 호환되지 않는 유니코드 문자열 인코딩 방식(UTF-8, UTF-16, UTF-32) 중 하나를 택해야 한다.

문자 집합 vs 문자열 인코딩
문자 집합

사용할 수 있는 문자들의 집합

ex) 유니코드, ISO-8859, ASCII 등

문자열 인코딩

문자를 코드로 표현하는 방식

ex) 유니코드라는 문자 집합 을 표현하는 문자열 인코딩은 UTF-8, UTF-16, UTF-32 등이 있다.

아스키 코드(ASCII)
처음으로 표준을 정립한 문자열 인코딩 방식으로 아직도 많이 사용된다.

사용할 수 있는 문자의 종류에는

대/소문자, 공백 및 특수 문자들이 있으며

문자를 표현할 때는 0 ~ 127까지

총 128개의 숫자를 사용한다.



그림에서 알 수 있듯이

아스키 코드는 영어를 제외한 다른 언어를 표현할 수 없다.

그래서 각 나라에서 아스키코드 대신

독자적인 문자 집합과 인코딩 방식을 만들었다.

아스키코드에 대한 자세한 개념은 아스키코드(ASCII Code)을 참고하자.

EUC-KR
한국에서는 EUC-KR 문자 집합을 만들었다.

한국어 문자 집합으로

문자 하나를 표현하기 위해 2바이트를 사용한다.

단 아스키코드 문자를 표현할 때는

1바이트를 사용하기 때문에 아스키코드와 호환이 된다.

EUC-KR 특징


2바이트 저장

좌측에 있는 코드(b0a0, b0b0 등)를 기준으로

오른쪽으로 한 칸씩 이동할 때마다 1바이트를 더한다.

ex) ‘가’ 문자는 b0a0 코드 줄의 2번째 칸에 있어 1바이트를 더해 b0a1로 표현한다.

b0a1는 0xb0, 0xa1로 나뉘어

총 2바이트를 사용하게 된다.

완성형 코드

모든 글자가 완성된 형태로만 존재하는 완성형 코드이다.

따라서 조합해 문자를 만들 수 없으므로 표현할 수 없는 한글이 일부 존재하지만

그 문자는 잘 사용되지 않는다.

지원 언어

EUC-KR에는 한글뿐만 아니라

숫자, 특수 기호, 영문, 한문, 일어가 존재한다.

UTF-8, UTF-16
유니코드 문자열 인코딩 방식(UTF-8, UTF-16, UTF-32)에 대해서는

유니코드와 UTF-8 / UTF-16 글을 참고하자.
```

## 인코딩이 다른 기준
1. 운영체제
2. 소스코드
3. 통홥개발환경
4. 웹 소스
		1-4까지는 인코딩이 다르면 깨져 나온다.
5. http 요청; 클라이언트와 서버가 틀림
6. http 응답; 클라이언트와 서버가 틀림
7. 데이터베이스
8. 파일 -> 우연
		5-8까지는 인코딩이 다르면 null로 나온다.

# 유니코드
```java
유니코드는 모든 문자에 Index를 지정하는 것이다. 그 이상도 아니고, 그 이하도 아니다.
이 Index를 Code Point 혹은 Code Unit이라고 부르는데 일반적으로 Index라고 생각해도 무방하다.
더 많은 글자와 Index를 보려면 Code Charts를 참고하자.

문자열을 숫자로 표현하기 위하여 문자 하나와 숫자 하나를 각각 매핑(=연결)한 것이 바로 유니코드이다.

예를 들어 A는 U+0041에 매핑되어 있고 ‘가’는 U+AC00에 매핑되어 있다.

유니코드를 인코딩하는 방법에는 UTF-8, UTF-16 등등 여러 방법이 존재한다.
```

# 조합형 방식
* 초성, 중성, 종성으로 구분하여 문자를 작성(총 3바이트의 문자로 인식)
* UTF-8; 조합형으로 거의 모든 한글을 표현 가능

## 완성형 방식
* 하나의 문자를 하나의 완성되어있는 글자로 인식하는 방식
	* 문자표를 토대로 문자를 인식
	* 확장성이 떨어짐
* EUC-KR 방식은 완성형으로 조합형으로 표현 할 수 있는 모든 한글을 표현하지 못함
* CP949 방식은 완성형이지만 조합형으로 쓸 수 있는 거의 모든 한글을 포함

# 한글 표현 가능 관계
* ECU-KR  -> UTF-8 -> CP949(가능)
* ECU-KR <- UTF-8 <- CP949(불가능)
* 확장 완성형인 CP949의 경우에는 유니코드(UTF-8)에서 표현할 수 있는 모든 문자를 표현 가능
* 웹에서의 관계는 위처럼 표현 가능한 것이 아님
* UTF-8이면 UTF-8, EUC-KR이면 EUC-KR끼리 밖에 제대로 표현 못함



# CP949
* EUC-KR은 완성형 방식이고, 2바이트로 한글을 표현할 수 있게 만든 방식
* 아스키 값은 그대로 1바이트로 표현
* CP949도 같은 2바이트를 사용
* EUC-KR에서 표현할 수 없는 한글이 있어 마이크로소프트에서 CP949 사용 시작
* CP949는 EUC-KR보다 많은 한글 표현 가능하며 윈도우에서 주로 쓰이는 인코딩 기법



# UTF
* UTF는 몇 bit 단위로 사용해서 Index를 표현할 것인가를 뜻한다.
* UTF-8은 8bit씩 Index를 표현
* UTF-16은 16bit씩 Index를 표현
* UTF-32는 32bit씩 Index를 표현한다는 뜻을 갖고 있다.
* U+라는 접두어가 붙어있으면 유니코드
* 아스키코드 – 0x41 = A  /  유니코드 – U+0041 = A


# UTF-8
```java
UTF-8은 Universal Coded Character Set + Transformation Format – 8-bit의 약자이다.
UTF-8은 유니코드를 위한 가변 길이 문자 인코딩 방식 중 하나이다.
UTF-8의 코드 단위는 8bit입니다.
UTF-8 인코딩은 유니코드 한 문자를 나타내기 위해 1byte ~ 4byte까지를 사용한다.
UTF-8은 인터넷에 교환되는 대부분의 파일에 사용된다.
영문 byte 수 : 1byte 한글 byte 수 : 3byte
```

# UTF-16
- < 윈도우즈 메모장notepad에서 텍스트 파일 저장 시, 유니코드, 유니코드(big endian)이 바로 UTF-16에 해당한다. >

```java
UTF-16은 유니코드 문자 인코딩 방식의 하나이다.
주로 사용되는 기본 다국어 평면(BMP, Basic multilingual plane)에 속하는 문자들은
그대로 16bit값으로 인코딩이 되고 그 이상의 문자는 특별히 정해진 방식으로 32bit로 인코딩이 된다.
UTF-16의 코드 단위는 16bit이다.
UTF-16 인코딩은 유니코드 한 문자를 나타내기 위해 2byte ~ 4byte까지를 사용한다.
UTF-16은 윈도우 응용프로그램, 자바스크립트 등의 작동시 사용된다.
영문 byte 수 : 2byte 한글 byte 수 : 2byte
```

## UTF-8 vs UTF-16
* UTF-8과 UTF-16의 기본 차이는 문자 하나를 표현할 때 사용할 최소 byte 크기이다.
* UTF-8로 문자를 표현할 때 1 ~ 4byte가 필요하다. 하지만 UTF-16은 2 ~ 4byte가 필요하다.
	* 1byte: 영어
* 두 Encoding 방식의 큰 차이는 최소 8bit가 필요하냐 16bit가 필요하냐에 따라 다른 것이다.
* 최적의 상황(저장, 통신 용량을 아껴야할 때)이 필요하다면 어떤 CodePoint를 주로 사용하냐에 따라 UTF-8 또는 UTF-16을 선택하는 기준이 달라질 것이다.

# EUC-KR
- ECU-KR는 2350개의 한글만 처리할 수 있는 한글이며 '뷁' 등의 글자를 제대로 처리할 수가 없게됩니다. 결론적으로는 EUC-KR로 저장한다고 하더라도 글자가 깨져서 나타날 수 있기에 UTF-8로 저장하시길 권장드립니다.

# UTF-8 웹페이지용 유니코드
 * 이것은 인터넷이나, 리눅스/유닉스 등에서 사용하는 8비트 유니코드입니다. 웹페이지 관련 작업에서 "유니코드"라고 할 때에는 이 UTF-8 유니코드를 가리킵니다. 영문이나 숫자 등은 1바이트로 표현하고, 한글이나 한자 등은 3바이트로 표현합니다. 웹페이지를 유니코드 인코딩으로 만들 때에는 반드시 "UTF-8 유니코드"를 사용해야 합니다. 8비트 유니코드라고 해서, 16비트 유니코드보다 문자 표현 범위가 작다든지 그런 것은 전혀 없고 동일합니다.



# UTF-16 LE (MS OS, Office용 유니코드)
- 컴퓨터에서 그냥 "유니코드"라고 부를 때에는 이 UTF-16 LE 를 가리키는 경우가 많습니다. MS윈도우2000이나 윈도우XP에서 내부적으로 사용되는 유니코드입니다. 그렇다고 해서 마이크로소프트(MS)가 개발했다는 뜻은 아니고, 표준 유니코드 중의 하나입니다. 문자 1개를 16비트로 표현하는데, 앞의 8비트와 뒤의 8비트의 순서가 거꾸로 되어 있습니다. 인텔CPU가 Little-Endian 이기에, 유니코드도 앞뒤 바이트 순서를 바꾸면 이론적으로 더 처리 속도가 빨라집니다.

# UTF-16 BE (Mac, JAVA용 유니코드)
- BE는 Big-Endian 의 약자입니다. 이것은 맥(Mac)이나 자바(Java)에서 사용되는 16비트 유니코드인데, 앞뒤 바이트 순서가 거꾸로 바뀌지 않고 그대로 있는 것입니다. UTF-16 BE 는 윈도우에서는 거의 사용되지 않습니다.

# BOM이란
- BOM이란 문서 맨 앞에 눈에 보이지 않는 특정 바이트(byte)를 넣은 다음 이것을 해석해서 정확히 어떤 인코딩 방식이 사용되었는지 알아내는 방법을 나타냅니다. 자세하게 유니코드가 little-endian 인지 big-endian 인지 아니면 UTF-8 인지 쉽게 알 수 있도록, 유니코드 파일이 시작되는 첫부분에 보이지 않게, 2~3바이트의 문자열을 추가하는데 이것을 BOM이라고 합니다. BOM은 텍스트 에디터 화면에서는 보이지 않고, 헥사 에디터(Hex Editor)*로 열었을 때만 보입니다.
- UTF-16 이상 인코딩일 때, 문서의 맨 처음 BOM을 파악하여 Big Endian인지 Little Endian인지 구분하지만 UTF-8의 경우는 BOM이 하나로 고정입니다. 그래서 이 BOM은 바이트 순서와(Byte Order) 상관없기 때문에 UTF-8 Signature라고 불리기도 합니다. 즉, 해당 문서가 UTF-8로 인코딩되었다는 사실을 알리는 사인(signature)입니다.
 
# BOM 문제점
- UTF-8에는 BOM이 없는 것이 보통인데(UTF-8은 BOM이 고정이라 인코딩 방식을 자동으로 알 수 있음), 일부 윈도우즈 프로그램(메모장 같은)은 UTF-8 파일을 생성할 때 자동으로 BOM을 집어넣습니다. 윈도우즈 환경에서는 눈에 띄지 않는 경우가 많지만 리눅스(LINUX)나 유닉스(UNIX) 환경에서는 많은 문제를 일으키는 원인이 됩니다. BOM이 추가된 데이터의 경우, 글자 앞에 빈칸이 생기면 그 차이점을 알 수 있지만 대개 눈으론 보이지 않습니다.
- 데이터베이스에서 BOM이 추가된 데이터와 그렇지 않은 데이터를 비교할 경우 눈으로는 동일한 데이터지만 비교를 할 땐 같지 않다는 데이터로 나옵니다. 그 이유는 문자열 앞에 BOM이 붙어있기 때문입니다. (이 문제때문에 하루를 고생한적이..)
- 울트라에디트라는 프로그램을 울트라에디트의 헥사 모드(Ctrl+H)로 UTF-8 파일을 보면, 16비트 유니코드처럼 보이고 BOM이 있든 없든 항상 FF FE 라는 엉뚱한 BOM이 나타납니다. 이것은 울트라에디터가 유니코드를 편집할 때, 내부적으로 '16비트 little-endian 유니코드 (UTF-16LE)'로 변환하여 편집하기 때문입니다. 진짜 헥사 에디터로 보아야만 UTF-8의 BOM인 EF BB BF 가 제대로 보이게 됩니다. 물론 BOM이 없는 UTF-8이라면 BOM이 없는 것으로 나옵니다
- 가장 좋은 방법으로는 메모장 같은 프로그램보단 BOM설정이 가능한 프로그램을 사용하는 것입니다. 하지만 모든 파일을 BOM설정이 가능한 프로그램을 사용할 수 없기 때문에 BOM파일을 받은 다음, 코드로 해당 파일을 UTF-8로 인코딩 처리하는 부분도 생각해야 합니다.



## iso-8859-1 
- ASCII 확장 이며 단일 바이트 고정 길이 인코딩이다


## 아스키 코드
* 바이너리를 스트링으로 표현
- %: 아스키 코드가 표현하지 못하는 문자
- +는 공백
- 숫자는 아스키코드

```java
아스키코드란?
아스키코드란

ASCII(American Standard Code for Information Interchange )의 줄임말이다.

이름에서부터 알 수 있듯이

American을 위한 문자 집합이고

이는 영문 키보드로 입력할 수 있는

모든 기호가 할당되어 있는 부호 체계이다.

그래서 000(0x00)부터 127(0x7F)까지 총 128개의 부호가 사용된다.

Q. 왜 128개만 사용하는 걸까?

아스키코드는 1바이트를 사용한다.

그렇기 때문에 2^8 = 256개를 사용할 수 있지만

2^7 = 128개만 사용한다.

그 이유는 나머지 1bit를 통신 에러 검출을 위해 사용하기 때문이다.

## Parity Bit
7개의 비트 중 
1의 개수가 홀수면 1 
1의 개수가 짝수면 0으로 하는 
Parity Bit를 붙여 
전송 도중 변질된 것을 검출해낸다.


매우 단순하고 간단하므로

어느 시스템에서도 적용 가능하다는 장점이 있다.

하지만 2바이트 이상의 코드를 표현할 수 없기 때문에

국제표준의 위상은 유니코드에게 넘어갔다.

# 유니코드와 호환성
UTF-8의 경우

ASCII 영역은 그대로 1바이트를 사용하기 때문에 호환이 된다.

그러므로 UTF-8으로 인코딩된 문서에서

ASCII 영역에 해당하는 문자만 적혀 있고

Byte Order Mark(BOM)까지 없다면 그냥 ASCII 문서와 다를 게 없다.

하지만 UTF-16은

2바이트에서 시작하기 때문에 호환이 되지 않는다.

이 때문에 UTF-16에서

ASCII 문자를 나타낼 때는 앞에 0x00이 붙는다.

ex) A라는 글자를 표현하려면

ASCII 혹은 UTF-8에서는 0x41이라고만 표현하면 되지만

UTF-16에서는 0x0041로 표현해야 한다.

이를 무시하고 1바이트로만 표현하면

앞뒤의 바이트가 묶여 다른 문자로 인식된다.
```

#  ANSI 코드
- 그러나, 아스키코드를 이용해 다른 언어를 표현하기에는 7비트로는 부족했다.  그래서 8비트로 확장한 아스키 코드가 나왔다.  사람들은 이 코드를 ANSI 코드라고 부르기 시작했다.
-  7비트에서 8비트로 확장되었으니 사람들이 활용할 수 있는 문자는 몇 개가 더 늘어났을까?  1비트 늘어났으니 2개 더 늘어났다고 생각하면 안된다.  이렇게 되었으니 128개나 더 쓸 수 있게 되었다! 이때, 1바이트만으로 표현되는 경우를 SBCS(Single Byte Character Set)이라고도 한다. 반대의 경우는 MBCS(Multi-Byte Character Set)이라고 한다. 그러나! 비유럽 국가 특히 한국, 중국, 일본과 같은 문자가 많은 국가에서는 여전히 제한적이다.
(※ 우리나라의 경우 KSC5601 표준이라는 고유한 인코딩 방법으로 문자를 표현했다) 그래서 유니코드(Unicode)라는 전 세계 언어의 문자를 정의하기 위한 국제 표준 코드가 등장하게 되었다.
 
 ```java
 ANSI의 앞 7bit는 ASCII와 동일하고 뒤에 1bit를 이용하여 다른 언어의 문자를 표현한다.

그런데 새로 추가 된 128개 문자로는 모든 언어의 문자를 표현할 수 없다.

그래서 생긴 개념이 Code Page이다.

각 언어별로 Code 값을 주고 Code마다 다른 문자열 표를 의미하도록 약속을 했다.

쉽게 생각하면 아래와 같이 설명할 수 있다.

ANSI = ASCII(7bit) + CodePage(1bit)

이러한 원리를 고려하면 다음과 같이 정리할 수 있다.

영어만 사용하거나 ASCII를 사용할 경우 세계 어디에서나 사용에 문제가 없다.

영어 외 다른 언어를 사용할 경우 ANSI는 Code Page를 동일하게 맞춰야 한다.

Code Page가 다를 경우 의도와 다른 결과가 나올 수 있다.
 ```

# https
```java
HTTPS에 대해 알아보기 전에 HTTP를 간단하게 설명할 수 있으면 좋다.

HTTP는 HyperText Tranfer Protocol로 WWW상에서 정보를 주고 받는 프로토콜이다.

클라이언트인 웹브라우저가 서버에 HTTP를 통해 웹페이지나 이미지 정보를 요청하면 서버는 이 요청에 응답하여 
요구하는 정보를 제공하게 된다.

결국, HTTP 는 웹브라우저(Client)와 서버(Server)간의 웹페이지같은 자원을 주고 받을 때 쓰는 통신 규약이다.

http는 텍스트 교환이다. html페이지도 텍스트다. 바이너리 데이터로 되어있는 것도 아니고 단순 텍스트를 주고 받기 때문에 
누군가 네트워크에서 신호를 가로채어 본다면 내용이 노출된다.

이런 보안상의 문제를 해결해주는 프로토콜이 HTTPS다.

HTTPS는 인터넷 상에서 정보를 암호화하는 SSL(Secure Socket Layer)프로토콜을 이용하여 웹브라우저(클라이언트)와 
서버가 데이터를 주고 받는 통신 규약이다.

HTTPS는 http 메세지(text)를 암호화하는 것이다.

HTTPS의 S가 Secure Socket, 보안 통신망을 말한다.

HTTPS의 암호화 원리를 간단히 알아보면 핵심은 공개키 암호화 방식이다.

```
