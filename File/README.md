# 파일
* 메모리에 모두 올려놓을 수 없으니 논리적으로 만들어 놓은 구조

# 완전 파일 삭제
* shift delete나 휴지통 비우기는 invalid bit를 바꾸기만 한 것
	* Forensic website; 
	* Wiper 툴을 이용하여 지워도 자력 현미경을 이용하면 공간적 변화에 의한 흔적이 남는다고 한다; 하지만 하드 상태에 따라 복구할 수 있는 것이 다루고, 법적 효력여부도 확실하지 않다.
	* 하드웨어적으로 지우는것이 확실; 디가우저

# 랜덤숫자
* 폰 노이만이 에니악 만들던 시절 컴퓨터에게 랜덤 숫자를 알려줘야 했음; 자연의 숫자를 녹음한 후 숫자료 변경 -> 현재 시간 이용; -> 평방 채중법 이용 
* 현재: rand() 함수로 난수 60개 패턴의 테이블과 현재 시간을 이용하기
	2. 노이즈(HDD, FA 등 노이즈 이용) 하여 값을 이용 
* 세계 최초로 양자난수; 2017년 SK텔레콤이 분당사옥에 있는 '양자암호통신 국가시험망'에서 5x5mm 크기의 '양자난수생성 칩'이 구현되는 모습을 처음 공개; 수달러 수준으로 저렴해진 가격과 손톱보다 작은 초소형 칩형태라는 점에서 세계가 주목하고 있다. 반도체 칩 형태의 양자난수생성기는 제품 개발 단계부터 탑재해 사용 가능하다. 반면 USB형태는 이미 상용화된 제품에도 연결만 하면 양자난수를 생성해줄 수 있어 활용가치가 높아지는 이점이 있다. 


# Object

# Binary
* bin, ser(serialization) 파일
* 2진법 (1100 0011)으로 되어있는 파일

# Serialiazation
* 목적: 저장(Object -> binary(하드디스크))
* 자바: FileOutputStream -> ObjectOutputStream

# Deserialiazation
* binary(하드디스크) -> Object; 하드디스크의 정보를 가져옴


# 텍스트 파일
-  텍스트 파일이란, 글자들이 씌어 있는 파일입니다. 사람이 눈으로 직접 내용을 읽을 수 있습니다. 텍스트 파일은 아스키 파일이라고도 합니다. 대부분의 텍스트 파일이 아스키 코드 (ASCII Code)로 글자들을 나타내기 때문입니다. Plain Text File 이라고도 합니다. "암호화되지 않은 평범한 텍스트"라는 뜻입니다.
- (우리 키보드에 있는 문자중 한글을 제외한 모든 문자들은 전부 아스키코드로 표현된다. 한글의 표현 방법은 다음에 살표보자)  그럼 텍스트 파일로 저장 한다 하면 아스키코드로 저장된다고 생각하면 된다. 
- 텍스트 파일의 대표적인 확장자는 ".txt" 입니다. 또한 .c .cpp .pl .bat .java .html .xml .css 등의 각종 프로그래밍 소스들과 웹문서도 텍스트 파일입니다.
- 텍스트 모드에서는 "\n"은 "\r\n"으로 변경되어 저장됨; 분명 "\n"로 저장했는데 "\r\n"으로 바뀌었다. 실제로 파일의 바이트 수를 살펴봐도 자신이 저장한 문자열에 "\r"이 추가되어 1byte가 추가됨을 알 수 있다. 그렇다면 결국 개행 하나에 1byte가 추가되는 셈이다.
- \r은 0x0D 로 저장되고 (1byte) 아스키 코드 13, \n은 0x0A 로 저장된다.(1byte) 아스키 코드 10, 그리고 \r\n은 0x0D0x0A 형태가 될 것이다.


- 리눅스에서 만든 문서는 리눅스에서 위와 같이 깨진다. 줄이 바뀌는 부분에 검은색 네모 안에 동그라미 표시 문자가 나타난다. 이 것은 "\n"을 의미하는 문자다. 윈도우는 "\n"을 위와 같은 문자로 표현해 준다. 이를 해결하기 위해서 "\n"을 "\r\n"으로 바꿔주면 된다. 어떻게 바꿔줄 수 있을까? 사실 파이썬으로는 너무 간단하다. 바이너리 모드로 열어서 "\n"을 "\r\n"로 바꿔주기만 하면 된다.



## 텍스트 파일의 장점
 * 단순히 텍스트 편집기만으로 리소스 파일을 생성, 수정 할 수 있다.
 * 쉽게 파일의 내용을 살펴볼 수 있어서 디버깅이 쉽다.

# 바이너리 파일
- * 이진 파일은, 바이너리 파일 Binary File 이라고도 합니다. "0"과 "1"이라는, 2진수 데이터만으로 이루어진 파일입니다. (사실 텍스트 파일 역시 "0"과 "1"이라는, 2진수로 이루어져 있는 것은 마찬가지입니다.) 사람이 직접 읽을 수는 없습니다.
- .exe .dll 등의 프로그램 파일과, .zip .rar 등의 압축파일, .mp3 .mpg .jpg .gif 등의 멀티미디어 파일은 이진파일입니다.
- 도스의 type 명령은 파일의 내용을 화면에 출력하는 명령입니다. type 명령으로, "test.txt"라는 텍스트 파일과, "notepad.exe"라는 이진파일의 내용을 출력한 결과가 아래의 그림입니다.
 
## 바이너리 파일의 장점
 * 데이터를 처리하고 전송하는데 일반적으로 비용이 적게 든다.
 * 보통 텍스트에 비해서 파싱이 쉬워서 데이터 처리 속도가 빠르다.
 * 필요한 데이터 공간도 더 작은 경우가 많다.

## 텍스트 파일과 바이너리 파일의 차이
- 예상대로 바이너리 파일이 더 빠르게 처리 할 수 있을것 같다. 이유는 텍스트 파일의 경우 숫자 하나가 8bit 의 아스키 코드로 이루어져 있어서 정수형 데이터 하나가 몇 bit 로 이루어 졌는지 탐색하는 비용이 클것 같다. 하지만 바이너리 파일의 경우 정수형 데이터 하나는 4bit 으로 고정되어 있어서 offset 값을 옮겨가면서 합을 구하면 더 빠르게 처리가 될것 같다.

## 텍스트, 바이너리 파일 차이
 * 파일을 다루다 보면 텍스트 파일과 바이너리 파일이 있다는 알게 됩니다. 과연 두 파일은 어떤 차이가 있을까요?
 * 텍스트 파일도 바이너리 파일의 일종입니다. 바이너리 파일 중 문장을 읽기 편한 문자 코드만 사용해서 만들어진 파일이
 * 텍스트 파일입니다. 그래서 텍스트 파일을 ASCII 파일이라고도 하는데 한글도 사용할 수 있다는 것을 상기한다면
 * ASCII 파일이라고 말하는 것은 옳지 못 합니다.
 *  
 * 영문이든 한글이든 일본어이든 여러 줄의 문장으로 되어 있다면, 그래서 한 줄씩 읽을 수 있다면 텍스트 파일이라고
 * 생각하시면 되겠습니다. 그렇다면 어떻게 텍스트 파일을 만들어야 할까요?
 *  
 * 문장과 문장 사이는 개행 특수 코드(0x0d)가 있어야겠지요? 행 바꿈 없이 하나의 문장이라서 사용하지 않는 경우도 있습니다.
 * 무엇보다도 문장은 개행 코드 전까지 모두 읽어 들일 수 있도록 NULL 코드가 없어야합니다.
 *  
 * 이에 비해 바이너리 파일은 NULL 코드든, 개행 코드(0x0d), 0x01, 0x02, 등등 모든 코드를 자유롭게 저장할 수 있습니다.
 * 영화나 압축 파일을 생각해 보면 이해가 쉽죠. 영화 내용에 따라, 압축된 데이터 코드 중에는 0x00, 0x0d, 0x11, ...
 * 숫자로 표현할 수 있는 모든 코드를 사용해야 합니다.
 *  
 * C언어에서도 문자열에 0x01, 0x02, 0x07 처럼 다양한 코드를 사용할 수 있습니다.
 * 물론 화면에 출력하거나 파일로 저장하면 이상한 문자로 보이지만, 사용할 수 있죠.
 * 그러나 문장 사이에 NULL을 사용할 수 없습니다. 
 *  
 * 화면에 출력하고 싶어도, 파일로 저장하고 싶어도 바이너리 용 함수가 아닌 텍스트 전용 함수로는
 * NULL 문자를 출력하거나 저장할 수 없습니다.
 *  
 * 즉, NULL 문자를 자유롭게 사용할 수 있느냐 없느냐로 따지는 것이 텍스트 파일과 바이너리 파일을 
 * 구분하기 제일 간편한 방법입니다.
 *  
 * 예로 "falinux.com 입니다." 사이에 NULL 문자가 숨어 있다면 텍스트 관련 함수는 NULL 까지만 처리합니다.
 * 왜냐하면 C 언어에서는 NULL Terminated String을 사용하기 때문이죠. 즉, NULL 코드를 문자의 끝으로 인식합니다.
 * 파스칼 처럼 문자열 변수가 [문자열 길이][문장]처럼 길이 값을 갖지 않습니다. C 언어는 [문장][NULL]을 사용하죠.


# 인코딩
## 인코딩이 다른 기준
1. 운영체제
2. 소스코드
3. 통홥개발환경
4. 웹 소스
		1-4까지는 인코딩이 다르면 깨져 나온다.
5. http 요청; 클라이언트와 서버가 틀림
6. http 응답; 클라이언트와 서버가 틀림
7. 데이터베이스
8. 파일 -> 우연
		5-8까지는 인코딩이 다르면 null로 나온다.

# 유니코드
```java
유니코드는 모든 문자에 Index를 지정하는 것이다. 그 이상도 아니고, 그 이하도 아니다.
이 Index를 Code Point 혹은 Code Unit이라고 부르는데 일반적으로 Index라고 생각해도 무방하다.
더 많은 글자와 Index를 보려면 Code Charts를 참고하자.

문자열을 숫자로 표현하기 위하여 문자 하나와 숫자 하나를 각각 매핑(=연결)한 것이 바로 유니코드이다.

예를 들어 A는 U+0041에 매핑되어 있고 ‘가’는 U+AC00에 매핑되어 있다.

유니코드를 인코딩하는 방법에는 UTF-8, UTF-16 등등 여러 방법이 존재한다.
```

# UTF
* UTF는 몇 bit 단위로 사용해서 Index를 표현할 것인가를 뜻한다.
* UTF-8은 8bit씩 Index를 표현
* UTF-16은 16bit씩 Index를 표현
* UTF-32는 32bit씩 Index를 표현한다는 뜻을 갖고 있다.


# UTF-8
```java
UTF-8은 Universal Coded Character Set + Transformation Format – 8-bit의 약자이다.
UTF-8은 유니코드를 위한 가변 길이 문자 인코딩 방식 중 하나이다.
UTF-8의 코드 단위는 8bit입니다.
UTF-8 인코딩은 유니코드 한 문자를 나타내기 위해 1byte ~ 4byte까지를 사용한다.
UTF-8은 인터넷에 교환되는 대부분의 파일에 사용된다.
영문 byte 수 : 1byte 한글 byte 수 : 3byte
```

# UTF-16
- < 윈도우즈 메모장notepad에서 텍스트 파일 저장 시, 유니코드, 유니코드(big endian)이 바로 UTF-16에 해당한다. >

```java
UTF-16은 유니코드 문자 인코딩 방식의 하나이다.
주로 사용되는 기본 다국어 평면(BMP, Basic multilingual plane)에 속하는 문자들은
그대로 16bit값으로 인코딩이 되고 그 이상의 문자는 특별히 정해진 방식으로 32bit로 인코딩이 된다.
UTF-16의 코드 단위는 16bit이다.
UTF-16 인코딩은 유니코드 한 문자를 나타내기 위해 2byte ~ 4byte까지를 사용한다.
UTF-16은 윈도우 응용프로그램, 자바스크립트 등의 작동시 사용된다.
영문 byte 수 : 2byte 한글 byte 수 : 2byte
```

## UTF-8 vs UTF-16
* UTF-8과 UTF-16의 기본 차이는 문자 하나를 표현할 때 사용할 최소 byte 크기이다.
* UTF-8로 문자를 표현할 때 1 ~ 4byte가 필요하다. 하지만 UTF-16은 2 ~ 4byte가 필요하다.
	* 1byte: 영어
* 두 Encoding 방식의 큰 차이는 최소 8bit가 필요하냐 16bit가 필요하냐에 따라 다른 것이다.
* 최적의 상황(저장, 통신 용량을 아껴야할 때)이 필요하다면 어떤 CodePoint를 주로 사용하냐에 따라 UTF-8 또는 UTF-16을 선택하는 기준이 달라질 것이다.

# EUC-KR
- ECU-KR는 2350개의 한글만 처리할 수 있는 한글이며 '뷁' 등의 글자를 제대로 처리할 수가 없게됩니다. 결론적으로는 EUC-KR로 저장한다고 하더라도 글자가 깨져서 나타날 수 있기에 UTF-8로 저장하시길 권장드립니다.

# UTF-8 웹페이지용 유니코드
 * 이것은 인터넷이나, 리눅스/유닉스 등에서 사용하는 8비트 유니코드입니다. 웹페이지 관련 작업에서 "유니코드"라고 할 때에는 이 UTF-8 유니코드를 가리킵니다. 영문이나 숫자 등은 1바이트로 표현하고, 한글이나 한자 등은 3바이트로 표현합니다. 웹페이지를 유니코드 인코딩으로 만들 때에는 반드시 "UTF-8 유니코드"를 사용해야 합니다. 8비트 유니코드라고 해서, 16비트 유니코드보다 문자 표현 범위가 작다든지 그런 것은 전혀 없고 동일합니다.



# UTF-16 LE (MS OS, Office용 유니코드)
- 컴퓨터에서 그냥 "유니코드"라고 부를 때에는 이 UTF-16 LE 를 가리키는 경우가 많습니다. MS윈도우2000이나 윈도우XP에서 내부적으로 사용되는 유니코드입니다. 그렇다고 해서 마이크로소프트(MS)가 개발했다는 뜻은 아니고, 표준 유니코드 중의 하나입니다. 문자 1개를 16비트로 표현하는데, 앞의 8비트와 뒤의 8비트의 순서가 거꾸로 되어 있습니다. 인텔CPU가 Little-Endian 이기에, 유니코드도 앞뒤 바이트 순서를 바꾸면 이론적으로 더 처리 속도가 빨라집니다.

# UTF-16 BE (Mac, JAVA용 유니코드)
- BE는 Big-Endian 의 약자입니다. 이것은 맥(Mac)이나 자바(Java)에서 사용되는 16비트 유니코드인데, 앞뒤 바이트 순서가 거꾸로 바뀌지 않고 그대로 있는 것입니다. UTF-16 BE 는 윈도우에서는 거의 사용되지 않습니다.

# BOM이란
- BOM이란 문서 맨 앞에 눈에 보이지 않는 특정 바이트(byte)를 넣은 다음 이것을 해석해서 정확히 어떤 인코딩 방식이 사용되었는지 알아내는 방법을 나타냅니다. 자세하게 유니코드가 little-endian 인지 big-endian 인지 아니면 UTF-8 인지 쉽게 알 수 있도록, 유니코드 파일이 시작되는 첫부분에 보이지 않게, 2~3바이트의 문자열을 추가하는데 이것을 BOM이라고 합니다. BOM은 텍스트 에디터 화면에서는 보이지 않고, 헥사 에디터(Hex Editor)*로 열었을 때만 보입니다.
- UTF-16 이상 인코딩일 때, 문서의 맨 처음 BOM을 파악하여 Big Endian인지 Little Endian인지 구분하지만 UTF-8의 경우는 BOM이 하나로 고정입니다. 그래서 이 BOM은 바이트 순서와(Byte Order) 상관없기 때문에 UTF-8 Signature라고 불리기도 합니다. 즉, 해당 문서가 UTF-8로 인코딩되었다는 사실을 알리는 사인(signature)입니다.
 
# BOM 문제점
- UTF-8에는 BOM이 없는 것이 보통인데(UTF-8은 BOM이 고정이라 인코딩 방식을 자동으로 알 수 있음), 일부 윈도우즈 프로그램(메모장 같은)은 UTF-8 파일을 생성할 때 자동으로 BOM을 집어넣습니다. 윈도우즈 환경에서는 눈에 띄지 않는 경우가 많지만 리눅스(LINUX)나 유닉스(UNIX) 환경에서는 많은 문제를 일으키는 원인이 됩니다. BOM이 추가된 데이터의 경우, 글자 앞에 빈칸이 생기면 그 차이점을 알 수 있지만 대개 눈으론 보이지 않습니다.
- 데이터베이스에서 BOM이 추가된 데이터와 그렇지 않은 데이터를 비교할 경우 눈으로는 동일한 데이터지만 비교를 할 땐 같지 않다는 데이터로 나옵니다. 그 이유는 문자열 앞에 BOM이 붙어있기 때문입니다. (이 문제때문에 하루를 고생한적이..)
- 울트라에디트라는 프로그램을 울트라에디트의 헥사 모드(Ctrl+H)로 UTF-8 파일을 보면, 16비트 유니코드처럼 보이고 BOM이 있든 없든 항상 FF FE 라는 엉뚱한 BOM이 나타납니다. 이것은 울트라에디터가 유니코드를 편집할 때, 내부적으로 '16비트 little-endian 유니코드 (UTF-16LE)'로 변환하여 편집하기 때문입니다. 진짜 헥사 에디터로 보아야만 UTF-8의 BOM인 EF BB BF 가 제대로 보이게 됩니다. 물론 BOM이 없는 UTF-8이라면 BOM이 없는 것으로 나옵니다
- 가장 좋은 방법으로는 메모장 같은 프로그램보단 BOM설정이 가능한 프로그램을 사용하는 것입니다. 하지만 모든 파일을 BOM설정이 가능한 프로그램을 사용할 수 없기 때문에 BOM파일을 받은 다음, 코드로 해당 파일을 UTF-8로 인코딩 처리하는 부분도 생각해야 합니다.



## iso-8859-1 
- ASCII 확장 이며 단일 바이트 고정 길이 인코딩이다


## 아스키 코드
- %: 아스키 코드가 표현하지 못하는 문자
- +는 공백
- 숫자는 아스키코드


#  ANSI 코드
- 그러나, 아스키코드를 이용해 다른 언어를 표현하기에는 7비트로는 부족했다.  그래서 8비트로 확장한 아스키 코드가 나왔다.  사람들은 이 코드를 ANSI 코드라고 부르기 시작했다.
-  7비트에서 8비트로 확장되었으니 사람들이 활용할 수 있는 문자는 몇 개가 더 늘어났을까?  1비트 늘어났으니 2개 더 늘어났다고 생각하면 안된다.  이렇게 되었으니 128개나 더 쓸 수 있게 되었다! 이때, 1바이트만으로 표현되는 경우를 SBCS(Single Byte Character Set)이라고도 한다. 반대의 경우는 MBCS(Multi-Byte Character Set)이라고 한다. 그러나! 비유럽 국가 특히 한국, 중국, 일본과 같은 문자가 많은 국가에서는 여전히 제한적이다.
(※ 우리나라의 경우 KSC5601 표준이라는 고유한 인코딩 방법으로 문자를 표현했다) 그래서 유니코드(Unicode)라는 전 세계 언어의 문자를 정의하기 위한 국제 표준 코드가 등장하게 되었다.
 
 ```java
 ANSI의 앞 7bit는 ASCII와 동일하고 뒤에 1bit를 이용하여 다른 언어의 문자를 표현한다.

그런데 새로 추가 된 128개 문자로는 모든 언어의 문자를 표현할 수 없다.

그래서 생긴 개념이 Code Page이다.

각 언어별로 Code 값을 주고 Code마다 다른 문자열 표를 의미하도록 약속을 했다.

쉽게 생각하면 아래와 같이 설명할 수 있다.

ANSI = ASCII(7bit) + CodePage(1bit)

이러한 원리를 고려하면 다음과 같이 정리할 수 있다.

영어만 사용하거나 ASCII를 사용할 경우 세계 어디에서나 사용에 문제가 없다.

영어 외 다른 언어를 사용할 경우 ANSI는 Code Page를 동일하게 맞춰야 한다.

Code Page가 다를 경우 의도와 다른 결과가 나올 수 있다.
 ```
