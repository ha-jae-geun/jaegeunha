* [Linux](./Linux/README.md)
* [Android](./Android/README.md)

# 윈도우 7
1. 윈도우7 언제까지 사용할 수 있나
* 2020년 1월14일 이후에도 윈도우7 PC를 사용하는데 사실상 문제없다. 단, 운영체제 보안에 구멍이 생겨도 마이크로소프트는 이에 대한 패치 또는 소프트웨어 업데이트를 제공하지 않는다. 지원 종료 후 보안 구멍이 발견되면 해커의 공격에 노출될 수 있다.

2. 윈도우10 지원 종료 기간은
* 윈도우10은 직전 세대의 윈도우 운영체제와 달리 사실상 영구 라이선스다. 마이크로소프트는 최신 버전으로 업데이트에 기간 제한을 두지 않는다. 시작 메뉴에서 ‘설정→윈도우 업데이트→업데이트 확인’ 단계를 거쳐 새로운 업데이트를 받을 수 있는지 알 수 있다. 단, 특정 버전에 대한 지원 기간은 1년 6개월 정도이며 순차적으로 지원을 마감한다. 의도적으로 구형 버전을 사용하는 경우 주의가 요구된다.

# 윈도우 10
## 윈도우 디펜더
* 윈도우10에는 기본적으로 보안 소프트웨어가 탑재되어 있다. 타사 백신 소프트웨어를 설치하고 쓸 수 있지만 굳이 그럴 필요 없다. 윈도우 디펜더는 윈도우10에 내장된 무료 서비스이고 지금까지 돈을 내고 사용했던 안티 바이러스 소프트웨어만큼이나 우수하다


# 운영체제
* 하드웨어 <> 운영체제 <> 응용 프로그램 <> 사용자
	* 하드웨어: 하드웨어 장치, 마이크로 프로그래밍, 기계어
	* 시스템 프로그램: 운영체제, 컴파일러, 편집기, 명령어 해석기
		* 컴퓨터 기종에 따라 다르다.
	* 응용 프로그램: 은행 시스템, 항공 예약, 명령어 해석기, 프리스타일
		* 기종에 관계 없이 작성될 수 있는 것.

# CFS 스케줄러
* 스케줄러는 CPU 자원을 프로세스들에게 분배하는 OS의 중요한 일부분이다.
* 2007년 발표 된 리눅스 커널의 스케줄러인 CFS(Completely Fiar Scheduler) RSDL(Rotating Staircase Deadline) 스케줄러를 기초로 한 RB-트리(Red-Black Tree) 데이터 구조를 사용하는 O(logN) 성능을 가지는 스케줄러이다.
* CFS는 시간단위로 나노초를 사용한다.

* 만약 A, B 두 개의 태스크가 진행되고 있다면 A와 B의 CPU 사용시간은 항상 1:1로 같아야한다.
* 그러나 두 태스크가 번갈아 가며 수행되므로 임의의 시점에 두 태스크의 CPU 사용 시간이 항상 1:1로 같을 수 없다.
* 따라서 CFS는 정해진 ‘시간 단위’로 봤을때 시스템에 존재하는 태스크들에게 공평한 CPU 시간을 할당하는 것을 목표로 한다.
* 만약 1초를 ‘시간 단위’로 한다면 0.5초 동안 A 태스크를 수행시키고, 그런 뒤 0.5초간 B 태스크를 수행시킴으로써 1초가 지난 이후 A와 B의 CPU 사용시간이 1:1이 되도록 하는 것이다.
* CFS의 기본 개념은 작업에 프로세서 시간을 제공할 때 밸런스(공평성)를 유지하는 것이다.
* 즉 프로세스에 공평한 양의 프로세서(=CPU)가 제공되어야 한다.
* 작업 시간의 밸런스가 무너진 경우에는(다른 작업에 비해 하나 이상의 작업에 공평한 양의 시간이 주어지지 않은 경우) 작업 시간이 적게 지정된 작업에 실행 시간이 주어져야 한다.

## 가상 런타임
* CFS에서는 밸런스를 결정하기 위해 가상 런타임이라는 지정된 작업에 제공된 시간의 양을 관리한다.
* 작업의 가상 런타임이 작을수록 즉, 프로세서에 액세스할 수 있도록 허용된 시간이 작은 작업일수록 더 많은 프로세서 시간이 필요하다.

## 대기자 공평성
* 이 개념은 현재 실행할 수 없는 작업(예를 들어, I/O를 대기 중인 작업)이 나중에 프로세서가 필요할 때 대기했던 시간에 상응하는 프로세서 시간을 받을 수 있도록 보장한다.

## RB-트리
* 하지만 CFS는 이전 Linux 스케줄러와는 달리 실행 큐에서 작업을 관리하지 않고 시간순으로 정렬된 RB-트리를 유지한다.
* 첫 번째는 스스로 밸런스를 조절한다는 것이다.
* 즉, 이 트리의 모든 경로는 다른 경로보다 두 배 이상 길어지지 않는다.
* 두 번째는 트리에 대한 작업이 O(log n) 시간(여기서 n는 트리의 노드 수임) 내에 발생한다는 것이다.
* 따라서 작업을 빠르고 효율적으로 삽입하거나 삭제할 수 있다.

# 쓰레드
* 프로세스 안에 존재하여, 프로세스의 자원을 공유하는 개체 흔히 경량 프로세스라고 부름 각 쓰레드는 별도의 레지스터와 스택을 갖고, 힙 영역은 공유.
## 스택을 쓰레드마다 독립적으로 할당하는 이유
* 쓰레드는 독립적인 작업을 수행해야 하기 때문에 각자의 스택과 PC 레지스터 값을 갖고 있다.
* 스택은 함수 호출 시 전달되는 인자, 되돌아갈 주소값 및 함수 내에서 선언하는 변수 등을
* 저장하기 위해 사용되는 메모리 공간이므로
* 스택 메모리 공간이 독립적이라는 것은
* 독립적인 함수 호출이 가능하다는 것이고
* 이는 독립적인 실행 흐름이 가능하게 한다.

## PC Resister를 쓰레드마다 독립적으로 할당하는 이유
* PC 값은 쓰레드가 명령어의 어디까지 수행하였는지를 나타나게 된다.
* 쓰레드는 CPU를 할당받았다가 스케줄러에 의해 다시 선점당한다.
* 그렇기 때문에 명령어가 연속적으로 수행되지 못하고 어느 부분까지 수행했는지 기억할 필요가 있다.

## 쓰레드는 프로세스보다 생성 및 종료시간, 쓰레드간 전환시간이 짧다.
* 쓰레드는 프로세스의 메모리, 자원등을 공유하므로 커널의 도움없이 상호간에 통신이 가능하다.

## 멀티 스레드, 멀티 프로세스 장단점
```java
Multi process
독립적으로 어떤 일을 수행하므로, 문제가 발생해도 다른 프로세스에 영향을 주지 않는다.
하지만, 프로세스 처리는 쓰레드와 비교했을 때 무겁다.
Context Switching 에서의 오버헤드
CS 가 일어날 때마다 PCB 를 통째로 캐시에 저장, 로드 해야함.
IPC 에서의 오버헤드
자원 공유가 번거롭고, 느림.
좀 더 가볍게 여러 테스크를 진행할 수 없을까?


Multi Threading
하나의 목적을 가지고 하는 일을 여러 개로 나눠서 병행처리해야할 경우 쓰레드를 쓰자.
Multi prcoess 와 비교했을 때, 다음과 같은 장점이 있다.
프로세스보다 메모리 사용가 적다. (Stack 만 할당하므로)
쓰레드간 데이터 통신이 빠르다. (Heap 을 공유, 접근 가능하므로)
수행 속도가 일반적으로 빠르다. (CS 시, Stack 영역만 처리하므로)
다음과 같은 단점이 있다.
쓰레드간 자원 공유에 대한 문제 (동기화, synchronization)
설계와 제어가 까다롭다.


출처: https://dailyheumsi.tistory.com/130?category=855210 [하나씩 점을 찍어 나가며]
```

## 1.3. User-level Thread vs Kernel-level Thread
* [블로그](https://dailyheumsi.tistory.com/130?category=855210)
```java
커널 레벨 쓰레드와 유저 레벨 쓰레드는 생성 주체가 누구냐에 따라 구분된다. (매우 헷갈림 주의)

* User-level Thread
프로그래머가 커널에 의존적이지 않게, 라이브러리를 통해 생성하는 쓰레드가 유저 레벨 쓰레드이다.
이렇게 생성된 쓰레드는, 커널에게는 보이지 않는다.
즉 커널은 프로세스 그 자체만 알지 , 내부의 유저 쓰레드는 모른다.
커널 스케쥴링의 기본 단위가 즉 프로세스 단위다.
커널이 전혀 관여하지 안고, 프로세스에서 관리한다.
즉, 프로세스가 자체적인 쓰레드 스케줄링을 가진다.
모드 변경이 필요없어 생성과 관리가 빠르다.
즉, 쓰레드간 CS 시, 커널 스케쥴러를 호출하지 않으므로, 오버헤드가 적다.
하지만, 프로세스 내 하나의 쓰레드가 커널에 의해 블록되면 해당 프로세스가 통째로 블록된다.
이를 해결하는 프로그래밍과 결과 예측이 매우 어렵다.

* Kernel-level Thread
프로그래머 요청에 따라 쓰레드를 생성하고 스케줄링하는 주체가 커널이면 커널 레벨 쓰레드라고 한다.
커널 스케쥴링의 기본 단위가 즉 프로세스 단위가 아닌, 쓰레드 단위다.
하나의 프로세스는 적어도 하나의 커널 쓰레드에게 관리된다.
단일 프로세스 = 1개의 쓰레드
하지만 유저 <-> 커널 모드 전환에서 오버헤드가 크다.
같은 프로세스 내 쓰레드 전환(유저 레벨)의 경우 CS 비용이 적지만,
다른 프로세스 간의 쓰레드 전환(커널 레벨)의 경우 이 비용이 크기 때문이다.
현대 대부분의 OS 는 이 방식을 채택

- 커널 레벨 쓰레드 장점 : 
안전성, 기능의 다양성 
단점 : 커널에서 기능을 제공하기 때문에 성능 저하 

- 유저레벨 쓰레드 장점 
전환 필요없기때문에 성능 좋음 
단점 : 프로세스 내에 쓰레드가 하나만 블로킹 되어도 나머지 쓰레드가 작동하기 어려움 


```

## . 다중 쓰레드 모델
```java
보통 운영체제는 유저레벨 쓰레드와 커널레벨 쓰레드 모두 제공한다.

다대일 (N-to-one) 모델
효율적이긴 하지만 한 스레드가 블락당할 경우 전체 프로세스가 봉쇄된다.
진정한 병렬성의 개념이 없다.


일대일 (One-to-one) 모델
다대일 보다 더 많은 병렬성을 제공한다.
많은 쓰레드가 생성됐을 시, CS 비용이 크다.


다대다 (N-to-M) 모델
위 두 모델의 문제점을 어느 정도 해결한 모델

```

## 쓰레드 동기화 방법의 종류
* Mutex / Semaphore / Monitor
* 공통점은 세가지 모두 운영체제의 동기화 기법이라는 것이다.

### 뮤텍스(Mutual Exclusion)
* 쓰레드의 동시 접근을 허용하지 않는다는 의미.
* 뮤텍스의 쓰레드 동기화 방법은 임계영역에 들어가기 위해 이 뮤텍스를 가지고 있어야 들어갈 수 있다.
* 예) 일종의 자물쇠와 같은 역할을 한다.
* 임계영역에 들어간 쓰레드가 뮤텍스를 이용해 임계영역에서 본인이 나올때까지 다른 쓰레드가 못들어오게 내부에서 자물쇠로 잠근다.

### 세마포어(Semaphore)
* 세마포어 역시 뮤텍스와 비슷한 역할을 하지만 세마포어는 동시 접근 동기화가 아닌 접근 순서 동기화에 더 관련있다.

### 모니터(Monitor)
* Mutex(Lock)와 Condition Variables(Queue라고도 함)을 가지고 있는 Synchronization 메카니즘이다.


### 전자(뮤텍스,모니터)는 상호 배제를 함으로써 임계구역에 하나의 쓰레드만 들어갈 수 있다.
* 후자(세마포어)는 하나의 쓰레드(binary semaphore)만 들어가거나
* 혹은 여러 개의 쓰레드(counting semaphore)가 들어가게 할 수도 있다.


### . 뮤텍스와 모니터의 차이는?
* 가장 큰 차이는 뮤텍스는 다른 프로세스(애플리케이션)간에 동기화를 위해 사용한다.
* 반면 모니터는 하나의 프로세스(애플리케이션)내에 다른 쓰레드 간에 동기화할 때 사용한다.
* 또한, 뮤텍스는 보통 운영체제 커널 의해서 제공되는 반면에 모니터는 프레임워크나 라이브러리 그 자체에서 제공된다.
* 따라서 뮤텍스는 무겁고(heavy-weight) 느리며(slower) 모니터는 가볍고(light-weight) 빠르다(faster).


### 세마포어와 모니터의 차이는?
* Java에서는 모니터를 모든 객체에게 기본적으로 제공하고 있는 반면 C에서는 모니터를 사용할 수 없다.
* 세마포어는 카운터라는 변수값으로 프로그래머가 상호 배제나 정렬의 목적으로 사용 시 매번 값을 따로 지정해줘야하는 등 조금 번거롭다.
* 반면, 모니터는 이러한 일들이 캡슐화 되어 있어서(encapsulation) 개발자는 카운터값을 1 또는 0으로 주어야 하는 고민을 할 필요 없이 synchronized, wait(), notify() 등의 키워드를 이용해 좀 더 편하게 동기화할 수 있다.


### 뮤텍스와 세마포의 차이는?
* 세마포어는 뮤텍스가 될 수 있지만 뮤텍스는 세마포어가 될 수 없다.
* 예를 들어 Casting을 한다고 보면
	* (뮤텍스)세마포어 –> 가능
	* (세마포어)뮤텍스 –> 불가능
* 세마포어는 소유할 수 없는 반면 뮤텍스는 소유할 수 있고 소유자가 이에 책임을 진다
* 뮤텍스는 1개만 동기화가 되지만 세마포어는 하나 이상을 동기화 할 수 있다.


```java
변기가 하나뿐인 화장실에서는 
앞의 사람이 볼일을 마치고 나가야 다음 사람이 들어갈 수 있다. 
이렇게 한번에 오직 하나만 처리할 수 있는 대상에 사용하는 것이 뮤텍스이다. 

변기가 세개인 화장실에서는 동시에 세 사람이 볼일을 볼 수 있고 
이 세 사람 중 아무나 한명이 나오면 다음 사람이 볼일을 볼 수 있다. 
이렇게 동시에 제한된 수의 여러 처리가 가능하면 세마포어이다. 

만약 변기 세개짜리 화장실의 각 변기에 대해 뮤텍스를 사용한다면 
대기중인 사람은 각 변기 앞에 줄을 서는 것이고 
이렇게 되면 옆 칸이 비어도 들어가지 못하게 된다. 

만약 변기 세개를 묶어서 뮤텍스를 사용한다면 
변기 수에 관계없이 무조건 한명만 사용할 수 있게 된다. 

이 예에서 변기는 동기화 대상, 사람은 그 동기화 대상에 접근하는 쓰레드를 나타낸다. 

뮤텍스와 세마포어의 목적은 특정 동기화 대상이 이미 특정 쓰레드에 의해 사용중일 경우 
다른 쓰레드가 해당 동기화 대상에 접근하는 것을 제한하는 것으로 동일하지만 
관리하는 동기화 대상이 몇개 인가에 따라 차이가 생기게 되는 것이다.
```

# 임계영역
* [블로그](https://dailyheumsi.tistory.com/132?category=855210)
* 공유되는 자원, 즉 동시접근하려고 하는 그 포커싱된 자원!에서 문제가 발생하지 않게 독점을 보장해줘야 하는 영역을 임계영역이라고 해요
```java
동기화를 위해, 하나의 프로세스 혹은 쓰레드가 공유 자원에 대한 작업이 완료될 때까지, 
다른 프로세스, 쓰레드의 방해없이 완전하게 완료가 되어야 하는데, 이렇게 진행되는 원칙을 상호배재(Mutual Exclusion) 라고 하고, 
이렇게 수행되는 연산들을 Atomic Operation 이라 한다. 또, 
이렇게 공유자원에 대해 동기화해야하는 코드 부분을 임계 영역(Critical Section) 이라고 한다.

1.3. Critical Section 의 속성
임계 영역의 문제를 해결하기 위해서는 다음을 만족해야 한다.

상호배재 (Mutual Exclusion)
어떤 프로세스가 임계 영역을 실행하고 있을 때, 다른 프로세스는 임계 영역을 실행할 수 없다.
즉, 어떤 프로세스가 임계 영역을 실행할 때, 다른 프로세스는 코드 실행을 못하게 처리해줘야 한다.


진행 (Progress)
임계 영역에 실행되고 있는 프로세스가 없을 경우, 임계 영역을 실행하고자 기다리는 프로세스는 즉각적으로 임계 영역을 실행할 수 있어야 한다. 즉, 기다리고 있는 프로세스들에 대한 처리를 해줘야 한다.


한정 대기 (Bounded Waiting)
임계 영역을 실행하고자 하는 프로세스가 무한정으로 대기하면 안된다. 즉, 제한된 대기시간을 가져야 한다.

```

```java
화장실에 일을 보러 가야 하는데 변기는 혼자서만 사용해야 한다.
그러면 누군가가 사용하고 있다면 다른 사람은 사용할 수 가 없다.
이 때 문을 잠금다면(=Locking) 다른 사람이 들어가고 싶어도 못들어가게(=Waiting) 된다.
안에 있던 사람이 일을 보고 나오면 문을 열고(=Unlocking) 나와야 다른 사람이 들어갈 수 있게 된다.
```

```java
기본적으로 현재 일반 유저가 사용하는 대부분의 OS는 선점형 시분할 운영체제이다.
간단하게 말해서 크롬을 띄우고 메모장을 같이 띄워도 두개다 동작하는 것은 각각 일정 시간동안만 CPU를 선점하여 사용하기 때문이다.

이 때 할당되는 시간 단위를 타임 슬라이스(Time Slice)라고 한다.

일단 여기서 각각의 프로그램은 프로세스라는 단위로 움직인다.
그리고 프로세스 안에서 동작하는 실행 단위인 쓰레드가 존재한다.

크롬으로 스포츠 영상을 보면 크롬이 프로세스가 되고
크롬안에서 영상을 처리해주는 부분과 네트워크로 영상을 받아오는 부분이 각각 쓰레드가 된다.

그런데 프로세스 or 쓰레드가 Wait라는 상태가 걸리는 때가 있다.

이걸 이해하기 위해선 H/W를 살펴볼 필요가 있다.

H/W는 CPU보다 느리다.

그렇기 때문에 디스크에서 데이터를 읽는 작업처럼 느린 동작을 처리하기 위해서 작업이 잠깐 중단될 필요가 생긴다.

그러면 CPU는 디스크에서 데이터를 읽어 달라는 명령을 요청하고 다른 작업을 계속한다. (=Task Switch)
```

## Sleep 가능한 락
```java
락 중에는 이런식으로 자원에 접근 하는 락이 있다.

앞에서 살펴본 워터파크에는 k명만 입장이 가능하다.

k명에 들어간다면 그냥 입장 가능하겠지만 k명에 해당되지 않는다면 대기자는 그냥 졸면서 기다린다.

그리고 자원을 다 사용한 사람들이 나가면 졸고 있는 사람들을 깨워서 들여보낸다.

이게 바로 세마포어(Semaphore) 개념이다.

세마포어는 보통 자원에 관계된 락이다.

그래서 락을 걸때 특정 수만큼의 카운트를 갖고 빼주는 형식으로 처리된다.

이런 락을 슬립(Sleep)가능한 락이라고 한다.

또한 뮤텍스(Mutex)라는 락이 있는데 이는 Mutualy Exclusive라는 락이다.

결국 이것도 세마포어긴 한데, 특별히 카운트가 1인 락으로 봐도 무방하다.

이와 반대로 스핀락은 자지 않고 게속해서 버틴다고 볼 수 있다
```

## 스핀락은
```java
만약 다른 쓰레드가 lock을 소유하고 있다면 그 lock이 반환될 때까지 계속 확인하며 기다리는 것이다.

조금만 기다리면 바로 쓸 수 있는데 굳이 문맥 교환으로 부하를 줄 필요가 있나? 라는 컨셉으로 개발됐다.

일반적으로 프로세스를 컨트롤 하는 입장에서
Sleep을 시키고 태스크를 스위칭 하는 일련의 작업은 그다지 작은 연산이 아니다.

Sleep된 프로세스를 깨우기 위해선 일단 데이터를 메모리에다가 쓰고 스위칭 작업을 하고 모든 작업이 다 끝났을때 가능하다.

그렇기 때문에 아주 작은 작업에 대해서는 세마포어 or 뮤텍스를 사용하지 않고 스핀락을 사용하는 게 효율적일 수 있다.
```

## 스핀락 주의할 점
```java
예를들어 어떤 숫자를 단순히 +1 해주는데 사용될 락이 있다 생각해보자.
이 경우는 거창하게 문맥 교환을 하면서 구현할 필요가 없다.
잠깐 밖에서 값을 검사해보고 내가 사용가능하면 바로 처리 하도록 하는게 효율적이다.
이 개념이 "스핀락" 개념이다.

그냥 단순히 적절한 시간동안 외부에서 for나 while로 루프를 돌면서 락을 검사하고 처리하게 되는 것이다.
이때 임계 영역은 굉장히 작거나 아주 빨리 처리가 가능할 경우 이런 락을 쓰게 된다. 

대신에 이런 락을 쓰고 있을 때 Sleep을 하게 되면 다른 쪽(쓰레드든, 프로세스든)에서는 
CPU는 사용하고 있는데(=루프가 돌고 있기 때문에) 락을 얻지 못하는 사실상의 데드락 상태에 빠지게 된다.

그래서 스핀락은 이런 특성 때문에 "바쁜 대기 상태(Busy Waiting)"라고도 불린다.
```

```java
임계 구역(Critical Section)에 진입이 불가능할 때 문맥 교환을 하지 않고 루프를 돌면서 재시도를 한다.

스핀락은 운영 체제의 스케줄링 지원을 받지 않기 때문에 해당 쓰레드에 대한 문맥 교환이 일어나지 않는다.

따라서 스핀락은 임계 구역에 짧은 시간 안에 진입할 수 있는 경우에 문맥 교환을 제거할 수 있어 효율적이다.

하지만 스핀락이 오랜 시간을 소요한다면 다른 쓰레드를 실행하지 못하고 대기하게 되며
이 경우 비효율적인 결과를 가져온다.

만약 오래 걸리는 작업에 대해 스핀락을 사용한다면
많은 쓰레드들이 락을 잡으려는 시도를 계속 하게되며
이렇게 되면 CPU 점유율이 엄청나게 올라가게 될 것 이다.
하지만 실질적인 작업은 수행하지 않는다.
```

## spin lock 특징ㅇ
1. Lock을 얻을 수 없다면, 계속해서 Lock을 확인하며 얻을 때까지 기다린다. 이른바 바쁘게 기다리는 Busy Wating이다.
2. 바쁘게 기다린다는 것은 무한 루프를 돌면서 최대한 다른 쓰레드에게 CPU를 양보하지 않는 것이다.
3. Lock이 곧 사용가능해질 경우 컨택스트 스위치를 줄여 CPU의 부담을 덜어준다. 하지만, 만약 어떤 쓰레드가 Lock을 오랫동안 유지한다면 오히려 CPU 시간을 많이 소모할 가능성이 있다.
4. 단일 CPU or 단일 코어인 경우에는 유용하지 않다. 그 이유는 만약 다른 쓰레드가 Lock을 가지고 있고 그 쓰레드가 Lock을 풀어 주려면 싱글 CPU 시스템에서는 어차피 컨택스트 스위치가 일어나야 하기 때문이다.
5. 주의할 점은 스핀락을 잘못 사용하면 CPU 사용률 100%를 만드는 상황이 발생된다.
6. 스핀락은 기본적으로 무한 루프를 돌며 lock을 기다리므로 하나의 쓰레드가 lock을 오랫동안 가지고 있다면, 다른 Blocking된 쓰레드는 Busy Waiting을 하므로 CPU를 쓸데없이 낭비하게 된다.
* 스핀락을 잘 사용하면 문맥 교환을 줄여 효율을 높일 수 있다. 

### 뮤텍스 락 vs 스핀락
* 락을 얻을 수 없을때 쓰레드 슬립 모드로 빠지지 않고 반복문을 계속 돌며 락을 얻으려는 시도를 한다.
* 락이 해제될 때 별도의 쓰레드 문맥교환(Context Switching)에 대한 오버헤드 없이 임계 구역에 접근을 한다.
* 뮤텍스 락의 경우 락이 해제되더라도 운영체제에 의해 쓰레드가 다시 깨어나야하지만 스핀락은 락을 얻을때까지 계속해서 CPU 자원을 점유하므로 CPU를 비효율적으로 낭비할 위험이 있다.
* 그러므로 임계구역 진입을 위한 대기 시간이 짧을 때 사용하는게 바람직하다.

# 멀티 쓰레드
* 쓰레드 간의 통신이 필요한 경우에도 별도의 자원을 이용하는 것이 아니라 전역 변수의 공간 또는 동적으로 할당된 공간인 힙(Heap) 영역을 이용하여 데이터를 주고받을 수 있다.
* 그렇기 때문에 프로세스 간 통신 방법에 비해 쓰레드 간의 통신 방법이 훨씬 간단하다.
* 심지어 쓰레드의 문맥 교환은 프로세스 문맥 교환과는 달리 캐시 메모리를 비울 필요가 없기 때문에 더 빠르다.
* 따라서 시스템의 처리량이 향상되고 자원 소모가 줄어들어 자연스럽게 프로그램의 응답 시간이 단축된다.


## 쓰레딩의 문제점
* 멀티 프로세스 기반으로 프로그래밍할 때는 프로세스 간 공유하는 자원이 없기 때문에 동일한 자원에 동시에 접근하는 일이 없었지만
* 멀티 쓰레딩을 기반으로 프로그래밍할 때는 이 부분을 신경써줘야 한다. 서로 다른 쓰레드가 데이터와 힙 영역을 공유하기 때문에
* 어떤 쓰레드가 다른 쓰레드에서 사용중인 변수나 자료 구조에 접근하여 엉뚱한 값을 읽어오거나 수정할 수 있다. 그렇기 때문에 멀티쓰레딩 환경에서는 동기화 작업이 필요하다.
* 동기화를 통해 작업 처리 순서를 컨트롤 하고 공유 자원에 대한 접근을 컨트롤 하는 것이다.
* 하지만 이로 인해 병목 현상이 발생하여 성능이 저하될 가능성이 높다. 그러므로 과도한 락(lock)으로 인한 병목 현상을 줄여야 한다.
* 공유 자원이 아닌 부분은 동기화 처리를 할 필요가 없다. 즉, 동기화 처리가 필요한 부분에만 synchronized 키워드를 통해 동기화하는 것이다.
* 불필요한 부분까지 동기화를 할 경우 현재 쓰레드는 락(lock)을 획득한 쓰레드가 종료하기 전까지 대기해야한다. 그렇게 되면 전체 성능에 영향을 미치게 된다.
* 즉 동기화를 하고자 할 때는 메소드 전체를 동기화 할 것인가 아니면 특정 부분만 동기화할 것인지 고민해야 한다.

# 운영체제 개념
## 윈도우 특징

## 리눅스 특징

## CLI와 GUI 차이

## 윈도우 부팅 시 시작프로그램 핸들링 하는 명령어: msconfig


# 인터럽트
## 컴퓨터 시스템의 구조
 * 프로그램이 CPU에서 명령을 수행하려면 수행하려는 주소 영역이 메모리에 올라가 있어야 한다. 
 * 이 때 프로그램의 주소 영역은 크게 코드,데이터,스택 영역으로 구분된다.
 * 코드영역은 우리가 작성한 프로그램 함수들의 코드가 기계어 명령으로 변환되어 저장되는 부분이다.
 * 데이터 영역은 전역 변수 등 프로그램이 사용하는 데이터를 저장하는 부분이다.
 * 스택 영역은 함수가 호출될 때 호출된 함수의 수행을 마치고 복귀할 주소 및 데이터를 임시로 저장하는 데 사용되는 공간이다.
 * 일반적으로 프로그램 내에서 발생되는 함수 호출에 필요한 복귀 주소는 각 프로그램의 주소 공간 중 스택 영역에 보관한다.
 * 반면, 인터럽트 때문에 CPU를 선점당한 위치를 저장하기 위한 공간은 OS 커널 부분에 존재하게 된다.
 * OS는 현재 실행중인 모든 프로그램을 관리하기 위한 자료구조를 유지하고 있다.
    * 예를 들어 A,B 두 개의 프로그램이 현재 수행중이라면  커널 어딘가에 이 두 프로그램을 관리하기 위한 자료 구조가 존재한다.  이 자료 구조를 "프로세스 제어 블록(PCB)"라 부른다.


## 컨텍스트 스위칭
## context switching
* 멀티프로세스 환경에서 CPU가 어떤 프로세스를 실행하고 있는 상태에서, interrupt 요청에 의해 다음 우선쉰위으 프로세스가 실행되야 할 때, 기존 프로세스의 상태 또는 레지스터 값을 저장하고 cpu가 다음 프로세스를 수행하도록 상태 또는 레지트서 값을 교체하는 작업이다. 컨텍스트 스위칭 작업간에 cpu는 아무 작업을 할 수 없다. 따라서 잦은 컨텍스트 스위칭으로 오버헤드가 발생해 효율이 낮아질 수 있다.

```java
CPU에 실행할 프로세스를 교체하는 기술 (Context Switching)
실행 중지할 프로세스 정보를 해당 프로세스의 PCB에 업데이트해서, 메인 메모리에 저장
다음 실행할 프로세스 정보를 메인 메모리에 있는 해당 PCB 정보를 CPU에 넣고, 실행
실행 중지할 프로세스 정보를 해당 프로세스의 PCB에 업데이트해서, 메인 메모리에 저장
다음 실행할 프로세스 정보를 메인 메모리에 있는 해당 PCB정보(PC,SP)를 CPU의 레지스터에 넣고, 실행
dispatch : ready상태의 프로세스를 running 상태로 바꾸는 것
컨텍스트 스위칭 시간이 오래 걸리면 운영체제 속도가 느려진다
실제로는 굉장히 짧은시간(ms) 단위로, 프로세스 스위칭이 일어남
```

### 컨텍스트 스위칭의 원리
* 프로세스 A가 실행이 될려면 스케쥴러에 프로세스가 들어가게 된다. 스케쥴러아 해당 status를 running으로 변경한다. 프로세스 A가 실행을 하다가 스케쥴러가 프로세스 B를 running status로 변경하는 것을 컨택스트 스위칭이라고 한다. (pc와 stack pointer가 핵심이다 !!)
* process A에서 process B로넘어갈때 현재의 컨텍스트를 PCB라는 별도의 저장공간을 만들어서 저장하고 운영체제가 관리한다. 프로세스 B실행중 스케쥴러에 의해 다시 Process A로 넘어오면 PCB를 읽어서 Context를 불러 와서 프로세스를 실행한다.


## PCB
* 프로그램 A가 수행중에 인터럽트가 발생하면 현재 실행중이던 지점을 A의 프로세스 제어 블록에 저장한 후 인터럽트 처리 루틴으로 가서 인터럽트 발생관련 일 처리를 한다. 인터럽트 처리를 모두 마치면  프로그램 A의 프로세스 제어 블록에 저장된 주소를 복원시켜 원래 수행하던 일을 재개하게 된다.

## 컴퓨터 시스템의 작동 개요 @ 스택
 * CPU를 컴퓨터의 두뇌라고 부르지만 CPU는 인간의 뇌처럼 스스로 생각하고 판단하는 능력을 갖추고 있지는 못하다.
 * 이는 CPU가 빠른 속도로 처리하는 계산 능력은 가지고 있지만, 어떠한 작업을 수행해야 하는지에 대해 스스로 결정하는 능력은 없기 때문이다.
 * CPU는 현재 수행해야 할 메모리 주소의 명령을 있는 그대로 처리할 뿐이다. 
 * 이 때, CPU가 수행해야 할 메모리 주소를 담고 있는 레지스터를 프로그램 카운터라고 부른다. 
 * 즉, CPU는 매번 프로그램 카운터가 가리키는 메모리 영역의 명령을 처리하게 된다.
 * 일반적으로 조건문, 반복문, 함수 호출 등에 의한 주소 이동이 없는 이상 프로그램 카운터는 
 * 바로 다음 주소의 명령을 가리키게 되어 코드의 순차적인 수행이 이루어진다.
* 메모리에는 사용자 프로그램 + OS 같이 올라가 수행된다.  이 때 CPU는 프로그램 카운터가 가리키는 메모리 위치의 프로그램을 수행하게 된다.
* if 프로그램 카운터가 메모리 주소 중 OS가 존재하는 부분을 가리킨다면 CPU가 커널 모드에서 수행중이라고 이야기한다. else CPU가 사용자 모드에서 수행중이라고 이야기한다.


## CPU 명령  @커널
* CPU가 수행하는 명령에는 일반 명령과 특권 명령이 있다. 일반 명령은 메모리에서 자료를 읽어와서 CPU에서 계산하고 결과를 메모리에 쓰는 일련의 명령들을 말한다.  이러한 일반 명령은 모든 프로그램이 수행할 수 있는 명령이다. 특권 명령은 보안이 필요한 명령으로 입출력 장치, 타이머 등 각종 장치를 접근하는 명령이다. 컴퓨터 시스템에서는 CPU내에 모드 비트를 두어 특권 명령을 항상 OS만이 수행할 수 있도록 제한하고 있다.

# 시스템 콜  @ 특권명령
 * 사용자 프로그램이 특권 명령의 수행이 필요한 경우 OS에게 특권 명령의 대행을 요청한다.이와 같은 서비스 요청을 시스템 콜이라고 한다.
 * 사용자 프로그램이 시스템 콜을 하게 되면 OS는 자신의 커널 영역에 정의된 시스템 콜 처리 코드를 수행하게 된다.
 * 프로그램이 아닌 주변 장치가 CPU에게 서비스를 요청할 때에도 시스템 콜과 비슷한 방식을 사용한다.
 * CPU는 프로그램 카운터가 가리키는 메모리 위치의 명령만 계속 수행하기 때문에 
 * 주변 장치의 상태를 지속적으로 파악할 수 없다. 
 * 따라서, 주변 장치는 CPU의 도움이 필요한 경우 인터럽트를 사용해 CPU에게 서비스를 요청하게 된다.
 * 인터럽트를 발생시키기 위해 주변 장치는 인터럽트 라인을 세팅하고 CPU는 매번 명령을 수행한 후 인터럽트 라인을 체크해 서비스 요청이 있는지 체크한다.
 * 인터럽트가 발생하면 CPU는 해당 인터럽트를 처리하기 위한 루틴으로 넘어가서 커널 내의 인터럽트 처리 코드를 수행한다.
 
## 프로그램의 실행
 * “프로그램이 실행되고 있다”는 것은 컴퓨터 시스템 차원에서 볼 때 크게 두 가지 중요한 의미를 갖는다.
 * 첫째는 디스크에 존재하던 실행 파일이 메모리에 적재됨을 의미한다.
 * 두 번째는 프로그램이 CPU를 할당받고 기계 명령을 수행하고 있는 상태를 의미한다.
 * 일반적인 컴퓨터 시스템의 경우 CPU는 하나밖에 없으므로 매 시점 CPU에서 명령을 수행하는 프로그램은 하나뿐이다. 하지만, 여러 프로그램이 짧은 시간 단위로 CPU를 나누어 쓰고, 이들 프로그램이 메모리에 동시에 적재되어 있을 수 있으므로 여러 프로그램이 동시에 실행된다는 말을 보편적으로 사용하는 것이다.
 * 실행 파일이 메모리에 적재될 때 실행 파일 전체가 메모리에 한꺼번에 올라가기보다는 일부분만 메모리에 올라가고 나머지는 디스크의 특정 영역에 내려가 있는 것이 일반적이다. 이는 여러 프로그램이 공유하는 메모리 공간을 효율적으로 사용하기 위한 방법이다.
 * 프로그램의 주소 공간 중 당장 CPU의 수행에 필요한 부분은 메모리에 올려놓고 
 * 그렇지 않은 부분은 디스크 중 메모리의 연장 공간으로 사용되는 스왑 영역에 내려놓는 방식으로 운영된다.
 * 프로세스의 주소 공간은 코드, 데이터, 스택 등으로 구성된다.  각각의 프로그램마다 이러한 주소 공간을 별도로 가지며,  각 프로그램마다 독자적으로 존재하는 이와 같은 주소 공간을 가상 메모리 또는 논리적 메모리라 부른다.

## OS의 메모리
* OS도 하나의 프로그램이므로 OS 커널 역시 코드,데이터,스택의 주소 공간 구성을 갖는다.
 * 커널의 코드
     * OS의 기능 : 아랫단의 HW 자원을 효율적으로 관리하는 일 + 윗단의 응용 프로그램 및 사용자에게 편리한 서비스 제공
     * CPU, 메모리 등의 자원을 관리하기 위한 부분 + 사용자에게 편리한 인터페이스를 제공하기 위한 부분이 주를 이룬다.
     * 이 밖에도 시스템 콜 및 인터럽트를 처리하기 위한 부분을 포함한다.
 * 커널의 데이터 영역
     * 각종 자원을 관리하기 위한 자료 구조가 저장된다.
     * CPU, 메모리와 같은 HW 자원을 관리하기 위한 자료 구조뿐만 아니라 
     * 현재 수행중인 프로그램을 관리하기 위한 자료 구조도 커널의 데이터 영역에 유지된다.
     * 이 때, 현재 수행중인 프로그램을 프로세스라고 부른다.
     * 각 프로세스의 상태, CPU사용 정보, 메모리 사용 정보 등을 유지하기 위한 자료구조 PCB가 존재한다.
     * 즉, HW + SW를 포함하는 시스템 내의 모든 자원을 관리하기 위한 자료 구조를 각각 유지한다
 * 커널의 스택 영역
     * 함수 호출시 복귀 주소를 저장하기 위한 용도로 사용된다.
     * 커널의 스택은 일반 사용자 프로그램의 스택과 달리 현재 수행중인 프로세스마다 별도의 스택을 두어 관리한다.
     * 즉, 프로그램이 실행되어 자기 자신의 코드 내에서 함수 호출 및 복귀 주소를 유지하기 위해서는 자기 주소 공간 내의 스택을 사용하고, 시스템 콜 등 커널 내의 함수를 호출하는 경우에는 커널의 주소 공간에 존재하는 커널 스택을 사용하게 된다.

### Q. 프로세스마다 별도의 스택을 두는 이유
 * 프로세스가 함수를 호출할 때 자기 주소 영역 내부에 정의된 함수를 호출하면 자신의 스택에 복귀 주소를 저장하지만, 
 * 프로세스가 특권 명령을 수행하려고 커널에 정의된 시스템 콜을 호출하고 시스템 콜 내부에서 다른 함수를 호출하는 경우 그 복귀 주소는 커널 내의 주소가 되어 사용자 프로그램의 스택과는 별도의 저장 공간이 필요하기 때문이다.
 * 또한, 커널은 일종은 공유 코드로서 모든 사용자 프로그램이 시스템 콜을 통해 커널의 함수를 접근 할 수 있으므로  일관성 유지를 위해 각 프로세스마다 커널 내에 별도의 스택을 두게 된다.

## 사용자 프로그램의 사용 함수  @ 시스템 콜 등 커널 내의 함수
 * 프로그램이 사용하는 함수는 크게 1. 사용자 정의 함수와 2. 라이브러리 함수, 3. 커널 함수 세 가지로 구분할 수 있다.
 * 사용자 정의 함수란 프로그래머가 직접 작성한 함수를 뜻한다.
 * 라이브러리 함수란 누군가가 작성해 놓은 함수를 호출만 하여 사용하는 경우를 뜻한다.
 * 사용자 정의 함수와 라이브러리 함수는 모두 컴파일하여 실행 파일을 만들게 되면 프로그램의 코드 부분에 기계어 명령 형태로 삽입된다. 
 * 따라서 이 두 함수는 프로그램이 실행될 때에 해당 프로세스의 주소 공간에 포함된다. 
 * 또한, 함수 호출시에도 자신의 주소 공간에 있는 스택을 사용하게 된다.
 * 한편 커널 함수는 OS 커널의 정의된 함수를 뜻한다.
 * 커널 함수의 종류에는 사용자 프로그램이 OS의 서비스를 요청하기 위한 시스템 콜 함수와 HW / SW가 CPU의 서비스를 요청하기 위한 인터럽트 처리 함수가 있다.
 * 이와 같은 커널 함수는 OS 커널의 주소 공간에 코드가 정의된다. 
 * 즉, OS 있는 함수를 사용자 프로그램이 호출해서 사용하는 것이다.


## 인터럽트  @ 인터럽트 처리 함수
 * 인터럽트와 꽌련된 주요 용어로는 인터럽트 벡터와 인터럽트 핸들러가 있다.

### 인터럽트 벡터
 * 여러가지 인터럽트에 대해 해당 인터럽트 발생시 처리해야 할 루틴의 주소를 보관하고 있는 테이블을 의미한다.
 * 일종의 함수를 가리키는 포인터라고도 할 수 있다.

### 인터럽트 핸들러
 * 실제 인터럽트를 처리하기 위한 루틴으로 인터럽트 서비스 루틴이라고도 부른다.
 * OS 코드 부분에는 각종 인터럽트별로 처리해야 할 내용이 이미 프로그램되어 있으며, 
 * 이 부분을 인터럽트 서비스 루틴 또는 인터럽트 핸들러라고 부른다.

## 시스템 콜 @ 인터럽트 라인
 * 컴퓨터 시스템에서는 HW 및 SW 자원의 보안을 위해 CPU가 실행할 수 있는 명령을 일반 명령과 특권 명령으로 나누어 관리한다.
 * 사용자 프로그램이 CPU의 제어권을 가지고 프로그램을 수행하다 보면, 입출력 등 특권 명령을 수행해야 할 필요가 있다. 
 * 이 경우 사용자가 프로그램은 OS에게 시스템 콜을 통해 특권 명령의 대행을 요청하게 된다. 
 * 사용자 프로그램이 이와 같이 특권 명령을 수행하는 커널 함수를 호출하게 되면 CPU의 제어권이 OS에게 넘어가게 된다. 
 * 이 때 하드웨어적으로 모드 비트가 1에서 0으로 자동 세팅되기 때문에 OS는 특권 명령을 수행할 수 있다.
 * 모든 프로그램은 자신의 독자적인 주소 공간을 가지고 있으며, 
 * 프로그램이 함수 호출을 하는 경우 자신의 주소 공간 내에서 호출이 이루어지게 된다. 
 * 그러나 시스템 콜은 비록 함수 호출이긴 하지만 자신의 주소 공간을 거스르는 영역에 존재하는 함수를 호출하는 것이다. 
 * 커널이라는 다른 프로그램의 주소 공간에 존재하는 함수를 호출하는 일이기 때문이다.
 * 시스템 콜은 주소 공간 자체가 다른 곳으로 이동해야 하므로 일반 함수 호출과는 상이한 방법을 사용한다. 
 * 프로그램 자신이 인터럽트 라인에 인터럽트를 세팅하는 명령을 통해 이루어진다.

### 중요
 * 사용자 프로그램이 이와 같이 특권 명령을 수행하는 커널 함수를 호출하게 되면 CPU의 제어권이 OS에게 넘어가게 된다. 
*  시스템 콜은 주소 공간 자체가 다른 곳으로 이동해야 하므로 일반 함수 호출과는 상이한 방법을 사용한다. 프로그램 자신이 인터럽트 라인에 인터럽트를 세팅하는 명령을 통해 이루어진다.

## CPU 선점
 * 어떤 프로그램이 CPU를 할당받고 명령을 수행하다 중간에 CPU를 선점당하는 경우는 크게 두 가지 경우가 있다.

1. 타이머에 의해 인터럽트 발생
 * 특정 프로그램이 CPU를 독점하는 것을 방지하기 위한 하드웨어로 
 * CPU 할당 시간이 만료되면 인터럽트를 발생시킨다.
 * 이러한 는 여러 프로세스가 CPU를 나누어 사용하는 시분할 시스템의 구현을 위한 필수적인 요소이다.
 
 2. 입출력 요청을 위한 시스템 콜
 * 오래 걸리는 입출력 작업이 완료되기까지 그 프로세스에게 CPU를 다시 할당하더라도 
 * 당장 다음 명령을 수행하지 못하는 경우가 일반적이므로 CPU를 다른 프로세스에게 이양하게 된다.
 * 입출력을 요청했던 프로세스는 입출력 요청이 완료되어 컨트롤러가 인터럽트를 발생시킨 시점부터 
 * 다시 CPU를 얻을 수 있는 기회가 생기며 CPU를 기다리는 큐에 삽입하여 CPU 할당을 기다린다.


## 프로세스의 상태  @ CPU 선점
 * 프로세스의 상태는 실행, 준비, 봉쇄의 세 가지로 크게 나누어 볼 수 있다.


## PCB


### 실행
 * CPU를 할당받고 기계어 명령을 수행하고 있는 프로세스의 상태이다.

### 준비 상태
 * CPU만 할당받으면 당장 명령을 수행할 수 있지만 CPU가 하나밖에 없어 현재 CPU를 할당받지 못한 프로세스의 상태이다.

### 봉쇄 상태
 * CPU를 할당받더라도 명령을 수행할 수 없는 프로세스의 상태이다. 
 * 프로세스가 요청한 입출력 작업이 진행중인 경우 CPU를 할당받더라도 입출력이 끝나기전까지 작업을 진행할 수 없기 때문에 CPU를 할당하지 않는다.


### 준비 상태에 있는 프로세스가 실행 상태로 변경되는 경우
 * 실행 상태에 있던 프로세스가 입출력 요청 등으로 봉쇄 상태가 되거나 또는 실행 상태에 있던 프로세스의 CPU 할당 시간이 만료되어 타이머 인터럽트가 발생한 경우를 들 수 있다.
 * OS는 준비 상태에 있는 프로세스들을 줄 세우기 위해 준비 큐(Ready Queue)를 두고 
 * 준비 큐의 제일 앞에 있는 프로세스에게 CPU를 할당한다. 
 * 준비 큐에 프로세스를 줄 세우는 방법은 CPU 스케줄링 방법에 따라 달라진다.

### OS는 특정 자원을 기달리는 프로세스들을 줄 세우기 위해 자원별로 큐를 두고 있다.
* 예를 들어 디스크에 입출력 서비스를 요청한 프로세스들은 
 * 디스크 입출력 큐(Dist I/O Queue)에 줄 서게 된다.
 * 그러면, 디스크 컨트롤러는 디스크 입출력 큐에 줄 서 있는 순서대로 프로세스들의 입출력 작업을 수행하게 된다.
 * 프로세스별 입출력 작업이 완료되면 디스크 컨트롤러가 CPU에게 인터럽트를 발생시키고, 
 * 그러면 인터럽트 처리 루틴에 의해 디스크 입출력이 완료된 프로세스는 입출력 큐에서 빠져나와
 * CPU를 기다리는 준비 큐에 줄 서게 된다.


## 위에서 언급된 큐는 HW 자원을 기다리는 프로세스들을 줄 세우기 위한 것이었다. 
* 이와 같은 큐는 SW 자원을 기다리는 경우에도 필요하다.
 * 예를 들어 데이터에 대한 접근 권한은 SW 자원으로 분류될 수 있다.
 * 어떠한 프로세스가 공유 데이터를 사용하고 있는 도중에 
 * 다른 프로세스가 같은 데이터를 접근하면 데이터에 대한 일관성이 훼손될 수 있다.
 * 따라서, 공유 데이터는 매 시점 하나의 프로세스만이 접근할 수 있도록 해야 한다.
 * 이 때 접근한다는 의미가 반드시 CPU가 그 데이터를 사용하고 있다는 의미는 아니다.
 * 공유 데이터를 접근중인 프로세스가 "준비 상태"나 "봉쇄 상태로" 변경된 경우에도
 * 새롭게 CPU를 할당받은 프로세스가 동일한 데이터를 접근하게 되면
 * 데이터의 일관성이 깨질 수 있으므로 접근을 허락해서는 안 된다.
 * 즉, 공유 데이터라는 일종의 SW 자원을 앞서 접근중인 프로세스가 다 사용하고 반날할 때까지는
 * 다른 프로세스가 CPU를 할당 받았다 하더라도 접근하지 않고 기다려야 하는 것이다.
 * 여러 프로세스가 공유 데이터를 동시에 접근하려고 할 경우 공유 데이터를 기다리는 "큐"에 줄 서게 하여
 * 현재 그 데이터를 사용중인 프로세스가 데이터를 반납하기 전까지는 접근을 못하게 하고,
 * 반납할 경우 큐에 줄 서 있는 순서대로 데이터의 접근 권한을 주는 방법을 사용하게 된다.
* 위 그림처럼 프로세스의 상태 관리는 커널의 주소 영역 중 데이터 영역에 다양한 큐를 두어 이루어지게 된다.
* 각 프로세스들이 CPU를 기다리는지, 입출력을 기다리는지 등의 정보를 커널이 총체적으로 관리하고 있다는 뜻이다.

### 예시
 * 예를 들어 타이머 인터럽트가 발생하면
 * 커널은 자신의 데이터 영역에 있는 준비 큐의 정보를 참조해
 * 다음에 어느 프로세스에게 CPU를 할당할지 결정하고
 * 현재 실행되던 프로세스는 준비 큐의 제일 뒤로 보내게된다.
 * // 준비 큐는 CPU를 할당받기 위해 기다리는 큐이므로
 * // 어떤 프로세스에게 CPU를 할당할지 결정하려면 준비 큐를 봐야한다.
 * // 타이머 인터럽트이기 때문에 "봉쇄 상태"가 아니라 준비 큐의 가장 마지막에 재삽입하는 것이다.
 * // 입출력 요청이였을 시에는 "봉쇄 상태"로 빠져 준비 큐에 들어가지 못하게 된다.


## 프로세스의 두 가지 실행 상태
* 하나의 프로세스가 시작되어 수행을 완료하기까지는 프로세스 자신의 주소 공간에 있는 코드만 실행되는 것이 아니라 커널의 주소 공간에 있는 코드도 실행된다.
* 이는 프로그램이 사용자 정의 함수나 라이브러리 함수뿐 아니라 입출력 시스템 콜 등을 통해 OS 커널의 함수도 호출하여 실행하기 때문이다.

### 예시
 * 예를 들어 프로세스 A가 CPU에서 실행되고 있다고 하면
 * 이는 자신의 주소 공간에 정의된 코드를 실행하는 것과
 * 커널의 시스템 콜 함수를 실행하는 것으로 나누어 볼 수 있다.
 * 전자를 사용자 모드에서의 실행 상태(User mode Running)이라 하고,
 * 후자를 커널 모드에서의 실행 상태(Kerner mode Running)라고 한다.
 * 한 가지 주의할 점은 시스템 콜이 수행되는 동안
 * 프로세스 A의 코드가 아니라 OS 커널의 코드이지만
 * 커널이 실행 상태에 있다고 하지 않고
 * 프로세스 A가 실행 상태에 있다고 말한다.
 * 프로세스 A 입장에서는 CPU를 OS 커널에게 빼앗긴 것으로 생각할 수도 있지만
 * 커널의 코드가 실행되는 것이 사실상 프로세스 A가 해야 할 일을 대행하는 것이기 때문에
 * 시스템 콜이 실행중일 때에도 여전히 프로세스 A는 실행 상태에 있는 것으로 간주한다.
 * 다만, 프로세스 A 자신의 코드를 실행하는 것과 구분지어
 * 이러한 상태를 프로세스 A가 커널 모드에서 실행중이라고 이야기한다.


### 정리
 * 정리하자면, 프로그램이 시작되어 종료될 때까지 다양한 함수 호출을 하며 실행되는데, 
 * 이를 사용자 모드와 커널 모드의 실행 상태로 구분 지을 수 있다.
 * 프로그램이 사용자 정의 함수나 라이브러리 함수를 호출할 때에는 모드의 변경없이 사용자 모드에서의 실행을 하게 되며, 
 * 시스템 콜을 하는 경우에는 커널 모드로 진입해 커널의 주소 공간에 정의된 함수를 실행하게 된다. 
 * 시스템 콜의 실행이 끝나면 다시 사용자 모드로 복귀해서 시트템 콜 이후의 명령들을 계속 실행하게 된다. 
 * 프로그램의 실행이 끝날 때에는 커널 모드로 진입해 프로그램을 종료하게 된다.

# Process
* 프로그램을 운영하는 기초 단위  
    ^basuc unit of running program
* Concurrent
* Code, Stack, Heap, Data
* Stack:  

# 프로세스
- https://bowbowbow.tistory.com/16 
- 프로그램 -> 실행 내용 -> 프로세스 -> 중앙처리장치(CPU)
- 프로그램은 일반적으로 하드 디스크 등에 저장되어 있는 실행코드를 뜻하고, 프로세스는 프로그램을 구동하여 프로그램 자체와 프로그램의 상태가 메모리 상에서 실행되는 작업 단위를 지칭한다. 예를 들어, 하나의 프로그램을 여러 번 구동하면 여러 개의 프로세스가 메모리 상에서 실행된다.
- 프로세스와 프로그램의 차이는 정말 명확합니다. 프로그램자체는 생명이 없습니다. 프로그램은 보조 기억장치(하드디스크, SSD)에 존재하며 실행되기를 기다리는 명령어(코드)와 정적인 데이터의 묶음입니다. 이 프로그램의 명령어와 정적 데이터가 메모리에 적재되면 생명이 있는 프로세스가 됩니다.

## 프로세스의 정의
* 커널에 등록되고 커널의 관리하에 있는 작업
* 각종 자원들을 요청하고 할당 받을 수 있는 개체
* 프로세스 관리 블록을 할당받은 개체
* 능동적인 개체(실행 중에 각종 자원을 요구, 할당, 반납하여 진행)

## 코드가 프로세스가 되는 과정
* 먼저, 하나의 코드가 프로그램이 되고, 프로그램이 프로세스가 되는 과정은 다음과 같다.
* 코드 작성 -- (컴파일) --> 오브젝트 파일 -- (링킹) --> 실행 파일(=프로그램) -- (로드) --> 메모리 적재 및 수행(=프로세스)
* [출처]['https://dailyheumsi.tistory.com/137?category=855210 [하나씩 점을 찍어 나가며]']

```java
컴파일러
​ 사용자가 작성한 원시코드를 컴퓨터가 읽을 수 있는 형태의 오브젝트 파일로 만드는 프로그램

어셈블러
​ 어셈블리어 코드를 기계어 코드로 변환시켜주는 프로그램.
​ 명확히 말하면, 어셈블러는 큰 의미 컴파일러 내부에 속한다.
​ 큰 의미의 컴파일러는 사실 다음과 같이 구성된다.
​ (원시 코드) -> (컴파일러) -> (어셈블리어 코드) -> (어셈블러) -> (기계어 코드 = 오브젝트 코드)

링커
​ 프로그램이 되기 위해 여러 개의 오브젝트 파일과 라이브러리를 엮는 과정(링킹)을 수행하는 프로그램

로더
​ 사용자가 프로그램을 실행하면, 메모리에 적재하는 일(로드)을 수행하는 프로그램


```

## 프로세스가 접근할 수 있는 메모리 공간
- 이 주소 공간은 Text, Data, BSS, Heap, Stack 영역으로 구성됩니다. 아래 그림에서 각 영역에 프로그램의 어떤 정보를 저장하는지 나타냈습니다.
- Text: 기계어; Data: 초기화된 전역 변수, static 변수, BSS: 초기화되지 않은 전역 변수, static 변수, Heap: malloc으로 동적 할당된 변수   stack: 지역 변수




## PCB
- 프로세스에 대한 정보는 프로세스 제어블록(PCB, Process Control Block)또는 프로세스 기술자(process descriptor)라고 부르는 자료구조에 저장됩니다. 대부분 PCB라고 부릅니다. 이 자료구조 크게 다음과 같은 정보를 담고있습니다. 
- 운영체제가 각 프로세스를 식별하기 위해 부여된 프로세스 식별번호(PID, Process IDentification)입니다.
- CPU는 프로세스를 빠르게 교체하면서 실행하기 때문에 실행중인 프로세스도 있고 대기 중인 프로세스도 있습니다. 그런 프로세스의 상태를 저장합니다.
- CPU가 다음으로 실행할 명령어를 가리키는 값입니다. CPU는 기계어를 한 단위씩 읽어서 처리하는데 프로세스를 실행하기 위해 다음으로 실행할 기계어가 저장된 메모리 주소를 가리키는 값입니다.
- 운영체제는 여러개의 프로세스를 동시에 실행하는 환상을 제공합니다. 운영체제가 여러 개의 프로세스가 CPU에서 실행되는 순서를 결정하는 것을 스케줄링이라고 합니다. 이 스케줄링에서 우선순위가 높으면 먼저 실행될 수 있는데 이를 스케줄링 우선순위라고 합니다.
- 프로세스가 접근할 수 있는 자원을 결정하는 정보입니다. 안드로이드 앱을 예로 들면 아무 앱이나 휴대폰 통화내역을 볼 수 있는 권한을 가지면 이를 악의적으로 이용하는 앱이 등장하겠죠? 그래서 프로세스마다 어디까지 접근할 수 있는지에 대한 권한이 필요합니다.
- 최초로 생성되는 init 프로세스를 제외하고 모든 프로세스는 부모 프로세스를 복제해서 생성되고 이 계층관계는 트리를 형성합니다. 그래서 각 프로세스는 자식 프로세스와 부모프로세스에 대한 정보를 가지고 있습니다.
 
 * 출처: https://bowbowbow.tistory.com/16 [멍멍멍]

## 프로세스의 상태
- 생성(create) : 프로세스가 생성되는 중이다.
- 실행(running) : 프로세스가 CPU를 차지하여 명령어들이 실행되고 있다.
- 준비(ready) : 프로세스가 CPU를 사용하고 있지는 않지만 언제든지 사용할 수 있는 상태로, CPU가 할당되기를 기다리고 있다. 일반적으로 준비 상태의 프로세스 중 우선순위가 높은 프로세스가 CPU를 할당받는다.
- 대기(waiting) : 보류(block)라고 부르기도 한다. 프로세스가 입출력 완료, 시그널 수신 등 어떤 사건을 기다리고 있는 상태를 말한다.
- 종료(terminated) : 프로세스의 실행이 종료되었다.

##상태전이
- 디스패치(dispatch)
- 준비 리스트의 맨 앞에 있던 프로세스가 CPU를 점유하게 되는 것, 즉 준비 상태에서 실행 상태로 바뀌는 것을 디스패치라고 하며 다음과 같이 표시한다.
- dispatch (processname) : ready → running

- 보류(block)
- 실행 상태의 프로세스가 허가된 시간을 다 쓰기 전에 입출력 동작을 필요로 하는 경우 프로세스는 CPU를 스스로 반납하고 보류 상태로 넘어 간다. 이것을 보류라고 하며 다음과 같이 표시한다.
- block (processname) : running → blocked

- 깨움(wakeup)
- 입출력 작업 종료 등 기다리던 사건이 일어났을 때 보류 상태에서 준비 상태로 넘어가는 과정을 깨움이라고 하며 다음과 같이 표시한다.
- wakeup (processname) : blocked → ready



- 시간제한(timeout)
- 운영체제는 프로세스가 프로세서를 계속 독점해서 사용하지 못하게 하기 위해 clock interrupt를 두어서 프로세스가 일정 시간동안만 (시분할 시스템의 time slice) 프로세서를 점유할 수 있게 한다
- timeout(processname) : running -> ready


## Process Creation
* [블로그](https://dailyheumsi.tistory.com/129?category=855210)
```java
Process Creation
현재 프로세스에서 새로운 프로세스를 생성하거나 실행시키는 경우, 2가지 구현 방법이 있다.
모두 OS에서 제공해주는 시스템 콜(System call) 로 fork() 와 exec() 이다.

3.1. fork()
fork() 는 OS가 새로운 메모리 공간을 할당하도록 한 후, 현재 프로세스의 코드와 정보를 
모두 새로운 메모리 공간에 복사하도록 한다. 즉, 현재 실행중인 프로세스와 동일한 프로세스 하나를 더 만드는 셈이다.
프로세스는 결과적으로 1개에서 2개가 되는 셈이다.


핵심은 다음과 같다.

1) `fork()` 를 하면, 현재 프로세스의 자식 프로세스를 생성한다.  
2) 이 때, 반환 값이 0이면 자식이고, 0보다 크면 부모 프로세스를 의미한다. (즉 자식 프로세스를 pid 로 구분해야함)  
3) 부모 프로세스를 그대로 복사하여 생성하기 때문에, PC(프로그램 카운터)도 그대로 가져간다.
즉 자식 프로세스는 `fork()` 이 시점부터 프로그렘이 실행된다. 한편 저장되어있던 지역변수 등 모두 동일하다.

3.2. exec()
exec() 는 OS가 현재 프로세스의 공간에 새로운 프로세스를 덮어쓰게 한다.
예를 들어, execl("/bin/ls", "ls") 와 같이 했다면, 이 명령어를 담고있는 프로세스에 해당 프로그램 /bin/ls 를 실행시킨다.
즉, /bin/ls 이 성공했으므로, 뒤에 수행되는 코드들은 모두 덮혀버린다.
프로세스는 결과적으로 그대로 1개인 셈이다.

자세한 내용은 아래 링크 참조.

```

## process termination
```java
Process Termination
일반적으로, 프로세스가 마지막 명령어(코드) 를 수행하면 OS에게 삭제해달라는 exit() 요청을 하게된다.
다만, 이 때 자식 프로세스가 아직 실행중인 경우, 부모 프로세스는 OS에 의해 wait 명령을 받아 wait 상태에 있게 된다.
이후, 모두 완료되면 OS가 할당했었던 메모리를 회수해간다.

보통 부모 프로세스가, 자식 프로세스보다 먼저 삭제되는 경우, OS는 이를 비정상적인 상황이라 인지하고 
해당 부모의 자식 프로세스도 모두 삭제시키는데, 이를 Cascading Termination 이라 한다.


4.1. Zombie vs Orphan Process
Zombie Process
실행이 완료된 프로세스임에도, 여전히 프로세스 테이블에 남아있는 (지워지지 않은) 프로세스를 말한다.
이러한 프로세스가 발생하는 이유는 다음과 같다.
부모 프로세스는 자식 프로세스의 실행이 끝난 뒤의 상태(status) 를 받기 위해 계속 wait(&status) 하고 있는다.
자식 프로세스는 실행이 끝나고 exit status 로 상태를 바꾼 뒤, 
이를 부모 프로세스에게 전달하고, 부모가 전달받을 때까지 기다린다.
이 기다리는 동안, (부모 프로세스가 자식 프로세스를 회수해가지 않는 동안) 메모리 공간을 잡아먹지는 않지만, 
프로세스 테이블에는 남아있으므로 일종의 Zombie 상태가 된다.
여하튼, 종료된 프로세스임에도 프로세스 테이블에 남아있는 것은 좋지않으므로,
부모 프로세스에서 반드시 wait(&status) 를 통해, 자식 프로세스의 종료상태를 읽어야 한다.

Orphan Process
자식 프로세스가 종료되기 전에, 부모 프로세스가 먼저 지워진 자식 프로세스를 말한다.
이러한 프로세스가 발생하는 이유는 부모 프로세스 실행 중, 비정상적인 종료 혹은 wait() 을 하지 않았기 때문이다.
Orphan Process 는 OS에 의해 Init Process 가 부모로 할당된다.


```



## IPC (Inter-Process Communication)
* 프로세스간 통신하는 방법에는 다음과 같은 방법이 있다.
```java

5.1. Shared Memory
일반적으로 프로세스들은 메모리에서 각자의 독립된 공간을 보장받는다. 
즉 어떤 프로세스가 다른 프로세스의 메모리 영역에 접근할 수 없도록 OS가 설계되어져 있다.
하지만, Shared Memory 를 OS 에게 요청하면, 프로세스의 해당 영역은 다른 프로세스와 공유할 수 있는 공간이 된다.
프로세스간 통신에서 가장 빠르게 작동하는 방법이다.
다만, 동기화를 직접 해줘야 한다는 것, 메모리 공간을 직접 제어해줘야한다는(생성, 삭제) 단점이 있다.

5.2. Message passing
위 그림에서도 보이듯, 기본적으로 큐 형태를 취하기 때문에, 동기화 제어가 쉽게 가능하다.
다만, 동시에 Shared Memory 보다 통신 속도가 느리다.
대표적으로 아래와 같이 3가지 구현 형태가 있다.

1) Pipe
OS 에서 제공하는 pipe buffer 로, 한 프로세스에서 다른 프로세스로 통신하는, 단 방향 통신 방법이다.
ex. ps -aux | grep root | tail 에서 | 가 pipe 다.

2) Named Pipe
mkfifo() 라는 시스템 콜로 이름이 있는 파이프를 만들어 통신한다.
이전의 Pipe (익명 Pipe 라고 한다.) 는 통신을 할 프로세스를 명확히 아는 경우
(이를 테면 부모와 자식 프로세스 간)에만 사용 가능하지만, 
Named Pipe의 경우, 파이프의 이름을 통해 통신에 접근하기 때문에, 모든 프로세스 간에 통신이 가능하다.
하지만 여전히 Pipe 의 특성상, 읽기/쓰기가 동시에 가능하지 않으며, 따라서 일반적으로 읽기용 Pipe, 쓰기용 Pipe, 이렇게 2개를 사용한다.

3) Message Queue
커널에서 관리하는 큐를 통해 프로세스간 통신한다.
Named Pipe 처럼 일종의 식별자를 통해 각 프로세스마다 필요한 자료에 접근하게 된다.
Named Pipe 와 다른 점은, Pipe 는 단방향인데 반해, Queue는 양방향이라는 점, 메모리 공간에 할당된다는 점 등이 다르다.



출처: https://dailyheumsi.tistory.com/129?category=855210 [하나씩 점을 찍어 나가며]

```

## 프로세스간 커뮤니케이션
```java
IPC 기법 이지만, 이외에도 많이 사용되는 두 가지 기술이 있다.

1. 시그널
2. 소켓


1. 시그널(signal)
유닉스에서 30년이상 사용된 전통적인 기법
커널 또는 프로세스에서 다른 프로세스에 어떤 이벤트가 발생되었는지를 알려주는 기법
프로세스 관련 코드에 관련 시그널 핸들러를 등록해서, 해당 시그널 처리 실행

시그널 무시
시그널 블록(블록을 푸는 순간, 프로세스에 해당 시그널 전달)
등록된 시그널 핸들러로 특정 동작 수행
등록된 시그널 핸들러가 없다면, 커널에서 기본 동작 수행

주요 시그널
SIGKILL : 프로세스를 죽여라
SIGALARM : 알람을 발생한다
SIGSTOP : 프로세스럴 멈춰라
SIGCONT : 멈춰진 프로세스를 실행해라
SIGINT : 프로세스에 인터럽트를 보내서 프로세스를 죽여라
SIGSEGV : 프로세스가 다른 메모리영역을 침범했다.


2. 소켓(socket)
소켓은 네트워크 통신을 위한 기술
기본적으로는 클라이언트와 서버등 두 개의 다른 컴퓨터간의 네트워크 기반 통신을 위한 기술
소켓을 하나의 컴퓨터 안에서, 두 개의 프로세스간에 통신 기법으로 사용 가능
```


## 데드락 문제
* - 프로세스가 자원을 얻지 못해 다음 처리를 하지 못하는 상태로, ‘교착 상태’라고도 하며 시스템적으로 한정된 자원을 여러 곳에서 사용하려고 할 때 발생합니다.
* - 멀티 프로그래밍 환경에서 한정된 자원을 사용하려고 서로 경쟁하는 상황이 발생 할 수 있습니다. 어떤 프로세스가 자원을 요청 했을 때 그 시각에 그 자원을 사용할 수 없는 상황이 발생할 수 있고 그 때는 프로세스가 대기 상태로 들어 가게됩니다. 대기 상태로 들어간 프로세스들이 실행 상태로 변경 될 수 없을 때 이러한 상황을 교착 상태라 합니다.

### 예제
* P1과 P2가 리소스 A, B 둘 다를 얻어야 한다고 가정할 때, t1에 P1이 리소를 A를 얻고 P2가 리소스 B를 얻었다면 t2때 P1은 리소스 B를, P2는 리소스 A를 기다리게 됩니다. 하지만 서로 원하는 리소스가 상대방에게 할당되어 있기 때문에 이 두 프로세스는 무한정 기다리게 되는데 이러한 상태을 DeadLock상태라고 합니다.


### 데드락 (Dead lock)의 발생 조건

- 교착 상태는 한 시스템 내에서 다음의 네 가지 조건이 동시에 성립 할 때 발생합니다
- 따라서, 아래의 네 가지 조건 중 하나라도 성립하지 않도록 만든다면 교착 상태를 해결할 수 있습니다.

1. 상호 배제 (Mutual exclusion)
- 자원은 한 번에 한 프로세스만이 사용할 수 있어야 한다.

2. 점유 대기 (Hold and wait)
- 최소한 하나의 자원을 점유하고 있으면서 다른 프로세스에 할당되어 사용하고 있는 자원을 추가로 점유하기 위해 대기하는 프로세스가 있어야 한다.

3. 비선점 (No preemption)
- 다른 프로세스에 할당된 자원은 사용이 끝날 때까지 강제로 빼앗을 수 없어야 한다.

4. 순환 대기 (Circular wait)
- 프로세스의 집합 {P0, P1, ,…Pn}에서 P0는 P1이 점유한 자원을 대기하고 P1은 P2가 점유한 자원을 대기하고 P2…Pn-1은 Pn이 점유한 자원을 대기하며 Pn은 P0가 점유한 자원을 요구해야 한다.

 

### 데드락 (Dead lock) 처리

1. 교착 상태 예방(Prevention): 교착 상태 발생 조건 중 하나를 제거함으로써 해결하는 방법
- 자원의 낭비가 심하다.

#### 상호 배제 (Mutual exclusion) 부정
- 여러 개의 프로세스가 공유 자원을 사용할 수 있도록 한다.

#### 점유 대기 (Hold and wait) 부정
- 프로세스가 실행되기 전 필요한 모든 자원을 할당한다.

#### 비선점 (No preemption) 부정
- 자원을 점유하고 있는 프로세스가 다른 자원을 요구할 때 점유하고 있는 자원을 반납하고, 요구한 자원을 사용하기 위해 기다리게 한다.

#### 순환 대기 (Circular wait) 부정
- 자원에 고유한 번호를 할당하고, 번호 순서대로 자원을 요구하도록 한다.



2. <회피(Avoidance)법>: 교착 상태가 발생하면 피해나가는 방법

- 은행원 알고리즘 (Banker’s Algorithm)

* E,J,Dijkstra가 제안한 방법으로, 은행에서 모든 고객의 요구가 충족되도록 현금을 할당하는 데서 유래한 기법이다.
* 프로세스가 자원을 요구할 때 시스템은 자원을 할당한 후에도 안정 상태로 남아있게 되는지를 사전에 검사하여 교착 상태를 회피하는 기법
* 안정 상태에 있으면 자원을 할당하고, 그렇지 않으면 다른 프로세스들이 자원을 해지할 때까지 대기함
* 교착 상태가 되지 않도록 보장하기 위하여 교착 상태를 예방하거나 회피하는 프로토콜을 이용하는 방법



3. 교착 상태 탐지 및 회복 : 교착 상태가 되도록 허용한 다음에 회복시키는 방법


* 교착 상태 무시
	* 대부분의 시스템은 교착 상태가 잘 발생하지 않으며, 교착 상태 예방, 회피, 탐지, 복구하는 것은 비용이 많이 든다. **

* < 교착 상태 탐지 (Detection) >
	- 자원 할당 그래프를 통해 교착 상태를 탐지할 수 있다.
	- 자원 할당 그래프 예시
	- - 자원을 요청할 때마다 탐지 알고리즘을 실행하면 그에 대한 오버헤드가 발생한다.
	- 출처: https://jwprogramming.tistory.com/12 [개발자를 꿈꾸는 프로그래머]


4. < 교착 상태로부터 회복 (Recovery) >
- 교착 상태를 일으킨 프로세스를 종료하거나, 할당된 자원을 해제함으로써 회복하는 것을 의미한다.
- 프로세스를 종료하는 방법
	1. 교착 상태의 프로세스를 모두 중지
	2. 교착 상태가 제거될 때까지 한 프로세스씩 중지


- 자원을 선점하는 방법
	1. 교착 상태의 프로세스가 점유하고 있는 자원을 선점하여 다른 프로세스에게 할당하며, 해당 프로세스를 일시 정지 시키는 방법
	2. 우선 순위가 낮은 프로세스, 수행된 횟수가 적은 프로세스 등을 위주로 프로세스의 자원을 선점한다.





# 스케줄링
## CPU 스케쥴링 목적
* [블로그](https://dailyheumsi.tistory.com/131?category=855210)
```java
다중 프로그래밍을 함으로써, 항상 실행할 수 있는 프로세스를 있도록 하여,
CPU 사용 효율을 극대화 하는 것이 목적이다.

* CPU, I/O burst
프로세스는 계산과 입출력의 반복.
계산(CPU burst) / 입출력(I/O burst)

* 선점 / 비선점 스케쥴링
선점은 RUN 중인 프로세스를 갑자기 중단시키고 다른 프로세스가 RUN 할 수 있는 방식
비선점은 RUN 중인 프로세스를 중간에 갑자기 중단 불가능.
일단 한 번 할당 받으면, 시간이 다 되거나, 완료 될 때까지 다른 프로세스들이 기다려야함.

* Dispatcher
스케쥴러가 선택한 프로세스를 CPU에 할당해주는 요소를 가르킴
Dispatch latency
	A 프로세스 STOP -> B 프로세스 RUN 하는 동안 소요되는 시간

```
## 스케쥴링 기준
```java
스케쥴링 알고리즘을 선택할 때, 고려되는 기준을 살펴본다.

처리율 (Throughput)
시간당 완료되는 프로세스의 수

반환시간 (Turnaround time)
한 프로세스가 큐에 들어간 시점부터 실행완료할 때까지 걸리는 시간

대기시간 (Waiting time)
한 프로세스가 큐에서 대기한 총 시간

응답시간 (Response time)
큐에 들어가고, 첫 번째 실행 때까지 걸리는 시간
처리율은 높이고, 반환, 대기, 응답시간은 낮추는게 가장 이상적인 알고리즘이다.

```

## 3. 스케쥴링 알고리즘
```java
3.1. 싱글레벨 큐
하나의 큐만 사용한다.

* FCFS (First Come First Served)
비선점 방식
FIFO 형태. 큐로 쉽게 구현
Convoy 효과
하나의 큰 프로세스가 CPU를 양보할 때 까지 다른 모든 프로세스가 기다리는 현상

* SJF (Shortest Job First)
현재 큐에 들어와있는 프로세스 중, CPU burst 시간이 제일 짧은 프로세스 순으로 스케쥴링
평균 대기 시간 측면에서는 그나마 최적에 가까움.
다음 CPU burst 시간 예측의 어려움
	지수 평균 방법으로 예측
선점방식일 경우, 다음 방법으로 선점여부 결정
	새 프로세스가 큐에 도착하면, 이 프로세스의 다음 CPU burst 시간(A) 예측
	현재 RUN 중인 프로세스의 남은 CPU burst 시간(B) 계산
	이 두 시간 A, B 를 비교해서 A < B 이면, 새 프로세스가 CPU 선점
	이 방식은 SRTF (Shortest Remaining Time First) 라고 함.
	
* 우선순위 스케쥴링
	우선순위가 높은 프로세스가 먼저 CPU를 선점함
	SJF 도 이 스케쥴링의 일종임.
우선순위는 OS 또는 사용자에 의해 지정될 수 있음
영구 대기(infinite blocking), 굶주림(starvation) 이 발생할 수 있음.
즉 우선순위가 낮은 프로세스는 영원히 실행되지 않는 문제
이를 극복하기 위해 우선순위를 점진적으로 낮춰주는 aging 기법을 사용함

* RR (Round robin)
시간 조각(time quantum) 을 정의하여, 이 시간이 경과할 때마다 CPU를 선점하는 프로세스를 바꿈.
예를 들어, 시간 조각 q=4ms 이면, 4ms 동안 프로세스 A가 선점한 후, 다음 4ms 에는 프로세스 B가 선점.
일반적으로 CPU burst 시간의 80% 는 시간 조각보다 적어야 가장 바람직함.


3.2. 다중레벨 큐
여러 개의 큐를 사용한다.

큐 간 독자적인 스케쥴링 알고리즘을 사용한다.
프로세스는 여러 개의 큐간 이동하며 수행된다.
이 스케쥴링의 주 목표는 CPU burst 시간 특성이 다른 프로세스들을 분리하여,
굶주림과 호위 효과 현상을 제거하는 것이다.
예를 들어, 입출력 중심의 프로세스는 상위 큐에, CPU 중심의 프로세스는 하위 큐에 할당된다.
다음과 같은 사항을 고려하여, 다중레벨 큐를 만들 수 있다.
	큐의 개수
	각 큐의 스케쥴링 알고리즘
	aging 혹은 그 반대로 만드는 방법
	큐 이동 순서

``
## Memory structure
* Data; initialized
  - static variable, global variable
  - 프로그램이 종료 될 때까지 먼저 호출되고 남아 있습니다.  
      ^it is called first and remain until programs terminate 
  - -> it's fixed
  - BSS (Block Stated Symbol); uninitialized
* Stack(function): local variable, parameter, return, pointer variable
  - 모든 프로그램은 스택을 가지고 있다. 나중에 프로그램을 백업시키는데 도움을 준다.  
      ^ALl programs have stacks. It helps to go back
  - 밑에서 위로 저장된다.  
      ^from bottom to top
  - funcion이 호출되면 스택이 시작됩니다.  
      ^when the funcion is called, it starts to be stacked. (recursive)
  - 메모리가 할당되면 스택 영역을 확장해야합니다 (컴파일 시간)  
      ^when memory is allocated, stack area has to be extended(compile time)
  - 컴파일 될 때 스택 크기가 결정됩니다.  
      ^At compile time, stack size has to be decided
  - 함수가 종료되면 스택도 사라집니다.  
      ^if the function is terminated, stack is also deleted
  - -> it's static
  - 배열의 길이는 일정해야 합니다.  
      ^Array's length has to be a constant
  - 스택 사이즈는 고정입니다.  
      ^stack size is fixed
* Heap; dynamic(malloc, free)  C++: new()
  - 위에서 아래로 저장됩니다.  
      ^from top to bottom
  - 스택과 다르게 실행 시간에 데이터가 저장됩니다.  
    <> stack; running time 
* Text(Code); assembly code about function; function, statement, constant
* SMA(Static Memory Allocation): data, stack   | DMA(Dynamic Memory Allocation): Heap Area
* 스택과 힙은 반비례 관계이다.  
    ^Stack and heap are in inverse proportion
```

# 메모리 관리
* [블로그](https://dailyheumsi.tistory.com/137?category=855210)

```java
1.1. 주소 바인딩
코드에서 변수로 쓰이던 공간들이 실제 메모리에 매핑되는 동작을 '바인딩' 이라고 한다.
주소를 바인딩하는 시간은 다음과 같이 나뉜다.

컴파일 타임
로드 타임
실행 타임
1.2. Logical vs Physical Address
Logical Address (= Virtual Address)
​ CPU에 의해 생성되는 주소다. 즉 실제적인 물리주소와는 관련없고, 메모리에 적재되기 전 가지는 가상주소다.

Physical Address
​ 실제 메모리(RAM) 상에서의 주소다.

MMU (Memory Management Unit)
​ Logical Address 를 Physical Address 로 매핑시켜주는 하드웨어 장치다.
​ 예를 들어, base register 가 14000 이고, logical address 가 346이면, 실제 Physical Address 는 14346이 된다.

1.3. Static vs Dynamic Linking

Static Linking
​ 컴파일 타임에, 라이브러리 파일 전체가 오브젝트 파일에 복사된다.
​ 실행 파일의 크기가 비대해질 수 있다.
​ 또한 실행 시, 모든 코드가 로드된다.

Dynamic Linking
​ 런타임 중에 호출된 라이브러리 파일이 최초 한 번만, 메모리 공간에 적재된다.
​ 필요한 코드만 로드된다.
​ 또한 라이브러리 갱신에 용이하다.
```

```java
2. Swapping
프로세스 실행 도중, 일시적으로 주기억장치에서 보조기억장치로 옮겨진 후, 
나중에 다시 주기억장치에 로드할 수 있게한다. 이 과정을 스와핑이라 한다.

우선순위에 의해 발생되면 roll in, roll out 이라는 용어를 사용한다.

3. 메모리 할당
3.1. 연속적 할당
Fixed size
​ 메모리를 고정된 크기로 일정하게 나누어(파티션), 각각의 프로세스에게 할당한다.
​ 즉, 파티션의 개수가 곧 가능한 멀티 프로세스의 수(degree of multiprogramming) 와 같다.
​ 관리는 용이하나, 적절한 파티션의 크기를 잡기가 어렵고, 메모리 낭비도 심하다.
​ 지금은 안쓴다.

Variable size
​ Hole = 할당 가능한 메모리 블락
​ OS 는 할당한 파티션들과, 할당 가능한 파티션(hole) 둘 다 관리해야 한다.
​ Fixed Size 보다 훨씬 유연하지만, 이제 이슈는 여러 hole 들이 있을 때 프로세스를 어떻게 어디에 할당할 것인지에 대한 것이다.
​ 이에 다음과 같은 방법들이 있다.

First-fit
현재 hole 리스트 탐색 중, 프로세스가 들어갈 수 있는 첫 번째 hole 을 할당한다.

Best-fit
현재 hole 리스트 탐색 중 프로세스의 들어갈 수 있는 가장 작은 hole을 할당한다.

Worst-fit
현재 hole 리스트 중 그냥 제일 큰 hole 을 할당해준다.
그러나 Variable Size 방법은 여전히 최적화 문제가 있는데,
모든 프로세스들이 할당되지 않은 파티션들(holes)을 '최대한' 활용하지 못하는 문제가 생긴다.


즉, 위와 같이 메모리에 충분히 여유공간이 있는데, 모두 조각나(fragmentation) 있어, 
메모리 공간을 제대로 활용하지 못하는 상황이 발생한다.

Internal Fragmentation
OS는 프로세스가 요청한 메모리 공간보다 조금 더 많이 할당해주는데, 이 메모리 공간이 활용되지 않는다면, 이는 낭비다.

External Fragmentation
위 그림과 같은 상황으로, 활용가능한 메모리 공간이 연속적이지 않아서 사용할 수 없는 경우다.
보통 할당된 영역이 N개 이면, 0.5N 개의 영역이 fragmentation 으로 낭비된다.
이에 대한 해결책으로 compaction 이 있다.
이는, 현재 프로세스들의 메모리 공간을 재배치하여, fragmented 한 hole 들을 continuous 하게 만드는 방법이다. 하지만, 전체 프로세스들을 재배치한다는 점에서 오버헤드가 있다.

3.2. 비연속적 할당
Paging
Fragmentation 문제를 해결하기 위해서, 일정 크기의 단위로 나누어서 분산 적재하는 방법이다.
다음과 같은 방법을 사용한다.

- 물리적 기억장치를 고정된 크기로 나눈다. 이를 프레임이라 한다. (보통 4KB)
- 논리적 주소공간도 프레임과 같은 크기로 나눈다. 이를 페이지라 한다.
- 논리주소는 페이지 번호(number)와 오프셋(offset) 으로 구성한다.
- 별도의 페이지 테이블이 존재하여, 논리주소의 페이지 번호로 이 테이블에 접근한다.
- 페이지 테이블에는 각 페이지 번호에 매핑되는 물리주소 정보를 담고있다.
- 즉 실제주소는 페이지 테이블에 매핑되는 물리주소 + 오프셋으로 만들어진다.


예를들어, 32비트 페이지와 프레임의 크기가 4KB 라면, 한 프레임 내 1Byte 메모리블럭이 2^12 개 있는 것이다.
(근데 사실 하나의 32비트에서 하나의 명령어는 4Bytes 로 구성되어있으므로, 접근은 4Bytes 단위로 한다.
즉 접근은 4Bytes 단위지만, 주소는 1Byte 로 단위로 매핑되어 있음.)
그렇다면, 한 프레임 내에 2^12 개의 주소를 가질 수 있다는 뜻이고,
32비트 명령어안에 뒤에 12비트는 오프셋을 담는 위치가 된다.
그러면 나머지 20비트는 페이지 넘버의 영역이다.
즉 우리는 2^20개의 페이지 주소(공간) 을 갖는다!
정리하면, 다음과 같다.

논리 주소 공간의 크기가 2^m 이고,
페이지의 크기가 2^n 일 때,
=> 주소의 하위 n 비트는 오프셋, 상위 m-n 비트는 페이지 번호가 된다.

페이징을 사용하면, 외부 단편화는 일어나지 않지만 내부 단편화(Fragmentation)는 일어날 수 있다.
일반적으로, 프로세스마다 프레임의 절반크기 정도의 내부 단편화가 일어난다.


Page Table
페이지 테이블은 메인 메모리에 상주한다. 즉, 논리주소는 메모리 내 페이지 테이블을 거쳐, 
원래 목적 메모리 주소에 도달하게 되는, 즉 2번 메모리를 접근하여 명령어를 수행하게 된다.
메인 메모리의 모든 페이지 엔트리를 갖고있기 때문에, 사이즈가 메인 메모리에 비례하여 커진다.
한편, 논리주소에서 페이지 넘버는 페이지 테이블에서의 인덱스이기 때문에, 검색 비용이 들지 않는다.

페이지 테이블에는 모든 프레임에 대한 테이블을 기준으로 나누고 다음의 내용을 담는다.


각 프레임의 할당 여부
할당 되어있을 경우, 어떤 프로세스가 할당되어있는지
물리 메모리의 시작 주소
또, 각 프로세스마다 PCB 에 페이지 테이블을 가진다.
프로세스마다 독립적인 가상 공간이 주어지고, 필요한 물리적 메모리 공간과 매핑할 수 있어야하기 때문이다.
즉, 전역 메모리에 상주해있는 페이지 테이블은, 프로세스 단위로 메모리를 매핑하는 것이고,
각 프로세스 내 페이지 테이블은, 지역변수 등 코드 단위로 메모리를 매핑하는 것이다.
실질적으로 할당가능한 프레임 엔트리는 프레임 테이블이라는 애가 별도로 관리한다.

한편, PCB 내 페이지 테이블이 들어가므로, Context Switching 시 overhead 가 더 늘어난다..

페이징 시스템에서는 MMU 가 곧 페이지 테이블이 된다.
또한, 이런 페이징 시스템은 OS 가 하는 것이 아닌, 별도의 하드웨어에서 한다.

Paging 특징 정리
사용자/프로세스의 편의성
연속된 논리 주소 공간을 독립적으로 사용
MMU 에 의한 비교적 빠른 주소 변환
프레임 단위의 비연속적 메모리 할당
외부 단편화가 없음.
하지만 내부 단편화는 있음 (필수불가결).
CS 시 오버헤드 증가
공유 페이지를 통한 IPC 효율성 증가

```

# 가상 메모리
*   모든 프로세스는 자신만의 가상 주소 공간을 가지고 있다. 모든 프로세스들은 자신만의 주소 공간을 가지기 때문에, 특정 프로세스 내에서 쓰레드가 수행될 때 해당 쓰레드는 프로세스가 소유하고 있는 메모리에 대해서만 접근이 가능하다. (다른 프로세스에 의해 소유된 메모리는 접근 불가)
* 즉, 가상메모리는 프로세스의 물리 메모리와 논리 메모리를 분리하기 위해 생겨난 것이라 볼 수 있다. 이를 이용해서 논리 메모리가 물리 메모리보다 커지는 것을 가능케 한다. (램이 1gb인 컴퓨터에서 게임,포토샵,인터넷익스플로러를 동시에 실행할 수 있는 것이 가상메모리 덕분)
* 실제 각 프로세스마다 충분한 메모리를 할당하기에는 메모리 크기에 한계가 있음
* 운영체제에서 디스크 공간을 메모리처럼 활용할 수 있는 기능을 제공
* 디스크 상에 존재하는 이러한 파일을 paging file 이라고 한다.
	* 실제 메모리보다 많이 보이게 하는 기술
* 실제 사용하는 메모리는 작다는 점에 착안해서 고안된 기술
* 프로세스간 공간 분리로, 프로세스 이슈가 전체 시스템에 영향을 주지 않을 수 있음

## 가상 메모리 기본 아이디어
* 프로세스는 가상 주소를 사용하고, 실제 해당 주소에서 데이터를 읽고/쓸대만 물리 주소로 바꿔주면 된다.
* virtual address(가상주소) : 프로세스가 참조하는 주소
* physical address : 실제 메모리 주소

## MNU (Memory Management Unit)
* cpu에 코드 실행시, 가상 메모리 접근이 필요할 때, 해당 주소를 물리 주소값으로 변환해주는 하드웨어 장치

## [ 가상메모리 없을때 ]
* 프로세스 a,b가 4gb의 메모리를 점유한다고 가정하자. 가상메모리가 존재하지 않으면, 물리공간(6gb)메모리에 a가 필요한 메모리 4g를 할당 되면서, b는 공간이 모자라서 사용할 수 없게 된다.

##  가상메모리 존재]
* 프로세스 a,b,c,가 4gb의 메모리를 점유한다고 가정하자. process가 현재 사용되는 공간 만큼만 메모리에 넣어주면서, 물리 공간에 할당과 해제를 반복하는 과정을 거친다.


## 가상메모리가 필요한 이유
* 하나의 프로세스만 실행 가능한 시스템(배치 처리 시스템)에서는 크게 필요가 없다.

1. 프로그램을 메모리로 로드
2. 프로세스 실행
3. 프로세스 종료(메모리 해제)

* 여러 프로세스 동시 실행 시스템에서는 가상메모리가 필수적으로 필요하다.
1. 메모리 용량 부족 이슈
2. 프로세스 메모리 영역간에 침범 이슈

## 페이징(paging)
* 페이징 방식에서는 가상메모리상의 주소공간을 일정한 크기의 페이지로 분할하게 되는데 실제 메모리 또한 가상메모리와 같은 크기로 페이지를 분할한다.
* 페이지의 크기는 대부분 4Kbyte를 사용한다.
* 크기가 동일한 페이지로 가상 주소 공간과 이에 매칭하는 물리 주소 공간을 관리

## 페이지 테이블
* 가상 메모리의 페이지와 실제메모리의 페이지를 연결시켜주기 위한 매핑 테이블
* 가상메모리의 페이지넘버와 실제메모리의 페이지프레임을 하나의 순서쌍으로 정의하고 있는 도표
* 이러한 페이지 테이블이 메모리에 존재하면, 성능은 하락한다. 따라서 MMU라는 하드웨어를 통해 매핑을 시킨다. (MMU를 통해 맵핑작업을 수행해서, 메모리 접근 회수를 줄인다.)


## 페이징 시스템
* PCB에 Page Table 구조체를 가리키는 주소가 들어있다.
* Page Table에는 가상 주소와 물리주소간 매핑 정보가 있음
* Page Table에 접근할 수 있는 가장 위의 주소를 가지고 있다가, cpu가 가상 주소에 접근하려고 하면 페이지 테이블의 가장 위의 주소에 원하는 번호에 접근해서 실제 메모리 주소에 접근한다.

## 페이징 시스템 구조
* 페이지 또는 페이지 프레임 : 고정된 크기의 block(4kb)
* paging system
* 가상 주소 v = (p,d)
	* p : 가상 메모리 페이지 (페이지 번호)
	* d : p안에서 참조하는 위치 (변위)
* 페이지 크기가 4kb 예
	* 가상 주소의 0비트에서 11비트가 변위를 나타냄
	* 12비트 이상이 페이지 번호가 될 수 있음

## Log
* 이벤트 뷰어  
  ^Window: Event viewer(systemlog > application program)
* 파일 형식으로 되어 있음  
  Linux: 1. /var/log  2. History
* 소프트웨어 측면에서는 시스템 로그에 로그를 남길 수 있지만 시스템과 관련이없는 경우 파일에 로그를 남깁니다.  
  ^In terms of software, they can leave log on system log but if they are not related to system, they leave logs on files

## Linux, WIndow

### Regestry(regedit)
* 과거에 INI 파일은 각 프로그램의 구성을 저장하는 데 사용됐찌만 여기저기 퍼져 있었기 때문에 찾기가 어려워 레지스트리가 나왔다.  
    ^Back in the day, INI file is used to contain each programs' configuration. But it's hard to find because they are spread. That's why the registry came out.
* [1]('https://www.youtube.com/watch?v=_U78iAem3uo')
* [2]('http://editorizer.tistory.com/239')
* [3]('http://pastime0.tistory.com/66')
* File location
  - C:\Windows\System32\config
  - System Reserved\Boot\BCD
  - C:\Users\User_Account\NTUSER.DAT
* Registry <> Linux file
* 레지스트리는 하드웨어, 소프트웨어, 환경 설정 및 사용자에 대한 설정 및 옵션을 저장하는 데이터베이스입니다.  
    ^Registry is the database that stores settings and options for Hardware, Software, preferences and users
* 클래스 객체 : 그것이 나타내는 객체로 할 수있는 것을 정의하는 명명 된 함수 그룹  
    ^class object: a named group of functions that defines what you can do with the object it represents 
* Registry keys(similar to folders) and Registry values(files) are components
* HKey_LOCAL_MACHINE
  - SAM: security accounts manager
* HKEY_CURRENT_CONFIG
  - Current Hardware information
  - 런타임에 수집 된 정보가 포함되어 있습니다. 정보를 여기에 저장하면이 키는 영구적으로 디스크에 저장되지 않습니다.  
      ^It contains information gathered at runtime; information stored here, this key is not permantently stored on disk
* HKEY_CLASSES_ROOT
  - 파일 연결과 같은 등록 된 응용 프로그램에 대한 정보가 들어 있습니다.  
      ^contains information about registered applicatoins, such as file associations
* HKEY_CURRENT_USER
  - 현재 로그인 한 사용자에게 특정한 설정을 저장합니다.  
      ^stores settings that are specific to the currently logged-in user
* Type of registry
  - Binary data, String values, unsigned integers, symbolic links, multi-string values, resource list, resource descriptor, 64-bit integers
