# 프로세스
* 실행중인 프로그램
* 커널에 등록되고 커널의 관리하에 있는 작업
* 각종 자원들을 욫어하고 할당 받을 수 있는 개체
* 프로세스 관리 블록을 할당 받은 개체
* 능동적인 개체

# 쓰레드
* 프로세스 안에 존재하여, 프로세스의 자원을 공유하는 개체 흔히 경량 프로세스라고 부름 각 쓰레드는 별도의 레지스터와 스택을 갖고, 힙 영역은 공유.
## 스택을 쓰레드마다 독립적으로 할당하는 이유
* 쓰레드는 독립적인 작업을 수행해야 하기 때문에 각자의 스택과 PC 레지스터 값을 갖고 있다.
* 스택은 함수 호출 시 전달되는 인자, 되돌아갈 주소값 및 함수 내에서 선언하는 변수 등을
* 저장하기 위해 사용되는 메모리 공간이므로
* 스택 메모리 공간이 독립적이라는 것은
* 독립적인 함수 호출이 가능하다는 것이고
* 이는 독립적인 실행 흐름이 가능하게 한다.

## PC Resister를 쓰레드마다 독립적으로 할당하는 이유
* PC 값은 쓰레드가 명령어의 어디까지 수행하였는지를 나타나게 된다.
* 쓰레드는 CPU를 할당받았다가 스케줄러에 의해 다시 선점당한다.
* 그렇기 때문에 명령어가 연속적으로 수행되지 못하고 어느 부분까지 수행했는지 기억할 필요가 있다.

## 쓰레드는 프로세스보다 생성 및 종료시간, 쓰레드간 전환시간이 짧다.
* 쓰레드는 프로세스의 메모리, 자원등을 공유하므로 커널의 도움없이 상호간에 통신이 가능하다.

## 멀티 스레드, 멀티 프로세스 장단점
```java
Multi process
독립적으로 어떤 일을 수행하므로, 문제가 발생해도 다른 프로세스에 영향을 주지 않는다.
하지만, 프로세스 처리는 쓰레드와 비교했을 때 무겁다.
Context Switching 에서의 오버헤드
CS 가 일어날 때마다 PCB 를 통째로 캐시에 저장, 로드 해야함.
IPC 에서의 오버헤드
자원 공유가 번거롭고, 느림.
좀 더 가볍게 여러 테스크를 진행할 수 없을까?


Multi Threading
하나의 목적을 가지고 하는 일을 여러 개로 나눠서 병행처리해야할 경우 쓰레드를 쓰자.
Multi prcoess 와 비교했을 때, 다음과 같은 장점이 있다.
프로세스보다 메모리 사용가 적다. (Stack 만 할당하므로)
쓰레드간 데이터 통신이 빠르다. (Heap 을 공유, 접근 가능하므로)
수행 속도가 일반적으로 빠르다. (CS 시, Stack 영역만 처리하므로)
다음과 같은 단점이 있다.
쓰레드간 자원 공유에 대한 문제 (동기화, synchronization)
설계와 제어가 까다롭다.


출처: https://dailyheumsi.tistory.com/130?category=855210 [하나씩 점을 찍어 나가며]
```

## 1.3. User-level Thread vs Kernel-level Thread
* [블로그](https://dailyheumsi.tistory.com/130?category=855210)
```java
커널 레벨 쓰레드와 유저 레벨 쓰레드는 생성 주체가 누구냐에 따라 구분된다. (매우 헷갈림 주의)

* User-level Thread
프로그래머가 커널에 의존적이지 않게, 라이브러리를 통해 생성하는 쓰레드가 유저 레벨 쓰레드이다.
이렇게 생성된 쓰레드는, 커널에게는 보이지 않는다.
즉 커널은 프로세스 그 자체만 알지 , 내부의 유저 쓰레드는 모른다.
커널 스케쥴링의 기본 단위가 즉 프로세스 단위다.
커널이 전혀 관여하지 안고, 프로세스에서 관리한다.
즉, 프로세스가 자체적인 쓰레드 스케줄링을 가진다.
모드 변경이 필요없어 생성과 관리가 빠르다.
즉, 쓰레드간 CS 시, 커널 스케쥴러를 호출하지 않으므로, 오버헤드가 적다.
하지만, 프로세스 내 하나의 쓰레드가 커널에 의해 블록되면 해당 프로세스가 통째로 블록된다.
이를 해결하는 프로그래밍과 결과 예측이 매우 어렵다.

* Kernel-level Thread
프로그래머 요청에 따라 쓰레드를 생성하고 스케줄링하는 주체가 커널이면 커널 레벨 쓰레드라고 한다.
커널 스케쥴링의 기본 단위가 즉 프로세스 단위가 아닌, 쓰레드 단위다.
하나의 프로세스는 적어도 하나의 커널 쓰레드에게 관리된다.
단일 프로세스 = 1개의 쓰레드
하지만 유저 <-> 커널 모드 전환에서 오버헤드가 크다.
같은 프로세스 내 쓰레드 전환(유저 레벨)의 경우 CS 비용이 적지만,
다른 프로세스 간의 쓰레드 전환(커널 레벨)의 경우 이 비용이 크기 때문이다.
현대 대부분의 OS 는 이 방식을 채택

- 커널 레벨 쓰레드 장점 : 
안전성, 기능의 다양성 
단점 : 커널에서 기능을 제공하기 때문에 성능 저하 

- 유저레벨 쓰레드 장점 
전환 필요없기때문에 성능 좋음 
단점 : 프로세스 내에 쓰레드가 하나만 블로킹 되어도 나머지 쓰레드가 작동하기 어려움 


```

## . 다중 쓰레드 모델
```java
보통 운영체제는 유저레벨 쓰레드와 커널레벨 쓰레드 모두 제공한다.

다대일 (N-to-one) 모델
효율적이긴 하지만 한 스레드가 블락당할 경우 전체 프로세스가 봉쇄된다.
진정한 병렬성의 개념이 없다.


일대일 (One-to-one) 모델
다대일 보다 더 많은 병렬성을 제공한다.
많은 쓰레드가 생성됐을 시, CS 비용이 크다.


다대다 (N-to-M) 모델
위 두 모델의 문제점을 어느 정도 해결한 모델

```

## 쓰레드 동기화 방법의 종류
* Mutex / Semaphore / Monitor
* 공통점은 세가지 모두 운영체제의 동기화 기법이라는 것이다.

### 뮤텍스(Mutual Exclusion)
* 쓰레드의 동시 접근을 허용하지 않는다는 의미.
* 뮤텍스의 쓰레드 동기화 방법은 임계영역에 들어가기 위해 이 뮤텍스를 가지고 있어야 들어갈 수 있다.
* 예) 일종의 자물쇠와 같은 역할을 한다.
* 임계영역에 들어간 쓰레드가 뮤텍스를 이용해 임계영역에서 본인이 나올때까지 다른 쓰레드가 못들어오게 내부에서 자물쇠로 잠근다.

### 세마포어(Semaphore)
* 세마포어 역시 뮤텍스와 비슷한 역할을 하지만 세마포어는 동시 접근 동기화가 아닌 접근 순서 동기화에 더 관련있다.

### 모니터(Monitor)
* Mutex(Lock)와 Condition Variables(Queue라고도 함)을 가지고 있는 Synchronization 메카니즘이다.


### 전자(뮤텍스,모니터)는 상호 배제를 함으로써 임계구역에 하나의 쓰레드만 들어갈 수 있다.
* 후자(세마포어)는 하나의 쓰레드(binary semaphore)만 들어가거나
* 혹은 여러 개의 쓰레드(counting semaphore)가 들어가게 할 수도 있다.


### . 뮤텍스와 모니터의 차이는?
* 가장 큰 차이는 뮤텍스는 다른 프로세스(애플리케이션)간에 동기화를 위해 사용한다.
* 반면 모니터는 하나의 프로세스(애플리케이션)내에 다른 쓰레드 간에 동기화할 때 사용한다.
* 또한, 뮤텍스는 보통 운영체제 커널 의해서 제공되는 반면에 모니터는 프레임워크나 라이브러리 그 자체에서 제공된다.
* 따라서 뮤텍스는 무겁고(heavy-weight) 느리며(slower) 모니터는 가볍고(light-weight) 빠르다(faster).


### 세마포어와 모니터의 차이는?
* Java에서는 모니터를 모든 객체에게 기본적으로 제공하고 있는 반면 C에서는 모니터를 사용할 수 없다.
* 세마포어는 카운터라는 변수값으로 프로그래머가 상호 배제나 정렬의 목적으로 사용 시 매번 값을 따로 지정해줘야하는 등 조금 번거롭다.
* 반면, 모니터는 이러한 일들이 캡슐화 되어 있어서(encapsulation) 개발자는 카운터값을 1 또는 0으로 주어야 하는 고민을 할 필요 없이 synchronized, wait(), notify() 등의 키워드를 이용해 좀 더 편하게 동기화할 수 있다.


### 뮤텍스와 세마포의 차이는?
* 세마포어는 뮤텍스가 될 수 있지만 뮤텍스는 세마포어가 될 수 없다.
* 예를 들어 Casting을 한다고 보면
	* (뮤텍스)세마포어 –> 가능
	* (세마포어)뮤텍스 –> 불가능
* 세마포어는 소유할 수 없는 반면 뮤텍스는 소유할 수 있고 소유자가 이에 책임을 진다
* 뮤텍스는 1개만 동기화가 되지만 세마포어는 하나 이상을 동기화 할 수 있다.


```java
변기가 하나뿐인 화장실에서는 
앞의 사람이 볼일을 마치고 나가야 다음 사람이 들어갈 수 있다. 
이렇게 한번에 오직 하나만 처리할 수 있는 대상에 사용하는 것이 뮤텍스이다. 

변기가 세개인 화장실에서는 동시에 세 사람이 볼일을 볼 수 있고 
이 세 사람 중 아무나 한명이 나오면 다음 사람이 볼일을 볼 수 있다. 
이렇게 동시에 제한된 수의 여러 처리가 가능하면 세마포어이다. 

만약 변기 세개짜리 화장실의 각 변기에 대해 뮤텍스를 사용한다면 
대기중인 사람은 각 변기 앞에 줄을 서는 것이고 
이렇게 되면 옆 칸이 비어도 들어가지 못하게 된다. 

만약 변기 세개를 묶어서 뮤텍스를 사용한다면 
변기 수에 관계없이 무조건 한명만 사용할 수 있게 된다. 

이 예에서 변기는 동기화 대상, 사람은 그 동기화 대상에 접근하는 쓰레드를 나타낸다. 

뮤텍스와 세마포어의 목적은 특정 동기화 대상이 이미 특정 쓰레드에 의해 사용중일 경우 
다른 쓰레드가 해당 동기화 대상에 접근하는 것을 제한하는 것으로 동일하지만 
관리하는 동기화 대상이 몇개 인가에 따라 차이가 생기게 되는 것이다.
```



# 멀티 쓰레드
* 쓰레드 간의 통신이 필요한 경우에도 별도의 자원을 이용하는 것이 아니라 전역 변수의 공간 또는 동적으로 할당된 공간인 힙(Heap) 영역을 이용하여 데이터를 주고받을 수 있다.
* 그렇기 때문에 프로세스 간 통신 방법에 비해 쓰레드 간의 통신 방법이 훨씬 간단하다.
* 심지어 쓰레드의 문맥 교환은 프로세스 문맥 교환과는 달리 캐시 메모리를 비울 필요가 없기 때문에 더 빠르다.
* 따라서 시스템의 처리량이 향상되고 자원 소모가 줄어들어 자연스럽게 프로그램의 응답 시간이 단축된다.


## 쓰레딩의 문제점
* 멀티 프로세스 기반으로 프로그래밍할 때는 프로세스 간 공유하는 자원이 없기 때문에 동일한 자원에 동시에 접근하는 일이 없었지만
* 멀티 쓰레딩을 기반으로 프로그래밍할 때는 이 부분을 신경써줘야 한다. 서로 다른 쓰레드가 데이터와 힙 영역을 공유하기 때문에
* 어떤 쓰레드가 다른 쓰레드에서 사용중인 변수나 자료 구조에 접근하여 엉뚱한 값을 읽어오거나 수정할 수 있다. 그렇기 때문에 멀티쓰레딩 환경에서는 동기화 작업이 필요하다.
* 동기화를 통해 작업 처리 순서를 컨트롤 하고 공유 자원에 대한 접근을 컨트롤 하는 것이다.
* 하지만 이로 인해 병목 현상이 발생하여 성능이 저하될 가능성이 높다. 그러므로 과도한 락(lock)으로 인한 병목 현상을 줄여야 한다.
* 공유 자원이 아닌 부분은 동기화 처리를 할 필요가 없다. 즉, 동기화 처리가 필요한 부분에만 synchronized 키워드를 통해 동기화하는 것이다.
* 불필요한 부분까지 동기화를 할 경우 현재 쓰레드는 락(lock)을 획득한 쓰레드가 종료하기 전까지 대기해야한다. 그렇게 되면 전체 성능에 영향을 미치게 된다.
* 즉 동기화를 하고자 할 때는 메소드 전체를 동기화 할 것인가 아니면 특정 부분만 동기화할 것인지 고민해야 한다.



# 인터럽트
## 컴퓨터 시스템의 구조
 * 프로그램이 CPU에서 명령을 수행하려면 수행하려는 주소 영역이 메모리에 올라가 있어야 한다. 
 * 이 때 프로그램의 주소 영역은 크게 코드,데이터,스택 영역으로 구분된다.
 * 코드영역은 우리가 작성한 프로그램 함수들의 코드가 기계어 명령으로 변환되어 저장되는 부분이다.
 * 데이터 영역은 전역 변수 등 프로그램이 사용하는 데이터를 저장하는 부분이다.
 * 스택 영역은 함수가 호출될 때 호출된 함수의 수행을 마치고 복귀할 주소 및 데이터를 임시로 저장하는 데 사용되는 공간이다.
 * 일반적으로 프로그램 내에서 발생되는 함수 호출에 필요한 복귀 주소는 각 프로그램의 주소 공간 중 스택 영역에 보관한다.
 * 반면, 인터럽트 때문에 CPU를 선점당한 위치를 저장하기 위한 공간은 OS 커널 부분에 존재하게 된다.
 * OS는 현재 실행중인 모든 프로그램을 관리하기 위한 자료구조를 유지하고 있다.
    * 예를 들어 A,B 두 개의 프로그램이 현재 수행중이라면  커널 어딘가에 이 두 프로그램을 관리하기 위한 자료 구조가 존재한다.  이 자료 구조를 "프로세스 제어 블록(PCB)"라 부른다.


## 컨텍스트 스위칭
```JAVA
멀티프로세스 환경에서 CPU가 어떤 하나의 프로세스를 실행하고 있는 상태에서 인터럽트 요청에 의해 
다음 우선 순위의 프로세스가 실행되어야 할 때 기존의 프로세스의 상태 또는 레지스터 값(Context)을 저장하고
CPU가 다음 프로세스를 수행하도록 새로운 프로세스의 상태 또는 레지스터 값(Context)를 교체하는 작업을 
Context Switch(Context Switching)라고 한다.

질문에 대한 답변은 이정도로 하고 좀 더 명확하게 이해해본다.

* Context Switching을 문맥 교환으로 번역하지 말자.

Context는 무엇인가?

사용자와 다른 사용자, 사용자와 시스템 또는 디바이스간의 상호작용에 영향을 미치는 사람, 장소, 
개체등의 현재 상황(상태)을 규정하는 정보들을 말한다.

android나 servlet등에서도 context가 있지만 OS에서 Context는 CPU가 해당 프로세스를 실행하기 위한 해당 프로세스의 정보들이다.

이 Context는 프로세스의 PCB(Process Control Block)에 저장된다.

그래서 Context Switching 때 PCB의 정보를 읽어(적재) CPU가 전에 프로세스가 일을 하던거에 이어서 수행이 가능한 것이다.

PCB의 저장정보

- 프로세스 상태 : 생성, 준비, 수행, 대기, 중지

- 프로그램 카운터 : 프로세스가 다음에 실행할 명령어 주소

- 레지스터 : 누산기, 스택, 색인 레지스터

- 프로세스 번호

* 참고로 Context Switching 때 해당 CPU는 아무런 일을 하지 못한다. 따라서 컨텍스트 스위칭이 잦아지면 
오히려 오버헤드가 발생해 효율(성능)이 떨어진다.

Context가 뭔지 알았고 멀티프로세싱하기 위해 CPU를 나눠서 사용하기 위해 Context를 교체하는 것이 Context Switching임을 알았다.
그리고 PCB에 Context가 저장됨도 알았다.

남은 것은 인터럽트 요청이 뭐고 어떤 종류가 있는지 + 서브로 우선 순위에 대한 이야기다.

Context Switching - 인터럽트(Interrupt)

인터럽트는 CPU가 프로그램을 실행하고 있을 때 실행중인 프로그램 밖에서 예외 상황이 발생하여 처리가 필요한 경우 
CPU에게 알려 예외 상황을 처리할 수 있도록 하는 것을 말한다.



어떤 인터럽트 요청이 와야 Context Switching이 일어날까?

1. I/O request (입출력 요청할 때)

2. time slice expired (CPU 사용시간이 만료 되었을 때)

3. fork a child (자식 프로세스를 만들 때)

4. wait for an interrupt (인터럽트 처리를 기다릴 때)

+ 더 있겠지만 자세한 것은 생략.

* 우선 순위는 해당 OS의 스케줄러가 우선 순위 알고리즘에 의해 정해지고 수행하게 되어있다.

라운드로빈 스케줄링(Round Robin Scheduling)은 시분할 시스템을 위해 설계된 선점형 스케줄링의 하나다.

쉽게 설명하면 순서대로 시간단위(Time Quantum)을 CPU에 할당하는 방식이다.

꽤 효율적인 스케줄링 알고리즘이지만 이 시간단위를 작게 설정하면 CPU가 조금 일하고 Context Switching을 
반복하므로 아까 말했듯이 효율이 떨어진다.

* Context Switch를 하는 주체 = OS 스케줄러


```
## context switching
* 멀티프로세스 환경에서 CPU가 어떤 프로세스를 실행하고 있는 상태에서, interrupt 요청에 의해 다음 우선쉰위으 프로세스가 실행되야 할 때, 기존 프로세스의 상태 또는 레지스터 값을 저장하고 cpu가 다음 프로세스를 수행하도록 상태 또는 레지트서 값을 교체하는 작업이다. 컨텍스트 스위칭 작업간에 cpu는 아무 작업을 할 수 없다. 따라서 잦은 컨텍스트 스위칭으로 오버헤드가 발생해 효율이 낮아질 수 있다.

```java
CPU에 실행할 프로세스를 교체하는 기술 (Context Switching)
실행 중지할 프로세스 정보를 해당 프로세스의 PCB에 업데이트해서, 메인 메모리에 저장
다음 실행할 프로세스 정보를 메인 메모리에 있는 해당 PCB 정보를 CPU에 넣고, 실행
실행 중지할 프로세스 정보를 해당 프로세스의 PCB에 업데이트해서, 메인 메모리에 저장
다음 실행할 프로세스 정보를 메인 메모리에 있는 해당 PCB정보(PC,SP)를 CPU의 레지스터에 넣고, 실행
dispatch : ready상태의 프로세스를 running 상태로 바꾸는 것
컨텍스트 스위칭 시간이 오래 걸리면 운영체제 속도가 느려진다
실제로는 굉장히 짧은시간(ms) 단위로, 프로세스 스위칭이 일어남
```

### 컨텍스트 스위칭의 원리
* 프로세스 A가 실행이 될려면 스케쥴러에 프로세스가 들어가게 된다. 스케쥴러아 해당 status를 running으로 변경한다. 프로세스 A가 실행을 하다가 스케쥴러가 프로세스 B를 running status로 변경하는 것을 컨택스트 스위칭이라고 한다. (pc와 stack pointer가 핵심이다 !!)
* process A에서 process B로넘어갈때 현재의 컨텍스트를 PCB라는 별도의 저장공간을 만들어서 저장하고 운영체제가 관리한다. 프로세스 B실행중 스케쥴러에 의해 다시 Process A로 넘어오면 PCB를 읽어서 Context를 불러 와서 프로세스를 실행한다.


## PCB
* 프로그램 A가 수행중에 인터럽트가 발생하면 현재 실행중이던 지점을 A의 프로세스 제어 블록에 저장한 후 인터럽트 처리 루틴으로 가서 인터럽트 발생관련 일 처리를 한다. 인터럽트 처리를 모두 마치면  프로그램 A의 프로세스 제어 블록에 저장된 주소를 복원시켜 원래 수행하던 일을 재개하게 된다.

## 컴퓨터 시스템의 작동 개요 @ 스택
 * CPU를 컴퓨터의 두뇌라고 부르지만 CPU는 인간의 뇌처럼 스스로 생각하고 판단하는 능력을 갖추고 있지는 못하다.
 * 이는 CPU가 빠른 속도로 처리하는 계산 능력은 가지고 있지만, 어떠한 작업을 수행해야 하는지에 대해 스스로 결정하는 능력은 없기 때문이다.
 * CPU는 현재 수행해야 할 메모리 주소의 명령을 있는 그대로 처리할 뿐이다. 
 * 이 때, CPU가 수행해야 할 메모리 주소를 담고 있는 레지스터를 프로그램 카운터라고 부른다. 
 * 즉, CPU는 매번 프로그램 카운터가 가리키는 메모리 영역의 명령을 처리하게 된다.
 * 일반적으로 조건문, 반복문, 함수 호출 등에 의한 주소 이동이 없는 이상 프로그램 카운터는 
 * 바로 다음 주소의 명령을 가리키게 되어 코드의 순차적인 수행이 이루어진다.
* 메모리에는 사용자 프로그램 + OS 같이 올라가 수행된다.  이 때 CPU는 프로그램 카운터가 가리키는 메모리 위치의 프로그램을 수행하게 된다.
* if 프로그램 카운터가 메모리 주소 중 OS가 존재하는 부분을 가리킨다면 CPU가 커널 모드에서 수행중이라고 이야기한다. else CPU가 사용자 모드에서 수행중이라고 이야기한다.



## 프로세스의 상태  @ CPU 선점
 * 프로세스의 상태는 실행, 준비, 봉쇄의 세 가지로 크게 나누어 볼 수 있다.


## PCB
* os가 프로세스 관링 ㅔ필요한 정보 저장
* 프로세스 생성 시 생성됨

### 실행
 * CPU를 할당받고 기계어 명령을 수행하고 있는 프로세스의 상태이다.

### 준비 상태
 * CPU만 할당받으면 당장 명령을 수행할 수 있지만 CPU가 하나밖에 없어 현재 CPU를 할당받지 못한 프로세스의 상태이다.

### 봉쇄 상태
 * CPU를 할당받더라도 명령을 수행할 수 없는 프로세스의 상태이다. 
 * 프로세스가 요청한 입출력 작업이 진행중인 경우 CPU를 할당받더라도 입출력이 끝나기전까지 작업을 진행할 수 없기 때문에 CPU를 할당하지 않는다.


### 준비 상태에 있는 프로세스가 실행 상태로 변경되는 경우
 * 실행 상태에 있던 프로세스가 입출력 요청 등으로 봉쇄 상태가 되거나 또는 실행 상태에 있던 프로세스의 CPU 할당 시간이 만료되어 타이머 인터럽트가 발생한 경우를 들 수 있다.
 * OS는 준비 상태에 있는 프로세스들을 줄 세우기 위해 준비 큐(Ready Queue)를 두고 
 * 준비 큐의 제일 앞에 있는 프로세스에게 CPU를 할당한다. 
 * 준비 큐에 프로세스를 줄 세우는 방법은 CPU 스케줄링 방법에 따라 달라진다.

### OS는 특정 자원을 기달리는 프로세스들을 줄 세우기 위해 자원별로 큐를 두고 있다.
* 예를 들어 디스크에 입출력 서비스를 요청한 프로세스들은 
 * 디스크 입출력 큐(Dist I/O Queue)에 줄 서게 된다.
 * 그러면, 디스크 컨트롤러는 디스크 입출력 큐에 줄 서 있는 순서대로 프로세스들의 입출력 작업을 수행하게 된다.
 * 프로세스별 입출력 작업이 완료되면 디스크 컨트롤러가 CPU에게 인터럽트를 발생시키고, 
 * 그러면 인터럽트 처리 루틴에 의해 디스크 입출력이 완료된 프로세스는 입출력 큐에서 빠져나와
 * CPU를 기다리는 준비 큐에 줄 서게 된다.


## 위에서 언급된 큐는 HW 자원을 기다리는 프로세스들을 줄 세우기 위한 것이었다. 
* 이와 같은 큐는 SW 자원을 기다리는 경우에도 필요하다.
 * 예를 들어 데이터에 대한 접근 권한은 SW 자원으로 분류될 수 있다.
 * 어떠한 프로세스가 공유 데이터를 사용하고 있는 도중에 
 * 다른 프로세스가 같은 데이터를 접근하면 데이터에 대한 일관성이 훼손될 수 있다.
 * 따라서, 공유 데이터는 매 시점 하나의 프로세스만이 접근할 수 있도록 해야 한다.
 * 이 때 접근한다는 의미가 반드시 CPU가 그 데이터를 사용하고 있다는 의미는 아니다.
 * 공유 데이터를 접근중인 프로세스가 "준비 상태"나 "봉쇄 상태로" 변경된 경우에도
 * 새롭게 CPU를 할당받은 프로세스가 동일한 데이터를 접근하게 되면
 * 데이터의 일관성이 깨질 수 있으므로 접근을 허락해서는 안 된다.
 * 즉, 공유 데이터라는 일종의 SW 자원을 앞서 접근중인 프로세스가 다 사용하고 반날할 때까지는
 * 다른 프로세스가 CPU를 할당 받았다 하더라도 접근하지 않고 기다려야 하는 것이다.
 * 여러 프로세스가 공유 데이터를 동시에 접근하려고 할 경우 공유 데이터를 기다리는 "큐"에 줄 서게 하여
 * 현재 그 데이터를 사용중인 프로세스가 데이터를 반납하기 전까지는 접근을 못하게 하고,
 * 반납할 경우 큐에 줄 서 있는 순서대로 데이터의 접근 권한을 주는 방법을 사용하게 된다.
* 위 그림처럼 프로세스의 상태 관리는 커널의 주소 영역 중 데이터 영역에 다양한 큐를 두어 이루어지게 된다.
* 각 프로세스들이 CPU를 기다리는지, 입출력을 기다리는지 등의 정보를 커널이 총체적으로 관리하고 있다는 뜻이다.

### 예시
 * 예를 들어 타이머 인터럽트가 발생하면
 * 커널은 자신의 데이터 영역에 있는 준비 큐의 정보를 참조해
 * 다음에 어느 프로세스에게 CPU를 할당할지 결정하고
 * 현재 실행되던 프로세스는 준비 큐의 제일 뒤로 보내게된다.
 * // 준비 큐는 CPU를 할당받기 위해 기다리는 큐이므로
 * // 어떤 프로세스에게 CPU를 할당할지 결정하려면 준비 큐를 봐야한다.
 * // 타이머 인터럽트이기 때문에 "봉쇄 상태"가 아니라 준비 큐의 가장 마지막에 재삽입하는 것이다.
 * // 입출력 요청이였을 시에는 "봉쇄 상태"로 빠져 준비 큐에 들어가지 못하게 된다.


## 프로세스의 두 가지 실행 상태
* 하나의 프로세스가 시작되어 수행을 완료하기까지는 프로세스 자신의 주소 공간에 있는 코드만 실행되는 것이 아니라 커널의 주소 공간에 있는 코드도 실행된다.
* 이는 프로그램이 사용자 정의 함수나 라이브러리 함수뿐 아니라 입출력 시스템 콜 등을 통해 OS 커널의 함수도 호출하여 실행하기 때문이다.

### 예시
 * 예를 들어 프로세스 A가 CPU에서 실행되고 있다고 하면
 * 이는 자신의 주소 공간에 정의된 코드를 실행하는 것과
 * 커널의 시스템 콜 함수를 실행하는 것으로 나누어 볼 수 있다.
 * 전자를 사용자 모드에서의 실행 상태(User mode Running)이라 하고,
 * 후자를 커널 모드에서의 실행 상태(Kerner mode Running)라고 한다.
 * 한 가지 주의할 점은 시스템 콜이 수행되는 동안
 * 프로세스 A의 코드가 아니라 OS 커널의 코드이지만
 * 커널이 실행 상태에 있다고 하지 않고
 * 프로세스 A가 실행 상태에 있다고 말한다.
 * 프로세스 A 입장에서는 CPU를 OS 커널에게 빼앗긴 것으로 생각할 수도 있지만
 * 커널의 코드가 실행되는 것이 사실상 프로세스 A가 해야 할 일을 대행하는 것이기 때문에
 * 시스템 콜이 실행중일 때에도 여전히 프로세스 A는 실행 상태에 있는 것으로 간주한다.
 * 다만, 프로세스 A 자신의 코드를 실행하는 것과 구분지어
 * 이러한 상태를 프로세스 A가 커널 모드에서 실행중이라고 이야기한다.


### 정리
 * 정리하자면, 프로그램이 시작되어 종료될 때까지 다양한 함수 호출을 하며 실행되는데, 
 * 이를 사용자 모드와 커널 모드의 실행 상태로 구분 지을 수 있다.
 * 프로그램이 사용자 정의 함수나 라이브러리 함수를 호출할 때에는 모드의 변경없이 사용자 모드에서의 실행을 하게 되며, 
 * 시스템 콜을 하는 경우에는 커널 모드로 진입해 커널의 주소 공간에 정의된 함수를 실행하게 된다. 
 * 시스템 콜의 실행이 끝나면 다시 사용자 모드로 복귀해서 시트템 콜 이후의 명령들을 계속 실행하게 된다. 
 * 프로그램의 실행이 끝날 때에는 커널 모드로 진입해 프로그램을 종료하게 된다.

# Process
* 프로그램을 운영하는 기초 단위  
    ^basuc unit of running program
* Concurrent
* Code, Stack, Heap, Data
* Stack:  

# 프로세스
- https://bowbowbow.tistory.com/16 
- 프로그램 -> 실행 내용 -> 프로세스 -> 중앙처리장치(CPU)
- 프로그램은 일반적으로 하드 디스크 등에 저장되어 있는 실행코드를 뜻하고, 프로세스는 프로그램을 구동하여 프로그램 자체와 프로그램의 상태가 메모리 상에서 실행되는 작업 단위를 지칭한다. 예를 들어, 하나의 프로그램을 여러 번 구동하면 여러 개의 프로세스가 메모리 상에서 실행된다.
- 프로세스와 프로그램의 차이는 정말 명확합니다. 프로그램자체는 생명이 없습니다. 프로그램은 보조 기억장치(하드디스크, SSD)에 존재하며 실행되기를 기다리는 명령어(코드)와 정적인 데이터의 묶음입니다. 이 프로그램의 명령어와 정적 데이터가 메모리에 적재되면 생명이 있는 프로세스가 됩니다.

## 프로세스의 정의
* 커널에 등록되고 커널의 관리하에 있는 작업
* 각종 자원들을 요청하고 할당 받을 수 있는 개체
* 프로세스 관리 블록을 할당받은 개체
* 능동적인 개체(실행 중에 각종 자원을 요구, 할당, 반납하여 진행)

## 코드가 프로세스가 되는 과정
* 먼저, 하나의 코드가 프로그램이 되고, 프로그램이 프로세스가 되는 과정은 다음과 같다.
* 코드 작성 -- (컴파일) --> 오브젝트 파일 -- (링킹) --> 실행 파일(=프로그램) -- (로드) --> 메모리 적재 및 수행(=프로세스)
* [출처]['https://dailyheumsi.tistory.com/137?category=855210 [하나씩 점을 찍어 나가며]']

```java
컴파일러
​ 사용자가 작성한 원시코드를 컴퓨터가 읽을 수 있는 형태의 오브젝트 파일로 만드는 프로그램

어셈블러
​ 어셈블리어 코드를 기계어 코드로 변환시켜주는 프로그램.
​ 명확히 말하면, 어셈블러는 큰 의미 컴파일러 내부에 속한다.
​ 큰 의미의 컴파일러는 사실 다음과 같이 구성된다.
​ (원시 코드) -> (컴파일러) -> (어셈블리어 코드) -> (어셈블러) -> (기계어 코드 = 오브젝트 코드)

링커
​ 프로그램이 되기 위해 여러 개의 오브젝트 파일과 라이브러리를 엮는 과정(링킹)을 수행하는 프로그램

로더
​ 사용자가 프로그램을 실행하면, 메모리에 적재하는 일(로드)을 수행하는 프로그램


```

## 프로세스가 접근할 수 있는 메모리 공간
- 이 주소 공간은 Text, Data, BSS, Heap, Stack 영역으로 구성됩니다. 아래 그림에서 각 영역에 프로그램의 어떤 정보를 저장하는지 나타냈습니다.
- Text: 기계어; Data: 초기화된 전역 변수, static 변수, BSS: 초기화되지 않은 전역 변수, static 변수, Heap: malloc으로 동적 할당된 변수   stack: 지역 변수




## PCB
- 프로세스에 대한 정보는 프로세스 제어블록(PCB, Process Control Block)또는 프로세스 기술자(process descriptor)라고 부르는 자료구조에 저장됩니다. 대부분 PCB라고 부릅니다. 이 자료구조 크게 다음과 같은 정보를 담고있습니다. 
- 운영체제가 각 프로세스를 식별하기 위해 부여된 프로세스 식별번호(PID, Process IDentification)입니다.
- CPU는 프로세스를 빠르게 교체하면서 실행하기 때문에 실행중인 프로세스도 있고 대기 중인 프로세스도 있습니다. 그런 프로세스의 상태를 저장합니다.
- CPU가 다음으로 실행할 명령어를 가리키는 값입니다. CPU는 기계어를 한 단위씩 읽어서 처리하는데 프로세스를 실행하기 위해 다음으로 실행할 기계어가 저장된 메모리 주소를 가리키는 값입니다.
- 운영체제는 여러개의 프로세스를 동시에 실행하는 환상을 제공합니다. 운영체제가 여러 개의 프로세스가 CPU에서 실행되는 순서를 결정하는 것을 스케줄링이라고 합니다. 이 스케줄링에서 우선순위가 높으면 먼저 실행될 수 있는데 이를 스케줄링 우선순위라고 합니다.
- 프로세스가 접근할 수 있는 자원을 결정하는 정보입니다. 안드로이드 앱을 예로 들면 아무 앱이나 휴대폰 통화내역을 볼 수 있는 권한을 가지면 이를 악의적으로 이용하는 앱이 등장하겠죠? 그래서 프로세스마다 어디까지 접근할 수 있는지에 대한 권한이 필요합니다.
- 최초로 생성되는 init 프로세스를 제외하고 모든 프로세스는 부모 프로세스를 복제해서 생성되고 이 계층관계는 트리를 형성합니다. 그래서 각 프로세스는 자식 프로세스와 부모프로세스에 대한 정보를 가지고 있습니다.
 
 * 출처: https://bowbowbow.tistory.com/16 [멍멍멍]

## 프로세스의 상태
- 생성(create) : 프로세스가 생성되는 중이다.
- 실행(running) : 프로세스가 CPU를 차지하여 명령어들이 실행되고 있다.
- 준비(ready) : 프로세스가 CPU를 사용하고 있지는 않지만 언제든지 사용할 수 있는 상태로, CPU가 할당되기를 기다리고 있다. 일반적으로 준비 상태의 프로세스 중 우선순위가 높은 프로세스가 CPU를 할당받는다.
- 대기(waiting) : 보류(block)라고 부르기도 한다. 프로세스가 입출력 완료, 시그널 수신 등 어떤 사건을 기다리고 있는 상태를 말한다.
- 종료(terminated) : 프로세스의 실행이 종료되었다.

##상태전이
- 디스패치(dispatch)
- 준비 리스트의 맨 앞에 있던 프로세스가 CPU를 점유하게 되는 것, 즉 준비 상태에서 실행 상태로 바뀌는 것을 디스패치라고 하며 다음과 같이 표시한다.
- dispatch (processname) : ready → running

- 보류(block)
- 실행 상태의 프로세스가 허가된 시간을 다 쓰기 전에 입출력 동작을 필요로 하는 경우 프로세스는 CPU를 스스로 반납하고 보류 상태로 넘어 간다. 이것을 보류라고 하며 다음과 같이 표시한다.
- block (processname) : running → blocked

- 깨움(wakeup)
- 입출력 작업 종료 등 기다리던 사건이 일어났을 때 보류 상태에서 준비 상태로 넘어가는 과정을 깨움이라고 하며 다음과 같이 표시한다.
- wakeup (processname) : blocked → ready



- 시간제한(timeout)
- 운영체제는 프로세스가 프로세서를 계속 독점해서 사용하지 못하게 하기 위해 clock interrupt를 두어서 프로세스가 일정 시간동안만 (시분할 시스템의 time slice) 프로세서를 점유할 수 있게 한다
- timeout(processname) : running -> ready


## Process Creation
* [블로그](https://dailyheumsi.tistory.com/129?category=855210)
```java
Process Creation
현재 프로세스에서 새로운 프로세스를 생성하거나 실행시키는 경우, 2가지 구현 방법이 있다.
모두 OS에서 제공해주는 시스템 콜(System call) 로 fork() 와 exec() 이다.

3.1. fork()
fork() 는 OS가 새로운 메모리 공간을 할당하도록 한 후, 현재 프로세스의 코드와 정보를 
모두 새로운 메모리 공간에 복사하도록 한다. 즉, 현재 실행중인 프로세스와 동일한 프로세스 하나를 더 만드는 셈이다.
프로세스는 결과적으로 1개에서 2개가 되는 셈이다.


핵심은 다음과 같다.

1) `fork()` 를 하면, 현재 프로세스의 자식 프로세스를 생성한다.  
2) 이 때, 반환 값이 0이면 자식이고, 0보다 크면 부모 프로세스를 의미한다. (즉 자식 프로세스를 pid 로 구분해야함)  
3) 부모 프로세스를 그대로 복사하여 생성하기 때문에, PC(프로그램 카운터)도 그대로 가져간다.
즉 자식 프로세스는 `fork()` 이 시점부터 프로그렘이 실행된다. 한편 저장되어있던 지역변수 등 모두 동일하다.

3.2. exec()
exec() 는 OS가 현재 프로세스의 공간에 새로운 프로세스를 덮어쓰게 한다.
예를 들어, execl("/bin/ls", "ls") 와 같이 했다면, 이 명령어를 담고있는 프로세스에 해당 프로그램 /bin/ls 를 실행시킨다.
즉, /bin/ls 이 성공했으므로, 뒤에 수행되는 코드들은 모두 덮혀버린다.
프로세스는 결과적으로 그대로 1개인 셈이다.

자세한 내용은 아래 링크 참조.

```

## process termination
```java
Process Termination
일반적으로, 프로세스가 마지막 명령어(코드) 를 수행하면 OS에게 삭제해달라는 exit() 요청을 하게된다.
다만, 이 때 자식 프로세스가 아직 실행중인 경우, 부모 프로세스는 OS에 의해 wait 명령을 받아 wait 상태에 있게 된다.
이후, 모두 완료되면 OS가 할당했었던 메모리를 회수해간다.

보통 부모 프로세스가, 자식 프로세스보다 먼저 삭제되는 경우, OS는 이를 비정상적인 상황이라 인지하고 
해당 부모의 자식 프로세스도 모두 삭제시키는데, 이를 Cascading Termination 이라 한다.


4.1. Zombie vs Orphan Process
Zombie Process
실행이 완료된 프로세스임에도, 여전히 프로세스 테이블에 남아있는 (지워지지 않은) 프로세스를 말한다.
이러한 프로세스가 발생하는 이유는 다음과 같다.
부모 프로세스는 자식 프로세스의 실행이 끝난 뒤의 상태(status) 를 받기 위해 계속 wait(&status) 하고 있는다.
자식 프로세스는 실행이 끝나고 exit status 로 상태를 바꾼 뒤, 
이를 부모 프로세스에게 전달하고, 부모가 전달받을 때까지 기다린다.
이 기다리는 동안, (부모 프로세스가 자식 프로세스를 회수해가지 않는 동안) 메모리 공간을 잡아먹지는 않지만, 
프로세스 테이블에는 남아있으므로 일종의 Zombie 상태가 된다.
여하튼, 종료된 프로세스임에도 프로세스 테이블에 남아있는 것은 좋지않으므로,
부모 프로세스에서 반드시 wait(&status) 를 통해, 자식 프로세스의 종료상태를 읽어야 한다.

Orphan Process
자식 프로세스가 종료되기 전에, 부모 프로세스가 먼저 지워진 자식 프로세스를 말한다.
이러한 프로세스가 발생하는 이유는 부모 프로세스 실행 중, 비정상적인 종료 혹은 wait() 을 하지 않았기 때문이다.
Orphan Process 는 OS에 의해 Init Process 가 부모로 할당된다.


```



## IPC (Inter-Process Communication)
* 프로세스간 통신하는 방법에는 다음과 같은 방법이 있다.
```java

5.1. Shared Memory
일반적으로 프로세스들은 메모리에서 각자의 독립된 공간을 보장받는다. 
즉 어떤 프로세스가 다른 프로세스의 메모리 영역에 접근할 수 없도록 OS가 설계되어져 있다.
하지만, Shared Memory 를 OS 에게 요청하면, 프로세스의 해당 영역은 다른 프로세스와 공유할 수 있는 공간이 된다.
프로세스간 통신에서 가장 빠르게 작동하는 방법이다.
다만, 동기화를 직접 해줘야 한다는 것, 메모리 공간을 직접 제어해줘야한다는(생성, 삭제) 단점이 있다.

5.2. Message passing
위 그림에서도 보이듯, 기본적으로 큐 형태를 취하기 때문에, 동기화 제어가 쉽게 가능하다.
다만, 동시에 Shared Memory 보다 통신 속도가 느리다.
대표적으로 아래와 같이 3가지 구현 형태가 있다.

1) Pipe
OS 에서 제공하는 pipe buffer 로, 한 프로세스에서 다른 프로세스로 통신하는, 단 방향 통신 방법이다.
ex. ps -aux | grep root | tail 에서 | 가 pipe 다.

2) Named Pipe
mkfifo() 라는 시스템 콜로 이름이 있는 파이프를 만들어 통신한다.
이전의 Pipe (익명 Pipe 라고 한다.) 는 통신을 할 프로세스를 명확히 아는 경우
(이를 테면 부모와 자식 프로세스 간)에만 사용 가능하지만, 
Named Pipe의 경우, 파이프의 이름을 통해 통신에 접근하기 때문에, 모든 프로세스 간에 통신이 가능하다.
하지만 여전히 Pipe 의 특성상, 읽기/쓰기가 동시에 가능하지 않으며, 따라서 일반적으로 읽기용 Pipe, 쓰기용 Pipe, 이렇게 2개를 사용한다.

3) Message Queue
커널에서 관리하는 큐를 통해 프로세스간 통신한다.
Named Pipe 처럼 일종의 식별자를 통해 각 프로세스마다 필요한 자료에 접근하게 된다.
Named Pipe 와 다른 점은, Pipe 는 단방향인데 반해, Queue는 양방향이라는 점, 메모리 공간에 할당된다는 점 등이 다르다.



출처: https://dailyheumsi.tistory.com/129?category=855210 [하나씩 점을 찍어 나가며]

```

## shared memory
```java
모든 프로세스는 자신의 업무를 수행하기 위해서 필요한 자료를 저장하기 위한 메모리 공간을 가지게 된다. 
이러한 메모리공간에는 CPU에 의해 수행되는 명령어들, 프로그램 시작시 정의되고 초기화된 데이터, 
프로그램 시작시 정의되었지만 초기화되지 않은 데이터, 함수호출에 필요한 정보, 동적할당이 이루어지는 데이터 등이 들어가게 된다.

 

프로세스는 시작시 혹은 실행중에 이러한 데이터를 저장하고 사용하기 위한 메모리공간을 커널에 요구하여서 
할당 받아 사용하게 되는데, 이러한 메모리 공간은 기본적으로 메모리를 요청한 프로세스만이 접근가능하도록 
되어 있다. 하지만 가끔은 여러개의 프로세스가 특정 메모리공간을 동시에 접근해야할 필요성을 가질때가 있을 것이다. 
공유메모리를 이러한 작업을 위한 효율적인 방법을 제공한다.

 

공유메모리는 여러 IPC 중에서 가장 빠른 수행속도를 보여준다. 그 이유는 하나의 메모리를 공유해서 접근하게 되므로, 
데이터 복사와 같은 불필요한 오버헤드가 발생하지 않기 때문으로, 빠른 데이터의 이용이 가능하다.

 

그러나 하나의 프로세스가 메모리에 접근중에 있을때, 또 다른 프로세스가 메모리에 접근하는 일이 
발생하면 자칫 데이터가 훼손될 수 있을 것이므로, 한번에 하나의 프로세스가 메모리에 접근하고 있다는 
걸 보증해 줄 수 있어야 할 것이다.  

 

공유메모리는 어떻게 할당되는가

 

공유메모리의 생성요청은 최초 공유 메모리 영역을 만드는 프로세스가 커널에 공유메모리 공간의 할당을 
요청함으로써 이루어지며, 만들어진 공유메모리는 커널에 의해서 관리되게 된다. 이런 이유로 한번 만들어진 
공유메모리는 운영체제를 재부팅하거나, 직접 공유메모리공간을 삭제 시켜주지 않는 한, 공유메모리를 사용하는 
모든 프로세스가 없어졌다 하더라도 계속적으로 유지되게 된다.

 

프로세스가 커널에게 공유메모리 공간을 요청하게 되면, 커널은 공유메모리 공간을 할당시켜주고 
이들 공유메모리공간을 관리하기 위한 내부자료구조를 통하여, 이들 공유메모리를 관리하게 된다.
```

## 프로세스간 커뮤니케이션
```java
IPC 기법 이지만, 이외에도 많이 사용되는 두 가지 기술이 있다.

1. 시그널
2. 소켓


1. 시그널(signal)
유닉스에서 30년이상 사용된 전통적인 기법
커널 또는 프로세스에서 다른 프로세스에 어떤 이벤트가 발생되었는지를 알려주는 기법
프로세스 관련 코드에 관련 시그널 핸들러를 등록해서, 해당 시그널 처리 실행

시그널 무시
시그널 블록(블록을 푸는 순간, 프로세스에 해당 시그널 전달)
등록된 시그널 핸들러로 특정 동작 수행
등록된 시그널 핸들러가 없다면, 커널에서 기본 동작 수행

주요 시그널
SIGKILL : 프로세스를 죽여라
SIGALARM : 알람을 발생한다
SIGSTOP : 프로세스럴 멈춰라
SIGCONT : 멈춰진 프로세스를 실행해라
SIGINT : 프로세스에 인터럽트를 보내서 프로세스를 죽여라
SIGSEGV : 프로세스가 다른 메모리영역을 침범했다.


2. 소켓(socket)
소켓은 네트워크 통신을 위한 기술
기본적으로는 클라이언트와 서버등 두 개의 다른 컴퓨터간의 네트워크 기반 통신을 위한 기술
소켓을 하나의 컴퓨터 안에서, 두 개의 프로세스간에 통신 기법으로 사용 가능
```

