# 메모리 관리
* [블로그](https://dailyheumsi.tistory.com/137?category=855210)
* [정아마추어](https://jeong-pro.tistory.com/91?category=793347)

# 페이지 계산
* [페이지 계산](https://eduon.com/itembank/itemlist/11/1308/#page-2)

```java
메모리 크기가 200KB인 시스템에서 요구 페이징(demand paging)으로 
가상 메모리(virtual memory)를 구현한다고 하자. 페이지 크기가 2KB이고
페이지 테이블(page table)의 각 항목이 3바이트라고 하면, 
25KB 크기의 프로세스를 위한 최소 페이지 테이블의 크기는 어떻게 되는가?
①	25바이트	 	②	39바이트
③	60바이트		④	75바이트

 페이지 크기가 2KB이고, 프로세스의 크기가 25KB이므로 25KB / 2KB = 12.5가 되어 13개의 페이지가 필요
∙ 페이지 테이블(page table)의 각 항목이 3바이트라고 하였으므로 13개의 페이지 정보를 표현하기 위해서는 13 * 3바이트 = 39바이트
따라서 25KB 크기의 프로세스를 위한 최소 페이지 테이블의 크기는 39바이트



가상메모리(Virtual Memory)를 효과적으로 제공하기 위해 Core i7과 같은 프로세서 내부에 있는 장치는 무엇인가?
① TLB(Translation Lookaside Buffer)
② 캐시(Cache)
③ 페이지 테이블(Page Table)
④ 스왑 스페이스(Swap Space)

TLB(Translation Lookaside Buffer, 변환 색인 버퍼)
∙ 가상 메모리 주소를 물리적인 주소로 변환하는 속도를 높이기 위해 사용되는 캐시
∙ 최근에 일어난 가상 메모리 주소와 물리 주소의 변환 테이블을 저장하기 때문에 일종의 주소 변환 캐시라고 할 수 있음
∙ CPU와 CPU 캐시 사이, CPU 캐시와 메인 메모리 사이 등 여러가지 다른 레벨의 캐시들 사이에서 주소를 변환하는데 사용

```
```java
42. OS의 가상기억장치 관리에서 프로세스가 일정 시간동안 자  4번
주 참조하는 페이지들의 집합을 의미하는 것은?
① Thrashing ② Deadlock
③ Locality ④ Working Set
```

# LRU
* [LRU Page Fault](https://eduon.com/itembank/itemlist/11/1023/#page-2)


# 메모리
```java

1.2. Logical vs Physical Address
Logical Address (= Virtual Address)
​ CPU에 의해 생성되는 주소다. 즉 실제적인 물리주소와는 관련없고, 메모리에 적재되기 전 가지는 가상주소다.

Physical Address
​ 실제 메모리(RAM) 상에서의 주소다.

MMU (Memory Management Unit)
​ Logical Address 를 Physical Address 로 매핑시켜주는 하드웨어 장치다.
​ 예를 들어, base register 가 14000 이고, logical address 가 346이면, 실제 Physical Address 는 14346이 된다.

1.3. Static vs Dynamic Linking

Static Linking
​ 컴파일 타임에, 라이브러리 파일 전체가 오브젝트 파일에 복사된다.
​ 실행 파일의 크기가 비대해질 수 있다.
​ 또한 실행 시, 모든 코드가 로드된다.

Dynamic Linking
​ 런타임 중에 호출된 라이브러리 파일이 최초 한 번만, 메모리 공간에 적재된다.
​ 필요한 코드만 로드된다.
​ 또한 라이브러리 갱신에 용이하다.
```

```java
2. Swapping
프로세스 실행 도중, 일시적으로 주기억장치에서 보조기억장치로 옮겨진 후, 
나중에 다시 주기억장치에 로드할 수 있게한다. 이 과정을 스와핑이라 한다.

우선순위에 의해 발생되면 roll in, roll out 이라는 용어를 사용한다.

3. 메모리 할당
3.1. 연속적 할당
Fixed size
​ 메모리를 고정된 크기로 일정하게 나누어(파티션), 각각의 프로세스에게 할당한다.
​ 즉, 파티션의 개수가 곧 가능한 멀티 프로세스의 수(degree of multiprogramming) 와 같다.
​ 관리는 용이하나, 적절한 파티션의 크기를 잡기가 어렵고, 메모리 낭비도 심하다.
​ 지금은 안쓴다.

Variable size
​ Hole = 할당 가능한 메모리 블락
​ OS 는 할당한 파티션들과, 할당 가능한 파티션(hole) 둘 다 관리해야 한다.
​ Fixed Size 보다 훨씬 유연하지만, 이제 이슈는 여러 hole 들이 있을 때 프로세스를 어떻게 어디에 할당할 것인지에 대한 것이다.
​ 이에 다음과 같은 방법들이 있다.

First-fit
현재 hole 리스트 탐색 중, 프로세스가 들어갈 수 있는 첫 번째 hole 을 할당한다.

Best-fit
현재 hole 리스트 탐색 중 프로세스의 들어갈 수 있는 가장 작은 hole을 할당한다.

Worst-fit
현재 hole 리스트 중 그냥 제일 큰 hole 을 할당해준다.
그러나 Variable Size 방법은 여전히 최적화 문제가 있는데,
모든 프로세스들이 할당되지 않은 파티션들(holes)을 '최대한' 활용하지 못하는 문제가 생긴다.


즉, 위와 같이 메모리에 충분히 여유공간이 있는데, 모두 조각나(fragmentation) 있어, 
메모리 공간을 제대로 활용하지 못하는 상황이 발생한다.

Internal Fragmentation
OS는 프로세스가 요청한 메모리 공간보다 조금 더 많이 할당해주는데, 이 메모리 공간이 활용되지 않는다면, 이는 낭비다.

External Fragmentation
위 그림과 같은 상황으로, 활용가능한 메모리 공간이 연속적이지 않아서 사용할 수 없는 경우다.
보통 할당된 영역이 N개 이면, 0.5N 개의 영역이 fragmentation 으로 낭비된다.
이에 대한 해결책으로 compaction 이 있다.
이는, 현재 프로세스들의 메모리 공간을 재배치하여, fragmented 한 hole 들을 continuous 하게 만드는 방법이다. 하지만, 전체 프로세스들을 재배치한다는 점에서 오버헤드가 있다.

3.2. 비연속적 할당
Paging
Fragmentation 문제를 해결하기 위해서, 일정 크기의 단위로 나누어서 분산 적재하는 방법이다.
다음과 같은 방법을 사용한다.

- 물리적 기억장치를 고정된 크기로 나눈다. 이를 프레임이라 한다. (보통 4KB)
- 논리적 주소공간도 프레임과 같은 크기로 나눈다. 이를 페이지라 한다.
- 논리주소는 페이지 번호(number)와 오프셋(offset) 으로 구성한다.
- 별도의 페이지 테이블이 존재하여, 논리주소의 페이지 번호로 이 테이블에 접근한다.
- 페이지 테이블에는 각 페이지 번호에 매핑되는 물리주소 정보를 담고있다.
- 즉 실제주소는 페이지 테이블에 매핑되는 물리주소 + 오프셋으로 만들어진다.


예를들어, 32비트 페이지와 프레임의 크기가 4KB 라면, 한 프레임 내 1Byte 메모리블럭이 2^12 개 있는 것이다.
(근데 사실 하나의 32비트에서 하나의 명령어는 4Bytes 로 구성되어있으므로, 접근은 4Bytes 단위로 한다.
즉 접근은 4Bytes 단위지만, 주소는 1Byte 로 단위로 매핑되어 있음.)
그렇다면, 한 프레임 내에 2^12 개의 주소를 가질 수 있다는 뜻이고,
32비트 명령어안에 뒤에 12비트는 오프셋을 담는 위치가 된다.
그러면 나머지 20비트는 페이지 넘버의 영역이다.
즉 우리는 2^20개의 페이지 주소(공간) 을 갖는다!
정리하면, 다음과 같다.

논리 주소 공간의 크기가 2^m 이고,
페이지의 크기가 2^n 일 때,
=> 주소의 하위 n 비트는 오프셋, 상위 m-n 비트는 페이지 번호가 된다.

페이징을 사용하면, 외부 단편화는 일어나지 않지만 내부 단편화(Fragmentation)는 일어날 수 있다.
일반적으로, 프로세스마다 프레임의 절반크기 정도의 내부 단편화가 일어난다.


Page Table
페이지 테이블은 메인 메모리에 상주한다. 즉, 논리주소는 메모리 내 페이지 테이블을 거쳐, 
원래 목적 메모리 주소에 도달하게 되는, 즉 2번 메모리를 접근하여 명령어를 수행하게 된다.
메인 메모리의 모든 페이지 엔트리를 갖고있기 때문에, 사이즈가 메인 메모리에 비례하여 커진다.
한편, 논리주소에서 페이지 넘버는 페이지 테이블에서의 인덱스이기 때문에, 검색 비용이 들지 않는다.

페이지 테이블에는 모든 프레임에 대한 테이블을 기준으로 나누고 다음의 내용을 담는다.


각 프레임의 할당 여부
할당 되어있을 경우, 어떤 프로세스가 할당되어있는지
물리 메모리의 시작 주소
또, 각 프로세스마다 PCB 에 페이지 테이블을 가진다.
프로세스마다 독립적인 가상 공간이 주어지고, 필요한 물리적 메모리 공간과 매핑할 수 있어야하기 때문이다.
즉, 전역 메모리에 상주해있는 페이지 테이블은, 프로세스 단위로 메모리를 매핑하는 것이고,
각 프로세스 내 페이지 테이블은, 지역변수 등 코드 단위로 메모리를 매핑하는 것이다.
실질적으로 할당가능한 프레임 엔트리는 프레임 테이블이라는 애가 별도로 관리한다.

한편, PCB 내 페이지 테이블이 들어가므로, Context Switching 시 overhead 가 더 늘어난다..

페이징 시스템에서는 MMU 가 곧 페이지 테이블이 된다.
또한, 이런 페이징 시스템은 OS 가 하는 것이 아닌, 별도의 하드웨어에서 한다.

Paging 특징 정리
사용자/프로세스의 편의성
연속된 논리 주소 공간을 독립적으로 사용
MMU 에 의한 비교적 빠른 주소 변환
프레임 단위의 비연속적 메모리 할당
외부 단편화가 없음.
하지만 내부 단편화는 있음 (필수불가결).
CS 시 오버헤드 증가
공유 페이지를 통한 IPC 효율성 증가

```

# 메모리의 종류
* SW가 관리(OS): 보조 기억장치 - 메인 메모리 
- HW가 관리(CPU): 캐시 - 레지스터

# 메모리 계층구조
## 블락
* 보조기억장치와 주기억장치 사이의 데이터 전송 단위
* 사이즈: 1-4KB

## 워드
* 주 기억장치와 레지스터 사이의 데이터 전송 단위
* 사이즈: 16-64 bits

# 1.1. 주소 바인딩
* 프로그램의 논리 주소를 실제 메모리의 물리 주소로 매핑하는 작업
* 코드에서 변수로 쓰이던 공간들이 실제 메모리에 매핑되는 동작을 '바인딩' 이라고 한다.
* 주소를 바인딩하는 시간은 다음과 같이 나뉜다.

## Binding 시점에 따른 구분
```java
컴파일 타임
로드 타임
실행 타임
```

```java
소스코드 
-> 컴파일러(컴파일 타임)
-> 오브젝트 모듈 
-> 링커 -> 로드 모듈 -> 로더 (로드 타임)
-> In-memory binary image(실행 타임)
```

## 컴파일 타임 바인딩
* 프로세스가 메모리에 적재될 위치를 컴파일러가 알 수 있는 경우(위치가 변하지 않음)
* 프로그램 전체가 메모리에 올라가야 함

## 로드타임 바인딩
* 메모리 적재 위치를 컴파일 시점에서 모르면, 대체 가능한 상대주소를 생성
* 적재시점에 시작 주소를 반영하여 사용자 코드 상의 주소를 재설정
* 프로그램 전체가 메모리에 올라가야 함

## 런타임 바인딩
* Address binding을 수행시간까지 연기
	* 프로세스가 수행 도중 다른 메모리 위치로 이동할 수 있음
* HW의 도움이 필요하다
	* MMU
* 대부분의 OS가 


# 다이나믹 로딩
* 모든 루틴을 교체 가능한 형태로 디스크에 저장
* 실제 호출 전까지는 루틴을 적재하지 않음
	* 메인 프로그램만 메모리에 적재하여 수행
	* 루틴의 호출 시점에 address binding 수행

## 장점
* 메모리 공간의 효율적 사용

# Swapping
* 프로세서 할당이 끝나고 수행 완료 된 프로세스는 swap-device로 보내고(Swap-out)
* 새롭게 시작하는 프로세스는 메모리에 적재한다.(Swap-in)



# 연속 할당(Continuous Memory Allocation)
* Uni-programming
* Multi-programming
	* Fixed partition(FPM)
		* 고정 분할
	* Variable partition(VPM)
		* 가변 분할

## Continous allocation Address Mapping
* 상대 주소: 프로그램의 시작 주소를 0으로 가정한 주소
* 재배치: 메모리 할당 후 할당된 주소에 따라 상대 주소들을 조정하는 작업


## 연속 할당 정의
* 프로세스를 하나의 연속된 공간에 할당하는 정책
	* 프로그램, 데이터, 스택 등

## 메모리 구성 정책
* 메모리에 동시에 올라갈 수 있는 프로세스 수
* 각 프로세스에게 할당되는 메모리 공간 크기
* 메모리 분할 방법


## Uni-programming
* 하나의 프로세스만 메모리 상에 존재
* 가장 간단한 메모리 관리 기법

## Uniprogramming 문제점
1. 프로그램의 크기 > 메모리 크기
2. 커널 보호
	* 프로그램을 올릴 때 커널을 침범하여 올리면 안된다.
3. Low system resource utilization / Low System perfomance

## 해결법
1. Overlay Structure
	* 메모리에 현재 필요한 영역만 적재
	* 사용자가 프로그램의 흐름 및 자료구조를 모두 알고 있어야 함
2. 경계 레지스터(boundary register) 사용
3. Multi programming

## Multi-programming
### Fixed Partition Multiprogramming
* 메모리 공간을 고정된 크기로 분할(미리 분할되어 있음)
* 각 프로세스는 하나의 분할에 적재
	* 프로세스:파티션 = 1:1
* 파티션의 수 = K
	* Multiprogramming degree = K


### Fixed Partition Multiprogramming의 단점
* Internal/external fragmentation


# Non-continuous allocation
* 사용자 프로그램을 여러 개의 block으로 분할
* 실행 시 필요한 bloeck 들만 메모리에 존재
	* 나머지 block들은 swap device에 존재
* 기법들
	* Paging System
	* Segmentation System
	* Hybrid paging/segmentation system

## NonContinous allocation Address Mapping
* Virtual address(가상주소) = relative address
	* Logical address(논리 주소
	* 연속된 메모리 할당을 가정한 주소
* Real address(실제 주소) = absolute(physical)
	* 실제 메모리에 적재된 주소
* Address Mapping
	* Virtual address를 real address

## Block Mapping
* 사용자 프로그램을 block 단위로 분할/관리
	* 각 block에 대한 address mapping 정보 유지
* Virtual address: v=(b,d)
	* b = block number
	* d = displacement(offset) in a block
* Blcok map table(BMT)
	* Address mapping 정보 관리
		* Kernel 공간에 프로세스마다 하나의 BMT를 가짐
	* Residence bit: 해당 블록이 메모리에 적재되었는지 여부

### Block Mapping 과정
1. 프로세스의 BMT에 접근
2. BMT에서 block b에 대한 항목을 찾음
3. Residence bit 검사
	3-1. Residence bit = 0경우 swap device에서 해당 블록을 메모리로 가져옴, BTM 업데이트 이후 3-2 단계 수행
	3-2. REsidence bit=1 경우, BMT에서 b에 대한 real address 값 a 확인
4. 실제 주소 r계산( r = a + d)
5. r을 이용하여 메모리에 접근

# 단편화
```JAVA
메모리 단편화

 - RAM에서 메모리의 공간이 작은 조각으로 나뉘어져 사용가능한 메모리가 충분히 존재하지만 할당(사용)이 
 불가능한 상태를 보고 메모리 단편화가 발생했다고 한다.

메모리 단편화는 내부 단편화와 외부 단편화로 구분 가능하다.

내부 단편화(Internal Fragmentation)

메모리를 할당할 때 프로세스가 필요한 양보다 더 큰 메모리가 할당되어서 프로세스에서 사용하는 메모리 공간이 낭비 되는 상황

* 예를 들어 메모장을 켰는데 OS가 4kb를 할당해줬다. 그런데 사실상 1kb만큼만 사용하고 있을 때 필요 이상으로
프로세스가 메모리를 할당받았으므로 내부 단편화가 3kb만큼 생긴 것임.

외부 단편화(External Fragmentation)

메모리가 할당되고 해제되는 작업이 반복될 때 작은 메모리가 중간중간 존재하게 된다. 이 때 중간중간에 생긴 
사용하지 않는 메모리가 많이 존재해서 총 메모리 공간은 충분하지만 실제로 할당할 수 없는 상황

* 예를 들어 메모리 처음 주소에 8mb짜리 프로세스가 할당되었고 바로 이어서 16mb짜리 프로세스가 할당되었다고 
가정했을 때 8mb짜리 프로세스를 종료시키면 메모리 처음 주소부터 8mb만큼 공간이 생긴다.

이런 식으로 계속해서 빈 메모리가 쌓이는데 예를 들어서 빈 메모리의 공간중에 제일 큰 빈 메모리가 8mb라고 한다면
9mb짜리 프로세스를 할당을 해야할 때 마땅한 공간은 없지만 전체적으로 메모리 여유는 있을 때 외부단편화가 생겼다고 한다.

메모리 파편화 문제 해결 방법

1. 페이징(Paging)기법 - 가상메모리사용, 외부 단편화 해결, 내부 단편화 존재

보조기억장치를 이용한 가상메모리를 같은 크기의 블록으로 나눈 것을 페이지라고 하고 RAM을 페이지와 
같은 크기로 나눈 것을 프레임이라고 할 때,

페이징 기법이란 사용하지 않는 프레임을 페이지에 옮기고, 필요한 메모리를 페이지 단위로 프레임에 옮기는 기법.

페이지와 프레임을 대응시키기 위해 page mapping과정이 필요해서 paging table을 만든다.

페이징 기법을 사용하면 연속적이지 않은 공간도 활용할 수 있기 때문에 외부 단편화 문제를 해결할 수 있다.

대신 페이지 단위에 알맞게 꽉채워 쓰는게 아니므로 내부 단편화 문제는 여전히 있다.

* 페이지 단위를 작게하면 내부 단편화 문제도 해결할 수 있겠지만 대신 page mapping 과정이 많아지므로 오히려 효율이 떨어질 수 있다. 

2. 세그멘테이션(Segmentation)기법 - 가상메모리사용, 내부 단편화 해결, 외부 단편화 존재

페이징기법에서 가상메모리를 같은 크기의 단위로 분할했지만 세그멘테이션기법에서는 가상메모리를 
서로 크기가 다른 논리적 단위인 세그먼트로 분할해서 메모리를 할당하여 실제 메모리 주소로 변환을 하게 된다.

각 세그먼트는 연속적인 공간에 저장되어 있다.

세그먼트들의 크기가 다르기 때문에 미리 분할해 둘 수 없고 메모리에 적재될 때 빈 공간을 찾아 할당하는 기법이다.

마찬가지로 mapping을 위해 세그먼트 테이블이 필요하다.

(각 세그먼트 항목별 세그먼트 시작주소와 세그먼트의 길이 정보를 가지고 있음)

프로세스가 필요한 메모리 만큼 할당해주기 때문에 내부단편화는 일어나지 않으나 여전히 중간에 프로세스가
메모리를 해제하면 생기는 구멍, 즉 외부 단편화 문제는 여전히 존재한다.

3. 메모리 풀(Memory Pool)

필요한 메모리 공간을 필요한 크기, 개수 만큼 사용자가 직접 지정하여 미리 할당받아 놓고 필요할 때마다 사용하고 반납하는 기법

메모리 풀 없이 동적할당과 해제를 반복하면 메모리의 랜덤한(실제로는 알고리즘에 의한) 위치에 할당과 해제가 반복되면서 
단편화를 일으킬 수 있겠지만 미리 공간을 할당해놓고 가져다 쓰고 반납하기 때문에 할당과 해제로 인한 외부 단편화가 발생하지 않는다.

또한 필요한 크기만큼 할당을 해놓기 때문에 내부 단편화 또한 생기지 않는다.

하지만 메모리 단편화로 인한 메모리 낭비량보다 메모리 풀을 만들었지만 쓰지 않았을 때 메모리 양이 커질 경우 사용하지 않아야 한다.

메모리의 할당, 해제가 잦은 경우에 메모리 풀을 쓰면 효과적이다.

미리 할당해놓고 사용하지 않는 순간에도 계속 할당해놓으므로 메모리 누수가 있는 방식이다.



구현 방법

- 큰 메모리 블록(페이지)을 힙으로 부터 할당

- 할당 받은 페이지를 각 객체의 크기의 블록으로 나눔

- 각 객체를 위한 블록을 순차적으로 링크

- 이 때 현 시점에서 할당할 블록을 특정 포인터가 가리키게 함

- 메모리 요청이 생기면 현재 헤더 포인터가 가리키는 블록을 돌려준다.

- 할당이 일어난 후 헤더 포인터는 할당 직전에 가리키던 블록이 가리키던 블록을 가리킨다.

- 사용되던 메모리가 해제되어 메모리 풀로 돌아올 경우 헤더 포인터는 그 블록을 가리키고 
방금 전까지 헤더 포인터가 가리키던 블록을 돌아온 블록의 다음 포인터가 가리키게 한다.
```


# [Thrashing]( https://jwprogramming.tistory.com/56)
```java
Thrashing(쓰레싱)

- 메모리 영역에 접근하게 될 때, 메모리에 페이지 부재(=페이지 폴트(Page fault)율이 높은 것을 의미하며, 심각한 성능 저하를 초래합니다.

- 활발하게 사용되는 페이지 집합을 지원해 줄 만큼 프레임이 충분히 할당 받지 못한 프로세스는 페이지 폴트(Page fault)가 발생하게 됩니다.


이 때, 페이지 교체가 필요하지만 이미 활발히 사용되는 페이지들만으로 이루어져 있으므로 어떤 페이지가 교체되던 바로 다시 페이지 교체가 필요하게 될 것입니다.

결과적으로 바로바로 반복해서 페이지 폴트가 발생하며, 교체된 페이지는 또 다시 얼마 지나지 않아 읽어올 필요가 생기게 됩니다. 이렇게 과도한 페이징
작업을 Thrasing(쓰레싱) 이라 합니다.



(쓰레싱의 원인)

1) 다중 프로그래밍 정도가 높아짐에 따라 CPU이용률이 높아지게 되고, CPU이용률이 최대값에 도달했을 때, 다중 프로그래밍의 정도가 그 이상으로 
커지게 되면 쓰레싱이 일어나게 되고 CPU이용률은 급격히 떨어집니다.



2) 운영체제는 CPU이용률을 감시하며, CPU이용률이 너무 낮아지면 새로운 프로세스를 시스템에 추가하여 다중 프로그래밍의 정도를 높이게 됩니다. 
이 때 전역 페이지 교체 알고리즘을 사용하여 어떤 프로세스의 페이지인지에 대한 고려없이 교체를 수행하게 됩니다.

그런데, 교체된 페이지들이 해당 프로세스에서 필요로 하는 것이었다면 그 프로세스 역시 페이지 폴트를 발생시키고 또 다른 프로세스에서 프레임을 가져옵니다.

이러한 프로세스들이 페이지 스왑 인, 스왑 아웃을 위해 페이징 장치를 사용해야 하는데, 이 장치에 대한 Queueing 이 진행되며 Ready-Queue는 비게 됩니다.


 
프로세스들이 페이징 장치를 기다리는 동안 CPU이용률은 떨어지게 되고, CPU 스케줄러는 이용률이 떨어지는 것을 보고 높이기 위하여 새로운 프로세스를 
추가하여 다중 프로그래밍의 정도를 더 높입니다.

새로 시작하는 프로세스는 실행중인 프로세스들로부터 프레임을 가져오고자 하며, 더 많은 페이지 폴트와 더 긴 페이징 대기시간을 야기하게 됩니다.

결과적으로  CPU이용률은 더 떨어지게 되며, CPU스케줄러는 다중 프로그래밍의 정도를 더 높이려 하게 되어 쓰레싱이 일어나게 됩니다. 따라서 시스템 
처리율은 상당히 낮아지고 페이지 폴트는 늘게되어 실질적인 메모리에 접근하는 시간은 증가하고 프로세스들은 페이징 하는데에 시간을 소비하게 되어 
아무런 일도 할 수 없는 상태가 됩니다.



[다중 프로그래밍의 정도]

쓰레싱은 지역교환 알고리즘이나 우선순위 교환 알고리즘을 사용해 제한할 수 있습니다.

-> 지역교환 알고리즘 하에서는 한 프로세스가 쓰레싱을 유발하더라도 다른 프로세스로부터 프레임을 뺏어 올 수 없으므로 다른 프로세스는 쓰레싱에서 자유로울 수 있습니다.



(쓰레싱 현상 방지)

: 각 프로세스가 필요로 하는 최소한의 프레임 갯수를 보장해주어야 합니다.



출처: https://jwprogramming.tistory.com/56 [개발자를 꿈꾸는 프로그래머]
```



# Variable Partition Multipprogramming
* Continuous Memory Allcation
* 초기에는 전체가 하나의 영역
* 프로세스를 처리하는 과정에서 메모리 공간이 동적으로 분할
* no internal fragmentation

## 배치 전략(Placement strategies)
## 최초 적합(First-fit)
* 충분한 크기를 가진 첫 번째 Partition을 선택
* simple and low overhead
* 공간 활용률이 떨어질 수 있다.

## 최적 적합(Best-fit)
* Process가 들어갈 수 있는 partition 중 가장 작은 곳 선택
* 탐색 시간이 오래 걸림, 모든 partition을 살펴봐야 함
* 크기가 큰 partition을 유지할 수 있음
* 작은 크기의 partition이 많이 발생
	* 활용하기 너무 작다.
	
## 최악 적합(Worst-fit)
* process가 들어갈 수 있는 파지션 중 가장 큰 곳 선택
* 탐색 시간이 오래 걸림(모든 파티션을 살펴봐야 함)
* 작은 크기의 파티션 발생을 줄일 수 있음
* 큰 크기의 파티션 확보가 어려움

## 순차 최초 적합(Next-fit)
* 최초 적합 전략과 유사
* Stable table에서 마지막으로 탐색한 위치부터 탐색
* 메모리 영역의 사용 빈도 균등화
* Low Overhead

## 공간 통합(Coalescing holes)
* 인접한 빈 영역을 하나의 파티션으로 통합
* 프로세스가 메모리를 release하고 나가면 수행
* low overhaead

## 메모리 압축(Storage Compaction)
* 모든 빈 공간을 하나로 통합
* 프로세스 처리에 필요한 적재 공간 확보가 필요할 때 사용(한쪽에 모아둠)
* High overhead
	* 모든 프로세스 재배치(이때 프로세스 중지)
	* 많은 시스템 자원을 




# 비연속할당





# 가상 메모리
*   모든 프로세스는 자신만의 가상 주소 공간을 가지고 있다. 모든 프로세스들은 자신만의 주소 공간을 가지기 때문에, 특정 프로세스 내에서 쓰레드가 수행될 때 해당 쓰레드는 프로세스가 소유하고 있는 메모리에 대해서만 접근이 가능하다. (다른 프로세스에 의해 소유된 메모리는 접근 불가)
* 즉, 가상메모리는 프로세스의 물리 메모리와 논리 메모리를 분리하기 위해 생겨난 것이라 볼 수 있다. 이를 이용해서 논리 메모리가 물리 메모리보다 커지는 것을 가능케 한다. (램이 1gb인 컴퓨터에서 게임,포토샵,인터넷익스플로러를 동시에 실행할 수 있는 것이 가상메모리 덕분)
* 실제 각 프로세스마다 충분한 메모리를 할당하기에는 메모리 크기에 한계가 있음
* 운영체제에서 디스크 공간을 메모리처럼 활용할 수 있는 기능을 제공
* 디스크 상에 존재하는 이러한 파일을 paging file 이라고 한다.
	* 실제 메모리보다 많이 보이게 하는 기술
* 실제 사용하는 메모리는 작다는 점에 착안해서 고안된 기술
* 프로세스간 공간 분리로, 프로세스 이슈가 전체 시스템에 영향을 주지 않을 수 있음

## 가상 메모리 기본 아이디어
* 프로세스는 가상 주소를 사용하고, 실제 해당 주소에서 데이터를 읽고/쓸대만 물리 주소로 바꿔주면 된다.
* virtual address(가상주소) : 프로세스가 참조하는 주소
* physical address : 실제 메모리 주소

## MNU (Memory Management Unit)
* cpu에 코드 실행시, 가상 메모리 접근이 필요할 때, 해당 주소를 물리 주소값으로 변환해주는 하드웨어 장치

## [ 가상메모리 없을때 ]
* 프로세스 a,b가 4gb의 메모리를 점유한다고 가정하자. 가상메모리가 존재하지 않으면, 물리공간(6gb)메모리에 a가 필요한 메모리 4g를 할당 되면서, b는 공간이 모자라서 사용할 수 없게 된다.

##  가상메모리 존재]
* 프로세스 a,b,c,가 4gb의 메모리를 점유한다고 가정하자. process가 현재 사용되는 공간 만큼만 메모리에 넣어주면서, 물리 공간에 할당과 해제를 반복하는 과정을 거친다.


## 가상메모리가 필요한 이유
* 하나의 프로세스만 실행 가능한 시스템(배치 처리 시스템)에서는 크게 필요가 없다.

1. 프로그램을 메모리로 로드
2. 프로세스 실행
3. 프로세스 종료(메모리 해제)

* 여러 프로세스 동시 실행 시스템에서는 가상메모리가 필수적으로 필요하다.
1. 메모리 용량 부족 이슈
2. 프로세스 메모리 영역간에 침범 이슈

## 페이징(paging)
* 페이징 방식에서는 가상메모리상의 주소공간을 일정한 크기의 페이지로 분할하게 되는데 실제 메모리 또한 가상메모리와 같은 크기로 페이지를 분할한다.
* 페이지의 크기는 대부분 4Kbyte를 사용한다.
* 크기가 동일한 페이지로 가상 주소 공간과 이에 매칭하는 물리 주소 공간을 관리

## 페이지 테이블
* 가상 메모리의 페이지와 실제메모리의 페이지를 연결시켜주기 위한 매핑 테이블
* 가상메모리의 페이지넘버와 실제메모리의 페이지프레임을 하나의 순서쌍으로 정의하고 있는 도표
* 이러한 페이지 테이블이 메모리에 존재하면, 성능은 하락한다. 따라서 MMU라는 하드웨어를 통해 매핑을 시킨다. (MMU를 통해 맵핑작업을 수행해서, 메모리 접근 회수를 줄인다.)


## 페이징 시스템
* PCB에 Page Table 구조체를 가리키는 주소가 들어있다.
* Page Table에는 가상 주소와 물리주소간 매핑 정보가 있음
* Page Table에 접근할 수 있는 가장 위의 주소를 가지고 있다가, cpu가 가상 주소에 접근하려고 하면 페이지 테이블의 가장 위의 주소에 원하는 번호에 접근해서 실제 메모리 주소에 접근한다.

## 페이징 시스템 구조
* 페이지 또는 페이지 프레임 : 고정된 크기의 block(4kb)
* paging system
* 가상 주소 v = (p,d)
	* p : 가상 메모리 페이지 (페이지 번호)
	* d : p안에서 참조하는 위치 (변위)
* 페이지 크기가 4kb 예
	* 가상 주소의 0비트에서 11비트가 변위를 나타냄
	* 12비트 이상이 페이지 번호가 될 수 있음


# [메모리 풀 종류](https://brunch.co.kr/@leedongins/78)
```java
비 페이징 풀(Nonpaged Pool)
메모리 풀은 운영 체제 및 장치 드라이버가 데이터 구조를 저장하는 데 사용하는 메모리 리소스 역할을합니다. 메모리 풀은 비 페이징 풀과 
페이징 풀로 구성되어 있습니다. 비 페이징 풀은 가상화된 메모리를 사용하지 않고 항상 실제 메모리를 사용하는 메모리 풀을 의미합니다. 


메모리 풀 관리자는 시스템의 가상 주소 공간 영역을 사용하여 커널 모드에서 작동합니다. 커널 및 장치 드라이버는 시스템이 페이지 폴트를 다룰수 없는 
상황에서도 접근할수 있는 데이터를 저장하기 위해 항상 실제 메모리에 물리적으로 존재하는 비 페이징 풀을 사용합니다. 비 페이징 풀에 저장된 일반적인 
시스템 데이터 구조에는 프로세스 및 스레드를 나타내는 커널 및 개체, 뮤텍스, 세마포어 및 이벤트와 같은 동기화 개체, 파일 개체로 표시되는 파일 참조 
및 I / O 요청 패킷 (IRP)이 포함됩니다. 



비 페이징 풀의 경우 운영체제가 제한하는 범위는 아래와 같습니다. MS 개발자 센터 바로가기

32bit 운영체제인 경우

XP, Server 2003:  램이 1.2GB 이하인 경우 32MB에서 256 MB, 램이 1.2GB 넘으면 256MB 까지 

Vista, Server 2008, Windows 7, Server 2008 R2: 시스템 제공 범위의 75% 또는 2GB 까지

Windows 8, Server 2012: 시스템 제공 범위의 75% 또는 2GB 까지



64bit 운영체제인 경우

XP, Server 2003: 128MB 까지

Vista, Server 2008, Windows 7, Server 2008 R2: RAM 또는 128GB 까지

Windows 8.1 and Windows Server 2012 R2: RAM 또는 15.5TB 중 작은 값



페이징 풀(Paged Pool)
페이징 풀은 가상화된 메모리를 사용할 수 있다는 점에서 비 페이징 풀과 다릅니다. 페이징 풀을 사용하는 대표적인 경우는 레지스트리 키 
및 기타 레지스트리 데이터 구조에 대한 참조를 저장할 때 입니다. 페이징 풀의 사용량이 가장 큰 요소는 일반적으로 레지스트리입니다. 
내부적으로 섹션 이라고하는 메모리 매핑 된 파일을 나타내는 데이터 구조도 페이징 풀에 저장됩니다. 



페이징 풀의 경우 운영체제가 제한하는 범위는 아래와 같습니다. MS 개발자 센터 바로가기

32bit 운영체제인 경우

XP: 491MB 까지

Server 2003: 650MB 까지

Vista, Server 2008, Windows 7, Server 2008 R2: 시스템 제공 범위 또는 2GB 까지

Windows 8, Server 2012: 시스템 제한 또는 2GB 까지
```
