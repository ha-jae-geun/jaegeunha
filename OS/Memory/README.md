# 메모리 관리
* [블로그](https://dailyheumsi.tistory.com/137?category=855210)
* [정아마추어](https://jeong-pro.tistory.com/91?category=793347)

# 메모리의 종류
* SW가 관리(OS): 보조 기억장치 - 메인 메모리 
- HW가 관리(CPU): 캐시 - 레지스터

# 메모리 계층구조
## 블락
* 보조기억장치와 주기억장치 사이의 데이터 전송 단위
* 사이즈: 1-4KB

## 워드
* 주 기억장치와 레지스터 사이의 데이터 전송 단위
* 사이즈: 16-64 bits

# 1.1. 주소 바인딩
* 프로그램의 논리 주소를 실제 메모리의 물리 주소로 매핑하는 작업
* 코드에서 변수로 쓰이던 공간들이 실제 메모리에 매핑되는 동작을 '바인딩' 이라고 한다.
* 주소를 바인딩하는 시간은 다음과 같이 나뉜다.

## Binding 시점에 따른 구분
```java
컴파일 타임
로드 타임
실행 타임
```

```java
소스코드 
-> 컴파일러(컴파일 타임)
-> 오브젝트 모듈 
-> 링커 -> 로드 모듈 -> 로더 (로드 타임)
-> In-memory binary image(실행 타임)
```

## 컴파일 타임 바인딩
* 프로세스가 메모리에 적재될 위치를 컴파일러가 알 수 있는 경우(위치가 변하지 않음)
* 프로그램 전체가 메모리에 올라가야 함

## 로드타임 바인딩
* 메모리 적재 위치를 컴파일 시점에서 모르면, 대체 가능한 상대주소를 생성
* 적재시점에 시작 주소를 반영하여 사용자 코드 상의 주소를 재설정
* 프로그램 전체가 메모리에 올라가야 함

## 런타임 바인딩
* Address binding을 수행시간까지 연기
	* 프로세스가 수행 도중 다른 메모리 위치로 이동할 수 있음
* HW의 도움이 필요하다
	* MMU
* 대부분의 OS가 


# 다이나믹 로딩
* 모든 루틴을 교체 가능한 형태로 디스크에 저장
* 실제 호출 전까지는 루틴을 적재하지 않음
	* 메인 프로그램만 메모리에 적재하여 수행
	* 루틴의 호출 시점에 address binding 수행

## 장점
* 메모리 공간의 효율적 사용

# Swapping
* 프로세서 할당이 끝나고 수행 완료 된 프로세스는 swap-device로 보내고(Swap-out)
* 새롭게 시작하는 프로세스는 메모리에 적재한다.(Swap-in)


# 연속 할당(Continuous Memory Allocation)
* Uni-programming
* Multi-programming
	* Fixed partition(FPM)
		* 고정 분할
	* Variable partition(VPM)
		* 가변 분할

## 연속 할당 정의
* 프로세스를 하나의 연속된 공간에 할당하는 정책
	* 프로그램, 데이터, 스택 등

## 메모리 구성 정책
* 메모리에 동시에 올라갈 수 있는 프로세스 수
* 각 프로세스에게 할당되는 메모리 공간 크기
* 메모리 분할 방법


## Uni-programming
* 하나의 프로세스만 메모리 상에 존재
* 가장 간단한 메모리 관리 기법

## Uniprogramming 문제점
1. 프로그램의 크기 > 메모리 크기
2. 커널 보호
	* 프로그램을 올릴 때 커널을 침범하여 올리면 안된다.
3. Low system resource utilization / Low System perfomance

## 해결법
1. Overlay Structure
	* 메모리에 현재 필요한 영역만 적재
	* 사용자가 프로그램의 흐름 및 자료구조를 모두 알고 있어야 함
2. 경계 레지스터(boundary register) 사용
3. Multi programming

## Multi-programming
### Fixed Partition Multiprogramming
* 메모리 공간을 고정된 크기로 분할(미리 분할되어 있음)
* 각 프로세스는 하나의 분할에 적재
	* 프로세스:파티션 = 1:1
* 파티션의 수 = K
	* Multiprogramming degree = K


### Fixed Partition Multiprogramming의 단점
* Internal/external fragmentation


# 단편화
```JAVA
메모리 단편화

 - RAM에서 메모리의 공간이 작은 조각으로 나뉘어져 사용가능한 메모리가 충분히 존재하지만 할당(사용)이 
 불가능한 상태를 보고 메모리 단편화가 발생했다고 한다.

메모리 단편화는 내부 단편화와 외부 단편화로 구분 가능하다.

내부 단편화(Internal Fragmentation)

메모리를 할당할 때 프로세스가 필요한 양보다 더 큰 메모리가 할당되어서 프로세스에서 사용하는 메모리 공간이 낭비 되는 상황

* 예를 들어 메모장을 켰는데 OS가 4kb를 할당해줬다. 그런데 사실상 1kb만큼만 사용하고 있을 때 필요 이상으로
프로세스가 메모리를 할당받았으므로 내부 단편화가 3kb만큼 생긴 것임.

외부 단편화(External Fragmentation)

메모리가 할당되고 해제되는 작업이 반복될 때 작은 메모리가 중간중간 존재하게 된다. 이 때 중간중간에 생긴 
사용하지 않는 메모리가 많이 존재해서 총 메모리 공간은 충분하지만 실제로 할당할 수 없는 상황

* 예를 들어 메모리 처음 주소에 8mb짜리 프로세스가 할당되었고 바로 이어서 16mb짜리 프로세스가 할당되었다고 
가정했을 때 8mb짜리 프로세스를 종료시키면 메모리 처음 주소부터 8mb만큼 공간이 생긴다.

이런 식으로 계속해서 빈 메모리가 쌓이는데 예를 들어서 빈 메모리의 공간중에 제일 큰 빈 메모리가 8mb라고 한다면
9mb짜리 프로세스를 할당을 해야할 때 마땅한 공간은 없지만 전체적으로 메모리 여유는 있을 때 외부단편화가 생겼다고 한다.

메모리 파편화 문제 해결 방법

1. 페이징(Paging)기법 - 가상메모리사용, 외부 단편화 해결, 내부 단편화 존재

보조기억장치를 이용한 가상메모리를 같은 크기의 블록으로 나눈 것을 페이지라고 하고 RAM을 페이지와 
같은 크기로 나눈 것을 프레임이라고 할 때,

페이징 기법이란 사용하지 않는 프레임을 페이지에 옮기고, 필요한 메모리를 페이지 단위로 프레임에 옮기는 기법.

페이지와 프레임을 대응시키기 위해 page mapping과정이 필요해서 paging table을 만든다.

페이징 기법을 사용하면 연속적이지 않은 공간도 활용할 수 있기 때문에 외부 단편화 문제를 해결할 수 있다.

대신 페이지 단위에 알맞게 꽉채워 쓰는게 아니므로 내부 단편화 문제는 여전히 있다.

* 페이지 단위를 작게하면 내부 단편화 문제도 해결할 수 있겠지만 대신 page mapping 과정이 많아지므로 오히려 효율이 떨어질 수 있다. 

2. 세그멘테이션(Segmentation)기법 - 가상메모리사용, 내부 단편화 해결, 외부 단편화 존재

페이징기법에서 가상메모리를 같은 크기의 단위로 분할했지만 세그멘테이션기법에서는 가상메모리를 
서로 크기가 다른 논리적 단위인 세그먼트로 분할해서 메모리를 할당하여 실제 메모리 주소로 변환을 하게 된다.

각 세그먼트는 연속적인 공간에 저장되어 있다.

세그먼트들의 크기가 다르기 때문에 미리 분할해 둘 수 없고 메모리에 적재될 때 빈 공간을 찾아 할당하는 기법이다.

마찬가지로 mapping을 위해 세그먼트 테이블이 필요하다.

(각 세그먼트 항목별 세그먼트 시작주소와 세그먼트의 길이 정보를 가지고 있음)

프로세스가 필요한 메모리 만큼 할당해주기 때문에 내부단편화는 일어나지 않으나 여전히 중간에 프로세스가
메모리를 해제하면 생기는 구멍, 즉 외부 단편화 문제는 여전히 존재한다.

3. 메모리 풀(Memory Pool)

필요한 메모리 공간을 필요한 크기, 개수 만큼 사용자가 직접 지정하여 미리 할당받아 놓고 필요할 때마다 사용하고 반납하는 기법

메모리 풀 없이 동적할당과 해제를 반복하면 메모리의 랜덤한(실제로는 알고리즘에 의한) 위치에 할당과 해제가 반복되면서 
단편화를 일으킬 수 있겠지만 미리 공간을 할당해놓고 가져다 쓰고 반납하기 때문에 할당과 해제로 인한 외부 단편화가 발생하지 않는다.

또한 필요한 크기만큼 할당을 해놓기 때문에 내부 단편화 또한 생기지 않는다.

하지만 메모리 단편화로 인한 메모리 낭비량보다 메모리 풀을 만들었지만 쓰지 않았을 때 메모리 양이 커질 경우 사용하지 않아야 한다.

메모리의 할당, 해제가 잦은 경우에 메모리 풀을 쓰면 효과적이다.

미리 할당해놓고 사용하지 않는 순간에도 계속 할당해놓으므로 메모리 누수가 있는 방식이다.



구현 방법

- 큰 메모리 블록(페이지)을 힙으로 부터 할당

- 할당 받은 페이지를 각 객체의 크기의 블록으로 나눔

- 각 객체를 위한 블록을 순차적으로 링크

- 이 때 현 시점에서 할당할 블록을 특정 포인터가 가리키게 함

- 메모리 요청이 생기면 현재 헤더 포인터가 가리키는 블록을 돌려준다.

- 할당이 일어난 후 헤더 포인터는 할당 직전에 가리키던 블록이 가리키던 블록을 가리킨다.

- 사용되던 메모리가 해제되어 메모리 풀로 돌아올 경우 헤더 포인터는 그 블록을 가리키고 
방금 전까지 헤더 포인터가 가리키던 블록을 돌아온 블록의 다음 포인터가 가리키게 한다.
```


# 비연속할당

# 메모리
```java

1.2. Logical vs Physical Address
Logical Address (= Virtual Address)
​ CPU에 의해 생성되는 주소다. 즉 실제적인 물리주소와는 관련없고, 메모리에 적재되기 전 가지는 가상주소다.

Physical Address
​ 실제 메모리(RAM) 상에서의 주소다.

MMU (Memory Management Unit)
​ Logical Address 를 Physical Address 로 매핑시켜주는 하드웨어 장치다.
​ 예를 들어, base register 가 14000 이고, logical address 가 346이면, 실제 Physical Address 는 14346이 된다.

1.3. Static vs Dynamic Linking

Static Linking
​ 컴파일 타임에, 라이브러리 파일 전체가 오브젝트 파일에 복사된다.
​ 실행 파일의 크기가 비대해질 수 있다.
​ 또한 실행 시, 모든 코드가 로드된다.

Dynamic Linking
​ 런타임 중에 호출된 라이브러리 파일이 최초 한 번만, 메모리 공간에 적재된다.
​ 필요한 코드만 로드된다.
​ 또한 라이브러리 갱신에 용이하다.
```

```java
2. Swapping
프로세스 실행 도중, 일시적으로 주기억장치에서 보조기억장치로 옮겨진 후, 
나중에 다시 주기억장치에 로드할 수 있게한다. 이 과정을 스와핑이라 한다.

우선순위에 의해 발생되면 roll in, roll out 이라는 용어를 사용한다.

3. 메모리 할당
3.1. 연속적 할당
Fixed size
​ 메모리를 고정된 크기로 일정하게 나누어(파티션), 각각의 프로세스에게 할당한다.
​ 즉, 파티션의 개수가 곧 가능한 멀티 프로세스의 수(degree of multiprogramming) 와 같다.
​ 관리는 용이하나, 적절한 파티션의 크기를 잡기가 어렵고, 메모리 낭비도 심하다.
​ 지금은 안쓴다.

Variable size
​ Hole = 할당 가능한 메모리 블락
​ OS 는 할당한 파티션들과, 할당 가능한 파티션(hole) 둘 다 관리해야 한다.
​ Fixed Size 보다 훨씬 유연하지만, 이제 이슈는 여러 hole 들이 있을 때 프로세스를 어떻게 어디에 할당할 것인지에 대한 것이다.
​ 이에 다음과 같은 방법들이 있다.

First-fit
현재 hole 리스트 탐색 중, 프로세스가 들어갈 수 있는 첫 번째 hole 을 할당한다.

Best-fit
현재 hole 리스트 탐색 중 프로세스의 들어갈 수 있는 가장 작은 hole을 할당한다.

Worst-fit
현재 hole 리스트 중 그냥 제일 큰 hole 을 할당해준다.
그러나 Variable Size 방법은 여전히 최적화 문제가 있는데,
모든 프로세스들이 할당되지 않은 파티션들(holes)을 '최대한' 활용하지 못하는 문제가 생긴다.


즉, 위와 같이 메모리에 충분히 여유공간이 있는데, 모두 조각나(fragmentation) 있어, 
메모리 공간을 제대로 활용하지 못하는 상황이 발생한다.

Internal Fragmentation
OS는 프로세스가 요청한 메모리 공간보다 조금 더 많이 할당해주는데, 이 메모리 공간이 활용되지 않는다면, 이는 낭비다.

External Fragmentation
위 그림과 같은 상황으로, 활용가능한 메모리 공간이 연속적이지 않아서 사용할 수 없는 경우다.
보통 할당된 영역이 N개 이면, 0.5N 개의 영역이 fragmentation 으로 낭비된다.
이에 대한 해결책으로 compaction 이 있다.
이는, 현재 프로세스들의 메모리 공간을 재배치하여, fragmented 한 hole 들을 continuous 하게 만드는 방법이다. 하지만, 전체 프로세스들을 재배치한다는 점에서 오버헤드가 있다.

3.2. 비연속적 할당
Paging
Fragmentation 문제를 해결하기 위해서, 일정 크기의 단위로 나누어서 분산 적재하는 방법이다.
다음과 같은 방법을 사용한다.

- 물리적 기억장치를 고정된 크기로 나눈다. 이를 프레임이라 한다. (보통 4KB)
- 논리적 주소공간도 프레임과 같은 크기로 나눈다. 이를 페이지라 한다.
- 논리주소는 페이지 번호(number)와 오프셋(offset) 으로 구성한다.
- 별도의 페이지 테이블이 존재하여, 논리주소의 페이지 번호로 이 테이블에 접근한다.
- 페이지 테이블에는 각 페이지 번호에 매핑되는 물리주소 정보를 담고있다.
- 즉 실제주소는 페이지 테이블에 매핑되는 물리주소 + 오프셋으로 만들어진다.


예를들어, 32비트 페이지와 프레임의 크기가 4KB 라면, 한 프레임 내 1Byte 메모리블럭이 2^12 개 있는 것이다.
(근데 사실 하나의 32비트에서 하나의 명령어는 4Bytes 로 구성되어있으므로, 접근은 4Bytes 단위로 한다.
즉 접근은 4Bytes 단위지만, 주소는 1Byte 로 단위로 매핑되어 있음.)
그렇다면, 한 프레임 내에 2^12 개의 주소를 가질 수 있다는 뜻이고,
32비트 명령어안에 뒤에 12비트는 오프셋을 담는 위치가 된다.
그러면 나머지 20비트는 페이지 넘버의 영역이다.
즉 우리는 2^20개의 페이지 주소(공간) 을 갖는다!
정리하면, 다음과 같다.

논리 주소 공간의 크기가 2^m 이고,
페이지의 크기가 2^n 일 때,
=> 주소의 하위 n 비트는 오프셋, 상위 m-n 비트는 페이지 번호가 된다.

페이징을 사용하면, 외부 단편화는 일어나지 않지만 내부 단편화(Fragmentation)는 일어날 수 있다.
일반적으로, 프로세스마다 프레임의 절반크기 정도의 내부 단편화가 일어난다.


Page Table
페이지 테이블은 메인 메모리에 상주한다. 즉, 논리주소는 메모리 내 페이지 테이블을 거쳐, 
원래 목적 메모리 주소에 도달하게 되는, 즉 2번 메모리를 접근하여 명령어를 수행하게 된다.
메인 메모리의 모든 페이지 엔트리를 갖고있기 때문에, 사이즈가 메인 메모리에 비례하여 커진다.
한편, 논리주소에서 페이지 넘버는 페이지 테이블에서의 인덱스이기 때문에, 검색 비용이 들지 않는다.

페이지 테이블에는 모든 프레임에 대한 테이블을 기준으로 나누고 다음의 내용을 담는다.


각 프레임의 할당 여부
할당 되어있을 경우, 어떤 프로세스가 할당되어있는지
물리 메모리의 시작 주소
또, 각 프로세스마다 PCB 에 페이지 테이블을 가진다.
프로세스마다 독립적인 가상 공간이 주어지고, 필요한 물리적 메모리 공간과 매핑할 수 있어야하기 때문이다.
즉, 전역 메모리에 상주해있는 페이지 테이블은, 프로세스 단위로 메모리를 매핑하는 것이고,
각 프로세스 내 페이지 테이블은, 지역변수 등 코드 단위로 메모리를 매핑하는 것이다.
실질적으로 할당가능한 프레임 엔트리는 프레임 테이블이라는 애가 별도로 관리한다.

한편, PCB 내 페이지 테이블이 들어가므로, Context Switching 시 overhead 가 더 늘어난다..

페이징 시스템에서는 MMU 가 곧 페이지 테이블이 된다.
또한, 이런 페이징 시스템은 OS 가 하는 것이 아닌, 별도의 하드웨어에서 한다.

Paging 특징 정리
사용자/프로세스의 편의성
연속된 논리 주소 공간을 독립적으로 사용
MMU 에 의한 비교적 빠른 주소 변환
프레임 단위의 비연속적 메모리 할당
외부 단편화가 없음.
하지만 내부 단편화는 있음 (필수불가결).
CS 시 오버헤드 증가
공유 페이지를 통한 IPC 효율성 증가

```



# 가상 메모리
*   모든 프로세스는 자신만의 가상 주소 공간을 가지고 있다. 모든 프로세스들은 자신만의 주소 공간을 가지기 때문에, 특정 프로세스 내에서 쓰레드가 수행될 때 해당 쓰레드는 프로세스가 소유하고 있는 메모리에 대해서만 접근이 가능하다. (다른 프로세스에 의해 소유된 메모리는 접근 불가)
* 즉, 가상메모리는 프로세스의 물리 메모리와 논리 메모리를 분리하기 위해 생겨난 것이라 볼 수 있다. 이를 이용해서 논리 메모리가 물리 메모리보다 커지는 것을 가능케 한다. (램이 1gb인 컴퓨터에서 게임,포토샵,인터넷익스플로러를 동시에 실행할 수 있는 것이 가상메모리 덕분)
* 실제 각 프로세스마다 충분한 메모리를 할당하기에는 메모리 크기에 한계가 있음
* 운영체제에서 디스크 공간을 메모리처럼 활용할 수 있는 기능을 제공
* 디스크 상에 존재하는 이러한 파일을 paging file 이라고 한다.
	* 실제 메모리보다 많이 보이게 하는 기술
* 실제 사용하는 메모리는 작다는 점에 착안해서 고안된 기술
* 프로세스간 공간 분리로, 프로세스 이슈가 전체 시스템에 영향을 주지 않을 수 있음

## 가상 메모리 기본 아이디어
* 프로세스는 가상 주소를 사용하고, 실제 해당 주소에서 데이터를 읽고/쓸대만 물리 주소로 바꿔주면 된다.
* virtual address(가상주소) : 프로세스가 참조하는 주소
* physical address : 실제 메모리 주소

## MNU (Memory Management Unit)
* cpu에 코드 실행시, 가상 메모리 접근이 필요할 때, 해당 주소를 물리 주소값으로 변환해주는 하드웨어 장치

## [ 가상메모리 없을때 ]
* 프로세스 a,b가 4gb의 메모리를 점유한다고 가정하자. 가상메모리가 존재하지 않으면, 물리공간(6gb)메모리에 a가 필요한 메모리 4g를 할당 되면서, b는 공간이 모자라서 사용할 수 없게 된다.

##  가상메모리 존재]
* 프로세스 a,b,c,가 4gb의 메모리를 점유한다고 가정하자. process가 현재 사용되는 공간 만큼만 메모리에 넣어주면서, 물리 공간에 할당과 해제를 반복하는 과정을 거친다.


## 가상메모리가 필요한 이유
* 하나의 프로세스만 실행 가능한 시스템(배치 처리 시스템)에서는 크게 필요가 없다.

1. 프로그램을 메모리로 로드
2. 프로세스 실행
3. 프로세스 종료(메모리 해제)

* 여러 프로세스 동시 실행 시스템에서는 가상메모리가 필수적으로 필요하다.
1. 메모리 용량 부족 이슈
2. 프로세스 메모리 영역간에 침범 이슈

## 페이징(paging)
* 페이징 방식에서는 가상메모리상의 주소공간을 일정한 크기의 페이지로 분할하게 되는데 실제 메모리 또한 가상메모리와 같은 크기로 페이지를 분할한다.
* 페이지의 크기는 대부분 4Kbyte를 사용한다.
* 크기가 동일한 페이지로 가상 주소 공간과 이에 매칭하는 물리 주소 공간을 관리

## 페이지 테이블
* 가상 메모리의 페이지와 실제메모리의 페이지를 연결시켜주기 위한 매핑 테이블
* 가상메모리의 페이지넘버와 실제메모리의 페이지프레임을 하나의 순서쌍으로 정의하고 있는 도표
* 이러한 페이지 테이블이 메모리에 존재하면, 성능은 하락한다. 따라서 MMU라는 하드웨어를 통해 매핑을 시킨다. (MMU를 통해 맵핑작업을 수행해서, 메모리 접근 회수를 줄인다.)


## 페이징 시스템
* PCB에 Page Table 구조체를 가리키는 주소가 들어있다.
* Page Table에는 가상 주소와 물리주소간 매핑 정보가 있음
* Page Table에 접근할 수 있는 가장 위의 주소를 가지고 있다가, cpu가 가상 주소에 접근하려고 하면 페이지 테이블의 가장 위의 주소에 원하는 번호에 접근해서 실제 메모리 주소에 접근한다.

## 페이징 시스템 구조
* 페이지 또는 페이지 프레임 : 고정된 크기의 block(4kb)
* paging system
* 가상 주소 v = (p,d)
	* p : 가상 메모리 페이지 (페이지 번호)
	* d : p안에서 참조하는 위치 (변위)
* 페이지 크기가 4kb 예
	* 가상 주소의 0비트에서 11비트가 변위를 나타냄
	* 12비트 이상이 페이지 번호가 될 수 있음
