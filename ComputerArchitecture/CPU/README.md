# [안될과학 CPU 역사](https://www.youtube.com/watch?v=SiC74U8aJbM&list=PLPBTs1IJBEyiacgGU4SK2tu9S1u3-ih4g&index=2&t=0s)
# [애플 반도체의 등장](https://www.youtube.com/watch?v=tbfEi_BQATM&list=PLJPjg3It2DXQUdlAocHh5FASozqwtJavv&index=29&t=0s)
# [AMD와 인텔의 전쟁](https://www.youtube.com/watch?v=6dp4E5HIpRU&list=PLJPjg3It2DXQUdlAocHh5FASozqwtJavv&index=106)


# 문제
```java
문 18. 마이크로프로세서에 관한 설명으로 옳은 것만을 모두 고르면? 4
ᄀ. 모든 명령어의 실행시간은 클럭 주기(clock period)보다 작다.
ᄂ. 클럭 속도는 에너지 절약이나 성능상의 이유로 일시적으로 변경할 수 있다.
ᄃ. 일반적으로 RISC는 CISC에 비해 명령어 수가 적고, 명령어 형식이 단순하다.
1 ᄃ 2 ᄀ, ᄂ
3 ᄀ, ᄃ 4 ᄂ, ᄃ
[해설]
- 클럭 신호는 보통 1 주기(period, λ)를 1 클럭이라 부르고 컴퓨터는 이 클럭 신호의 매 주기마다 연산을
수행한다. 클럭 주기(clock period)는 클럭 사이클의 지속시간이라 할 수 있다. 한 클럭 동안 실행되는
기본 동작으로 마이크로 오퍼레이션 동작이 여러 개 모여 하나의 명령을 처리하게 되는 것이 때문에
명령어의 실행시간은 클럭 주기와 비교했을 때 같거나 크다고 할 수 있다.


문 5. CPU(중앙처리장치)의 성능 향상을 위해 한 명령어 사이클 동안
여러 개의 명령어를 동시에 처리할 수 있도록 설계한 CPU구조는?
1
1 슈퍼스칼라(Superscalar)
2 분기 예측(Branch Prediction)
3 VLIW(Very Long Instruction Word)
4 SIMD(Single Instruction Multiple Data)
[해설]
- 슈퍼스칼라 (superscalar) : CPU 내에 파이프라인을 여러 개 두어 명령
어를 동시에 실행하는 기술이다. 파이프라인과 병렬 처리의 장점을 모은
것으로, 여러 개의 파이프라인에서 명령들이병렬로 처리되도록 한 아키텍
처이다. 여러 명령어들이 대기 상태를 거치지 않고 동시에 실행될 수 있
으므로 처리속도가 빠르다.


ㄱ. 가상(virtual) 메모리
ㄴ. L1 캐시(Level 1 cache) 메모리
ㄷ. L2 캐시(Level 2 cache) 메모리
ㄹ. 임의 접근 메모리(RAM)

∙ 저장장치의 접근 속도는 레지스터 > 캐시기억장치(L1 캐시 > L2 캐시) > 주기억장치(RAM) > 보조기억장치(가상 메모 리)입니다.



CPU의 연산을 처리하기 위한 데이터의 기본 단위로서 CPU가 한 번에 처리할 수 있는 데이터 크기를 나타내는 것은? 1번
①	워드(word)	 	②	바이트(byte)
③	비트(bit)		④	니블(nibble)

∙ 컴퓨터가 한 번에 처리할 수 있는 명령 단위는 워드(Word)입니다.


현재 사용되는 PC에서와 같이, 일반적인 폰-노이만 방식의 중앙처리장치에 대한 설명으로 옳지 않은 것은?
① 중앙처리장치의 중요 구성요소는 산술논리장치(ALU)와 제어부(CU)이다.
② 산술논리장치의 계산 결과는 레지스터에 저장된다.
③ 중앙처리장치에 연결된 어드레스 버스는 단방향 통신을 지원한다.
④ 중앙처리장치와 주기억장치 사이의 통신은 대부분 DMA 방식으로 처리된다.

∙ 폰-노이만 구조의 컴퓨터는 폰 노이만이 고안한 프로그램 내장 방식의 컴퓨터를 의미하며, 
  현재 사용되는 대부분의 컴 퓨터는 폰 노이만 구조로 동작합니다.
∙ DMA는 중앙처리장치와 주기억장치 사이의 통신이 아니라 
  주기억장치와 입출력(I/O)장치 간에 직접 전송하는 방식을 의미합니다

파이프라이닝(pipelining) 기법이 적용된 중앙처리장치(CPU)에서의 파이프라인 해저드(pipeline hazard) 
종류와 대응 방법을 바르게 짝지은 것만을 모두 고른 것은?  4번
ㄱ. 데이터 해저드(data hazard)－데이터 전방전달(data forwarding)
ㄴ. 구조적 해저드(structural hazard)－부족한 자원의 추가
ㄷ. 제어 해저드(control hazard)－분기 예측(branch prediction)
①	ㄱ, ㄴ	 	②	ㄱ, ㄷ
③	ㄴ, ㄷ		④	ㄱ, ㄴ, ㄷ

구조적 해저드(Structural Hazard)
∙ 자원 충돌(resource conflict)
∙ 메모리 충돌과 레지스터 충돌 등 자원 충돌
∙ 부족한 자원의 추가(구성 요소를 중복)
 
데이터 해저드(Data Hazard)
∙ 데이터 의존성(data dependency)
∙ 명령어간 충돌로 이전 명령어의 결과에 의존
∙ Data Forwarding(데이터 전방전달) : ALU1의 결과가 ALU2의 입력에 피드백
∙ 파이프라인 지연(Pipeline Stall) : 해저드를 감지하여 해결될 때까지 Pipeline Stall
 
제어 해저드(Control Hazard)
∙ 분기 곤란(branch difficulty)
∙ 조건, 무조건 분기 또는 명령어 PC를 변경
∙ 파이프라인 지연(Pipeline Stall) : 해저드를 감지하여 해결될 때까지 Pipeline Stall
∙ 분기 예측은 과거 실행 내역 및 빈도를 이용하여 확률적으로 예측



다음 중 나머지 셋과 역할 기능이 다른 하나는? 2번
① Array processor, ③ GPU, ④ SIMD는 병렬처리와 관련

GPU(Graphics Processing Unit)
∙ 컴퓨터의 영상정보를 처리하거나 화면 출력을 담당하는 그래픽카드를 의미
∙ 중앙처리장치의 그래픽 처리 작업을 돕기 위해 제작
∙ 컴퓨터의 영상정보 처리, 가속화, 신호전환, 화면출력을 담당하는 
  그래픽카드는 비디오 램과 그래픽 칩에 따라 성능이 달라짐
∙ 중앙처리장치(CPU)의 그래픽 작업으로 인해 생기는 병목 현상을 해결하기 위해 만든 것이 
 그래픽 가속기능으로, GPU를 그래픽 가속기(Graphics Accelerator)라고도 함
∙ CPU의 처리량은 줄었지만 GPU의 처리량은 계속 증가함에 따라 많은 열이 발생하여 CPU처럼 방열판이나 냉각팬이 설치되는 경우가 많음
∙ 하나의 CPU는 직렬 처리에 최적화된 몇 개의 코어로 구성된 반면, GPU는 병렬 처리용으로 설계된 수 천 개의 보다 소형이고 효율적인 코어로 구성

①	Array processor	 	②	DMA
③	GPU		④	SIMD


29. DMA에 대한 설명으로 가장 옳은 것은?  4번
① 인코더와 같은 기능을 수행한다.
② inDirect Memory Acknowledge의 약자이다.
③ CPU와 메모리 사이의 속도차이를 해결하기 위한 장치이다.
④ 메모리와 입출력 디바이스 사이에 데이터의 주고받음이 직
접 행해지는 기법이다.

문제) DMA의 장점에 해당되는 것은?
가. 속도가 느린 메모리가 사용될 수 있다.
나. 마이크로 프로세서가 데이터 전송을 제어한다.
다. 데이터 전송 회로가 보다 덜 복잡하다.
라. 보다 빠른 데이터 전송이 가능하다.


38. 일반적으로 CPU가 DMA 제어기로 보내는 정보가 아닌 것은? 3번
① I/O 장치의 주소
② 연산(쓰기 혹은 읽기)지정자
③ CPU 제조 고유 번호
④ 전송될 데이터 단어들의 수

```


# CPU
* CPU - 캐시(CPU 칩 안의 작은 칩) - 버스(CPU와 메인 메모리 사이에 데이터를 저장하기 위함) - 메인 메모리
*   MBR(CPU 안)- 데이터 버스 - 주기억 장치 - 주소버스 - MAR(CPU 안) - PC
 * 채널에 관리가 되는 입출력 장치도 꽂혀있음
* 양방향성: 데이터 버스
* 1K = 2의 10승;  1M = 2의 20승

# CPU 역사
* CISC(Complex Instruction Set Computer): 복잡 명령어 구성 방식
* 그린 컴퓨팅(에너지 효율을 극대화하는 환경 보호 개념의 컴퓨팅)의 필요성 대두
* RISC(Reduced Instruction Set Computer)
    * 스마트폰, 테블릿 PC, 넷북 등에 사용
    * 에너지 효율성 높고 가격이 낮음
* ARM(Advanced RISC Machine)
        * RISC 기본으로 개발한 단순 명령어 방식
        * 애플은 저전력 칩셋 개발을 위해서 조인트 벤처로 Acorn 컴퓨터와 ARM 설립에 참여(CISC 기반의 인텔 CPU의 비중 좁힘)
```java
마이크로소프트처럼 실패하지 않는 다는 전제하에, 애플의 이런 움직임이 장기적으로는 업계 전체에 큰 바람을 불러일으킬 수 
도 있겠지만 단기적으로는 소비자가 잃는 것도 많습니다.
일단 당장 쓸 수 있는 애플리케이션들이 매우 적습니다.
어도비 같은 기업들이 자사의 앱들을 기존의 x86 방식 대신 ARM 으로 새로 빌드해주기 전까지는 쓰지 못한다는 소리예요.
뒤늦게라도 이런 지원을 해주면 다행인데, 이미 문을 닫았거나 영세한 업체들의 앱은 영원히 사용 못 할 수 도 있죠.

윈도우 게임 플레이는 포기해야할거고,
트리플A 게임들과도 작별을 고하셔야 합니다.
안그래도 게이밍에 약점이 있는 mac 인데 ARM 이라니..

장점으로는 가격, 발열, iOS 와 iPadOS 간의 호환성 정도겠네요.
누군가에게는 큰 장점이 될 수 있겠지만,
제가 보기엔 아이패드와 맥북을 구분짓는 메리트가 오히려 애매해진다고 보여지네요.
기존의 많은 mac 어플리케이션을 포기해야하고 프로의 성능을 못내면 그냥 아이패드와 키보드 조합으로 쓰는 것과 큰 차이가 없으니까요.
```

# 아키텍처/설계방식
* x86, AMD64, ARM, RISC-V, POWER, PowerPC, MIPS

# X86
* 1978년 첫 8086 프로세서 출시 후 42년간 시장 리드


## 코어
* 코어가 많다고 무조건 좋은 것은 아니다. 프로그램이 Unfriendly 멀티코어  프로그램일 수 있따.
* 싱글코어는 일정 클락이상으로 가게 되면 열을 받아 터질 위험이 있다


### 코어와 스레드
* 코어: 물리적인 CPU의 프로세서
* 스레드: 하이퍼스레딩, SMT 기술을 이용하여 하나의 코어를 여러개의 코어처럼 보여주는 논리적인 기술

### SMT
```java
SMT라는 명칭은 동시 멀티스레딩을 뜻하며 학계에서 주로 지칭하는 용어로 사용되고 있다.

시장에서는 인텔이 이 기술을 부르는 이름인 하이퍼쓰레딩으로 더 유명하지만
이 기술이 인텔 독점인 것은 아니며
AMD에서도 기존의 불도저에 적용한 CMT(Cluster Multi-Threading) 구조를 버리고
2017년 3월 초에 출시된 RYZEN에 이 구조를 채용하면서 사실상 거의 모든 데스크탑 CPU에 적용되는 기술이 되었다.


* SMT의 원리
단일 코어에서 구현할 수 있는 명령어 수준의 병렬처리 능력(Instruction-Level Parallelism)은
명령어 종속성(Dependency)으로 인해 구현에 한계가 있다.

RAW(Read-After-Write), WAR(Write-After-Read), WAW(Write-After-Write) 등의 다양한 종속성이 있으며
일부는 구조적으로 극복할 수 있다고 해도 근본적인 종속은 해결되지 않는다.

그렇다면 이를 증가시킬 수 없다면 남는 연산 능력을 다른 스레드의 명령어를 처리하는데 사용한다면
양 스레드간의 명령어 종속성은 거의 없을 것이기에
단일 코어에서 전체적인 명령어 병렬 처리 능력을 증가시킬 수 있다는 개념의 기술이다.

현대의 CPU는 슈퍼스칼라 구조와 파이프라이닝 기법이라고 해서
CPU 전체가 한 번에 하나의 명령을 처리하는 것이 아니라
명령어 몇 개를 동시에 처리함과 동시에
명령 하나를 또다시 여러 단계의 작은 명령으로 나누고 각 부분을 차례대로 처리한다.

즉 몇 개의 명령어가 몇분의 1로 나누어지고, 그런 명령어 몇 개가 한번에 돌아가는 것이다.
이런 식으로 작동하는 이유는 많은 기계어 명령이 코드로는 하나로 되어 있어도
실제 처리해야 하는 일은 여러 단계로 나누어져 있고
각 단계는 이전 단계가 처리되기 전에는 수행이 불가능하기 때문이다.



```

```java
예를 들어 메모리의 값을 증가시키는 명령이 다음과 같이 작동한다면
1번이 끝나기 전에는 2번을 할 수 없고 2번이 끝나기 전에는 3번을 할 수 없다.

1. 메모리의 값을 읽는다.
2. 읽은 값을 더한다.
3. 값을 메모리에 쓴다.
그런데 실제로는 명령이 처리되기 위해 필요한 일이 명령마다 다르다.

CPU의 예시는 아니지만 네트워크 비동기 처리의 예시를 들어보자.

1. 네트워크의 값을 읽는다.
2. 읽은 값을 처리한다.
3. 값을 저장장치에 쓴다.
네트워크에서 특정 값을 읽어 이를 처리하는 경우 상당한 경우에는
네트워크의 대기 시간이 프로그램 전체 실행 시간의 대부분을 차지한다.

이 상황에서 위와 같이 코드를 작성한다면
1번의 네트워크 대기 지연 시간에 의해 프로그램은 상당히 비효율적인 구조를 가지게 될 것이다.


네트워크에서 값을 읽어오는 데 걸리는 시간은
시스템의 자체 저장장치인 메모리나 하드디스크에서 데이터를 읽는데 걸리는 시간에 비해 몇십~몇천배는 되기 때문이다.

이 때 CPU는 1번에서 값을 읽어올 때까지 대기하게 된다.

하지만 CPU가 처리해야 할 일 중에는 이렇게 서로 연계된 일만 있는 게 아니다.

예를 들어 네트워크에서 값이 들어오길 하염없이 기다리는 저 컴퓨터에서 동시에 MP3 파일도 하나 재생하고 있다고 하자.

그렇다면 네트워크에서 값이 들어올 때까지 MP3을 재생하고 있으면 효율이 올라가지 않을까?

하이퍼스레딩은 이렇게 놀고 있는 부분에
명령어 종속성이 없는 다른 스레드의 명령어를 투입하여
CPU의 효율을 높이는 일종의 우회책이다.

CPU의 최대 성능 이상은 절대 낼 수 없지만
프로그램의 한계 때문에 쓰지 못했던 CPU의 남은 성능을 끝까지 쥐어짜는 셈이다.

즉 S/W의 관점으로는 하나의 코어에 하나의 가상의 코어를 만들어서 CPU 2개로 인식된다.

기본적으로 별개의 명령을 처리해야 하기 때문이다.

그래서 HT(=하이퍼쓰레딩)가 지원되는 CPU를 작업 관리자에서 보면 코어 수가 2배로 뻥튀기 되는 것을 알 수 있다.
```

### 하이퍼스레딩이 없는 CPU
```java
이런 식으로 한번에 하나의 명령만 처리 할 수 있다.
두 개의 작업을 재빠르게 전환하는 멀티 태스킹이다.
하지만 하이퍼스레딩을 사용한다면 멀티 프로그래밍이라고 할 수 있다.

이런 식으로 처리할 내용을 우겨 넣어서 성능을 향상 시키는 원리다.

물론 2개의 물리적인 코어보다는 성능이 확실히 떨어진다.

이 논리로 하이퍼스레딩이 있어봤자 느리다고 하지만
그래도 단일 코어 환경에 비하면
상대적으로 다른 프로세스에 훨씬 많은 여유를 줄 수 있는 장점이 있다.

예를 들어 3D 렌더링을 할 경우 진가가 들어나는데
3D 렌더러는 쓰레드 당 한 개의 렌더링 블록을 생성해 내는데,
하이퍼스레딩이 켜진 쿼드 코어 CPU의 경우
8개의 스레드가 생성되어(즉 논리적인 옥타코어) 시간의 이점을 볼 수 있다. (20% 정도 차이가 난다)
```

### 파이프라이닝
```java
현대의 CPU는 슈퍼스칼라 구조와 파이프라이닝 기법이라고 해서
CPU 전체가 한 번에 하나의 명령을 처리하는 것이 아니라
명령어 몇 개를 동시에 처리함과 동시에
명령 하나를 또다시 여러 단계의 작은 명령으로 나누고 각 부분을 차례대로 처리한다.

즉 몇 개의 명령어가 몇분의 1로 나누어지고, 그런 명령어 몇 개가 한번에 돌아가는 것이다.
이런 식으로 작동하는 이유는 많은 기계어 명령이 코드로는 하나로 되어 있어도
실제 처리해야 하는 일은 여러 단계로 나누어져 있고
각 단계는 이전 단계가 처리되기 전에는 수행이 불가능하기 때문이다.
```

## 입출력과 CPU 접속
```java
CPU와 입출력 기기를 접속하는 방법에는 크게 두가지가 있다.

첫번째는 Memory Mapped I/O 라는 방식이 있고,
두번째로 I/O Mapped I/O 가 존재한다.

이 두가지 방식의 차이점 및 각 방식의 특징을 알아보자

Memory Mapped I/O방식은 메모리와 I/O가 하나의 연속된 어드레스영역에 할당된다.
따라서 I/O가 차지하는 만큼 메모리 용량은 감소한다.
CPU입장에서는 메모리와 I/O가 동일한 외부기기로 간주되므로 이들을 액세스 하기위하여 같은 
신호를 사용한다.(read/write) 또한 소프트웨어적으로도 메모리에 대한 엑세스나 I/O에 대한 
데이터 입출력이 동일한 것으로 간주되므로 Load나 Store 명령에 의해 수행된다.
(대표적인 프로세서 : ARM, MIPS, PowerPC, M68K)
위 방식의 가장 큰 장점은 포트 입출력을 구현할 때 부수적인 복잡성이 없어지기 때문에 
CPU 내부적으로 로직이 덜 필요하고, 이는 더 저렴하고 빠르고 쉬운 CPU를 만들 수 있게 한다. 
이 점이 RISC가 추구하는 바와 같다. 이러한 특징은 임베디드 시스템 구현시 장점으로 적용한다.
하지만 주소와 데이터 버스를 많이 사용하게 되어, 메인 메모리에 접근하는 것보다 매핑된 장치에 접근하는 것이 더 느리다.

※ 사용시 I/O영역 변수는 volatile 타입으로 선언해야 한다. (컴파일러의 최적화 방지)
    I/O영역은 Non-cacheable로 설정해야 한다. (캐쉬메모리로 접근할경우 변경된 내용을 못 가져올 수 있다.)


I/O Mapped I/O 는 메모리와 I/O가 별개의 어드레스 영역에 할당된다. 
따라서 I/O를 사용하더라도 메모리 용량은 감소하지 않는다. CPU의 입장에서는 메모리와 
I/O를 구분하여 취급해야 하므로 이들을 액세스하기 위해서는 RD, WR 신호 이외에 추가적으로 
I/O에 접근하기 위한 신호가 필요하다. 소프트웨어 적으로도 메모리에 대한 데이터의 액세스와
I/O에 대한 데이터의 입출력이 서로 다른 것으로 간주됭 메모리에 대한 엑세스는 Load/Store에 의해 
수행되고 I/O의 입출력은 Input이나 Output 명령에 의해 수행된다.
(주로 Intel 계열의 프로세서에서 사용 한다. x86)
이 방식의 가장 큰 장점은 어드레싱 능력이 제한된 CPU를 사용할 때이다. 입출력 접근을 메모리 접근과 
분리하기 때문에 메모리용으로 주소영역 전체를 사용할 수 있다. 또한 어셈블리어상에서 소스를 볼때 
입출력 수행 루틴을 알아보기 쉽다.

참고로 ARM Processor는 임베디드 시스템상의 프로세서로 RISC구조이며 Memory Mapped I/O(MMIO)방식을 취하고 있다.
ARM Assembler나 c로 작성할때 실제로 메모리 주소를 포인터로 잡아서 값에 접근하는 모습을 볼 수 있다. 
특히 어셈블러상에서 in/out과 같은 i/o port 접근 명령어가 따로 존재하지 않고, 일반 메모리에 대한 접근인 
ld/st 명령어를 사용한다. 어떻게 보면 이점이 작성시 더 편리한 듯 싶었다.
```

