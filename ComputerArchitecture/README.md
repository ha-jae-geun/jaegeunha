# 윈도우
* 루퍼스
* 3DP Chip

## 정품
* 개발용 컴퓨터: 폴더 보안

# 중고 컴퓨터
* CPU, 메인보드, 램, 그래픽카드/VGA, SSD, HDD, 본체
* CPU는 반후법칙
* 램은 16GB면 8GB 두개 끼거나 16GB 한개 끼거나( 램은 따로 떼어서 파는 사례가 많아 가격이 많이 안내려감)
* 중고나라, 다나와, 구글
  * 구글에 - vs 
* 기본적으로 컴퓨터 부품은 최소 1~3년 또는 3~5년 정도의 무상a/s기간이 존재합니다.  (이 기간은 부품별로 다릅니다.)
* 어느제조사 파워인지와 정격파워인지 뻥파워인지도 알아보셔야 합니다. 뻥파워라고 해서 못쓸건아닙니다만. 정격파워와는 다르게 뻥파워600W면 최대출력이 600W이고 안정적으로 사용할수 있는 실제 W수는 250-400W사이라고 합니다. (제조사마다 다릅니다.) 뻥파워의 성능은 그야말로 최악이죠.  그리고 뻥파워는 A/s또한 대부분 제대로 이루어지지 않기에 파워를 교체할 수 밖에 없게됩니다. 
* 5. 그냥 돈 10-20만원 더모아서 다나와에서 조립컴퓨터 맞추고 동네 컴퓨터점에서 윈도우만 깔아달라고 해라﻿
 
# 노트북
* 게이밍 / 경량(코딩 등에 특화) / 맥북
* 화면 크기(키패드 유무), 무게(저장 공간, 그래픽 카드), 램, CPU, 프리도스(운영체제 미설치)
* 무게 결정: 하드디스크, 그래픽카드
* 다나와

# 모니터
* 화면크기, 패널, 해상도(와이드; FHD/4K), 주사율, 플리커 프리, 블루라이트 차단, 틸트

## 일반 사무용 모니터
* 일반적으로 24, 27인치

## 게이밍 모니터


## 패널
1. 응답속도
* GTG: 회색 to 회색
* 빠르면 게임에 적합

2. 광시야각
* 어디에서 보든 정자세에서 보는 사람과 같은 화면 볼 수 있음

3. 색 표현

## 해상도
* 보통 16:9
* FHD(1920x1080)

## 주사율
* 1초에 화면이 새로고침 되는 횟수; 사무용은 60HZ면 충분
  * 높은 주사율을 구사하려면 그래픽 카드가 뒷받침 되야함(그만큼 많은 화면을 보여줘야 하기 때문)
* 기존엔 68HZ명 충분했지만 게이밍 모니터엔ㄴ 144HZ를 선호하기 시작; 2014년에 대부분 인터넷에서 최대 60프레임까지 사용 가능

## 플리커
* 플리커프리: 화면 깜빡임이 없어 장시간 사용에도 눈의 피로도가 적은 모니터

## 블루라이트
* 청색 파장은 자외선과 유사한 속성을 가져 눈의 망막 깊숙히 침투

## 무결성
* 무결점정책이라는게 전세계 통틀어서 한국에만 있는 웃기는 것임. 원래 모든 화면 제품에는 불량화소란 없어야 하는 것이지만 이 공정을 줄이고 불량화소 껴있어도 단가 후려치지 못하도록 양품에다가 프리미엄 가격을 붙여서 더 많이, 더 비싸게 팔기 위한 상술 
  * 회사마다 무결점의 기준, 불량 기준이 다르다.

## g-sync/Free-sync
* 모니터-그래픽 카드 사이의 싱크 맞추는

## 수직 동기화
* 프레임 고정; 프레임이 올라갔다 내려갔다 보다는 차라리 60HZ에 고정;
  * 안정된 프레임으로 고정되기 때문에 59HZ로 프레임이 내려가면 30HZ로 고정시킨다.

## 인풋랙 

## 핫키
* RPG/FPS 각각 다른 그래픽 셋팅 값

## 조준선

## 기타
* 자체 스피커, 틸트

# 비트

- 비트가 클수록 - 한 번에 처리할 수 있는 데이터가 더 많아지는데요. 쉬운 예로 32bit는 빵굽는 틀이 32개이고 64bit는 빵굽는 틀이 64개라는 것입니다. 당연히 구울수 있는 양의 차이가 날 수 밖에요.
- 64비트는 무려, 1천 844경 6744조 737억 955만 1616 비트만큼의 데이터를 처리할 수 있습니다!!
- 32비트와 64비트의 가장 큰 차이점은 메모리 인식률로, 32비트는 4GB까지 가능하지만 64비트는 4GB이상의 RAM을 인식할 수 있는데요. 그렇기에 윈도우 32비트에서는 8GB의 RAM을 꽂더라도 4GB까지만 사용할 수 있습니다. (결국 데이터의 처리 양과 속도, 업그레이드 가능/불가능의 차이로 볼 수 있죠) 데이터 처리속도의 경우 전문적으로 사용하지 않는 이상, 그래픽에서나 그 차이를 확인할 수 있는데요. 64bit가 32bit에 비해 더 정밀한 그래픽 처리가 가능하기 때문입니다. 그리고 이론적으로 32비트와 64비트의 차이는 2배 정도지만, 실제로는 10-20%정도라고 하네요.


## x86 표시 이유
- x86으로 표시된 이유는 바로 PC 칩셋의 품번 때문입니다. x86으로 표기가 된 것은 80-86이라는 숫자를 인텔 32비트이하 계열 제품명에 붙였기 때문인데요. 그리하여 32비트는 x86이라고 표시되어 있는것이죠. x64는 32비트와 다르게 64비트인것을 표시하기 위해 붙여진 것이고요.


## Y2K 문제
* 1900년대 시간을 가르킬 때 19라는 반복되는 숫자를 아끼기 위해 19 생략하고 뒤에 년도만 표시했었음
  * 평촌 목련아파트 온수 공급중단 사건

## Y38K 문제
* Y38K(2038년도) 문제; time_t가 1970년도 1월 1일부터 시간 세는 중; 2038년 1월 10일에 1901년대로 인식하게 되고 이렇게 되면 조그만 가정제품부터 큰 댐, 공장에게 치명적인 오류가 발생할 가능성이 높다.

## 32비트
* 4,294,967,295 숫자 표현 가능; 예전 바람의 나라 풀 경험치; 여기서 맨 왼쪽 부호비트 주면서 2,147,483,647 표현
* Y38K(2038년도) 문제; time_t가 1970년도 1월 1일부터 시간 세는 중; 2038년 1월 10일에 1901년대로 인식하게 되고 이렇게 되면 조그만 가정제품부터 큰 댐, 공장에게 치명적인 오류가 발생할 가능성이 높다.

## 64비트
* 2922억년 7천만년까지 카운트 가능
* 램을 192GB까지 지원 가능

## 게이밍 노트북
* 화면 크기가 크면 무겁지만 큰 것을 고려하는 사람이 많음

## 초경량 노트북; 울트라북


## 폰 노이만 구조
* 입력 장치 -> CPU(제어장치 / 산술+논리장치) <> 메모리 -> 출력장치
* 폰노이만 구조는 크게 CPU, 메모리, 입출력 장치로 구성되어 있으며, CPU안에는 산술/논리장치, 프로세서 레지스터를 포함하고 있는 처리 장치(Processing Unit)와 명령어 레지스터와 프로그램 카운터를 포함하는 제어장치로 구성된다. 메모리는 데이터와 명령어를 함께 저장할 수 있다.

## IOT
* OS + CPU + 메모리 + 

## 영상
* Decoder -> codec (열 많이 냄)

## 열 발생
* CPU, 그래픽 카드

# 램; Random Access Memory
* <> SAM; Sequential Access Memory; 순차 접근 메모리; 하드디스크, CD, 테이프
* DRAM = Dynamic RAM; 메인 메모리; 주기억장치(ROM+RAM)
  1. 최근에 접근된 데이터; Tempoary Locality - 시간적 지연성
  2. 최근에 접근된 데이터의 주변 데이터; Spatial Locality - 공간적 지연성
* CPU - 램 - 하드디스크
* Level 1,2,3 캐시 접근 - 메인 메모리(램) - SSD
* 램이 크면 느린 디스크와 상대할 일이 줄어들기 때문에 속도도 자연스럽게 빨라진다.
  * 현재 필요한 데이터와 가까운 미래에 필요할 것 같은 데이터만 램에 올려놓기 때문에 게임보다 작아도 정상 실행된다.
* 16GB 1개 VS 8GB 2개(듀얼채널); 

# CPU
* CPU - 캐시(CPU 칩 안의 작은 칩) - 버스(CPU와 메인 메모리 사이에 데이터를 저장하기 위함) - 메인 메모리
*   MBR(CPU 안)- 데이터 버스 - 주기억 장치 - 주소버스 - MAR(CPU 안) - PC
 * 채널에 관리가 되는 입출력 장치도 꽂혀있음
* 양방향성: 데이터 버스
* 1K = 2의 10승;  1M = 2의 20승

## 캐시
* 오늘날 CPU 칩의 면적 30~70%는 캐시가 차지한다. 1989년 생산된 싱글 코어 프로세서인 i486의 경우 8KB짜리 I/D 캐시 하나만 있었다. 한편 인텔 코어 i7 쿼드 코어 칩의 다이 맵(Die map)을 보면 4개의 코어에 각각 256KB L2 캐시가 있고, 모든 코어가 공유하는 8MB L3 캐시가 있는 것을 볼 수 있다. (L2 캐시 위에 있는 구역이 L1 캐시로 보이는데, 확실하지 않아서 따로 표시하지 않았다.)
* CPU 칩에는 여러 개의 캐시가 들어가며, 각각의 캐시는 각자의 목적과 역할을 가지고 있다.

### 캐시 종류
* L1 Cache: 프로세서와 가장 가까운 캐시. 속도를 위해 I$와 D$로 나뉜다.
* Instruction Cache (I$): 메모리의 TEXT 영역 데이터를 다루는 캐시.
* Data Cache (D$): TEXT 영역을 제외한 모든 데이터를 다루는 캐시.
* L2 Cache: 용량이 큰 캐시. 크기를 위해 L1 캐시처럼 나누지 않는다.
* L3 Cache: 멀티 코어 시스템에서 여러 코어가 공유하는 캐시.
* 캐시에 달러 기호($)를 사용하는 이유는 캐시(Cache)의 발음이 현금을 뜻하는 'Cash’와 같기 때문이다 :)

### Cache Metrics
* 캐시의 성능을 측정할 때는 히트 레이턴시(Hit latency)와 미스 레이턴시(Miss latency)가 중요한 요인으로 꼽힌다.
* CPU에서 요청한 데이터가 캐시에 존재하는 경우를 캐시 히트(Hit)라고 한다. 히트 레이턴시는 히트가 발생해 캐싱된 데이터를 가져올 때 소요되는 시간을 의미한다. 반면 요청한 데이터가 캐시에 존재하지 않는 경우를 캐시 미스(Miss)라고 하며, 미스 레이턴시는 미스가 발생해 상위 캐시에서 데이터를 가져오거나(L1 캐시에 데이터가 없어서 L2 캐시에서 데이터를 찾는 경우) 메모리에서 데이터를 가져올 때 소요되는 시간을 말한다.
* 캐시의 성능을 높이기 위해서는 캐시의 크기를 줄여 히트 레이턴시를 줄이거나, 캐시의 크기를 늘려 미스 비율을 줄이거나, 더 빠른 캐시를 이용해 레이턴시를 줄이는 방법이 있다.


### Cache Organization
* 캐시는 반응 속도가 빠른 SRAM(Static Random Access Memory)으로, 주소가 키(Key)로 주어지면 해당 공간에 즉시 접근할 수 있다. 이러한 특성은 DRAM(Dynamic Random Access Meomry)에서도 동일하지만 하드웨어 설계상 DRAM은 SRAM보다 느리다. 통상적으로 '메인 메모리’라고 말할 때는 DRAM을 의미한다.
* 주소가 키로 주어졌을 때 그 공간에 즉시 접근할 수 있다는 것은 캐시가 하드웨어로 구현한 해시 테이블(Hash table)과 같다 의미다. 캐시가 빠른 이유는 자주 사용하는 데이터만을 담아두기 때문이기도 하지만, 해시 테이블의 시간 복잡도가 O(1) 정도로 빠르기 때문이기도 하다.
* 캐시는 블록(Block)으로 구성되어 있다. 각각의 블록은 데이터를 담고 있으며, 주소값을 키로써 접근할 수 있다. 블록의 개수(Blocks)와 블록의 크기(Block size)가 캐시의 크기를 결정한다.

### 캐시 블로그
* [박성범](https://parksb.github.io/article/29.html?utm_source=gaerae.com&utm_campaign=%EA%B0%9C%EB%B0%9C%EC%9E%90%EC%8A%A4%EB%9F%BD%EB%8B%A4&utm_medium=social)

## 레지스터
* CPU 내의 처리에 필요한 명령이나 연산의 중간 결과 값 등을 일시적으로 기억하는 고속 메모리
* PC, MAR, MBR, Decoder, Encoder

## IO 장치가 시스템 버스에 직접 접속되지 못하는 이유
* 종류에 따라 제어 방법이 서로 다른 I/O 장치들의 제어 회로들을 CPU 내부에 모두 포함시키는 것이 어려워 CPU가 그들을 직접 제어할 숭 ㅓㅄ기 때문이다.(CPU도 채널로 하여금 관리)
* I/O 장치들의 데이터 전송 속도가 CPU의 데이터 처리 속도에 비해 훨씬 느려 CPU도 채널을 붙임
* I/O 장치들과 CPU가 사용하는 데이터의 형식ㅇ의 깅리가 서로 다른 경우가 많다.

# 캐시
- CPU 칩 안에 들어가는 작고 빠른 메모리이다. 
- =>  프로세서가 매번 메인 메모리에 접근해 데이터를 받아오면 시간이 오래 걸리기 때문에 캐시에 자주 사용하는 데이터를 담아두고, 해당 데이터가 필요할 때 프로세서가 메인 메모리 대신 캐싱[ 접근하도록해 처리 속도를 높인다. 

## 시간 지역성/ 공간 지역성

- 자주 사용하는 데이터 판단은 지역성의 원리를 따름. 지역성의 원리는 시간 지역성과 공간 지역성으로 구분해서 볼 수 있다.
- 시간 지역성은 최근 접근한 데이터에 다시 접근하는 경향을 말한다. 가령 루프에서 인덱스 역할을 하는 변수 i에는 짧은 시간안에 여러 번 접근이 이뤄진다. 
- 공간 지역성은 최근 접근한 데이터의 주변 공간에 다시 접근하는 경향을 말함.
- 한 프로세스에도 자주 사용하는 부분과 그렇지 않은 부분이 있기 때문에 운영체제는 프로세스를 페이지라는 단위로 나눠 관리한다. 페이지에 접근할 때도 지역성 원리가 적용된다.

## Caches
- CPU 칩에는 여러 개의 캐시가 들어가며, 각각의 캐시는 각자의 목적과 역할을 가지고 있다.
- L1 Cache: 프로세서와 가장 가까운 캐시 (속도를 위해 I$와 D$로 나뉜다.)
- Instruction Cache (I$): 메모리의 TEXT 영역 데이터를 다루는 캐시
- Data Cache (D$): TEXT 영역을 제외한 모든 데이터를 다루는 캐시
- L2 Cache: 용량이 큰 캐시. 크기를 위해 L1 캐시처럼 나누지 않는다. 
- L3 Cache: 멀티 코어 시스템에서 여러 코어가 공유하는 캐시
- 한 프로세스에도 자주 사용하는 부분과 그렇지 않은 부분이 있기 때문에 운영체제는 프로세스를 페이지라는 단위로 나눠 관리한다. 페이지에 접근할 때도 지역성 원리가 적용된다.

## Cache Metrics	
- 캐시의 성능 측정	
- 히트 레이턴시(Hit Latency) : 히트가 발생해 캐싱된 데이터를 가져올 때 소요되는 시간을 의미한다. 
- 미스 레이턴시(Miss Latency) : 미스가 발생해 상위 캐시에서 데이터를 가져오거나 메모리에서 데이터를 가져올 때 소요되는 시간을 말한다. 
- 평균 접근 시간(Average access time): Miss rate = Cache misses / Cache acesses
 - Average access time = Hit latency + Miss rate * miss latency
- 캐시의 성능을 높이기 위해서는 캐시의 크기를 줄여 히트 레이턴시를 줄이거나, 캐시의 크기를 늘려 미스 비율을 줄이거나, 더 빠른 캐시를 이용해 레이턴시를 줄이는 방법이 있다. 

## cache Organization

- 캐시는 반응 속도가 빠른 SRAM(Static Random Access Memory)으로, 주소가 키(Key)로 주어지면 해당 공간에 즉시 접근할 수 있다. 이러한 특성은 DRAM(Dynamic Random Access Memory)에서도 동일하지만 하드웨어 설계상 DRAM은 SRAM보다 느리다. 통상적으로 ‘메인 메모리'라고 말할 때는 DRAM을 의미한다. 
- 캐시가 빠른 이유는 자주 사용하는 데이터만을 담아두기 때문이기도 하지만, 해시 테이블의 시간 복잡도가  O(1)정도로 빠르기 때문이기도 하다. 
- 캐시는 블록(Block)으로 구성되어 있다. 각각의 블록은 데이터를 담고 있으며, 주소값을 키로써 접근할 수 있다. 블록의 개수(Blocks)와 블록의 크기(Block size)가 캐시의 크기를 결정한다. 

## 캐시메모리
* 시간적, 공간적 지역성을 기반으로 가까운 미래에 접근될 확률이 높은 데이터를 작지만 빠른 캐시 메모리에 미리 보관하여 전체적인 시스템의 성능을 높인다.
* 메인 메모리(램)보다 훨씬 빠르지만 용량이 작아 중요한 것들이 들어가야 함
* 캐시 메모리 저장 규칙
  1. 최근에 접근된 데이터; Tempoary Locality - 시간적 지연성
  2. 최근에 접근된 데이터의 주변 데이터; Spatial Locality - 공간적 지연성
* 사용하는 곳: 파일 시스템, OS, 구글 크롬, FM, CPU 안에서도 3단계로 나눔


### Cisc
* x86 아키텍처가 리틀 엔디언을 쓰기 때문에, 오늘날 x86 아키텍처를 사용하는 대부분의 데스크톱 컴퓨터는 리틀 엔디언을 쓰며 이를 ‘인텔 포맷’이라 한다. 거꾸로 네트워크에서는 주소를 빅 엔디언으로 쓰는데, 역사적으로 라우팅이 전화를 거는 식으로 접두 부호로 이루어졌기 때문이다. 이의 영향으로 많은 프로토콜과 몇몇 파일 포맷이 빅 엔디언을 사용하고 있다. 모토로라 프로세서들은 일반적으로 빅 엔디언을 사용하며, ARM 프로세서들은 성능 향상을 위해 빅 엔디언과 리틀 엔디언을 선택할 수 있도록 되어 있다.
* 명령어가 복잡하기 때문에 명령어를 해석하는 데 시간이 오래 걸리며, 명령어 해석에 필요한 회로도 복잡하다.
* CISC란 소프트웨어 특히, 컴파일러 작성을 쉽게 하기 위해 하드웨어화할 수 있는 것은 가능한 모두 하드웨어에게 맡긴다는 원칙 아래 설계된 컴퓨터이다. 
* 뒤에서부터 스택에 PUSH
* 계산연산에서 빅 엔디안보다 속도가 빠름

### Risc
* RISC의 특징을 CISC와 비교하여 알아보면 다음과 같다. 첫째, 명령의 대부분은 1머신 사이클에 실행되고, 명령길이는 고정이며, 명령세트는 단순한 것으로 구성되어 있는데, 가령 메모리에 대한 액세스는 Load/Store 명령으로 한정되어 있다. 둘째, 어드레싱 모드가 적으며, 마이크로 프로그램에 의한 제어를 줄이고, 와이어드 로직을 많이 이용하고 있다. 반면에 레지스터수가 많으며 마이크로 프로그램을 저장하는 칩의 공간에 레지스터를 배치한다. 셋째, 어셈블러 코드를 읽기 어려울 뿐 아니라 파이프라인을 효과적으로 사용하기 위해서 일부 어셈블러 코드를 시계열로 나열하지 않은 부분이 존재하여 컴파일러의 최적화가 필요하다. 최적화를 하지 않으면 파이프라인을 유효하게 이용할 수 없고, RISC을 사용하는 의미가 없어진다.
* RISC는 CISC 형식의 CPU내 ROM에 소프트웨어적으로 적재된 내부 명령어들을 하드웨어적으로 구성해 제어기가 제거된 부분에 프로세서 레지스터 뱅크와 캐시를 둡니다. 이렇게 함으로써 CPU가 상대적으로 느린 메인 메모리에 접근하는 횟수를 줄여 시스템 수행속도를 향상시킬 수 있습니다.  
* 반면 RISC는 실행 속도를 높히기 위해 가능한 한 복잡한 처리는 소프트웨어에게 맡기는 방법을 택한 컴퓨터이다.
* Unix 의 RISC계열의 프로세서가 사용하는 바이트 오더링
* 네트워크에서 사용하는 바이트 오더링
* 앞에서부터 스택에 PUSH
* 비교연산에서 리틀 엔디안보다 속도가 빠름
* Intel 계열의 프로세서가 사용하는 바이트 오더링
* RISC 프로세서의 경우 CISC 프로세서보다 파이프라인 효율이 좋다. RISC는 명령어가 한 클록에 처리되므로, 한 명령어를 오래 처리해서 다음 명령어의 처리가 늦어지지 않기 때문이다. 또한, 메모리에 접근하는 경우, 매우 오랜 처리시간이 걸리는데, RISC는 LOAD나 STORE 명령어만으로 메모리에 접근하므로 비효율적인 접근이 CISC보다 적기 때문이다.
* 최대의 단점은 코드밀도가 감소하여 같은 내용을 처리하는 데 더 많은 코드 용량이 필요하게 되었다는 점이다. 그 원인은 또 다음과 같이 분류할 수 있다.
  + 항상 16bit 혹은 32bit를 차지하는 고정 길이 명령어는 상황에 따라 8~32bit를 오가는 CISC의 가변 길이 명령어에 비해 코드밀도 면에서 원천적으로 불리하다.
  + 메모리를 대상으로 하는 연산 명령어의 경우 CISC에서는 1개 명령어로 표현 가능한데 RISC에서는 load-execute-store로 3개의 명령어가 필요하다.
  + 마이크로코드로 한 줄로 구현된 CISC명령어를 몇 개, 혹은 수십개의 RISC명령어로 변환해야 한다.

### Cisc, Risc 차이점
* Complex
  + CISC의 단점이자 RISC의 장점은 CISC의 경우 하드웨어의 회로가 복잡해져서 RISC에 비해 가격이 비싸지고 발열이 많고 전력소모가 많게 됩니다.
  +  RISC 명령어가 단순히 명령어 수를 줄인 것이 아니라 명령어 해석기에서의 마이크로코드의 의존도를 제거하고 관련 로직을 단순화하여 성능을 올리는 방향으로 발전했다는 것을 상기하라.
* Instruction
  + RISC: CPI(Clock Per Instruction)을 1 이하로 줄이는 것임, 동급의 CISC에 비해 더 높은 clock frequency를 실현하는 것임
  + RISC 프로세서의 경우 CISC 프로세서보다 파이프라인 효율이 좋다. RISC는 명령어가 한 클록에 처리되므로, 한 명령어를 오래 처리해서 다음 명령어의 처리가 늦어지지 않기 때문이다. 또한, 메모리에 접근하는 경우
  + CISC에서는 여러 clock을 차지하는 복잡한 연산을 하는 명령어들이 종종 있었다. 심지어 for 루프를 실행하는 명령어가 존재했을 정도였다. 이는 과거에 컴파일러의 성능이 부족했기 때문에, 컴파일러를 사용한 후에도 최적화를 하기 위해서 기계어 코드를 수정하는 등 프로그래머가 기계어를 직접 다루는 경우가 많았기 때문이다. 
* Set
  + CPU는 메모리 접근을 피하기 위해 인자나 지역변수를 저장하는데에도 레지스터를 사용한다.
  + 즉, CISC 각각의 명령어는 머신코드는 길지만 전체 프로그램 사이즈는 RISC보다 작습니다. 따라서 코드를 수행할 때 RISC가 메모리를 더 많이 참조해야 하므로.... [CISC가 RISC보다 빠른 요인이 됩니다.] CISC는 복잡한 하드웨어를 가지게 되므로 보통 hard wired방식 보다는 microprogram 방식을 사용하게 됩니다. RISC는 hard wired 방식을 사용할 수 있습니다. [RISC가 CISC보다 빠른 요인이 됩니다.]
  CISC는 레지스터의 양이 많을 필요가 없고 RISC는 레지스터의 양이 많아야 하므로.... (예>함수에 파라미터를 메모리에 저장하는 경우와 레지스터에 저장하는 경우의 차이)
CISC가 메모리의 access가 많아지게 됩니다. [RISC가 CISC보다 빠른 요인이 됩니다.] RISC머신이 파이프라인구현이 용이하다라고 합니다..
* Stack
  + CISC: 일반적으로 하드웨어 스택이 내장되어 있어서 서브루틴 리턴 주소나 인자, 지역변수, 기타 임시 값을 저장하는데 사용한다. Call, ret, push, pop 같은 기계어 명령어를 사용할 경우 stack의 데이터는 자동적으로 관리된다.
  + RISC; Stack 관련 명령어가 존재하지 않음; Return address 나 기타 stack 자료 구조는 SW 적으로 처리해주어야 한다.; Power PC 의 경우, 함수의 인자를 전달하기 위해 8개의 레지스터를 따로 준비하고 있다. 인자값을 메모리에 접근하는 stack operation에 비해 register에 load 한다. 지역변수를 저장하기 위해 stack을 사용할 필요가 없다. 대부분의 짧은 프로시저나 함수를 호출할 때 리턴주소를 SW stack에 저장하기 위해 stack을 사용할 필요가 없다.

## 파이프라인
* 파이프라인(instruction pipeline)은 명령어를 읽어 순차적으로 실행하는 프로세서에 적용되는 기술로, 한 번에 하나의 명령어만 실행하는 것이 아니라 하나의 명령어가 실행되는 도중에 다른 명령어 실행을 시작하는 식으로 동시에 여러 개의 명령어를 실행하는 기법이다.
* 하나의 명령어는 여러 개의 단계로 나눌 수 있는데, 이때 하나의 명령어를 처리할 때까지 다음 명령어가 처리되지 않고 기다린다면, 명령어의 특정 단계를 처리하는 동안 다른 단계를 처리하는 부분은 아무 작업도 하지 않게 된다. 이때 파이프라인을 사용하면 한 명령어의 특정 단계를 처리하는 동안 다른 부분에서는 다른 명령어의 다른 단계를 처리할 수가 있게 되므로 속도가 향상될 수 있다.
* 파이프라인의 효율은 브랜치나 서브루틴 콜이 많아질수록 떨어진다. 그 이유는, 브랜치나 서브루틴 콜이 이루어지면, 파이프라인에서 처리되던 명령어들이 다 취소되고 새로 브랜치나 서브루틴의 명령어를 처리해야하기 때문이다. 최신 아키텍처는 분기 예측 등의 기법을 통해 이런 문제를 회피한다.
* RISC 프로세서의 경우 CISC 프로세서보다 파이프라인 효율이 좋다. RISC는 명령어가 한 클록에 처리되므로, 한 명령어를 오래 처리해서 다음 명령어의 처리가 늦어지지 않기 때문이다. 또한, 메모리에 접근하는 경우, 매우 오랜 처리시간이 걸리는데, RISC는 LOAD나 STORE 명령어만으로 메모리에 접근하므로 비효율적인 접근이 CISC보다 적기 때문이다.

### 부연설명
* CPU 전체가 한 번에 하나의 명령을 처리하는 것이 아니라 명령어 몇 개를 동시에 처리함과 동시에 명령 하나를 또다시 여러 단계의 작은 명령으로 나누고 각 부분을 차례대로 처리한다. 
* 즉 몇 개의 명령어가 몇분의 1로 나누어지고, 그런 명령어 몇 개가 한번에 돌아가는 것이다. 이런 식으로 작동하는 이유는 많은 기계어 명령이 코드로는 하나로 되어 있어도 실제 처리해야 하는 일은 여러 단계로 나누어져 있고 각 단계는 이전 단계가 처리되기 전에는 수행이 불가능하기 때문이다.

### 클록
* 클럭 속도(문화어: 박자속도) 또는 클록 주파수는 컴퓨터 프로세서의 동작 속도이다. "초당 사이클"로 측정하며 헤르츠(Hz) 단위를 사용한다.



## bus
* CPU와 메인 메모리 사이에 데이터를 저장하기 위한 터미널이다.  
  ^bus is terminal between CPU and Main memory to save data
* Address bus, Data bus, Control bus
* [Bus link](http://ssoonidev.tistory.com/14)
* [Bus link2](http://contents.kocw.net/KOCW/document/2015/cup/leesangkwan/6.pdf)

## SSD HDD
* Hdd: 디스크가 돌아야 한다.  
    ^Hdd: disk has to spin
* 기가바이트 회사가 HDD를 RAM으로 만들었었다.  
    ^Gigabyte Company made the HDD with RAM. It didn't release
* SSD는 HDD보다 약 5배 빠르다.  
    ^SSD is 5times faster than HDD
* SSD는 읽기위 쓰기를 하는 개수에 한계가 있다.  
    ^Reading and writing have a limit in SSD
* SSD: Flash memory(Like USB) + Controller  
  - 읽기가 쓰기보다 빠르다
      ^Reading is faster than writing
  - Cell(Memory Storation way) SLC(single) > MLC(Multi) > TLC(triple)  //Usually we use MLC
    + 셀의 개수가 SSD의 가격을 결정한다.  
        ^The number of cell decides SSD's price
    + SLC: 1비트가 1개의 방에 저장된다.  
        ^SLC: 1 bit will be stored in one room
    + SLC: 컨트롤러를 복잡하게 만들고, 불안정하게 한다.  
        ^SLC: It makes a controller complicated and it makes it unstable

### SSD 메모리 셀의 타입
* SLC, MLC, TLC
* TLC는 용량이 큼, 동작 속도가 느림(하나에 3개의 비트가 들어가 있음)
 * 전자 가출률 높음(컴퓨터를 지속적으로 사용해야 함)

### SSD의 장점
* 발전 속도가 빠름(용량/속도)
* 충격에 강함(전자적으로 처리하기 때문에; HDD는 헤드가 머리카락 크기정도의 간격으로 처리하기 때문에 약함)
* 크기가 작고 가벼움
* 병렬처리가 쉬움

### SSD의 단점
1. 배드블록; FTL
* 사용 가능한 블록이 없을 때 GC(Garbage Collection)에서 사용된 블록 정리
 * OP(Over Provisioning 영역)에서 배드 블록을 교환해줄 수 있는게 들어있음.(SSD가 128GB라고 하면 할당 안됐던 부분)
* 배드 블록이 생길 가능성
 1. 블록 내구도 초과
 2. 자연 배드 블록
2. 쓰기/읽기 방해
3. 리텐션 에러

## Clipboard
* 윈도우 뿐만 아니라 다른 OS에도 있다.  
    ^Not only on Windows, but also on other operating systems.




# 키보드

## 멤브레인
* 장점: 러버돔 고무; 제조 간단; 단가 저렴; 방수; 가벼운 무게, 저소음
* 단점: 손가락 피로감, 낮은 병렬성->동시 입력 제한, 고장-> 키보드 교환
* 구성: 키캡, 러버돔, 멤브레인, 쇠로 구성

## 무접점
* 구성은 비슷하지만 러버돔 안에 스프링이 존재; 러버돔이 밑에 바닥부분과 접촉하지 않아도 쉽게 눌림
* 장점: 키보드에 무리가 덜감으로 인해 높은 내구도
* 단점: 비싼 가격; 러버돔의 변형
* 키압 선택 가능(균등/차등); wasd 키는 가볍게 다른 것은 무겁게

## 기계식
* 적축, 흑축, 청축, 갈축
  * 1. 필요 키압 2. 소리와 느낌
* 독립적인 스위치; 동시 입력 + 반 영구적인 내구도; 키가 고장나면 한개만 수리
* 비싼 가격; 무게; 오염에 약함

### 청축
* PC방 사운드; 힘 50g; 

### 갈축
* 소음기 달린 청축버전; 힘 45g; 조용하지만 소리 내고 싶음; 입문하기 좋은 기계식

### 적축
* 갈축과 비슷; 빠른 입력/잦은 오타; 힘 45g; 전문가 느낌
* 단시간에 같은 키 반복 입력에 편리

### 흑축
* 입문용에서 제일 먼; 높은 키압; 힘 60g; 조용함+바닥소리
* 리듬게임이나 격투게임의 유저같이 키 실수가 가장 나면 안되는 사람들이 사용; 힘 60g


# Bus 
## CPU
* CPU - 캐시(CPU 칩 안의 작은 칩) - 버스(CPU와 메인 메모리 사이에 데이터를 저장하기 위함) - 메인 메모리
*   MBR(CPU 안)- 데이터 버스 - 주기억 장치 - 주소버스 - MAR(CPU 안) - PC
 * 채널에 관리가 되는 입출력 장치도 꽂혀있음
* 양방향성: 데이터 버스
* 1K = 2의 10승;  1M = 2의 20승

## IO 장치가 시스템 버스에 직접 접속되지 못하는 이유
* 종류에 따라 제어 방법이 서로 다른 I/O 장치들의 제어 회로들을 CPU 내부에 모두 포함시키는 것이 어려워 CPU가 그들을 직접 제어할 숭 ㅓㅄ기 때문이다.(CPU도 채널로 하여금 관리)
* I/O 장치들의 데이터 전송 속도가 CPU의 데이터 처리 속도에 비해 훨씬 느려 CPU도 채널을 붙임
* I/O 장치들과 CPU가 사용하는 데이터의 형식ㅇ의 깅리가 서로 다른 경우가 많다.

## 버스의 종류
- CPU가 처리한 데이터들은 모니터에 출력되거나 메모리에 저장되어 진다. 이러한 행위가 이루어 지기 위해서는 위의 데이터들이 각 컴포넌트끼리 통신이 가능 해야한다. 이러한 통신을 가능하게 해주는 Subsystem이 존재한다. 또한 이러한 Subsystem을 Computer Bus라고 한다. 즉 버스는 데이터를 통신할 수 있게 해주는 시스템이다.
 
### System Bus
-  CPU와 메모리를 연결하는 Subsystem을 System Bus라고 명명한다.
- 입출력장치는 조건(프린터,키보드,태블릿 등)에 따라 읽어들이는 데이터가 일일이 다르다. 느리고 서로 읽는 데이터양도 다른고, 그 두개의 문제가 다 해결됬다 하더라도 문제가 또 있다. cpu가 입출력장치를 직접 컨트롤 하지 않는 이유는 입출력장치가 너무 다양하다는 것이다. cpu입장에서는 개별적인 입출력장치를 어떻게 처리해야할지 고민 안해도되고 중간 제어기와 어떻게 대화할지만 생각하면된다. 이런 중간제어기가 바로 시스템버스다. 
 
### I/O Bus   https://richong.tistory.com/92 [study]
- 메모리와 다른 입출력 장치와 통신을 하는 Subsystem을 I/O Bus라고한다.
 
 
# 시스템 버스
## 데이터 버스
- 데이터 버스는 시스템 모듈들 간의 데이터 이동 경로를 제공한다. 주로 32, 64, 128 또는 그 이상의 분리된 선들로 구성되어 있으며 선의 수는 한 번에 전송할수 있는 비트 수를 결정지어 주는데 이것은 CPU가 수용할 수 있는 데이터의 크기, Word와 밀접한 관계가 있다.
• CPU가 기억장치 또는 I/O 장치간의 데이터 전송 신호 선 • 데이터 선의 수는 CPU가 한 번에 전송할 수 있는 비트 수를 결정 [예] 데이터 버스 폭 = 32 비트라면, CPU와 기억장치 간의 데이터 전송은 한 번에 32 비트씩 가능 
- 한편 버스에는 데이터 버스도 있다. 데이터 버스는 위에서 언급한 예에서, 데이터를 보낼 때 사용하는 버스이다.  데이터 버스는 각종 장치들이 자신들의 데이터를 보내는 만큼, 당연히 서로가 보낼 수 있는 양방향 버스이다.  데이터 버스는 워드(한 번에 처리하는 명령어의 단위)에 맞먹는 회선이 필요하다. 가령 요즘 쓰는 64비트 컴퓨터는 64비트 버스가 되어야 하는 것이다. 
 
 
## 주소 버스
- 주소 버스는 데이터의 근원지나 목적지의 일정한 메모리 주소를 전달하는 버스이다. 
- 주소 버스의 폭은 최대 기억장치의 용량을 결정지어 주는데 32개의 주소 버스를 지닌 컴퓨터 시스템은 2^32개의 메모리 위치를 할당할 수 있다. 또한 I/O포트를 지정하기 위해서도 사용되어진다.
- CPU에서 외부(주변장치)로 발생하는 주소 정보 전송 신호선 • 주소 선의 수는 CPU와 접속되는 최대 기억장치 용량 결정 [예] 주소 버스의 비트 수 = 16 비트라면, 최대 216 = 64K 개의 기억 장소들의 주소지정 가능 
- 가령 중앙처리장치에서 메모리 중 01111111에 해당하는 곳에 데이터를 보내려면, 이 데이터만이 아니라 이 데이터가 갈 곳인 01111111이라는 정보도 주소 버스를 통해 보내야 하는 것이다. 
 
## 제어 버스
- 제어 버스는 데이터 버스와 주소 버스를 제어하기위해 사용되어 진다. 데이터 버스와 주소 버스는 공유하는 선들의 집합이므로 이들을 제어하는 수단이 반드시 필요하기 때문에 사용한다. 
- CPU가 시스템 내의 각종장치들의 동작을 제어하기 위한 신호선 

### 제어버스 예제
- 기억장치의 읽기/쓰기(memory read/write) 신호 
- 입출력장치의 입력/출력(I/O input/output) 신호 
- 인터럽트(interrupt) 신호
-  버스 제어(bus control) 신호 
 
# CPU와 시스템 버스간의 접속
- 주소 버스 : 단방향성(unidirectional) 주소는 CPU로부터 기억장치 혹은 I/O 장치들로 보내지는 정보 
- 데이터 버스, 제어 버스 : 양방향성(bidirectional) 읽기와 쓰기 동작을 모두 지원 
 
2. 동기식 버스 vs 비동기식 버스

# 동기식 버스
 * 동기식 버스는 정해진 시간에 데이터를 전송하는 방법이다. 이 때 시간은 버스가 가지고 있는 Clock을 기준으로 하며 빠르고 인터페이스 논리회로가 간단하다는 장점이 있지만 느린 장비도 이 Clock에 맞춰야 한다는 점에서 시간 낭비가 발생할 수 있다. 
 
# 비동기식 버스
 * 비동기식 버스는 동기식 버스와 달리 시간을 따로 정하지 않는다. 단지 서로 데이터를 주고 받을 준비가 되어있는지 확인하는 핸드쉐이킹 프로토콜을 사용하여 수신측에서 준비가 되었으면 바로 전송을 하는 방식이다.
장점은 따로 정해진 시간이 없기 때문에 시간 낭비가 적다는 점이고 단점은 회로 구성이 복잡하고 핸드쉐이킹하는 과정이 필요해서 속도도 동기식에 비해 느리다.
 
3. PCIe
 * 버스의 특징이 공용 선이라는 것인데 이 특징덕분에 한 쪽이 데이터 선을 점령하면 다른 쪽에서는 신호 중첩을 유발 시킬수 있어서 사용을 하면 안된다. 이 점을 보완하기 위해 점대점 상호연결방식이 등장하였다.
 
## QPI(Quick Path Interconnect)
 * 다른 구성요소와 직접연결하는 점대점 상호방식중 하나로 레이어로 구성된 프로토콜 구조이므로 물리적으로 연결되어 있는 부분부터 오류의 존재 여부를 점검하는 등 각각의 레이어에서 하는 일을 구분되어 있다. 고속, 고효율의 패킷 기반의 전송방식을 사용하며 인텔의 i7 데스크톱 프로세서 이후로 사용되어지는 방식이다.
 
## PCIe(Peripheral Component Interconnect Express)
 * 버스를 1대 1로 연결해서 택시로 만들어 버렸다. 높은 용량덕분에 기가이더넷과 같은 빠른 데이터 속도의 I/O 디바이스를 지원하는데 사용되어지며 각각의 버스마다  독립적인 데이터 흐름을 제공하여 많이 사용되어진다. 또한 핀수가 적고 물리적 면적이 작으며 상세한 오류검출 및 보고구조 등의 장점을 가지고 있다.
 * 최근엔 I/O 가상화도 지원한다.

# 환경변수 등록

## Path
- 서비스에 등록한 것과 같음.
- 우선순위가 높은 것이 올라가는 등 순서가 바뀜
  - 시작 프로그램에 등록해놓으면 우선순위 올라감; 수동적으로 수정해서 우선순위 변경 가능
