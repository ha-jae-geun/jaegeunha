# GPU
* 논리적으로 수천 개의 코어가 있으며 쉽고 서로 관련 되어있지 않은 독립적인 일을 병렬적으로 하는데 

# 슈퍼 컴퓨터
* 슈퍼 컴퓨터가 할 수 있는 것은 일반 컴퓨터도 할 수 있다.
* CPU는 고성능보다 저전력에 다량으로 집어넣음
 * 한 슈퍼컴퓨터가 사용하는 전력의 양 = 중소도시 전체 사용량

## 계산노드
* 예를 들어 54코어 CPU + RAM(512GB) + 여러개의 GPU

## IO노드
* 54코어 CPU + 여러 SSD(TLC, QLC) + SLC/MLC(용량 작지만 속도 빠른) + 램(계층별로) 

## 네트워크 스위치
* 랙(rack) 끼리 네트워크 연결 위함

## 랙(rack)
* 네트워크 스위치 - CN - IO노드

## 스토리지 노드
* 네트워크 스위치 - 여러 랙 - 네트워크 스위치 - 스토리지 노드(최종저장)

## 스토리지 메타데이터 노드
* 파일을 찾을 때 그 파일이 어디 SN에 있는지 몇번째 하드에 있는지 알려주는 정보 보관

# 윈도우
* 루퍼스
* 3DP Chip

## 정품
* 개발용 컴퓨터: 폴더 보안

# 중고 컴퓨터
* CPU, 메인보드, 램, 그래픽카드/VGA, SSD, HDD, 본체
* CPU는 반후법칙
* 램은 16GB면 8GB 두개 끼거나 16GB 한개 끼거나( 램은 따로 떼어서 파는 사례가 많아 가격이 많이 안내려감)
* 중고나라, 다나와, 구글
  * 구글에 - vs 
* 기본적으로 컴퓨터 부품은 최소 1~3년 또는 3~5년 정도의 무상a/s기간이 존재합니다.  (이 기간은 부품별로 다릅니다.)
* 어느제조사 파워인지와 정격파워인지 뻥파워인지도 알아보셔야 합니다. 뻥파워라고 해서 못쓸건아닙니다만. 정격파워와는 다르게 뻥파워600W면 최대출력이 600W이고 안정적으로 사용할수 있는 실제 W수는 250-400W사이라고 합니다. (제조사마다 다릅니다.) 뻥파워의 성능은 그야말로 최악이죠.  그리고 뻥파워는 A/s또한 대부분 제대로 이루어지지 않기에 파워를 교체할 수 밖에 없게됩니다. 
* 5. 그냥 돈 10-20만원 더모아서 다나와에서 조립컴퓨터 맞추고 동네 컴퓨터점에서 윈도우만 깔아달라고 해라﻿
 
# 노트북
* 게이밍 / 경량(코딩 등에 특화) / 맥북
* 화면 크기(키패드 유무), 무게(저장 공간, 그래픽 카드), 램, CPU, 프리도스(운영체제 미설치)
* 무게 결정: 하드디스크, 그래픽카드
* 다나와

# 모니터
* 화면크기, 패널, 해상도(와이드; FHD/4K), 주사율, 플리커 프리, 블루라이트 차단, 틸트

## 일반 사무용 모니터
* 일반적으로 24, 27인치

## 게이밍 모니터


## 패널
1. 응답속도
* GTG: 회색 to 회색
* 빠르면 게임에 적합

2. 광시야각
* 어디에서 보든 정자세에서 보는 사람과 같은 화면 볼 수 있음

3. 색 표현

## 해상도
* 보통 16:9
* FHD(1920x1080)

## 주사율
* 1초에 화면이 새로고침 되는 횟수; 사무용은 60HZ면 충분
  * 높은 주사율을 구사하려면 그래픽 카드가 뒷받침 되야함(그만큼 많은 화면을 보여줘야 하기 때문)
* 기존엔 68HZ명 충분했지만 게이밍 모니터엔ㄴ 144HZ를 선호하기 시작; 2014년에 대부분 인터넷에서 최대 60프레임까지 사용 가능

## 플리커
* 플리커프리: 화면 깜빡임이 없어 장시간 사용에도 눈의 피로도가 적은 모니터

## 블루라이트
* 청색 파장은 자외선과 유사한 속성을 가져 눈의 망막 깊숙히 침투

## 무결성
* 무결점정책이라는게 전세계 통틀어서 한국에만 있는 웃기는 것임. 원래 모든 화면 제품에는 불량화소란 없어야 하는 것이지만 이 공정을 줄이고 불량화소 껴있어도 단가 후려치지 못하도록 양품에다가 프리미엄 가격을 붙여서 더 많이, 더 비싸게 팔기 위한 상술 
  * 회사마다 무결점의 기준, 불량 기준이 다르다.

## g-sync/Free-sync
* 모니터-그래픽 카드 사이의 싱크 맞추는

## 수직 동기화
* 프레임 고정; 프레임이 올라갔다 내려갔다 보다는 차라리 60HZ에 고정;
  * 안정된 프레임으로 고정되기 때문에 59HZ로 프레임이 내려가면 30HZ로 고정시킨다.

## 인풋랙 

## 핫키
* RPG/FPS 각각 다른 그래픽 셋팅 값

## 조준선

## 기타
* 자체 스피커, 틸트

# 비트

- 비트가 클수록 - 한 번에 처리할 수 있는 데이터가 더 많아지는데요. 쉬운 예로 32bit는 빵굽는 틀이 32개이고 64bit는 빵굽는 틀이 64개라는 것입니다. 당연히 구울수 있는 양의 차이가 날 수 밖에요.
- 64비트는 무려, 1천 844경 6744조 737억 955만 1616 비트만큼의 데이터를 처리할 수 있습니다!!
- 32비트와 64비트의 가장 큰 차이점은 메모리 인식률로, 32비트는 4GB까지 가능하지만 64비트는 4GB이상의 RAM을 인식할 수 있는데요. 그렇기에 윈도우 32비트에서는 8GB의 RAM을 꽂더라도 4GB까지만 사용할 수 있습니다. (결국 데이터의 처리 양과 속도, 업그레이드 가능/불가능의 차이로 볼 수 있죠) 데이터 처리속도의 경우 전문적으로 사용하지 않는 이상, 그래픽에서나 그 차이를 확인할 수 있는데요. 64bit가 32bit에 비해 더 정밀한 그래픽 처리가 가능하기 때문입니다. 그리고 이론적으로 32비트와 64비트의 차이는 2배 정도지만, 실제로는 10-20%정도라고 하네요.


## x86 표시 이유
- x86으로 표시된 이유는 바로 PC 칩셋의 품번 때문입니다. x86으로 표기가 된 것은 80-86이라는 숫자를 인텔 32비트이하 계열 제품명에 붙였기 때문인데요. 그리하여 32비트는 x86이라고 표시되어 있는것이죠. x64는 32비트와 다르게 64비트인것을 표시하기 위해 붙여진 것이고요.


## Y2K 문제
* 1900년대 시간을 가르킬 때 19라는 반복되는 숫자를 아끼기 위해 19 생략하고 뒤에 년도만 표시했었음
  * 평촌 목련아파트 온수 공급중단 사건

## Y38K 문제
* Y38K(2038년도) 문제; time_t가 1970년도 1월 1일부터 시간 세는 중; 2038년 1월 10일에 1901년대로 인식하게 되고 이렇게 되면 조그만 가정제품부터 큰 댐, 공장에게 치명적인 오류가 발생할 가능성이 높다.

## 32비트
* 4,294,967,295 숫자 표현 가능; 예전 바람의 나라 풀 경험치; 여기서 맨 왼쪽 부호비트 주면서 2,147,483,647 표현
* Y38K(2038년도) 문제; time_t가 1970년도 1월 1일부터 시간 세는 중; 2038년 1월 10일에 1901년대로 인식하게 되고 이렇게 되면 조그만 가정제품부터 큰 댐, 공장에게 치명적인 오류가 발생할 가능성이 높다.

## 64비트
* 2922억년 7천만년까지 카운트 가능
* 램을 192GB까지 지원 가능

## 게이밍 노트북
* 화면 크기가 크면 무겁지만 큰 것을 고려하는 사람이 많음

## 초경량 노트북; 울트라북


## 폰 노이만 구조
* 입력 장치 -> CPU(제어장치 / 산술+논리장치) <> 메모리 -> 출력장치
* 폰노이만 구조는 크게 CPU, 메모리, 입출력 장치로 구성되어 있으며, CPU안에는 산술/논리장치, 프로세서 레지스터를 포함하고 있는 처리 장치(Processing Unit)와 명령어 레지스터와 프로그램 카운터를 포함하는 제어장치로 구성된다. 메모리는 데이터와 명령어를 함께 저장할 수 있다.

## IOT
* OS + CPU + 메모리 + 

## 영상
* Decoder -> codec (열 많이 냄)

## 열 발생
* CPU, 그래픽 카드

# NAND
* SSD 는 NAND Falsh Memory 를 사용합니다.
* SLC ( Single Level Cell ) : 셀당 1바이트를 기록, 속도와 수명이 가장 높다. 가격 또한 비싸다. 초기 SSD에 사용됬었다.
* MLC ( Multi Level Cell) : 셀당 2바이트를 기록, 속도와 수명은 보통. 가격 또한 적당. 현재 대부분 SSD에 사용된다.
* TLC ( Triple Level Cell) :  셀당 3바이트를 기록 , 속도와 수명이 매우 낮다. 주로 USB에 많이 사용된다.
* NAND Falsh Memory 는 셀마다 플로팅 게이트(FG) 라는곳에 전자를 채우고 비우는 방식으로 기록 됩니다.
* SLC 상에서는 가득차고 비우고로 구분을 하기때문에 간단하지만 MLC 부터 TLC 는 채워진 전자의 양에 따락 구분하므로 읽고 , 쓰기 속도가 떨어집니다.
* 또한 NAND Falsh Memory 는 덮어쓰기 기능이 존재하지 않습니다. 말했듯이 전자를 채우고 비우는 방식으로 기록하기 때문에 일단 지우고 다시 채우는 방식을 택하기때문에, 덮어쓰기가 불가능 합니다ㅏ.
* 그러므로 MLC 와 TLC 처럼 전자의 채워진 양을 구분해서 기록하고 쓰기때문에 이 작업은 더뎌 질 수 밖에 없죠.
* 정확한 전자량을 측정하기 매우 힘들기때문에 , 전자의량을 세부화 시킨 TLC 는 오류량도 그만큼 많고, 그 많은 오류를 측정하기 때문에, 속도가 더욱 떨어지게 된다고 합니다.

## NAND와 DRAM의 차이
* 메모리 반도체는 어떤 디바이스든 모두 스위칭 및 데이터 저장 기능을 갖습니다. 스위칭 기능은 창고에서 데이터 집단을 받을 것인지 받지 않을 것인지의 여부를 결정하는 문(door)의 여닫이 역할을 하고, 데이터 저장 기능은 말 그대로 데이터를 쌓아두는 창고 역할을 하지요.
* 스위칭 동작에 있어서는 디램이 훨씬 빠르지만, 데이터 저장 기능에서는 낸드플래시가 월등합니다. 디램은 64ms(1,000분의 1초) 동안만 저장할 수 있는 반면, 낸드플래시는 디램과 비교했을 때 저장기간이 상상을 초월합니다. 제품별로 다르지만, 저장하는 Cell의 물리적인 입장에서 본다면 SLC는 약 5~10년, MLC/TLC는 약 1~2년 동안의 기간을 저장할 수 있습니다(SW 등의 보완 조치로 저장 기간을 더욱 길게 확장 할 수 있음). 그래서 낸드플래시는 전원이 꺼져도 창고라는 공간에 저장된 데이터가 존재하므로 ‘비휘발성 메모리’라고 합니다. 반면 디램은 전원이 ON일 때 일정한 주기로 새로운 refresh 전원을 계속적으로 인가해주면 데이터는 저장창고에 남게 됩니다. 하지만 전원을 OFF하면 어떤 경우든 데이터는 소멸하므로 ‘휘발성 메모리’라고 부릅니다.
* 낸드플래시가 구조적으로 디램과 구분되는 가장 큰 차이점은 게이트(Gate)가 2개라는 점입니다. MOS형 트랜지스터(Tr)는 소스(Source), 드레인(Drain), 게이트 총 3개의 단자로 구성되는데요. 그중 게이트 단자가 1개이면 디램, 2개이면 낸드플래시가 됩니다. 낸드플래시의 추가된 게이트 단자는 부유 게이트, 즉 플로팅 게이트(Floating Gate)라고 부릅니다. 이는 모든 입체 영역으로부터 절연층으로 분리된 상태로 마치 섬처럼 부유하고 있다고 하여 붙여진 이름입니다. 이로 인해 낸드플래시는 읽고 쓰고 저장하는 모든 동작에서 디램과 에스램(SRAM)보다 독특한 특성을 지니게 되었는데요. 그 중 가장 핵심적인 특징이 데이터를 원하는 일정기간 저장할 수 있는 비휘발성 데이터의 저장 능력입니다. 그런데 이러한 장점을 갖기 위해서는 동작 속도 등 디바이스 특성에서 희생을 감수하고, 또 재질과 공정방법 및 설계 등에서 보완해야 한다는 단점이 다수 있습니다. 
* 따라서 구조적으로 볼 때, 디램은 스위칭 역할을 하는 Tr 1개와 Tr 밖에 별도로 데이터를 저장하는 캐패시터 1개를 둡니다(DRAM Cell=MOS Tr 1개+Capacitor 1개). 반면 낸드플래시는 스위칭 역할을 하는 트랜지스터 속에 데이터 저장 기능을 갖는 플로팅 게이트를 같이 내포하고 있어서 MOS Tr 1개만으로 메모리로서 해야 할 여러 가지 기능을 수행합니다(NAND Cell=MOS Tr 1개). 따라서 낸드플래시는 Top gate(상판게이트 혹은 Control 게이트)와 Bottom gate(하판 게이트 혹은 부유 게이트)가 있으므로 총 2개의 게이트를 갖게 되는 셈입니다.
* 집적도 측면에서는 낸드플래시가 메모리 디바이스 중 가장 유리합니다. 표면적을 차지하는 디바이스의 점유 면적을 상대적으로 가장 작게 할 수 있기 때문이지요. 낸드플래시의 집적도가 가장 높은 근본적인 이유는 구조에서 찾아볼 수 있는데요. 디램은 저장기능을 하는 캐패시터를 Tr 밖에 별도로 두어야 하므로 2D 표면적을 많이 점유합니다. 따라서 낸드플래시의 집적도는 항상 디램보다 앞서 나가며, 3D를 적용하고부터는 집적도 차이는 더욱 커질 것으로 예측됩니다. 동일 메모리의 저장용량으로 들여다볼 때, 2D 낸드플래시의 구조적인 차이가 디램과 10년 차이를 만들어 내었고, 3D 낸드플래시는 동일 집적도 비교 시 디램과는 15년 차이를 나타낼 것으로 예측됩니다. 
* 낸드플래시는 메모리 디바이스 중에 속도가 가장 느립니다. 이는 디램과는 달리 추가적으로 존재하는 게이트인 플로팅 게이트가 있기 때문인데요. 낸드플래시의 핵심 구조물인 플로팅 게이트는 낸드플래시에 전자들을 저장하는 역할을 합니다. 플로팅 게이트를 6개 면으로 둘러싸고 있는 절연막들은 그 안에 저장된 전자들이 쉽게 탈출하지 못하도록 막는 역할을 하지요. 그래서 플로팅 게이트의 위로는 Blocking Layer(ONO : 3개 절연층)가 있고, 아래로는 Tunneling Oxide(전자들이 건너가는 절연막, SiO2), 옆으로는 Sidewall Oxide(측벽절연막, SiO2)가 막아서고 있습니다. 이런 구조에서 동작 전압이 인가되면 플로팅 게이트와 아래위의 절연막들이 합작하여 여러 가지 캐패시턴스 성분을 만들고, 이런 성분들이 결국 낸드플래시의 동작 속도를 느리게 하는 요인으로 작용하게 됩니다.
* MOS Tr에 인가되는 게이트 단자에 디램과 낸드플래시에 동일한 크기로 전압이 인가될 경우, 채널 형성에 기여하는 실질적인 전압은 낸드플래시에 더 작게 인가됩니다. 이는 플로팅 게이트와 플로팅 게이트 아래위로 존재하는 2개 캐패시터의 영향 때문이지요. Word line으로 게이트 전압 Vgate가 인가 시에 디램은 기판층(Substrate) 혹은 채널에 직접적인 영향(Vgate=Vsub)을 끼칩니다. ▶<채널이 만들어 내는 반도체 동작특성, 드레인 전류의 변화> 편 참고 하지만 낸드플래시에서는 기판 방향으로 직렬로 늘어서 있는 캐패시터 2개(Cono+Ctox)를 통과하기 때문에 기판에 최종적으로 인가되는 전압 Vsub(Input 전압2 @NAND)은 초창기 게이트 전압 Vgate(Input 전압1 @DRAM)에 비해 작아집니다.
* 트랜지스터의 스위칭 작용인 ON/OFF를 결정 짓는 드레인 전류를 비교해보겠습니다. 게이트에 전압이 동일하게 인가되는 조건(Vgate)이라면, 디램보다는 낸드플래시의 드레인 전류가 적게 흐르고 전류 Drive 능력이 떨어지므로 동작 속도도 느려집니다. 일반적으로 게이트 입력 전압을 증가시킬 경우 기판 내의 전자가 이동할 채널의 체적이 커지므로 드레인 전류(소스 단자에서 드레인단자로 이동하는 전자의 흐름)는 게이트 전압에 비례하여 증가합니다. 또, 소스와 드레인 단자 사이를 연결하는 채널도 빠르게 형성되므로 동작 속도 역시 빨라지지요. 
* 그런데 디램과 낸드플래시의 드레인 전류 증가율을 비교해보면, 입력 게이트 전압이 높아질수록 디램에 비해 낸드 전류의 상승률이 낮습니다. 이는 실질적으로 기판의 채널에 영향을 주는 게이트 전압인 Vsub의 증가률이 낮기 때문이지요. 결국 MOS Tr이 ON/OFF 구실을 제대로 하기 위하여는 일정 전류량 이상이 확보되어야 하는데요. 따라서 낸드플래시의 경우, 드레인 전류량을 디램과 동일하게 하려면 인가하는 게이트 전압을 디램보다 높여야 하겠지요

# 램; Random Access Memory = 주기억장치(Rom+RAM), DRAM, 메인 메모리
* <> SAM; Sequential Access Memory; 순차 접근 메모리; 하드디스크, CD, 테이프(예전에 테이프 감으면서 썼던것 처럼; 랜덤하게 갈 수 없음)
* DRAM = Dynamic RAM; 메인 메모리; 주기억장치(ROM+RAM)
  1. 최근에 접근된 데이터; Tempoary Locality - 시간적 지연성
  2. 최근에 접근된 데이터의 주변 데이터; Spatial Locality - 공간적 지연성
* CPU - 램 - 하드디스크
* Level 1,2,3 캐시 접근 - 메인 메모리(램) - SSD
* 램이 크면 느린 디스크와 상대할 일이 줄어들기 때문에 속도도 자연스럽게 빨라진다.
  * 현재 필요한 데이터와 가까운 미래에 필요할 것 같은 데이터만 램에 올려놓기 때문에 게임보다 작아도 정상 실행된다.
* 16GB 1개 VS 8GB 2개(듀얼채널); 

## 속도
* CPU > Level1 cache access > Level2 cache access > Level3 cache access > RAM > Optane Memory > SSD > HDD

## Optane Memory: 비휘발성메모리
* 램에서 발전
* 인텔과 마이크론의 합작으로 탄생한 RAM과 플래시 메모리의 중간 형태. 일단은 비휘발성 메모리이다. 다만 DIMM 형태로 RAM이나 메모리가 아닌 새로운 패러다임으로 봐야할 지도 모른다. 기존의 NAND 형태의 SSD보다 레이턴시가 1,000배 더 빠르고,[1] 1,000만 번의 쓰기가 가능하는 등 1,000배 더 내구성이 뛰어나고, DRAM보다 10배 더 높은 집적도를 가진다고 홍보하고 있다.

## 램을 추가하면 속도가 빨라지는 이유
* 램이 크면 느린 디스크와 상대할 일이 줄어들기 때문에 자연스럽게 빨라진다.

## 게임들이 용량이 큰데 렘이 게임보다 작다
* 현재 필요한 데이터와 가까운 미래에 필요할 것 같은 데이터만 램에 올련호기 때문에 게임보다 작아도 정상 실행된다.

## 램 개수
* 8G2개보다 16GB 1개가 불리할 때가 있음; 

## 듀얼채널 구성

### 메모리 채널
* @@ CPU - 캐시 - 메모리 컨트롤러(채널) - 데이터 버스 
* [메모리 채널](https://thrillfighter.tistory.com/439)

```java
메모리 채널은 메모리와 CPU의 캐시 간에 데이터 전달 통로다. 비유하자면 자동차 도로의 하나의 차로가 하나의 채널이라고 생각하면 된다. 자동차 하나하나를 데이터로 생각하면 1차로 보다는 2차로를 사용할 때 시간당 데이터 전달 양을 많이 할 수 있다. 이것을 대역폭(bandwidth)라고 한다. 2개의 채널을 사용하게 되면 1개의 채널을 사용할 때 보다 대역폭이 2배로 커지므로 캐시에 데이터를 더 많이 전달할 수 있다. 

그렇다고 데이터 전송 속도가 빨라지는 것은 아니므로 대역폭 증가가 처리속도 증가를 보장하지는 않는다. 1차로로 충분한 도로를 2차로로 바꿔도 목적지까지 빨리갈 수 있는 것이 아니기 때문이다.
```

### 메모리 인터리빙
```java
메모리 인터리빙(Memory Interleaving)
채널을 여러 개 사용하면 메모리 인터리빙이라는 기능을 통해서 한번에 미리 사용가능한 데이터를 다채널(듀얼채널)로 캐시에 전달해 놓을 수 있다. 채널1을 통해서 현재 사용하려는 데이터를 캐시에 전달했다면 채널 2를 통해서 다음에 사용할 가능성이 높은 데이터를 동시에 전달하는 것이다. 다음에 사용할 가능성이 높은 데이터는 바로 다음 주소의 데이터가 된다.

이렇게 할 수 있는 이유는 앞에서도 말했지만 듀얼 채널을 사용할 경우 메모리 뱅크 1과 메모리 뱅크 2 간에 주소 순서가 번갈아가면서 연결되기 때문이다.
아무튼 램(메모리) 듀얼채널을 사용하는 이유는 이런 효율성을 위한 것이다. 
```

# CPU
* CPU - 캐시(CPU 칩 안의 작은 칩) - 버스(CPU와 메인 메모리 사이에 데이터를 저장하기 위함) - 메인 메모리
*   MBR(CPU 안)- 데이터 버스 - 주기억 장치 - 주소버스 - MAR(CPU 안) - PC
 * 채널에 관리가 되는 입출력 장치도 꽂혀있음
* 양방향성: 데이터 버스
* 1K = 2의 10승;  1M = 2의 20승


## 코어
* 코어가 많다고 무조건 좋은 것은 아니다. 프로그램이 Unfriendly 멀티코어  프로그램일 수 있따.
* 싱글코어는 일정 클락이상으로 가게 되면 열을 받아 터질 위험이 있다


### 코어와 스레드
* 코어: 물리적인 CPU의 프로세서
* 스레드: 하이퍼스레딩, SMT 기술을 이용하여 하나의 코어를 여러개의 코어처럼 보여주는 논리적인 기술

### SMT
```java
SMT라는 명칭은 동시 멀티스레딩을 뜻하며 학계에서 주로 지칭하는 용어로 사용되고 있다.

시장에서는 인텔이 이 기술을 부르는 이름인 하이퍼쓰레딩으로 더 유명하지만
이 기술이 인텔 독점인 것은 아니며
AMD에서도 기존의 불도저에 적용한 CMT(Cluster Multi-Threading) 구조를 버리고
2017년 3월 초에 출시된 RYZEN에 이 구조를 채용하면서 사실상 거의 모든 데스크탑 CPU에 적용되는 기술이 되었다.


* SMT의 원리
단일 코어에서 구현할 수 있는 명령어 수준의 병렬처리 능력(Instruction-Level Parallelism)은
명령어 종속성(Dependency)으로 인해 구현에 한계가 있다.

RAW(Read-After-Write), WAR(Write-After-Read), WAW(Write-After-Write) 등의 다양한 종속성이 있으며
일부는 구조적으로 극복할 수 있다고 해도 근본적인 종속은 해결되지 않는다.

그렇다면 이를 증가시킬 수 없다면 남는 연산 능력을 다른 스레드의 명령어를 처리하는데 사용한다면
양 스레드간의 명령어 종속성은 거의 없을 것이기에
단일 코어에서 전체적인 명령어 병렬 처리 능력을 증가시킬 수 있다는 개념의 기술이다.

현대의 CPU는 슈퍼스칼라 구조와 파이프라이닝 기법이라고 해서
CPU 전체가 한 번에 하나의 명령을 처리하는 것이 아니라
명령어 몇 개를 동시에 처리함과 동시에
명령 하나를 또다시 여러 단계의 작은 명령으로 나누고 각 부분을 차례대로 처리한다.

즉 몇 개의 명령어가 몇분의 1로 나누어지고, 그런 명령어 몇 개가 한번에 돌아가는 것이다.
이런 식으로 작동하는 이유는 많은 기계어 명령이 코드로는 하나로 되어 있어도
실제 처리해야 하는 일은 여러 단계로 나누어져 있고
각 단계는 이전 단계가 처리되기 전에는 수행이 불가능하기 때문이다.



```

```java
예를 들어 메모리의 값을 증가시키는 명령이 다음과 같이 작동한다면
1번이 끝나기 전에는 2번을 할 수 없고 2번이 끝나기 전에는 3번을 할 수 없다.

1. 메모리의 값을 읽는다.
2. 읽은 값을 더한다.
3. 값을 메모리에 쓴다.
그런데 실제로는 명령이 처리되기 위해 필요한 일이 명령마다 다르다.

CPU의 예시는 아니지만 네트워크 비동기 처리의 예시를 들어보자.

1. 네트워크의 값을 읽는다.
2. 읽은 값을 처리한다.
3. 값을 저장장치에 쓴다.
네트워크에서 특정 값을 읽어 이를 처리하는 경우 상당한 경우에는
네트워크의 대기 시간이 프로그램 전체 실행 시간의 대부분을 차지한다.

이 상황에서 위와 같이 코드를 작성한다면
1번의 네트워크 대기 지연 시간에 의해 프로그램은 상당히 비효율적인 구조를 가지게 될 것이다.


네트워크에서 값을 읽어오는 데 걸리는 시간은
시스템의 자체 저장장치인 메모리나 하드디스크에서 데이터를 읽는데 걸리는 시간에 비해 몇십~몇천배는 되기 때문이다.

이 때 CPU는 1번에서 값을 읽어올 때까지 대기하게 된다.

하지만 CPU가 처리해야 할 일 중에는 이렇게 서로 연계된 일만 있는 게 아니다.

예를 들어 네트워크에서 값이 들어오길 하염없이 기다리는 저 컴퓨터에서 동시에 MP3 파일도 하나 재생하고 있다고 하자.

그렇다면 네트워크에서 값이 들어올 때까지 MP3을 재생하고 있으면 효율이 올라가지 않을까?

하이퍼스레딩은 이렇게 놀고 있는 부분에
명령어 종속성이 없는 다른 스레드의 명령어를 투입하여
CPU의 효율을 높이는 일종의 우회책이다.

CPU의 최대 성능 이상은 절대 낼 수 없지만
프로그램의 한계 때문에 쓰지 못했던 CPU의 남은 성능을 끝까지 쥐어짜는 셈이다.

즉 S/W의 관점으로는 하나의 코어에 하나의 가상의 코어를 만들어서 CPU 2개로 인식된다.

기본적으로 별개의 명령을 처리해야 하기 때문이다.

그래서 HT(=하이퍼쓰레딩)가 지원되는 CPU를 작업 관리자에서 보면 코어 수가 2배로 뻥튀기 되는 것을 알 수 있다.
```

### 하이퍼스레딩이 없는 CPU
```java
이런 식으로 한번에 하나의 명령만 처리 할 수 있다.
두 개의 작업을 재빠르게 전환하는 멀티 태스킹이다.
하지만 하이퍼스레딩을 사용한다면 멀티 프로그래밍이라고 할 수 있다.

이런 식으로 처리할 내용을 우겨 넣어서 성능을 향상 시키는 원리다.

물론 2개의 물리적인 코어보다는 성능이 확실히 떨어진다.

이 논리로 하이퍼스레딩이 있어봤자 느리다고 하지만
그래도 단일 코어 환경에 비하면
상대적으로 다른 프로세스에 훨씬 많은 여유를 줄 수 있는 장점이 있다.

예를 들어 3D 렌더링을 할 경우 진가가 들어나는데
3D 렌더러는 쓰레드 당 한 개의 렌더링 블록을 생성해 내는데,
하이퍼스레딩이 켜진 쿼드 코어 CPU의 경우
8개의 스레드가 생성되어(즉 논리적인 옥타코어) 시간의 이점을 볼 수 있다. (20% 정도 차이가 난다)
```

### 파이프라이닝
```java
현대의 CPU는 슈퍼스칼라 구조와 파이프라이닝 기법이라고 해서
CPU 전체가 한 번에 하나의 명령을 처리하는 것이 아니라
명령어 몇 개를 동시에 처리함과 동시에
명령 하나를 또다시 여러 단계의 작은 명령으로 나누고 각 부분을 차례대로 처리한다.

즉 몇 개의 명령어가 몇분의 1로 나누어지고, 그런 명령어 몇 개가 한번에 돌아가는 것이다.
이런 식으로 작동하는 이유는 많은 기계어 명령이 코드로는 하나로 되어 있어도
실제 처리해야 하는 일은 여러 단계로 나누어져 있고
각 단계는 이전 단계가 처리되기 전에는 수행이 불가능하기 때문이다.
```

## 입출력과 CPU 접속
```java
CPU와 입출력 기기를 접속하는 방법에는 크게 두가지가 있다.

첫번째는 Memory Mapped I/O 라는 방식이 있고,
두번째로 I/O Mapped I/O 가 존재한다.

이 두가지 방식의 차이점 및 각 방식의 특징을 알아보자

Memory Mapped I/O방식은 메모리와 I/O가 하나의 연속된 어드레스영역에 할당된다.
따라서 I/O가 차지하는 만큼 메모리 용량은 감소한다.
CPU입장에서는 메모리와 I/O가 동일한 외부기기로 간주되므로 이들을 액세스 하기위하여 같은 
신호를 사용한다.(read/write) 또한 소프트웨어적으로도 메모리에 대한 엑세스나 I/O에 대한 
데이터 입출력이 동일한 것으로 간주되므로 Load나 Store 명령에 의해 수행된다.
(대표적인 프로세서 : ARM, MIPS, PowerPC, M68K)
위 방식의 가장 큰 장점은 포트 입출력을 구현할 때 부수적인 복잡성이 없어지기 때문에 
CPU 내부적으로 로직이 덜 필요하고, 이는 더 저렴하고 빠르고 쉬운 CPU를 만들 수 있게 한다. 
이 점이 RISC가 추구하는 바와 같다. 이러한 특징은 임베디드 시스템 구현시 장점으로 적용한다.
하지만 주소와 데이터 버스를 많이 사용하게 되어, 메인 메모리에 접근하는 것보다 매핑된 장치에 접근하는 것이 더 느리다.

※ 사용시 I/O영역 변수는 volatile 타입으로 선언해야 한다. (컴파일러의 최적화 방지)
    I/O영역은 Non-cacheable로 설정해야 한다. (캐쉬메모리로 접근할경우 변경된 내용을 못 가져올 수 있다.)


I/O Mapped I/O 는 메모리와 I/O가 별개의 어드레스 영역에 할당된다. 
따라서 I/O를 사용하더라도 메모리 용량은 감소하지 않는다. CPU의 입장에서는 메모리와 
I/O를 구분하여 취급해야 하므로 이들을 액세스하기 위해서는 RD, WR 신호 이외에 추가적으로 
I/O에 접근하기 위한 신호가 필요하다. 소프트웨어 적으로도 메모리에 대한 데이터의 액세스와
I/O에 대한 데이터의 입출력이 서로 다른 것으로 간주됭 메모리에 대한 엑세스는 Load/Store에 의해 
수행되고 I/O의 입출력은 Input이나 Output 명령에 의해 수행된다.
(주로 Intel 계열의 프로세서에서 사용 한다. x86)
이 방식의 가장 큰 장점은 어드레싱 능력이 제한된 CPU를 사용할 때이다. 입출력 접근을 메모리 접근과 
분리하기 때문에 메모리용으로 주소영역 전체를 사용할 수 있다. 또한 어셈블리어상에서 소스를 볼때 
입출력 수행 루틴을 알아보기 쉽다.

참고로 ARM Processor는 임베디드 시스템상의 프로세서로 RISC구조이며 Memory Mapped I/O(MMIO)방식을 취하고 있다.
ARM Assembler나 c로 작성할때 실제로 메모리 주소를 포인터로 잡아서 값에 접근하는 모습을 볼 수 있다. 
특히 어셈블러상에서 in/out과 같은 i/o port 접근 명령어가 따로 존재하지 않고, 일반 메모리에 대한 접근인 
ld/st 명령어를 사용한다. 어떻게 보면 이점이 작성시 더 편리한 듯 싶었다.
```

## 캐시
* 오늘날 CPU 칩의 면적 30~70%는 캐시가 차지한다. 1989년 생산된 싱글 코어 프로세서인 i486의 경우 8KB짜리 I/D 캐시 하나만 있었다. 한편 인텔 코어 i7 쿼드 코어 칩의 다이 맵(Die map)을 보면 4개의 코어에 각각 256KB L2 캐시가 있고, 모든 코어가 공유하는 8MB L3 캐시가 있는 것을 볼 수 있다. (L2 캐시 위에 있는 구역이 L1 캐시로 보이는데, 확실하지 않아서 따로 표시하지 않았다.)
* CPU 칩에는 여러 개의 캐시가 들어가며, 각각의 캐시는 각자의 목적과 역할을 가지고 있다.

### 캐시 종류
* L1 Cache: 프로세서와 가장 가까운 캐시. 속도를 위해 I$와 D$로 나뉜다.
* Instruction Cache (I$): 메모리의 TEXT 영역 데이터를 다루는 캐시.
* Data Cache (D$): TEXT 영역을 제외한 모든 데이터를 다루는 캐시.
* L2 Cache: 용량이 큰 캐시. 크기를 위해 L1 캐시처럼 나누지 않는다.
* L3 Cache: 멀티 코어 시스템에서 여러 코어가 공유하는 캐시.
* 캐시에 달러 기호($)를 사용하는 이유는 캐시(Cache)의 발음이 현금을 뜻하는 'Cash’와 같기 때문이다 :)

### Cache Metrics
* 캐시의 성능을 측정할 때는 히트 레이턴시(Hit latency)와 미스 레이턴시(Miss latency)가 중요한 요인으로 꼽힌다.
* CPU에서 요청한 데이터가 캐시에 존재하는 경우를 캐시 히트(Hit)라고 한다. 히트 레이턴시는 히트가 발생해 캐싱된 데이터를 가져올 때 소요되는 시간을 의미한다. 반면 요청한 데이터가 캐시에 존재하지 않는 경우를 캐시 미스(Miss)라고 하며, 미스 레이턴시는 미스가 발생해 상위 캐시에서 데이터를 가져오거나(L1 캐시에 데이터가 없어서 L2 캐시에서 데이터를 찾는 경우) 메모리에서 데이터를 가져올 때 소요되는 시간을 말한다.
* 캐시의 성능을 높이기 위해서는 캐시의 크기를 줄여 히트 레이턴시를 줄이거나, 캐시의 크기를 늘려 미스 비율을 줄이거나, 더 빠른 캐시를 이용해 레이턴시를 줄이는 방법이 있다.


### Cache Organization
* 캐시는 반응 속도가 빠른 SRAM(Static Random Access Memory)으로, 주소가 키(Key)로 주어지면 해당 공간에 즉시 접근할 수 있다. 이러한 특성은 DRAM(Dynamic Random Access Meomry)에서도 동일하지만 하드웨어 설계상 DRAM은 SRAM보다 느리다. 통상적으로 '메인 메모리’라고 말할 때는 DRAM을 의미한다.
* 주소가 키로 주어졌을 때 그 공간에 즉시 접근할 수 있다는 것은 캐시가 하드웨어로 구현한 해시 테이블(Hash table)과 같다 의미다. 캐시가 빠른 이유는 자주 사용하는 데이터만을 담아두기 때문이기도 하지만, 해시 테이블의 시간 복잡도가 O(1) 정도로 빠르기 때문이기도 하다.
* 캐시는 블록(Block)으로 구성되어 있다. 각각의 블록은 데이터를 담고 있으며, 주소값을 키로써 접근할 수 있다. 블록의 개수(Blocks)와 블록의 크기(Block size)가 캐시의 크기를 결정한다.

### 캐시 블로그
* [박성범](https://parksb.github.io/article/29.html?utm_source=gaerae.com&utm_campaign=%EA%B0%9C%EB%B0%9C%EC%9E%90%EC%8A%A4%EB%9F%BD%EB%8B%A4&utm_medium=social)

## 레지스터
* CPU 내의 처리에 필요한 명령이나 연산의 중간 결과 값 등을 일시적으로 기억하는 고속 메모리
* PC, MAR, MBR, Decoder, Encoder

## IO 장치가 시스템 버스에 직접 접속되지 못하는 이유
* 종류에 따라 제어 방법이 서로 다른 I/O 장치들의 제어 회로들을 CPU 내부에 모두 포함시키는 것이 어려워 CPU가 그들을 직접 제어할 숭 ㅓㅄ기 때문이다.(CPU도 채널로 하여금 관리)
* I/O 장치들의 데이터 전송 속도가 CPU의 데이터 처리 속도에 비해 훨씬 느려 CPU도 채널을 붙임
* I/O 장치들과 CPU가 사용하는 데이터의 형식ㅇ의 깅리가 서로 다른 경우가 많다.

# 캐시
- CPU 칩 안에 들어가는 작고 빠른 메모리이다. 
- =>  프로세서가 매번 메인 메모리에 접근해 데이터를 받아오면 시간이 오래 걸리기 때문에 캐시에 자주 사용하는 데이터를 담아두고, 해당 데이터가 필요할 때 프로세서가 메인 메모리 대신 캐싱[ 접근하도록해 처리 속도를 높인다. 

## 시간 지역성/ 공간 지역성

- 자주 사용하는 데이터 판단은 지역성의 원리를 따름. 지역성의 원리는 시간 지역성과 공간 지역성으로 구분해서 볼 수 있다.
- 시간 지역성은 최근 접근한 데이터에 다시 접근하는 경향을 말한다. 가령 루프에서 인덱스 역할을 하는 변수 i에는 짧은 시간안에 여러 번 접근이 이뤄진다. 
- 공간 지역성은 최근 접근한 데이터의 주변 공간에 다시 접근하는 경향을 말함.
- 한 프로세스에도 자주 사용하는 부분과 그렇지 않은 부분이 있기 때문에 운영체제는 프로세스를 페이지라는 단위로 나눠 관리한다. 페이지에 접근할 때도 지역성 원리가 적용된다.

법이 

## 캐시메모리
* 시간적, 공간적 지역성을 기반으로 가까운 미래에 접근될 확률이 높은 데이터를 작지만 빠른 캐시 메모리에 미리 보관하여 전체적인 시스템의 성능을 높인다.
* 메인 메모리(램)보다 훨씬 빠르지만 용량이 작아 중요한 것들이 들어가야 함
* 캐시 메모리 저장 규칙
  1. 최근에 접근된 데이터; Tempoary Locality - 시간적 지연성
  2. 최근에 접근된 데이터의 주변 데이터; Spatial Locality - 공간적 지연성
* 사용하는 곳: 파일 시스템, OS, 구글 크롬, FM, CPU 안에서도 3단계로 나눔


### Cisc
* x86 아키텍처가 리틀 엔디언을 쓰기 때문에, 오늘날 x86 아키텍처를 사용하는 대부분의 데스크톱 컴퓨터는 리틀 엔디언을 쓰며 이를 ‘인텔 포맷’이라 한다. 거꾸로 네트워크에서는 주소를 빅 엔디언으로 쓰는데, 역사적으로 라우팅이 전화를 거는 식으로 접두 부호로 이루어졌기 때문이다. 이의 영향으로 많은 프로토콜과 몇몇 파일 포맷이 빅 엔디언을 사용하고 있다. 모토로라 프로세서들은 일반적으로 빅 엔디언을 사용하며, ARM 프로세서들은 성능 향상을 위해 빅 엔디언과 리틀 엔디언을 선택할 수 있도록 되어 있다.
* 명령어가 복잡하기 때문에 명령어를 해석하는 데 시간이 오래 걸리며, 명령어 해석에 필요한 회로도 복잡하다.
* CISC란 소프트웨어 특히, 컴파일러 작성을 쉽게 하기 위해 하드웨어화할 수 있는 것은 가능한 모두 하드웨어에게 맡긴다는 원칙 아래 설계된 컴퓨터이다. 
* 뒤에서부터 스택에 PUSH
* 계산연산에서 빅 엔디안보다 속도가 빠름

### Risc
* RISC의 특징을 CISC와 비교하여 알아보면 다음과 같다. 첫째, 명령의 대부분은 1머신 사이클에 실행되고, 명령길이는 고정이며, 명령세트는 단순한 것으로 구성되어 있는데, 가령 메모리에 대한 액세스는 Load/Store 명령으로 한정되어 있다. 둘째, 어드레싱 모드가 적으며, 마이크로 프로그램에 의한 제어를 줄이고, 와이어드 로직을 많이 이용하고 있다. 반면에 레지스터수가 많으며 마이크로 프로그램을 저장하는 칩의 공간에 레지스터를 배치한다. 셋째, 어셈블러 코드를 읽기 어려울 뿐 아니라 파이프라인을 효과적으로 사용하기 위해서 일부 어셈블러 코드를 시계열로 나열하지 않은 부분이 존재하여 컴파일러의 최적화가 필요하다. 최적화를 하지 않으면 파이프라인을 유효하게 이용할 수 없고, RISC을 사용하는 의미가 없어진다.
* RISC는 CISC 형식의 CPU내 ROM에 소프트웨어적으로 적재된 내부 명령어들을 하드웨어적으로 구성해 제어기가 제거된 부분에 프로세서 레지스터 뱅크와 캐시를 둡니다. 이렇게 함으로써 CPU가 상대적으로 느린 메인 메모리에 접근하는 횟수를 줄여 시스템 수행속도를 향상시킬 수 있습니다.  
* 반면 RISC는 실행 속도를 높히기 위해 가능한 한 복잡한 처리는 소프트웨어에게 맡기는 방법을 택한 컴퓨터이다.
* Unix 의 RISC계열의 프로세서가 사용하는 바이트 오더링
* 네트워크에서 사용하는 바이트 오더링
* 앞에서부터 스택에 PUSH
* 비교연산에서 리틀 엔디안보다 속도가 빠름
* Intel 계열의 프로세서가 사용하는 바이트 오더링
* RISC 프로세서의 경우 CISC 프로세서보다 파이프라인 효율이 좋다. RISC는 명령어가 한 클록에 처리되므로, 한 명령어를 오래 처리해서 다음 명령어의 처리가 늦어지지 않기 때문이다. 또한, 메모리에 접근하는 경우, 매우 오랜 처리시간이 걸리는데, RISC는 LOAD나 STORE 명령어만으로 메모리에 접근하므로 비효율적인 접근이 CISC보다 적기 때문이다.
* 최대의 단점은 코드밀도가 감소하여 같은 내용을 처리하는 데 더 많은 코드 용량이 필요하게 되었다는 점이다. 그 원인은 또 다음과 같이 분류할 수 있다.
  + 항상 16bit 혹은 32bit를 차지하는 고정 길이 명령어는 상황에 따라 8~32bit를 오가는 CISC의 가변 길이 명령어에 비해 코드밀도 면에서 원천적으로 불리하다.
  + 메모리를 대상으로 하는 연산 명령어의 경우 CISC에서는 1개 명령어로 표현 가능한데 RISC에서는 load-execute-store로 3개의 명령어가 필요하다.
  + 마이크로코드로 한 줄로 구현된 CISC명령어를 몇 개, 혹은 수십개의 RISC명령어로 변환해야 한다.

### Cisc, Risc 차이점
* Complex
  + CISC의 단점이자 RISC의 장점은 CISC의 경우 하드웨어의 회로가 복잡해져서 RISC에 비해 가격이 비싸지고 발열이 많고 전력소모가 많게 됩니다.
  +  RISC 명령어가 단순히 명령어 수를 줄인 것이 아니라 명령어 해석기에서의 마이크로코드의 의존도를 제거하고 관련 로직을 단순화하여 성능을 올리는 방향으로 발전했다는 것을 상기하라.
* Instruction
  + RISC: CPI(Clock Per Instruction)을 1 이하로 줄이는 것임, 동급의 CISC에 비해 더 높은 clock frequency를 실현하는 것임
  + RISC 프로세서의 경우 CISC 프로세서보다 파이프라인 효율이 좋다. RISC는 명령어가 한 클록에 처리되므로, 한 명령어를 오래 처리해서 다음 명령어의 처리가 늦어지지 않기 때문이다. 또한, 메모리에 접근하는 경우
  + CISC에서는 여러 clock을 차지하는 복잡한 연산을 하는 명령어들이 종종 있었다. 심지어 for 루프를 실행하는 명령어가 존재했을 정도였다. 이는 과거에 컴파일러의 성능이 부족했기 때문에, 컴파일러를 사용한 후에도 최적화를 하기 위해서 기계어 코드를 수정하는 등 프로그래머가 기계어를 직접 다루는 경우가 많았기 때문이다. 
* Set
  + CPU는 메모리 접근을 피하기 위해 인자나 지역변수를 저장하는데에도 레지스터를 사용한다.
  + 즉, CISC 각각의 명령어는 머신코드는 길지만 전체 프로그램 사이즈는 RISC보다 작습니다. 따라서 코드를 수행할 때 RISC가 메모리를 더 많이 참조해야 하므로.... [CISC가 RISC보다 빠른 요인이 됩니다.] CISC는 복잡한 하드웨어를 가지게 되므로 보통 hard wired방식 보다는 microprogram 방식을 사용하게 됩니다. RISC는 hard wired 방식을 사용할 수 있습니다. [RISC가 CISC보다 빠른 요인이 됩니다.]
  CISC는 레지스터의 양이 많을 필요가 없고 RISC는 레지스터의 양이 많아야 하므로.... (예>함수에 파라미터를 메모리에 저장하는 경우와 레지스터에 저장하는 경우의 차이)
CISC가 메모리의 access가 많아지게 됩니다. [RISC가 CISC보다 빠른 요인이 됩니다.] RISC머신이 파이프라인구현이 용이하다라고 합니다..
* Stack
  + CISC: 일반적으로 하드웨어 스택이 내장되어 있어서 서브루틴 리턴 주소나 인자, 지역변수, 기타 임시 값을 저장하는데 사용한다. Call, ret, push, pop 같은 기계어 명령어를 사용할 경우 stack의 데이터는 자동적으로 관리된다.
  + RISC; Stack 관련 명령어가 존재하지 않음; Return address 나 기타 stack 자료 구조는 SW 적으로 처리해주어야 한다.; Power PC 의 경우, 함수의 인자를 전달하기 위해 8개의 레지스터를 따로 준비하고 있다. 인자값을 메모리에 접근하는 stack operation에 비해 register에 load 한다. 지역변수를 저장하기 위해 stack을 사용할 필요가 없다. 대부분의 짧은 프로시저나 함수를 호출할 때 리턴주소를 SW stack에 저장하기 위해 stack을 사용할 필요가 없다.

## 파이프라인
* 파이프라인(instruction pipeline)은 명령어를 읽어 순차적으로 실행하는 프로세서에 적용되는 기술로, 한 번에 하나의 명령어만 실행하는 것이 아니라 하나의 명령어가 실행되는 도중에 다른 명령어 실행을 시작하는 식으로 동시에 여러 개의 명령어를 실행하는 기법이다.
* 하나의 명령어는 여러 개의 단계로 나눌 수 있는데, 이때 하나의 명령어를 처리할 때까지 다음 명령어가 처리되지 않고 기다린다면, 명령어의 특정 단계를 처리하는 동안 다른 단계를 처리하는 부분은 아무 작업도 하지 않게 된다. 이때 파이프라인을 사용하면 한 명령어의 특정 단계를 처리하는 동안 다른 부분에서는 다른 명령어의 다른 단계를 처리할 수가 있게 되므로 속도가 향상될 수 있다.
* 파이프라인의 효율은 브랜치나 서브루틴 콜이 많아질수록 떨어진다. 그 이유는, 브랜치나 서브루틴 콜이 이루어지면, 파이프라인에서 처리되던 명령어들이 다 취소되고 새로 브랜치나 서브루틴의 명령어를 처리해야하기 때문이다. 최신 아키텍처는 분기 예측 등의 기법을 통해 이런 문제를 회피한다.
* RISC 프로세서의 경우 CISC 프로세서보다 파이프라인 효율이 좋다. RISC는 명령어가 한 클록에 처리되므로, 한 명령어를 오래 처리해서 다음 명령어의 처리가 늦어지지 않기 때문이다. 또한, 메모리에 접근하는 경우, 매우 오랜 처리시간이 걸리는데, RISC는 LOAD나 STORE 명령어만으로 메모리에 접근하므로 비효율적인 접근이 CISC보다 적기 때문이다.

### 부연설명
* CPU 전체가 한 번에 하나의 명령을 처리하는 것이 아니라 명령어 몇 개를 동시에 처리함과 동시에 명령 하나를 또다시 여러 단계의 작은 명령으로 나누고 각 부분을 차례대로 처리한다. 
* 즉 몇 개의 명령어가 몇분의 1로 나누어지고, 그런 명령어 몇 개가 한번에 돌아가는 것이다. 이런 식으로 작동하는 이유는 많은 기계어 명령이 코드로는 하나로 되어 있어도 실제 처리해야 하는 일은 여러 단계로 나누어져 있고 각 단계는 이전 단계가 처리되기 전에는 수행이 불가능하기 때문이다.

### 클록
* 클럭 속도(문화어: 박자속도) 또는 클록 주파수는 컴퓨터 프로세서의 동작 속도이다. "초당 사이클"로 측정하며 헤르츠(Hz) 단위를 사용한다.



## bus
* CPU와 메인 메모리 사이에 데이터를 저장하기 위한 터미널이다.  
  ^bus is terminal between CPU and Main memory to save data
* Address bus, Data bus, Control bus
* [Bus link](http://ssoonidev.tistory.com/14)
* [Bus link2](http://contents.kocw.net/KOCW/document/2015/cup/leesangkwan/6.pdf)

# SSD
* 우리가 사용하는 메모리카드, USB, SSD 등의 저장매체에는 낸드플래시(NAND Flash) 메모리가 사용됩니다. 그리고 낸드플래시 타입은 최소단위인 셀(Cell)에 몇 비트(bit)를 저장할 수 있느냐에 따라 SLC, MLC, TLC, QLC 방식으로 나뉘는데요. 동일한 용량일지라도 이 네 가지 방식에 따라 성능의 차이가 발생하고 가격 또한 달라지게 됩니다. 오늘 <궁금한 반도체 WHY> 4탄에서는 낸드플래시 메모리의 데이터 저장 방식이 각각 어떻게 다른지 알아보도록 하겠습니다.

## SSD의 단점
1. 배드블록
 * 배드 블록이 1개라도 있으면 SSD를 교체해야 함
 * 이를 방지 하기 위해 대부분의 SSD에는 이를 교체하기 위한 예비 블록들이 있음(그래서 SSD의 기본 용량에서 조금 부족한 용량)
2. 쓰기/읽기 방해
3. 리텐션 에러
 * 너무 오래 사용안하면 전자가 도망감


## SSD HDD
* Hdd: 디스크가 돌아야 한다.  
    ^Hdd: disk has to spin
* 기가바이트 회사가 HDD를 RAM으로 만들었었다.  
    ^Gigabyte Company made the HDD with RAM. It didn't release
* SSD는 HDD보다 약 5배 빠르다.  
    ^SSD is 5times faster than HDD
* SSD는 읽기위 쓰기를 하는 개수에 한계가 있다.  
    ^Reading and writing have a limit in SSD
* SSD: Flash memory(Like USB) + Controller  
  - 읽기가 쓰기보다 빠르다
      ^Reading is faster than writing
  - Cell(Memory Storation way) SLC(single) > MLC(Multi) > TLC(triple)  //Usually we use MLC
    + 셀의 개수가 SSD의 가격을 결정한다.  
        ^The number of cell decides SSD's price
    + SLC: 1비트가 1개의 방에 저장된다.  
        ^SLC: 1 bit will be stored in one room
    + SLC: 컨트롤러를 복잡하게 만들고, 불안정하게 한다.  
        ^SLC: It makes a controller complicated and it makes it unstable



### SSD 메모리 셀의 타입
* 데이터를 저장하는 방식은 SLC(Single Level Cell), MLC(Multi Level Cell), TLC(Triple Level Cell), QLC(Quadruple Level Cell)로 나눌 수 있습니다. 이는 데이터를 저장하는 최소 단위인 셀(Cell)에 몇 비트(bit)를 저장할 수 있느냐에 따라 분류한 개념입니다. SLC는 1bit, MLC는 2bits, TLC는 3bits, QLC는 4bits 을 저장할 수 있죠
* SLC, MLC, TLC
* TLC는 용량이 큼, 동작 속도가 느림(하나에 3개의 비트가 들어가 있음)
 * 전자 가출률 높음(컴퓨터를 지속적으로 사용해야 함)
* 데이터를 저장(Write)한다는 의미는 지정된 셀의 storage 영역에 전자를 주입하는 동작을 통해 기존 Erase ‘1’ 셀을 Program ‘0’ 셀로 변환하여, 셀들을 이진법적으로 ‘1’ 과 ‘0’ 상태로 구분 가능하게 만드는 것입니다. 만약 셀의 구분 가능한 상태를 2n개로 확장하면 저장 가능한 데이터의 비트 수(n)가 증가합니다.
* SLC는 ‘1’과 ‘0’ 2개 (N=1), MLC는 ‘11’~’00’ 4개 (N=2), TLC는 ‘111’~’000’ 8개 (N=3), QLC는 ‘1111’ ~ ‘0000’ 16개 (N=4)로 구분할 수 있도록 셀 상태를 조절합니다.
* 물리적 셀 집적도(density)는 동일하지만, 동작 조건만으로 SLC에서 QLC로 정보 저장 비트 수가 증가하면서 각각 가격과 성능의 차이가 발생합니다. 동일한 정보 저장 용량에서 물리적 집적도가 감소하면 생산 원가가 감소되어 SLC → MLC → TLC → QLC 순으로 가격이 하락합니다. 동작 횟수가 증가하고 Read 전압과 VT 분포간 간격이 좁은 SLC → MLC → TLC → QLC 순으로 Write time, Read time, 신뢰성과 같은 성능과 품질도 하락됩니다. 
* 그래서 사용자가 저렴한 가격을 원하면 QLC, 고성능을 추구하면 SLC, 가격과 성능의 적절한 조합이 필요하면 TLC 또는 MLC를 적용한 제품을 선택할 수 있습니다. 향후 SLC는 커넥티드 카(Connected Car), 인공위성 등과 같은 고성능&고사양 제품에 적용될 것입니다. 반면, QLC는 고성능을 요하지 않는 USB 메모리와 사용빈도가 높지 않고 다른 저장 장치(ex. HDD)에 비해 성능 대비 구매/유지 비용이 저렴한 분야(ex. Server) 등에 적용될 것으로 보입니다.


### 슈퍼 컴퓨터의 IO 노드
* 예를 들어 54코어 CPU + 여러 SSD(TLC, QLC) + SLC/MLC(용량 작지만 속도 빠른) + 램(계층별로) 

### SSD의 장점
* 발전 속도가 빠름(용량/속도)
* 충격에 강함(전자적으로 처리하기 때문에; HDD는 헤드가 머리카락 크기정도의 간격으로 처리하기 때문에 약함)
* 크기가 작고 가벼움
* 병렬처리가 쉬움

### SSD의 단점
1. 배드블록; FTL
* 사용 가능한 블록이 없을 때 GC(Garbage Collection)에서 사용된 블록 정리
 * OP(Over Provisioning 영역)에서 배드 블록을 교환해줄 수 있는게 들어있음.(SSD가 128GB라고 하면 할당 안됐던 부분)
* 배드 블록이 생길 가능성
 1. 블록 내구도 초과
 2. 자연 배드 블록
2. 쓰기/읽기 방해
3. 리텐션 에러

## Clipboard
* 윈도우 뿐만 아니라 다른 OS에도 있다.  
    ^Not only on Windows, but also on other operating systems.




# 키보드

## 멤브레인
* 장점: 러버돔 고무; 제조 간단; 단가 저렴; 방수; 가벼운 무게, 저소음
* 단점: 손가락 피로감, 낮은 병렬성->동시 입력 제한, 고장-> 키보드 교환
* 구성: 키캡, 러버돔, 멤브레인, 쇠로 구성

## 무접점
* 구성은 비슷하지만 러버돔 안에 스프링이 존재; 러버돔이 밑에 바닥부분과 접촉하지 않아도 쉽게 눌림
* 장점: 키보드에 무리가 덜감으로 인해 높은 내구도
* 단점: 비싼 가격; 러버돔의 변형
* 키압 선택 가능(균등/차등); wasd 키는 가볍게 다른 것은 무겁게

## 기계식
* 적축, 흑축, 청축, 갈축
  * 1. 필요 키압 2. 소리와 느낌
* 독립적인 스위치; 동시 입력 + 반 영구적인 내구도; 키가 고장나면 한개만 수리
* 비싼 가격; 무게; 오염에 약함

### 청축
* PC방 사운드; 힘 50g; 

### 갈축
* 소음기 달린 청축버전; 힘 45g; 조용하지만 소리 내고 싶음; 입문하기 좋은 기계식

### 적축
* 갈축과 비슷; 빠른 입력/잦은 오타; 힘 45g; 전문가 느낌
* 단시간에 같은 키 반복 입력에 편리

### 흑축
* 입문용에서 제일 먼; 높은 키압; 힘 60g; 조용함+바닥소리
* 리듬게임이나 격투게임의 유저같이 키 실수가 가장 나면 안되는 사람들이 사용; 힘 60g


# Bus 
## CPU
* CPU - 캐시(CPU 칩 안의 작은 칩) - 버스(CPU와 메인 메모리 사이에 데이터를 저장하기 위함) - 메인 메모리
*   MBR(CPU 안)- 데이터 버스 - 주기억 장치 - 주소버스 - MAR(CPU 안) - PC
 * 채널에 관리가 되는 입출력 장치도 꽂혀있음
* 양방향성: 데이터 버스
* 1K = 2의 10승;  1M = 2의 20승

## IO 장치가 시스템 버스에 직접 접속되지 못하는 이유
* 종류에 따라 제어 방법이 서로 다른 I/O 장치들의 제어 회로들을 CPU 내부에 모두 포함시키는 것이 어려워 CPU가 그들을 직접 제어할 숭 ㅓㅄ기 때문이다.(CPU도 채널로 하여금 관리)
* I/O 장치들의 데이터 전송 속도가 CPU의 데이터 처리 속도에 비해 훨씬 느려 CPU도 채널을 붙임
* I/O 장치들과 CPU가 사용하는 데이터의 형식ㅇ의 깅리가 서로 다른 경우가 많다.

## 버스의 종류
- CPU가 처리한 데이터들은 모니터에 출력되거나 메모리에 저장되어 진다. 이러한 행위가 이루어 지기 위해서는 위의 데이터들이 각 컴포넌트끼리 통신이 가능 해야한다. 이러한 통신을 가능하게 해주는 Subsystem이 존재한다. 또한 이러한 Subsystem을 Computer Bus라고 한다. 즉 버스는 데이터를 통신할 수 있게 해주는 시스템이다.
 
### System Bus
-  CPU와 메모리를 연결하는 Subsystem을 System Bus라고 명명한다.
- 입출력장치는 조건(프린터,키보드,태블릿 등)에 따라 읽어들이는 데이터가 일일이 다르다. 느리고 서로 읽는 데이터양도 다른고, 그 두개의 문제가 다 해결됬다 하더라도 문제가 또 있다. cpu가 입출력장치를 직접 컨트롤 하지 않는 이유는 입출력장치가 너무 다양하다는 것이다. cpu입장에서는 개별적인 입출력장치를 어떻게 처리해야할지 고민 안해도되고 중간 제어기와 어떻게 대화할지만 생각하면된다. 이런 중간제어기가 바로 시스템버스다. 
 
### I/O Bus   https://richong.tistory.com/92 [study]
- 메모리와 다른 입출력 장치와 통신을 하는 Subsystem을 I/O Bus라고한다.
 
 
# 시스템 버스
## 데이터 버스
- 데이터 버스는 시스템 모듈들 간의 데이터 이동 경로를 제공한다. 주로 32, 64, 128 또는 그 이상의 분리된 선들로 구성되어 있으며 선의 수는 한 번에 전송할수 있는 비트 수를 결정지어 주는데 이것은 CPU가 수용할 수 있는 데이터의 크기, Word와 밀접한 관계가 있다.
• CPU가 기억장치 또는 I/O 장치간의 데이터 전송 신호 선 • 데이터 선의 수는 CPU가 한 번에 전송할 수 있는 비트 수를 결정 [예] 데이터 버스 폭 = 32 비트라면, CPU와 기억장치 간의 데이터 전송은 한 번에 32 비트씩 가능 
- 한편 버스에는 데이터 버스도 있다. 데이터 버스는 위에서 언급한 예에서, 데이터를 보낼 때 사용하는 버스이다.  데이터 버스는 각종 장치들이 자신들의 데이터를 보내는 만큼, 당연히 서로가 보낼 수 있는 양방향 버스이다.  데이터 버스는 워드(한 번에 처리하는 명령어의 단위)에 맞먹는 회선이 필요하다. 가령 요즘 쓰는 64비트 컴퓨터는 64비트 버스가 되어야 하는 것이다. 
 
 
## 주소 버스
- 주소 버스는 데이터의 근원지나 목적지의 일정한 메모리 주소를 전달하는 버스이다. 
- 주소 버스의 폭은 최대 기억장치의 용량을 결정지어 주는데 32개의 주소 버스를 지닌 컴퓨터 시스템은 2^32개의 메모리 위치를 할당할 수 있다. 또한 I/O포트를 지정하기 위해서도 사용되어진다.
- CPU에서 외부(주변장치)로 발생하는 주소 정보 전송 신호선 • 주소 선의 수는 CPU와 접속되는 최대 기억장치 용량 결정 [예] 주소 버스의 비트 수 = 16 비트라면, 최대 216 = 64K 개의 기억 장소들의 주소지정 가능 
- 가령 중앙처리장치에서 메모리 중 01111111에 해당하는 곳에 데이터를 보내려면, 이 데이터만이 아니라 이 데이터가 갈 곳인 01111111이라는 정보도 주소 버스를 통해 보내야 하는 것이다. 
 
## 제어 버스
- 제어 버스는 데이터 버스와 주소 버스를 제어하기위해 사용되어 진다. 데이터 버스와 주소 버스는 공유하는 선들의 집합이므로 이들을 제어하는 수단이 반드시 필요하기 때문에 사용한다. 
- CPU가 시스템 내의 각종장치들의 동작을 제어하기 위한 신호선 

### 제어버스 예제
- 기억장치의 읽기/쓰기(memory read/write) 신호 
- 입출력장치의 입력/출력(I/O input/output) 신호 
- 인터럽트(interrupt) 신호
-  버스 제어(bus control) 신호 
 
# CPU와 시스템 버스간의 접속
- 주소 버스 : 단방향성(unidirectional) 주소는 CPU로부터 기억장치 혹은 I/O 장치들로 보내지는 정보 
- 데이터 버스, 제어 버스 : 양방향성(bidirectional) 읽기와 쓰기 동작을 모두 지원 
 
2. 동기식 버스 vs 비동기식 버스

# 동기식 버스
 * 동기식 버스는 정해진 시간에 데이터를 전송하는 방법이다. 이 때 시간은 버스가 가지고 있는 Clock을 기준으로 하며 빠르고 인터페이스 논리회로가 간단하다는 장점이 있지만 느린 장비도 이 Clock에 맞춰야 한다는 점에서 시간 낭비가 발생할 수 있다. 
 
# 비동기식 버스
 * 비동기식 버스는 동기식 버스와 달리 시간을 따로 정하지 않는다. 단지 서로 데이터를 주고 받을 준비가 되어있는지 확인하는 핸드쉐이킹 프로토콜을 사용하여 수신측에서 준비가 되었으면 바로 전송을 하는 방식이다.
장점은 따로 정해진 시간이 없기 때문에 시간 낭비가 적다는 점이고 단점은 회로 구성이 복잡하고 핸드쉐이킹하는 과정이 필요해서 속도도 동기식에 비해 느리다.
 
3. PCIe
 * 버스의 특징이 공용 선이라는 것인데 이 특징덕분에 한 쪽이 데이터 선을 점령하면 다른 쪽에서는 신호 중첩을 유발 시킬수 있어서 사용을 하면 안된다. 이 점을 보완하기 위해 점대점 상호연결방식이 등장하였다.
 
## QPI(Quick Path Interconnect)
 * 다른 구성요소와 직접연결하는 점대점 상호방식중 하나로 레이어로 구성된 프로토콜 구조이므로 물리적으로 연결되어 있는 부분부터 오류의 존재 여부를 점검하는 등 각각의 레이어에서 하는 일을 구분되어 있다. 고속, 고효율의 패킷 기반의 전송방식을 사용하며 인텔의 i7 데스크톱 프로세서 이후로 사용되어지는 방식이다.
 
## PCIe(Peripheral Component Interconnect Express)
 * 버스를 1대 1로 연결해서 택시로 만들어 버렸다. 높은 용량덕분에 기가이더넷과 같은 빠른 데이터 속도의 I/O 디바이스를 지원하는데 사용되어지며 각각의 버스마다  독립적인 데이터 흐름을 제공하여 많이 사용되어진다. 또한 핀수가 적고 물리적 면적이 작으며 상세한 오류검출 및 보고구조 등의 장점을 가지고 있다.
 * 최근엔 I/O 가상화도 지원한다.

# 환경변수 등록

## Path
- 서비스에 등록한 것과 같음.
- 우선순위가 높은 것이 올라가는 등 순서가 바뀜
  - 시작 프로그램에 등록해놓으면 우선순위 올라감; 수동적으로 수정해서 우선순위 변경 가능
