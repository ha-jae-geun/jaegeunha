# [캐싱 테코톡](https://www.youtube.com/watch?v=_0p72JJ9iM8)

# 캐시 일관성
```java
캐시 일관성(cache coherence) 문제를 해결하기 위한 기술과 관련이 없는 것은? 4번
① 스누핑(snooping) 프로토콜
② MESI 프로토콜
③ 디렉토리 기반(directory-based) 프로토콜
④ 우선순위 상속(priority-inheritance) 프로토콜

캐시 일관성 문제
∙ 각 프로세서별로 별도의 캐시 메모리를 가지고 있는 공유 메모리 멀티프로세서에서 
캐시의 갱신으로 인한 주기억 장치(공유 메모리)와 캐시에 저장된 데이터가 불일치하는 문제가 발생
 
하드웨어 방식의 캐시 일관성 유지
∙ 디렉토리 기반(directory-based) 프로토콜
∙ 스누핑(snooping) 프로토콜
∙ MESI 프로토콜
```

# Memory Hierachy
* 데이터를 저장하는 공간의 속도와 용량은 반비례 관계
* 데이터 저장 공간을 속도, 용량 순서대로 쌓으면 마치 피라미드와 같은 형상이 나타난다

# 파레토의 법칙
* 원인 중 상위 20%가 전체 결과의 80%를 만든다는 법칙

# 캐시
* 오늘날 CPU 칩의 면적 30~70%는 캐시가 차지한다. 1989년 생산된 싱글 코어 프로세서인 i486의 경우 8KB짜리 I/D 캐시 하나만 있었다. 한편 인텔 코어 i7 쿼드 코어 칩의 다이 맵(Die map)을 보면 4개의 코어에 각각 256KB L2 캐시가 있고, 모든 코어가 공유하는 8MB L3 캐시가 있는 것을 볼 수 있다. (L2 캐시 위에 있는 구역이 L1 캐시로 보이는데, 확실하지 않아서 따로 표시하지 않았다.)
* CPU 칩에는 여러 개의 캐시가 들어가며, 각각의 캐시는 각자의 목적과 역할을 가지고 있다.

## 캐시의 작동 방식
* 원본 데이터와(System-of-Record)는 별개로 자주 쓰이는 데이터(Hot Data)들을 복사할 캐시 공간을 마련한다.
    * 캐시 공간은 상수시간 등 낮은 식나 복잡도로 접근이 가능한 곳에 주로 사용한다.
* 데이터를 달라는 요청이 들어오면 원본 데이터가 담긴 곳에 접근하기 전에 캐시 내부를 찾는다.
* 캐시에 원하는 데이터가 없거나(miss) 너무 오래되어 최신성을 잃었으면(expiration) 그때서야 원본 데이터가 있는 곳에 접근하여 데이터를 가져온다. 
    * 이때 데이터를 가져오면서 캐시에도 해당 데이터를 복사하거나 혹은 갱신한다.
* 캐시에 원하는 데이터가 있으면 원본 데이터가 있는 공간에 접근하지 않고 캐시에 바로 해당 데이터를 제공한다.
* 캐시 공간은 작으므로 공간이 모자라게 되면 안쓰는 데이터부터 삭제하여 공간을 확보한다(Eviction)

## CPU의 캐시메모리
* 현대의 CPU는 1초에 최고 수십억번 작동 가능
     * 아무리 빠른 주기억장치라도 CPU를 따라가기 어려움
     * 그래서 SRAM이라는 특수한 메모리를 CPU에 넣어 캐시 메모리로 사용
* 최근 출시된 AMD의 3세대 라이젠 CPU는 L3 캐시 메모리의 용량을 기존의 2배로 늘려 게이밍 성능을 인텐 제품과 동등한 수준으로 올림
    * 이름 자체를 게임 캐시라고 지음
    * 캐시가 효율 향상에 중요함을 보여주는 한 사례

### 캐시 종류
* L1 Cache: 프로세서와 가장 가까운 캐시. 속도를 위해 I$와 D$로 나뉜다.
* Instruction Cache (I$): 메모리의 TEXT 영역 데이터를 다루는 캐시.
* Data Cache (D$): TEXT 영역을 제외한 모든 데이터를 다루는 캐시.
* L2 Cache: 용량이 큰 캐시. 크기를 위해 L1 캐시처럼 나누지 않는다.
* L3 Cache: 멀티 코어 시스템에서 여러 코어가 공유하는 캐시.
* 캐시에 달러 기호($)를 사용하는 이유는 캐시(Cache)의 발음이 현금을 뜻하는 'Cash’와 같기 때문이다 :)

### Cache Metrics
* 캐시의 성능을 측정할 때는 히트 레이턴시(Hit latency)와 미스 레이턴시(Miss latency)가 중요한 요인으로 꼽힌다.
* CPU에서 요청한 데이터가 캐시에 존재하는 경우를 캐시 히트(Hit)라고 한다. 히트 레이턴시는 히트가 발생해 캐싱된 데이터를 가져올 때 소요되는 시간을 의미한다. 반면 요청한 데이터가 캐시에 존재하지 않는 경우를 캐시 미스(Miss)라고 하며, 미스 레이턴시는 미스가 발생해 상위 캐시에서 데이터를 가져오거나(L1 캐시에 데이터가 없어서 L2 캐시에서 데이터를 찾는 경우) 메모리에서 데이터를 가져올 때 소요되는 시간을 말한다.
* 캐시의 성능을 높이기 위해서는 캐시의 크기를 줄여 히트 레이턴시를 줄이거나, 캐시의 크기를 늘려 미스 비율을 줄이거나, 더 빠른 캐시를 이용해 레이턴시를 줄이는 방법이 있다.

## 캐시가 쓰이는 사례
* 하드디스크
    * 하드디스크는 주기억장치에 비해 10만 배 이상 느린 장치
    * 처리 효율을 올리려면 자주 쓰이는 데이터를 캐싱해주는 것이 좋다
* 데이터베이스
    * 데이터베이스 또한 쿼리를 실ㄹ행하여 하드디스크에서 데이터를 읽고 쓰는 것은 시간이 오래 걸리는 작업
    * 대개 데이터베이스는 쓰기보다는 읽기가 많으므로 자주 요청받는 쿼리의 결과를 캐싱해두면 효율이 오른다.
    * 따라서 데이터 베이스 자체에서 별도의 캐시를 운영한다
        * JPA의 영속성 컨텍스트도 실은 캐시의 일종이다.
* CDN(Content Delivery Network)
    * 유튜브의 메인 서버는 미국에 있다
    * 한국과 미국을 잇는 국제 인터넷 회선은 비싸고 용량을 늘리기도 어렵다
    * 구글은 각 통신사마다 구글 글로벌 캐시를 두어 인기있는 유튜브 동영상은 미국 서버까지 접속할 필요 없이 국내 서버에서 처리하도록 하였다
    * 비싼 국제 회선 비용이 절감되고 버퍼링이 줄어 고화질 서비스의 이용 경험이 개선되엇다
    * 이처럼 세계 각지에 캐시 서버를 두어 전송속도를 높이고 부하를 분산하는 시스템이 바로 CDN이다
* 웹 캐시
  * 네트워크를 통해 데이터를 가져오는 것은 하드디스크보다도 느릴 때가 있다
  * 그래서 웹브라우저는 웹 페이지에 접속할 때 html, css, 자바스크립트, 이미지 등을 하드디스크나 메모리에 캐싱해 두었다가 다음 번에 다시 접속할때 사용한다(브라우저 캐시)
  * 웹 서버 또한 상당 수의 동적 웹페이지라 할지라도 매번 내용이 바뀌지 않은 경우가 많으므로 서버에서 생성한 HTML을 캐싱해 뒀다가 다음 번 요청에 이를 재활용한다(응답 캐시)
  * 이와 유사하게 클라이언트에서 자주 요청받는 내용은 웹 서버로 전달하지 않고 웹 서버 앞단의 프록시 서버에서 캐싱해둔 데이터를 바로 제공하기도 한다(프록시 캐시)
* 브라우저 캐시
    * 웹 서버에서 클라이언트에 보내느 HTTP 헤더에 캐시 지시자를 삽입하면 클라언트 웹 브라우저에서는 해당 지시자에 명시된 캐시 정책에 따라 캐싱을 실시한다
    * 캐시의 유효기간이 지나도 캐시된 데이터가 바뀌지 않은 경우를 확인하기 위해 ETag라는 유효성 검사 토큰을 사용한다
    * 때로는 캐시 유효 시간을 최대한 길게 잡으면서도 정적 파일의 업데이트를 신속히 적용하기 위해 정적 파일의 이름 뒤에 별도의 토큰이나 버전 번호를 붙여야 하는 경우도 있다
    * 캐시 정책은 해당 웹페이지의 전반적인 상황에 따라 각 파일마다 다르게 적용되어야 한다
        * 적어도 정적 파일과 동적 부분의 브라우저 캐시 정책은 달라야 한다.
        * 비공개 정보가 담긴 페이지는 보안상 아예 캐싱을 막아야 할 수도 있다.

## Redis
* 메모리 기반 오픈소스 NoSQL DBMS의 일종으로 웹 서비스에서 캐싱을 위해 많이들 쓴다
* Redis라는 이름은 Remote Dictionary Server의 약자이다
* 여기서 Dictionary는 JAVA의 HashMap을 생각하면 된다
* 기본적으로 모든 데이터를 메모리에 저장하여 처리하므로 속도가 빠르다
* 서버 재부팅 떄 메모리의 데이터가 휘발하지 않게끔 데이터를 하드디스크에 기록할 수 있따
* DBMS의 일종이므로 명시적으로 샂게하지 않는 한 메모리에서 데이터를 삭제하지 않는다
* 자체적으로 여러가지 자료형을 지원한다.

## EHache
* 자바의 표준 캐싱 API 명세인 JSR-107을 따르는 오픈소스 캐시 구현체
* 스프링 프레임워크나 Hibernate ORM 등에서 바로 사용 가능
* 자바 진영에서 가장 널리 쓰임
* 캐시 저장공간을 속도에 따라 여러 등급으로 나누어 메모리 계층 구조를 적용 가능
* 메모리에 캐시된 내용을 하드디스크에 기록 가능
* 대규모 서비스에서 캐시 서버 여럿을 클러스터로 묶을 수 있는 기능을 제공

### Cache Organization
* 캐시는 반응 속도가 빠른 SRAM(Static Random Access Memory)으로, 주소가 키(Key)로 주어지면 해당 공간에 즉시 접근할 수 있다. 이러한 특성은 DRAM(Dynamic Random Access Meomry)에서도 동일하지만 하드웨어 설계상 DRAM은 SRAM보다 느리다. 통상적으로 '메인 메모리’라고 말할 때는 DRAM을 의미한다.
* 주소가 키로 주어졌을 때 그 공간에 즉시 접근할 수 있다는 것은 캐시가 하드웨어로 구현한 해시 테이블(Hash table)과 같다 의미다. 캐시가 빠른 이유는 자주 사용하는 데이터만을 담아두기 때문이기도 하지만, 해시 테이블의 시간 복잡도가 O(1) 정도로 빠르기 때문이기도 하다.
* 캐시는 블록(Block)으로 구성되어 있다. 각각의 블록은 데이터를 담고 있으며, 주소값을 키로써 접근할 수 있다. 블록의 개수(Blocks)와 블록의 크기(Block size)가 캐시의 크기를 결정한다.

### 캐시 블로그
* [박성범](https://parksb.github.io/article/29.html?utm_source=gaerae.com&utm_campaign=%EA%B0%9C%EB%B0%9C%EC%9E%90%EC%8A%A4%EB%9F%BD%EB%8B%A4&utm_medium=social)

## 레지스터
* CPU 내의 처리에 필요한 명령이나 연산의 중간 결과 값 등을 일시적으로 기억하는 고속 메모리
* PC, MAR, MBR, Decoder, Encoder

## IO 장치가 시스템 버스에 직접 접속되지 못하는 이유
* 종류에 따라 제어 방법이 서로 다른 I/O 장치들의 제어 회로들을 CPU 내부에 모두 포함시키는 것이 어려워 CPU가 그들을 직접 제어할 숭 ㅓㅄ기 때문이다.(CPU도 채널로 하여금 관리)
* I/O 장치들의 데이터 전송 속도가 CPU의 데이터 처리 속도에 비해 훨씬 느려 CPU도 채널을 붙임
* I/O 장치들과 CPU가 사용하는 데이터의 형식ㅇ의 깅리가 서로 다른 경우가 많다.

# 캐시
- CPU 칩 안에 들어가는 작고 빠른 메모리이다. 
- =>  프로세서가 매번 메인 메모리에 접근해 데이터를 받아오면 시간이 오래 걸리기 때문에 캐시에 자주 사용하는 데이터를 담아두고, 해당 데이터가 필요할 때 프로세서가 메인 메모리 대신 캐싱[ 접근하도록해 처리 속도를 높인다. 

## 시간 지역성/ 공간 지역성

- 자주 사용하는 데이터 판단은 지역성의 원리를 따름. 지역성의 원리는 시간 지역성과 공간 지역성으로 구분해서 볼 수 있다.
- 시간 지역성은 최근 접근한 데이터에 다시 접근하는 경향을 말한다. 가령 루프에서 인덱스 역할을 하는 변수 i에는 짧은 시간안에 여러 번 접근이 이뤄진다. 
- 공간 지역성은 최근 접근한 데이터의 주변 공간에 다시 접근하는 경향을 말함.
- 한 프로세스에도 자주 사용하는 부분과 그렇지 않은 부분이 있기 때문에 운영체제는 프로세스를 페이지라는 단위로 나눠 관리한다. 페이지에 접근할 때도 지역성 원리가 적용된다.

법이 

## 캐시메모리
* 시간적, 공간적 지역성을 기반으로 가까운 미래에 접근될 확률이 높은 데이터를 작지만 빠른 캐시 메모리에 미리 보관하여 전체적인 시스템의 성능을 높인다.
* 메인 메모리(램)보다 훨씬 빠르지만 용량이 작아 중요한 것들이 들어가야 함
* 캐시 메모리 저장 규칙
  1. 최근에 접근된 데이터; Tempoary Locality - 시간적 지연성
  2. 최근에 접근된 데이터의 주변 데이터; Spatial Locality - 공간적 지연성
* 사용하는 곳: 파일 시스템, OS, 구글 크롬, FM, CPU 안에서도 3단계로 나눔
