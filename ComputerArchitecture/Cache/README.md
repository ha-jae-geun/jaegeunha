
## 캐시
* 오늘날 CPU 칩의 면적 30~70%는 캐시가 차지한다. 1989년 생산된 싱글 코어 프로세서인 i486의 경우 8KB짜리 I/D 캐시 하나만 있었다. 한편 인텔 코어 i7 쿼드 코어 칩의 다이 맵(Die map)을 보면 4개의 코어에 각각 256KB L2 캐시가 있고, 모든 코어가 공유하는 8MB L3 캐시가 있는 것을 볼 수 있다. (L2 캐시 위에 있는 구역이 L1 캐시로 보이는데, 확실하지 않아서 따로 표시하지 않았다.)
* CPU 칩에는 여러 개의 캐시가 들어가며, 각각의 캐시는 각자의 목적과 역할을 가지고 있다.

### 캐시 종류
* L1 Cache: 프로세서와 가장 가까운 캐시. 속도를 위해 I$와 D$로 나뉜다.
* Instruction Cache (I$): 메모리의 TEXT 영역 데이터를 다루는 캐시.
* Data Cache (D$): TEXT 영역을 제외한 모든 데이터를 다루는 캐시.
* L2 Cache: 용량이 큰 캐시. 크기를 위해 L1 캐시처럼 나누지 않는다.
* L3 Cache: 멀티 코어 시스템에서 여러 코어가 공유하는 캐시.
* 캐시에 달러 기호($)를 사용하는 이유는 캐시(Cache)의 발음이 현금을 뜻하는 'Cash’와 같기 때문이다 :)

### Cache Metrics
* 캐시의 성능을 측정할 때는 히트 레이턴시(Hit latency)와 미스 레이턴시(Miss latency)가 중요한 요인으로 꼽힌다.
* CPU에서 요청한 데이터가 캐시에 존재하는 경우를 캐시 히트(Hit)라고 한다. 히트 레이턴시는 히트가 발생해 캐싱된 데이터를 가져올 때 소요되는 시간을 의미한다. 반면 요청한 데이터가 캐시에 존재하지 않는 경우를 캐시 미스(Miss)라고 하며, 미스 레이턴시는 미스가 발생해 상위 캐시에서 데이터를 가져오거나(L1 캐시에 데이터가 없어서 L2 캐시에서 데이터를 찾는 경우) 메모리에서 데이터를 가져올 때 소요되는 시간을 말한다.
* 캐시의 성능을 높이기 위해서는 캐시의 크기를 줄여 히트 레이턴시를 줄이거나, 캐시의 크기를 늘려 미스 비율을 줄이거나, 더 빠른 캐시를 이용해 레이턴시를 줄이는 방법이 있다.


### Cache Organization
* 캐시는 반응 속도가 빠른 SRAM(Static Random Access Memory)으로, 주소가 키(Key)로 주어지면 해당 공간에 즉시 접근할 수 있다. 이러한 특성은 DRAM(Dynamic Random Access Meomry)에서도 동일하지만 하드웨어 설계상 DRAM은 SRAM보다 느리다. 통상적으로 '메인 메모리’라고 말할 때는 DRAM을 의미한다.
* 주소가 키로 주어졌을 때 그 공간에 즉시 접근할 수 있다는 것은 캐시가 하드웨어로 구현한 해시 테이블(Hash table)과 같다 의미다. 캐시가 빠른 이유는 자주 사용하는 데이터만을 담아두기 때문이기도 하지만, 해시 테이블의 시간 복잡도가 O(1) 정도로 빠르기 때문이기도 하다.
* 캐시는 블록(Block)으로 구성되어 있다. 각각의 블록은 데이터를 담고 있으며, 주소값을 키로써 접근할 수 있다. 블록의 개수(Blocks)와 블록의 크기(Block size)가 캐시의 크기를 결정한다.

### 캐시 블로그
* [박성범](https://parksb.github.io/article/29.html?utm_source=gaerae.com&utm_campaign=%EA%B0%9C%EB%B0%9C%EC%9E%90%EC%8A%A4%EB%9F%BD%EB%8B%A4&utm_medium=social)

## 레지스터
* CPU 내의 처리에 필요한 명령이나 연산의 중간 결과 값 등을 일시적으로 기억하는 고속 메모리
* PC, MAR, MBR, Decoder, Encoder

## IO 장치가 시스템 버스에 직접 접속되지 못하는 이유
* 종류에 따라 제어 방법이 서로 다른 I/O 장치들의 제어 회로들을 CPU 내부에 모두 포함시키는 것이 어려워 CPU가 그들을 직접 제어할 숭 ㅓㅄ기 때문이다.(CPU도 채널로 하여금 관리)
* I/O 장치들의 데이터 전송 속도가 CPU의 데이터 처리 속도에 비해 훨씬 느려 CPU도 채널을 붙임
* I/O 장치들과 CPU가 사용하는 데이터의 형식ㅇ의 깅리가 서로 다른 경우가 많다.

# 캐시
- CPU 칩 안에 들어가는 작고 빠른 메모리이다. 
- =>  프로세서가 매번 메인 메모리에 접근해 데이터를 받아오면 시간이 오래 걸리기 때문에 캐시에 자주 사용하는 데이터를 담아두고, 해당 데이터가 필요할 때 프로세서가 메인 메모리 대신 캐싱[ 접근하도록해 처리 속도를 높인다. 

## 시간 지역성/ 공간 지역성

- 자주 사용하는 데이터 판단은 지역성의 원리를 따름. 지역성의 원리는 시간 지역성과 공간 지역성으로 구분해서 볼 수 있다.
- 시간 지역성은 최근 접근한 데이터에 다시 접근하는 경향을 말한다. 가령 루프에서 인덱스 역할을 하는 변수 i에는 짧은 시간안에 여러 번 접근이 이뤄진다. 
- 공간 지역성은 최근 접근한 데이터의 주변 공간에 다시 접근하는 경향을 말함.
- 한 프로세스에도 자주 사용하는 부분과 그렇지 않은 부분이 있기 때문에 운영체제는 프로세스를 페이지라는 단위로 나눠 관리한다. 페이지에 접근할 때도 지역성 원리가 적용된다.

법이 

## 캐시메모리
* 시간적, 공간적 지역성을 기반으로 가까운 미래에 접근될 확률이 높은 데이터를 작지만 빠른 캐시 메모리에 미리 보관하여 전체적인 시스템의 성능을 높인다.
* 메인 메모리(램)보다 훨씬 빠르지만 용량이 작아 중요한 것들이 들어가야 함
* 캐시 메모리 저장 규칙
  1. 최근에 접근된 데이터; Tempoary Locality - 시간적 지연성
  2. 최근에 접근된 데이터의 주변 데이터; Spatial Locality - 공간적 지연성
* 사용하는 곳: 파일 시스템, OS, 구글 크롬, FM, CPU 안에서도 3단계로 나눔
